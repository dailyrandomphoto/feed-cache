<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>DEV Community</title>
    <author>DEV Community</author>
    <description>A constructive and inclusive social network for software developers. With you every step of your journey.</description>
    <link>https://dev.to</link>
    <language>en</language>
    <item>
      <title>OpenTelemetry tracing - things you need to know before implementing üòé</title>
      <author>Ankit Anand ‚ú®</author>
      <pubDate>Tue, 07 Sep 2021 12:54:41 +0000</pubDate>
      <link>https://dev.to/signoz/opentelemetry-tracing-things-you-need-to-know-before-implementing-57bd</link>
      <guid>https://dev.to/signoz/opentelemetry-tracing-things-you-need-to-know-before-implementing-57bd</guid>
      <description>&lt;p&gt;Setting up observability and robust monitoring for distributed systems is a challenging task. Engineering teams need access to different pieces of information to understand what's happening with their application. Is OpenTelemetry a step in the right direction for distributed tracing? Let's find out.&lt;/p&gt;




&lt;p&gt;Nothing can guarantee how your systems will behave in production. Things will go wrong, and it's critical to monitor your application for any signs that need troubleshooting. A robust monitoring and observability framework requires telemetry data - logs, metrics and traces.&lt;/p&gt;

&lt;p&gt;OpenTelemetry aims to standardize the creation and management of telemetry data. It can fit within any application's architecture and generate telemetry data with little to no overhead.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--5VoP5KQk--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pd9g24jdq62tqr7grvmm.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--5VoP5KQk--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pd9g24jdq62tqr7grvmm.png" alt="OpenTelemetry Architecture"&gt;&lt;/a&gt;OpenTelemetry architecture - client libraries instrument application code to send telemetry data to a collector agent which then exports the data to a backend analysis tool.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#why-is-distributed-tracing-needed"&gt;
  &lt;/a&gt;
  Why is distributed tracing needed?
&lt;/h2&gt;

&lt;p&gt;In microservices architecture, often engineering teams are responsible for just one service and it becomes a nightmare to troubleshoot issues without an overview. Correlating logs and metrics is challenging with a lot of manual effort.&lt;/p&gt;

&lt;p&gt;That's where distributed tracing comes into the picture. User requests are broken down into spans.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What are spans?&lt;br&gt;&lt;br&gt;
Spans represent a single operation within a trace.&lt;br&gt;
It represents work done by a single service which can be broken down further depending on the use case.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A trace context is passed along when requests travel between services, which tracks a user request across services. You can see how a user request performs across services and identify what exactly needs your attention without manually shifting through multiple dashboards.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--o5eUzX9m--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vdn2hqbptnhj6c2ny3hl.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--o5eUzX9m--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vdn2hqbptnhj6c2ny3hl.png" alt="OpenTelemetry tracing uses trace context to track user request across services"&gt;&lt;/a&gt;A trace context is passed when user requests passes from one service to another&lt;/p&gt;

&lt;p&gt;Using OpenTelemetry you can encapsulate several pieces of information with a span. Common information includes &lt;strong&gt;the name of the operation, start and end timestamp, events occurring during the span&lt;/strong&gt;. You can also add custom attributes with key/value pairs to enable more insights if needed.&lt;/p&gt;

&lt;p&gt;In the picture below, you can see the details for the selected span.¬†&lt;a href="https://signoz.io/"&gt;SigNoz&lt;/a&gt;¬†is a lightweight open-source APM tool based on OpenTelemetry, which can be used as an analysis tool.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--eebdGylr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/y55hdd4dbp7lwo7h09d8.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--eebdGylr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/y55hdd4dbp7lwo7h09d8.png" alt="Attributes can be added to spans for more context"&gt;&lt;/a&gt;SigNoz is a lightweight APM tool based on OpenTelemetry. it provides out of box visualization for traces and metrics.&lt;/p&gt;

&lt;p&gt;When the user request finishes operation in one of the services and travels to another one, a trace ID is passed along, unique for every request. This way, you can correlate information about your requests easily across your entire architecture.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#what-is-opentelemetry"&gt;
  &lt;/a&gt;
  What is OpenTelemetry?
&lt;/h2&gt;

&lt;p&gt;OpenTelemetry is a set of APIs, SDKs, libraries, and integrations that is aiming to standardize the generation, collection, and management of telemetry data(logs, metrics, and traces). OpenTelemetry is a Cloud Native Computing Foundation project created after the merger of OpenCensus(from Google) and OpenTracing(from Uber).&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#five-things-to-know-about-opentelemetry"&gt;
  &lt;/a&gt;
  Five things to know about OpenTelemetry
&lt;/h2&gt;

&lt;p&gt;Now that you understand a little bit about both OpenTelemetry and distributed tracing, let us see a list of things you must know about OpenTelemetry tracing:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Backed by major cloud vendors&lt;/strong&gt;&lt;br&gt;&lt;br&gt;
OpenTelemetry is an open-source project under Cloud Native Computing Foundation backed by major cloud providers like Microsoft and Google. As such, it has a wide community support as well as support by most APM and observability vendors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Reduced overhead for telemetry data&lt;/strong&gt;&lt;br&gt;&lt;br&gt;
OpenTelemetry reduces overhead from your application to create and manage telemetry data. Your application is decoupled from OpenTelemetry implementation as OpenTelemetry provides an API to interact with. Telemetry is collected by otel-collectors which can receive, process and export data in multiple data formats.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenTelemetry Tracing API is stable&lt;/strong&gt;&lt;br&gt;&lt;br&gt;
OpenTelemetry has stable tracing API release in Java, .NET, Javascript, Python, and Erlang.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Vendor-agnostic data formats&lt;/strong&gt;&lt;br&gt;&lt;br&gt;
OpenTelemetry provides an otel-collector that can be used to receive trace data in multiple formats. Otel-collector also provides processors and exporters using which you can choose to export the collected data in your required format.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Easy set-up and implementation&lt;/strong&gt;&lt;br&gt;&lt;br&gt;
OpenTelemetry libraries come with default support for tracing. You just need to configure OpenTelemetry collectors via a config file to collect traces data in the format you prefer.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;
  &lt;a href="#steps-involved-in-implementing-opentelemetry-tracing"&gt;
  &lt;/a&gt;
  Steps involved in implementing OpenTelemetry tracing&lt;br&gt;
&lt;/h2&gt;

&lt;p&gt;OpenTelemetry provides auto-instrumentation libraries in multiple languages. With auto-instrumentation, you can get started with tracing without making any changes to your code.&lt;/p&gt;

&lt;p&gt;For example &lt;a href="https://signoz.io/opentelemetry/java-agent/"&gt;OpenTelemetry Java JAR agent&lt;/a&gt; can detect a number of popular libraries and frameworks and instrument it right out of the box for generating telemetry data.&lt;/p&gt;

&lt;p&gt;You can also instrument your code manually to have more business specific context. Let's look at the steps involved in tracing code using OpenTelemetry API:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;strong&gt;Get a &lt;code&gt;Tracer&lt;/code&gt;&lt;/strong&gt; 
The first step is to acquire a &lt;code&gt;Tracer&lt;/code&gt;. The &lt;code&gt;Tracer&lt;/code&gt; is responsible for creating spans.
&lt;/li&gt;
&lt;/ol&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;   &lt;span class="nx"&gt;Tracer&lt;/span&gt; &lt;span class="nx"&gt;tracer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;
    &lt;span class="nx"&gt;openTelemetry&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;getTracer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;instrumentation-library-name&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;1.0.0&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;ol&gt;
&lt;li&gt;
&lt;strong&gt;Create a span&lt;/strong&gt;
Creating a span only involves naming it. The start and end time is managed by the OpenTelemetry SDK.
&lt;/li&gt;
&lt;/ol&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;   &lt;span class="nx"&gt;Span&lt;/span&gt; &lt;span class="nx"&gt;span&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;tracer&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;spanBuilder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;my span&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;startSpan&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
   &lt;span class="c1"&gt;// put the span into the current Context&lt;/span&gt;
   &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;Scope&lt;/span&gt; &lt;span class="nx"&gt;scope&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;span&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;makeCurrent&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="c1"&gt;// your use case&lt;/span&gt;
    &lt;span class="p"&gt;...&lt;/span&gt;
   &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;Throwable&lt;/span&gt; &lt;span class="nx"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;span&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;setStatus&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;StatusCode&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ERROR&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;Change it to your error message&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
   &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;finally&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;span&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;end&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;// closing the scope does not end the span, this has to be done manually&lt;/span&gt;
   &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;ol&gt;
&lt;li&gt;
&lt;strong&gt;Create nested spans&lt;/strong&gt;
There can be multiple logical operations inside a service for which you might want to measure things like duration or custom attributes. OpenTelemetry supports tracing within processes. Example of a method &lt;code&gt;A&lt;/code&gt; calling method &lt;code&gt;B&lt;/code&gt; where spans are linked manually:
&lt;/li&gt;
&lt;/ol&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;   &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="nx"&gt;parentOne&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="nx"&gt;Span&lt;/span&gt; &lt;span class="nx"&gt;parentSpan&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;tracer&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;spanBuilder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;parent&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;startSpan&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
   &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;childOne&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;parentSpan&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
   &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;finally&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;parentSpan&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;end&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
     &lt;span class="p"&gt;}&lt;/span&gt;
   &lt;span class="p"&gt;}&lt;/span&gt;

   &lt;span class="k"&gt;void&lt;/span&gt; &lt;span class="nx"&gt;childOne&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;Span&lt;/span&gt; &lt;span class="nx"&gt;parentSpan&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="nx"&gt;Span&lt;/span&gt; &lt;span class="nx"&gt;childSpan&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;tracer&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;spanBuilder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;child&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;setParent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;Context&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;current&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="kd"&gt;with&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;parentSpan&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;startSpan&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
   &lt;span class="c1"&gt;// do stuff&lt;/span&gt;
   &lt;span class="nx"&gt;childSpan&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;end&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
   &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;ol&gt;
&lt;li&gt;
&lt;strong&gt;Add span attributes&lt;/strong&gt;
With OpenTelemetry, you can add attributes on span to get additional context. Attributes provide additional context on the specific operation it tracks.
&lt;/li&gt;
&lt;/ol&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;   &lt;span class="nx"&gt;Span&lt;/span&gt; &lt;span class="nx"&gt;span&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;tracer&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;spanBuilder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;/resource/path&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;setSpanKind&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;SpanKind&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;CLIENT&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;startSpan&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
   &lt;span class="nx"&gt;span&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;setAttribute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;http.method&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;GET&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
   &lt;span class="nx"&gt;span&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;setAttribute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;http.url&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;url&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;toString&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;ol&gt;
&lt;li&gt;
&lt;strong&gt;Context propagation&lt;/strong&gt;
OpenTelemetry context propagation is based on &lt;a href="https://www.w3.org/TR/trace-context/" rel="noopener noreferrer nofollow"&gt;W3C Trace Context&lt;/a&gt; HTTP headers. The W3C trace context specification defines standard HTTP headers to propagate context information that enables distributed tracing.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;
  &lt;a href="#how-to-get-started-with-opentelemetry-tracing"&gt;
  &lt;/a&gt;
  How to get started with OpenTelemetry tracing?
&lt;/h2&gt;

&lt;p&gt;OpenTelemetry is becoming the world standard for instrumenting application code due to its multi-language support and ease of use. But OpenTelemetry helps only to generate and collect telemetry data. You need to export the telemetry data to a backend analysis tool so that your teams can store, query, and visualize the collected data.&lt;/p&gt;

&lt;p&gt;And that's where¬†&lt;a href="https://signoz.io/"&gt;SigNoz&lt;/a&gt;¬†comes into the picture. SigNoz uses OpenTelemetry natively to instrument application codes. OpenTelemetry collector then sends the data to the SigNoz backend, where users have the option to choose between ClickHouse or Kafka+Druid as their telemetry data storage option.&lt;/p&gt;

&lt;p&gt;SigNoz comes with out of box visualization of things like RED metrics. There is a unified UI of metrics and traces, unlike Prometheus, so that you can easily identify the root cause of issues causing things like latency in your apps.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--8fEE-jnY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/azk0yga369uv5nl8aw1c.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--8fEE-jnY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/azk0yga369uv5nl8aw1c.png" alt="SigNoz dashboard showing the popular RED metrics for application performance monitoring."&gt;&lt;/a&gt;Measure things like application latency, requests per sec, error percentage and see your top endpoints&lt;/p&gt;

&lt;p&gt;You can check out SigNoz's GitHub repo here üëá&lt;/p&gt;

&lt;p&gt;&lt;a href="https://bit.ly/2WkkmL4"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--od2lB_mG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8yroh39ngk6sz6tv3z9y.png" alt="SigNoz GitHub repo"&gt;&lt;/a&gt;&lt;/p&gt;

</description>
    </item>
    <item>
      <title>Today's Daily Dose of Programming Humor</title>
      <author>Daily Developer Jokes</author>
      <pubDate>Tue, 07 Sep 2021 12:00:12 +0000</pubDate>
      <link>https://dev.to/dailydeveloperjokes/today-s-daily-dose-of-programming-humor-2n45</link>
      <guid>https://dev.to/dailydeveloperjokes/today-s-daily-dose-of-programming-humor-2n45</guid>
      <description>&lt;p&gt;Hi there! Here's today's Daily Developer Joke. We hope you enjoy it; it's a good one.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--xt3ZgXuG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://private.xtrp.io/projects/DailyDeveloperJokes/public_image_server/images/5e1259427b3da.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--xt3ZgXuG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://private.xtrp.io/projects/DailyDeveloperJokes/public_image_server/images/5e1259427b3da.png" alt="Joke Image"&gt;&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;For more jokes, and to submit your own joke to get featured, check out the &lt;a href="https://dailydeveloperjokes.github.io/"&gt;Daily Developer Jokes Website&lt;/a&gt;. We're also open sourced, so feel free to view &lt;a href="https://github.com/dailydeveloperjokes"&gt;our GitHub Profile&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#leave-this-post-a-if-you-liked-todays-joke-and-stay-tuned-for-tomorrows-joke-too"&gt;
  &lt;/a&gt;
  Leave this post a ‚ù§Ô∏è if you liked today's joke, and stay tuned for tomorrow's joke too!
&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;This joke comes from &lt;a href="https://github.com/wesbos/dad-jokes"&gt;Dad-Jokes GitHub Repo by Wes Bos&lt;/a&gt; (thank you!), whose owner has given me permission to use this joke with credit.&lt;/em&gt;&lt;/p&gt;

</description>
      <category>jokes</category>
      <category>dailydeveloperjokes</category>
    </item>
    <item>
      <title>Is Node.js Single-Threaded or Multi-Threaded? and Why?</title>
      <author>Andres Reales</author>
      <pubDate>Tue, 07 Sep 2021 11:39:13 +0000</pubDate>
      <link>https://dev.to/arealesramirez/is-node-js-single-threaded-or-multi-threaded-and-why-ab1</link>
      <guid>https://dev.to/arealesramirez/is-node-js-single-threaded-or-multi-threaded-and-why-ab1</guid>
      <description>&lt;p&gt;Have you been reading multiple articles trying to understand whether Node.js is single-threaded or multi-threaded? Why are there many of them saying single-threaded and others saying multi-threaded? I‚Äôve been there and after reading one article after another, it seems there‚Äôs always a doubt in the back of your mind telling you the concept is still not clear. In this article, I hope to clarify this confusion.&lt;/p&gt;

&lt;p&gt;According to &lt;a href="https://nodejs.dev/learn"&gt;Node.js documentation&lt;/a&gt;, a Node.js application runs using the event loop. The event loop is what allows Node.js to perform non-blocking I/O operations and explains how Node.js can be asynchronous. The event loop, aka the main thread, allows running one thing at a time. Having said that, &lt;strong&gt;Node.js JavaScript code runs on a single thread&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Now, there are several points you have probably read about in different articles such as using &lt;strong&gt;worker_threads&lt;/strong&gt; making it multi-threaded, or the programming language used to develop Node.js applications makes it single-threaded, etc. I will cover those relevant points, but before we move forward, I‚Äôll refresh your knowledge with regards to what single and multi-thread processes are.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#what-a-singlethreaded-process-is"&gt;
  &lt;/a&gt;
  What a Single-Threaded Process is
&lt;/h2&gt;

&lt;p&gt;A single-threaded process is the execution of programmed instructions in a single sequence. Having said that, if an application has the following set of instructions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Instruction A&lt;/li&gt;
&lt;li&gt;Instruction B&lt;/li&gt;
&lt;li&gt;Instruction C&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If these set of instructions are executed in a single-threaded process, the execution would look like the following:&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Dp5YTWtO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vsf84myna0sp2rahh8uj.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Dp5YTWtO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vsf84myna0sp2rahh8uj.png" alt="Single Thread"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#what-a-multithreaded-process-is"&gt;
  &lt;/a&gt;
  What a Multi-Threaded Process is
&lt;/h2&gt;

&lt;p&gt;A multi-threaded process is the execution of programmed instructions in multiple sequences. Therefore, instructions won‚Äôt have to wait to execute unless multiple instructions are grouped within different sequences.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--avQGVjRD--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/zsyg6r77mt4h0n8ql5a6.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--avQGVjRD--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/zsyg6r77mt4h0n8ql5a6.png" alt="Multi thread"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#why-nodejs-is-singlethreaded"&gt;
  &lt;/a&gt;
  Why Node.js is Single-Threaded?
&lt;/h2&gt;

&lt;p&gt;Now you know Node.js architecture is single-threaded. However, why is it single-threaded? My first question for you is, do you understand how the event loop works? If not, I recommend you &lt;a href="https://nodejs.dev/learn/the-nodejs-event-loop"&gt;check this article&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;However, to keep things simple, the event loop runs one process at a time. That means it can only execute one function at a time, and since functions can have multiple instructions, the event loop will execute one instruction at a time.&lt;/p&gt;

&lt;p&gt;At first, it sounds not efficient providing poor performance. However, quite the opposite it turns out to be more performant and scalable than other multithreaded alternatives such as Java.&lt;/p&gt;

&lt;p&gt;Running a multithreaded solution involves leveraging multiple cores of a system. Having said that, if one thread is waiting for an I/O response, the other threads could still be in progress. In theory, multithread seems the way to go, but what we are not taking into consideration is that a thread could still be blocked regardless of other threads being available.&lt;/p&gt;

&lt;p&gt;The beauty of the event loop is not of running everything in a single thread, but it‚Äôs available to ‚Äúput aside‚Äù long time-consuming I/O operations to keep the execution of other instructions. This is the reason why we get fast responses even though we could have multiple users making requests to a Node.js API at the same time.&lt;/p&gt;

&lt;p&gt;The first thing to clarify is there is no such thing as making requests at the same time. It is perceived to have run requests at the same time, but in reality, the event loop runs processes defined for each request based on the order in which it arrived. Let‚Äôs make this concept simple to understand by using an example. In this case, we are going to assume we have the following API endpoints:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;/getCars&lt;/li&gt;
&lt;li&gt;/updateCar&lt;/li&gt;
&lt;li&gt;/updateDriver&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Remember, request are not made at the same time. The event loop will handle the requests in the following order assuming that was the order they were requested:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;/getCars&lt;/li&gt;
&lt;li&gt;/updateCar&lt;/li&gt;
&lt;li&gt;/updateDriver&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The event loop will execute the first instructions from the /getCars endpoint. At some point, there will be an instruction which is a request from the API to a database to fetch the cars. This is considered an I/O operation. This process can take a short or long time to execute. Regardless of how fast this gets executed. The event loop will trigger this request and move it ‚Äúaside‚Äù to prevent blocking the thread from executing other instructions. However, it will resume triggering the set of instructions for the /getCars endpoint once a response is sent back from the database.&lt;/p&gt;

&lt;p&gt;Therefore, while the request made from the /getCars endpoint to the database is triggered and waiting for a response, the /updateCar endpoint will trigger its set of instructions. If there is not I/O operation within the /updateCar endpoint, the /updateCar endpoint will return a response before the /getCars endpoint returns a response.&lt;/p&gt;

&lt;p&gt;In a similar way, if the /updateCar endpoints have an instruction to execute an I/O operation, the event loop will trigger it but won‚Äôt block the thread from executing instructions. In this way, it could either start executing the set of instructions from the /updateDriver endpoint, or resume the execution of the /getCars endpoint once it receives a response from the database. This is based on whichever is added first in the event queue.&lt;/p&gt;

&lt;p&gt;If you think about it, the major benefit of Node.js architecture is not the fact of being single-threaded, but its ability to not block the thread from executing other instructions. This is one of the main reasons Node.js is an excellent choice for developing APIs as these are heavily based on I/O operations. The event loop‚Äôs smart system to execute intensive I/O operations and resume processes once the I/O operations are completed while not worrying about issues that can come with using multithreaded solutions such as deadlocks or race conditions makes it a no brainer for many teams to use Node.js.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#dont-block-the-event-loop-aka-the-main-thread"&gt;
  &lt;/a&gt;
  Don‚Äôt Block the Event Loop (aka the Main Thread)
&lt;/h2&gt;

&lt;p&gt;Like most solutions, there are advantages and disadvantages, and Node.js is not an exclusion of this. Since we know Node.js runs using the event loop, aka as the main thread, blocking the loop will indeed prevent the system from running other instructions regardless of whether they belong to a single process or multiple different processes.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Didn‚Äôt you say the event loop ‚Äútriggers intensive operations and move them aside, resuming a process once the operations get a response‚Äù?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Yes.&lt;/p&gt;

&lt;p&gt;However, it is important to clarify the event loop‚Äôs ability to ‚Äúresume‚Äù an I/O operation process doesn‚Äôt mean it will be capable of getting away around with an intensive CPU operation. The beauty of an I/O operation is to use external CPU processing power to execute a process. However, &lt;strong&gt;if our Node.js application is the one using intensive CPU processing power to execute power, it means we cannot execute other sets of instructions until the heavy processing power instruction completes. This is called blocking the event loop&lt;/strong&gt;.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#confusing-javascript-and-nodejs-threading-process"&gt;
  &lt;/a&gt;
  Confusing JavaScript and Node.js Threading Process
&lt;/h2&gt;

&lt;p&gt;It is important to not say Node.js is single-threaded because the JavaScript programming language is single-threaded. This is incorrect. JavaScript can run in different programming environments, and Node.js being among the most popular environments using JavaScript. Therefore, it is a common misconception to think JavaScript is single-threaded. When speaking about single-threaded or multi-threaded, we should look at how the programming environment operates rather than how the language in itself.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#what-about-worker-threads-in-nodejs-does-it-make-nodejs-multithreaded"&gt;
  &lt;/a&gt;
  What About Worker Threads in Node.js? Does it Make Node.js Multi-threaded?
&lt;/h2&gt;

&lt;p&gt;While the implementation of worker threads in v10.5.0 allows the use of threads that execute JavaScript in parallel, Node.js event loop architecture is single-threaded based.&lt;/p&gt;

&lt;p&gt;What really happens when spawning multiple threads using &lt;strong&gt;worker_threads&lt;/strong&gt; is the generation of multiple V8 engines sharing memory. Workers threads are useful for performing CPU-intensive JavaScript operations. This frees up the main thread‚Äôs event loop from CPU-heavy processes and keeps it available for what is best for intensive I/O operations.&lt;/p&gt;

&lt;p&gt;The expense of generating worker threads doesn‚Äôt result in a positive impact around I/O intensive work as in the end, each thread will have the same mechanism: one event loop per thread, which won‚Äôt be any different than opting not to use worker threads. Node.js‚Äôs built-in asynchronous I/O operations are more efficient than workers can be.&lt;/p&gt;

&lt;p&gt;Having said that, each thread will use the same Node.js architecture which is single-threaded based. You can achieve multithreading by generating multiple nodes or Node.js V8 engines which in isolation are single-threaded. It is still correct to say Node.js is not multi-threaded.&lt;/p&gt;

</description>
      <category>node</category>
      <category>javascript</category>
      <category>webdev</category>
      <category>programming</category>
    </item>
    <item>
      <title>Simple Log in form using pure css </title>
      <author>Shubham Jadhav</author>
      <pubDate>Tue, 07 Sep 2021 11:10:27 +0000</pubDate>
      <link>https://dev.to/dev_shubham/simple-log-in-form-using-pure-css-3o3l</link>
      <guid>https://dev.to/dev_shubham/simple-log-in-form-using-pure-css-3o3l</guid>
      <description>&lt;p&gt;How to build login form in html and using pure css in few lines of codes. Let's make today login form using pure css. &lt;/p&gt;

&lt;p&gt;1.First we need a code editor, &lt;br&gt;
  I am using VS code editor. &lt;br&gt;
2.Let's make index.html and &lt;br&gt;
  style.css file in our &lt;br&gt;
  working folder. &lt;br&gt;
3.Let's add following code in y our editor.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Q_5KXayw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/xe5tdae34iawf9x0j5pn.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Q_5KXayw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/xe5tdae34iawf9x0j5pn.jpg" alt="reset code"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;4.Now,time to work on style &lt;br&gt;
  file. &lt;br&gt;
5.First, reset all auto margin &lt;br&gt;
  and padding of browser.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--WcpTFfhO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/a2pus2sk1pafrkhajoft.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--WcpTFfhO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/a2pus2sk1pafrkhajoft.jpg" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
6.Let's work on wrapper class &lt;br&gt;
  style,add following code in &lt;br&gt;
  css file. &lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--xrVfGRUH--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/tku05owjm34ig66wrq0v.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--xrVfGRUH--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/tku05owjm34ig66wrq0v.jpg" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
7.Now add style on inside &lt;br&gt;
  wrapper class elements, I &lt;br&gt;
  did it and code is below&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--xrVfGRUH--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/tku05owjm34ig66wrq0v.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--xrVfGRUH--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/tku05owjm34ig66wrq0v.jpg" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
8.Now add some css hover effects to our code, let's add following code&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--rSG9uqjo--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pciuokgaaeewuc45ig8o.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--rSG9uqjo--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pciuokgaaeewuc45ig8o.jpg" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here, our simple login form is ready &lt;br&gt;
üôè Thank you for reading&lt;br&gt;
üôè Share your feedback for &lt;br&gt;
   more improvement&lt;br&gt;
üëç Like the article &lt;/p&gt;

</description>
      <category>html</category>
      <category>css</category>
      <category>purecss</category>
      <category>css3</category>
    </item>
    <item>
      <title>2 Questions to Ask Before Choosing a Python Framework</title>
      <author>Profil Software</author>
      <pubDate>Tue, 07 Sep 2021 11:10:13 +0000</pubDate>
      <link>https://dev.to/profilsoftware/2-questions-to-ask-before-choosing-a-python-framework-1l99</link>
      <guid>https://dev.to/profilsoftware/2-questions-to-ask-before-choosing-a-python-framework-1l99</guid>
      <description>&lt;p&gt;Hello! My name is ≈Åukasz! I‚Äôm a Software Developer at &lt;a href="https://profil-software.com/"&gt;Profil Software&lt;/a&gt;. Like many Python developers who start new projects, I had to make a decision which back-end framework I should use, and it wasn‚Äôt easy to choose the best one. In making the decision, I asked myself two questions that helped point me in the right direction.&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#how-much-time-do-i-have-to-deliver-a-productionready-solution"&gt;
  &lt;/a&gt;
  How much time do I have to deliver a production-ready solution?
&lt;/h1&gt;

&lt;p&gt;I am sure that none of us would like to delay delivery time and become unreliable business partners or pay a fine because of contract terms. Having short time to deliver a production-ready app, I would choose &lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; as a back-end framework.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--GeLVTTjO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/w769m1wvsof9e1e8bmk1.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--GeLVTTjO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/w769m1wvsof9e1e8bmk1.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; is an advanced open source web framework whose main goal is to simplify developers‚Äô work. It uses the DRY philosophy (Don‚Äôt Repeat Yourself). Django allows developers to reuse existing code and focus on really unique ones. It is maintained by the &lt;a href="https://www.djangoproject.com/foundation/"&gt;Django Software Foundation&lt;/a&gt;, an independent American organisation. It was first released in 2005 and has many built-in features like ORM, authentication, and admin panel, which are easy to set up. Django is a secure framework ‚Äî developers don‚Äôt have to worry about most common security issues like SQL injections or cross-site scripting. We have security out-of-the-box. Django also has very good documentation for real-world applications. Because of the big community we can find many production-ready solutions and save development time.&lt;/p&gt;

&lt;p&gt;Here‚Äôs an example of Django REST view:&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--FdjynPpI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9c47pzsvo34taw9iyzp7.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--FdjynPpI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9c47pzsvo34taw9iyzp7.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
A big advantage of the Django framework is its built-in admin panel. It allows users or developers to make changes to a database through a user-friendly interface. It is generated automatically with minimal configuration.&lt;/p&gt;

&lt;p&gt;Here‚Äôs an example of what the admin looks like:&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--HOiHGXDI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4kcmchw2fkeasdvnbyyu.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--HOiHGXDI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4kcmchw2fkeasdvnbyyu.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
Django has a less-flexible structure than other frameworks. This is another big advantage especially if the development team is big. It helps keep back-end code well organised. Like any back-end application framework, Django isn‚Äôt perfect. As I mentioned above, it‚Äôs huge and includes many built-in features. In many cases we don‚Äôt need everything, but using Django we have to install all dependencies because it‚Äôs one big monolith. We can turn off the features we don‚Äôt need, but we still have to install them.&lt;/p&gt;

&lt;p&gt;The big minus of Django is that we don‚Äôt have alternatives for many built-in libraries. The general rule is that Django works fine as long as you do things in the Django way. A good example is ORM. There‚Äôs no easy way to change an object-relational mapping library to another one (e.g. &lt;a href="https://www.sqlalchemy.org/"&gt;SQL Alchemy&lt;/a&gt;).&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#how-customized-is-the-solution-i-would-like-to-build-or-how-customizable-is-the-solution-i-would-like-to-build"&gt;
  &lt;/a&gt;
  How customized is the solution I would like to build? (or How customizable is the solution I would like to build?)
&lt;/h1&gt;

&lt;p&gt;Delivery time is very important but it‚Äôs also good to think about flexibility. Let‚Äôs imagine that we want to build some features and it‚Äôs not possible to implement some solution using a built-in library, or that it‚Äôs possible but we will have problems with performance. Or what if we would like to split our application into smaller microservices? Using a big Python web framework like Django requires installing all features, which makes our app big right from the start.&lt;/p&gt;

&lt;p&gt;To help with the above two cases I would consider using a microframework, and the Python community provides many solutions. In my professional career I‚Äôve had the opportunity to work with three very good alternatives to Django: &lt;a href="https://flask.palletsprojects.com/en/2.0.x/"&gt;Flask&lt;/a&gt;, &lt;a href="https://falcon.readthedocs.io/en/stable/"&gt;Falcon&lt;/a&gt;, and &lt;a href="https://fastapi.tiangolo.com/"&gt;Fast API&lt;/a&gt;.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Ouelge1n--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bs9z1qdbpdk4y70b5es5.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Ouelge1n--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bs9z1qdbpdk4y70b5es5.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="https://flask.palletsprojects.com/en/2.0.x/"&gt;Flask&lt;/a&gt; is designed to be easy to use and extend. It follows the principles of minimalism and gives more control over the app. Choosing it, developers can use multiple types of databases, which is not easy to do in Django. We can also plug in our favorite ORM and use it without any risk of unpredictable app behavior. In contrast to Django, it‚Äôs easy to integrate NoSQL databases with &lt;a href="https://flask.palletsprojects.com/en/2.0.x/"&gt;Flask&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here‚Äôs an example Flask application:&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--xOodg2Df--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/agb0757lj8imd53virs5.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--xOodg2Df--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/agb0757lj8imd53virs5.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
The big advantage of using Flask is how easy it is to separate database logic from application views. It looks cleaner, and it‚Äôs easier to extend or replace.&lt;/p&gt;

&lt;p&gt;In Django, database logic is mixed with application views that might be confusing and sometimes hard to understand when we debug the code.&lt;/p&gt;

&lt;p&gt;Flask developers can also follow REST application patterns because it offers RESTful request dispatching. It also has API support, which Django does not offer.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--g31OkqVq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9g3n1iuug5wulmtph8gf.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--g31OkqVq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9g3n1iuug5wulmtph8gf.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
A second good alternative to the Django framework is &lt;a href="https://falcon.readthedocs.io/en/stable/"&gt;Falcon&lt;/a&gt;. It‚Äôs another light-weight microframework for building web APIs and app back-ends. The main focus of Falcon is REST APIs. It has a clean design and REST architectural style, but it‚Äôs not suitable for serving HTML pages at all.&lt;/p&gt;

&lt;p&gt;The big advantage of using Falcon is performance. Falcon turns around requests significantly faster than Flask or Django. It compiles itself with Cython when available and also works well with PyPy.&lt;/p&gt;

&lt;p&gt;Here‚Äôs an example of a Falcon resource class:&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--JJuR_kzr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/msep4155lupqm9ldi0x9.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--JJuR_kzr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/msep4155lupqm9ldi0x9.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="https://falcon.readthedocs.io/en/stable/"&gt;Falcon&lt;/a&gt; is a flexible microframework. Its authors leave a lot of decisions and implementation details to the developer. Like with Flask, we can choose ORM and a database engine that fits our needs and build the logic in the most convenient way. It also allows you to use NoSQL databases.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--YoHEkmqM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/wjq8wfjsg5n0cwf391yu.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--YoHEkmqM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/wjq8wfjsg5n0cwf391yu.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
The last microframework I‚Äôve had the chance to use is &lt;a href="https://fastapi.tiangolo.com/"&gt;Fast API&lt;/a&gt;. It‚Äôs new, modern, and was inspired by its predecessors. It‚Äôs very fast because it‚Äôs built over ASGI (Asynchronous Server Gateway) instead of WSGI. It also provides built-in async support, which is not available in Flask or Django.&lt;/p&gt;

&lt;p&gt;Here‚Äôs an example FastAPI view:&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--rDp_NpvK--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/856nw0bnm8i0xil0lo11.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--rDp_NpvK--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/856nw0bnm8i0xil0lo11.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
Fast API has a validation system which can detect invalid types at runtime and return a well formatted JSON response containing the reason for the bad input. It also generates documentation on the go, which is really helpful for developers. Fast API also allows users to choose the best ORM package and use it in a convenient way.&lt;/p&gt;

&lt;p&gt;Another big Fast API feature is schema validation. It uses &lt;a href="https://pydantic-docs.helpmanual.io/"&gt;pydantic&lt;/a&gt; ‚Äî a fast and intuitive package which relies on Python typing. It makes our code easy to understand.&lt;/p&gt;

&lt;p&gt;Here‚Äôs an example of a pydantic model:&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--_GCnSW1T--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fnz0ctpa7gorfp355tso.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--_GCnSW1T--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fnz0ctpa7gorfp355tso.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
Fast API also has built-in security features and makes it easy to implement both HTTP Basic Auth and Oauth2. It is well documented and contains many practical examples.&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#conclusion"&gt;
  &lt;/a&gt;
  Conclusion
&lt;/h1&gt;

&lt;p&gt;It‚Äôs not easy to choose a proper Python back-end framework. I‚Äôve had a chance to work with all of the above back-end frameworks and currently the best option for me is FastAPI. It is developed in a modern way and takes the best features from the other ones. Its flexible structure allows us to easily integrate it with other Python packages. If you have a tight deadline, I would consider using Django because of its many built-in, easy-to-setup features. The auto-generated Django admin panel for simple CRUD operations is another really big advantage for people who don‚Äôt need an advanced UI.&lt;/p&gt;

</description>
      <category>python</category>
      <category>programming</category>
      <category>backend</category>
      <category>frameworks</category>
    </item>
    <item>
      <title>Running Dapr on Kubernetes</title>
      <author>Ivan Cvitkovic</author>
      <pubDate>Tue, 07 Sep 2021 10:53:46 +0000</pubDate>
      <link>https://dev.to/cvitaa11/running-dapr-on-kubernetes-89g</link>
      <guid>https://dev.to/cvitaa11/running-dapr-on-kubernetes-89g</guid>
      <description>&lt;p&gt;The distributed application runtime, Dapr, is a portable, event-driven runtime that can run on the cloud or any edge infrastructure. It puts together the best practices for building microservice applications into components called building blocks.&lt;/p&gt;

&lt;p&gt;Each building block is completely independent so you can use one, some, or all of them in your application. Building blocks are extensible, so you can also write your own.&lt;/p&gt;

&lt;p&gt;Dapr supports a wide range of programming languages and frameworks such as .NET, Java, Node.js, Go and Python. That means you can write microservice apps using your favorite tools and deploy them literally anywhere.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--yQ1_eJLG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://docs.dapr.io/images/overview.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--yQ1_eJLG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://docs.dapr.io/images/overview.png" alt="Architecture Diagram"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Basically, building blocks are just HTTP or gRPC APIs that can be called from application code and use one or more Dapr components. They abstract some of the major challenges during development such as service-to-service communication, state managment, pub/sub, observability and more. Building blocks do not depend on underlying technology. This means if you need to implement, for example, pub/sub functionality you can use Apache Kafka, RabbitMQ, Redis Streams, Azure Service Bus or any other supported broker that interface with Dapr.&lt;/p&gt;

&lt;p&gt;In this example we will show how to run Dapr on the Kubernetes cluster with two .NET applications. First one will send messages to Apache Kafka while the second one will read those messages and store them in Redis. Communication to Kafka and Redis will be realized using the Dapr Client, which means that we will not have any dependencies on NuGet packages like &lt;code&gt;Confluent.Kafka&lt;/code&gt; or &lt;code&gt;StackExchange.Redis&lt;/code&gt;.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#architecture-diagram"&gt;
  &lt;/a&gt;
  Architecture diagram
&lt;/h4&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--WHagNN1g--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/cvitaa11/dapr-demo/main/Architecture_diagram.jpeg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--WHagNN1g--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/cvitaa11/dapr-demo/main/Architecture_diagram.jpeg" alt="Architecture Diagram"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#prerequisites"&gt;
  &lt;/a&gt;
  Prerequisites
&lt;/h4&gt;

&lt;p&gt;This demo requires you to have the following installed on your machine:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Kubernetes CLI &lt;a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/"&gt;kubectl&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Kubernetes cluster, such as &lt;a href="https://docs.dapr.io/operations/hosting/kubernetes/cluster/setup-minikube/"&gt;Minikube&lt;/a&gt; or &lt;a href="https://www.docker.com/products/docker-desktop"&gt;Docker Desktop&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Also, clone the repository and &lt;code&gt;cd&lt;/code&gt; into the right directory:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git clone https://github.com/cvitaa11/dapr-demo
cd dapr-demo
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h4&gt;
  &lt;a href="#step-1-setup-dapr-on-your-kubernetes-cluster"&gt;
  &lt;/a&gt;
  Step 1 - Setup Dapr on your Kubernetes cluster
&lt;/h4&gt;

&lt;p&gt;The first thing you need is an RBAC enabled Kubernetes cluster. This could be running on your machine using Minikube/Docker Desktop, or it could be a fully-fledged cluser in Azure using &lt;a href="https://azure.microsoft.com/en-us/services/kubernetes-service/"&gt;AKS&lt;/a&gt; or some other managed Kubernetes instance from different cloud vendor.&lt;/p&gt;

&lt;p&gt;Once you have a cluster, follow the steps below to deploy Dapr to it. For more details, look &lt;a href="https://docs.dapr.io/getting-started/install-dapr/#install-dapr-on-a-kubernetes-cluster"&gt;here&lt;/a&gt;&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;$ dapr init -k
‚åõ  Making the jump to hyperspace...
‚ÑπÔ∏è  Note: To install Dapr using Helm, see here: https://docs.dapr.io/getting-started/install-dapr-kubernetes/#install-with-helm-advanced

‚úÖ  Deploying the Dapr control plane to your cluster...
‚úÖ  Success! Dapr has been installed to namespace dapr-system. To verify, run `dapr status -k' in your terminal. To get started, go here: https://aka.ms/dapr-getting-started
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The &lt;code&gt;dapr&lt;/code&gt; CLI will exit as soon as the kubernetes deployments are created. Kubernetes deployments are asyncronous, so you will need to make sure that the dapr deployments are actually completed before continuing.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#step-2-setup-apache-kafka"&gt;
  &lt;/a&gt;
  Step 2 - Setup Apache Kafka
&lt;/h4&gt;

&lt;p&gt;The easiest way to setup Apache Kafka on your Kubernetes cluster is by using &lt;a href="https://helm.sh/"&gt;Helm&lt;/a&gt; package manager. To install Helm on your development machine follow this &lt;a href="https://helm.sh/docs/intro/install/"&gt;guide&lt;/a&gt;. &lt;br&gt;
We will use &lt;a href="https://github.com/bitnami/charts"&gt;Bitnamy Library for Kubernetes&lt;/a&gt; to launch Zookeper and Kafka message broker.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;helm repo add bitnami https://charts.bitnami.com/bitnami
helm install my-release bitnami/kafka
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h4&gt;
  &lt;a href="#step-3-setup-redis"&gt;
  &lt;/a&gt;
  Step 3 - Setup Redis
&lt;/h4&gt;

&lt;p&gt;Just like Apache Kafka, easy way to spin up Redis on your Kubernetes cluster is by using Helm.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;helm repo add bitnami https://charts.bitnami.com/bitnami
helm install redis bitnami/redis
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;To verify the installation of Kafka and Redis run &lt;code&gt;kubectl get all&lt;/code&gt; and you should see similiar output:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;NAME                             READY   STATUS        RESTARTS   AGE
pod/my-release-kafka-0           1/1     Running       0          18m
pod/my-release-zookeeper-0       1/1     Running       0          18m
pod/redis-master-0               1/1     Running       1          11m
pod/redis-slave-0                1/1     Running       1          11m
pod/redis-slave-1                1/1     Running       1          11m

NAME                                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
service/kubernetes                      ClusterIP   10.96.0.1        &amp;lt;none&amp;gt;        443/TCP                      15d
service/my-release-kafka                ClusterIP   10.110.225.238   &amp;lt;none&amp;gt;        9092/TCP                     18m
service/my-release-kafka-headless       ClusterIP   None             &amp;lt;none&amp;gt;        9092/TCP,9093/TCP            18m
service/my-release-zookeeper            ClusterIP   10.99.95.252     &amp;lt;none&amp;gt;        2181/TCP,2888/TCP,3888/TCP   18m
service/my-release-zookeeper-headless   ClusterIP   None             &amp;lt;none&amp;gt;        2181/TCP,2888/TCP,3888/TCP   18m
service/redis-headless                  ClusterIP   None             &amp;lt;none&amp;gt;        6379/TCP                     11m
service/redis-master                    ClusterIP   10.111.109.148   &amp;lt;none&amp;gt;        6379/TCP                     11m
service/redis-slave                     ClusterIP   10.111.66.85     &amp;lt;none&amp;gt;        6379/TCP                     11m

NAME                                    READY   AGE
statefulset.apps/my-release-kafka       1/1     18m
statefulset.apps/my-release-zookeeper   1/1     18m
statefulset.apps/redis-master           1/1     11m
statefulset.apps/redis-slave            2/2     11m
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h4&gt;
  &lt;a href="#step-4-create-dapr-components-in-kubernetes-cluster"&gt;
  &lt;/a&gt;
  Step 4 - Create Dapr components in Kubernetes cluster
&lt;/h4&gt;

&lt;p&gt;To deploy pub/sub and state store components make sure you are positioned in the right directory and then apply Dapr YAML manifests.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;cd dapr-components
kubectl apply -f .\kafka.yaml
kubectl apply -f .\redis.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h4&gt;
  &lt;a href="#step-5-deploy-net-core-applications"&gt;
  &lt;/a&gt;
  Step 5 - Deploy .NET Core applications
&lt;/h4&gt;

&lt;p&gt;Now when all prerequisites are ready we can deploy our apps. To deploy .NET Core publisher and consumer applications make sure you are positioned in the right directory and then apply Kubernetes manifests.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;cd k8s
kubectl apply -f .\publisher.yaml
kubectl apply -f .\consumer.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Each manifest contains &lt;code&gt;Deployment&lt;/code&gt; object for the application and &lt;code&gt;Service&lt;/code&gt; object for accessing the application through a browser.&lt;/p&gt;

&lt;p&gt;Navigate to the &lt;code&gt;localhost:8081/swagger&lt;/code&gt; and you will se our publisher app with a POST method on &lt;code&gt;MessageController&lt;/code&gt;. This action sends a message to &lt;em&gt;newMessage&lt;/em&gt; topic on Kafka pub/sub component. Communication between application and message broker is not performed directly. Dapr is running as a sidecar container inside publisher pod and handles the entire process of sending a message.&lt;/p&gt;

&lt;p&gt;Our consumer application is running on &lt;code&gt;localhost:9091&lt;/code&gt; and is subscribed to &lt;em&gt;newMessage&lt;/em&gt; topic on Kafka pub/sub component. When new message arrives it reads the content and trough the Dapr client saves it to Redis state store uneder the key &lt;em&gt;message&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;To test the entire process we can run Redis client pod and check if content is stored. First of all we will export password to REDIS_PASSWORD variable:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;export REDIS_PASSWORD=$(kubectl get secret --namespace default redis -o jsonpath="{.data.redis-password}" | base64 --decode)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Then run the client with the following command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;kubectl run --namespace default redis-client --rm --tty -i --restart='Never' \
    --env REDIS_PASSWORD=$REDIS_PASSWORD \
   --image docker.io/bitnami/redis:6.0.12-debian-10-r3 -- bash
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;and connect using Redis CLI:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;redis-cli -h redis-master -a $REDIS_PASSWORD
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now that you are connected to Redis you can use command &lt;code&gt;HGETALL message&lt;/code&gt; that will return content of the message we sent to Kafka. With this we have confirmed that the whole process works.&lt;/p&gt;

&lt;p&gt;If you want to find out more about Dapr, the best place to start is the official &lt;a href="https://dapr.io/"&gt;documentation&lt;/a&gt;.&lt;/p&gt;

</description>
      <category>kubernetes</category>
      <category>dotnet</category>
      <category>microservices</category>
      <category>architecture</category>
    </item>
    <item>
      <title>Paxful Clone Script-6 Steps to Provide a Website Like Paxful</title>
      <author>felix jordan</author>
      <pubDate>Tue, 07 Sep 2021 10:53:05 +0000</pubDate>
      <link>https://dev.to/fixitjordan/paxful-clone-script-6-steps-to-provide-a-website-like-paxful-baf</link>
      <guid>https://dev.to/fixitjordan/paxful-clone-script-6-steps-to-provide-a-website-like-paxful-baf</guid>
      <description>&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--3FwK98fB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/wo49tu8g1bq6z8bgn6by.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--3FwK98fB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/wo49tu8g1bq6z8bgn6by.png" alt="paxful is a p2p finance platform for trading cryptocurrencies"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#what-is-paxful"&gt;
  &lt;/a&gt;
  What is Paxful?
&lt;/h2&gt;

&lt;p&gt;Paxful is one of the best p2p finance platform for trading cryptocurrency. many companies are interested to launch &lt;strong&gt;&lt;a href="https://radindev.com/paxful-clone-script/"&gt;paxful clone script&lt;/a&gt;&lt;/strong&gt; similar to paxful exchange.&lt;br&gt;
In 2014, Ray Youssef and Artur Schaback founded EasyBitz which was then renamed to Paxful, which gets its name from the Latin word for "peace". They had one goal in mind when they created it: to make Bitcoin easier for everyone from businesses to traders. &lt;br&gt;
A lot of big problems in the world revolve around money, specifically earning it and transporting it. Sending money around the world is not fast or cheap in any way, but Paxful changed that.&lt;br&gt;
Paxful is the p2p cryptocurrency marketplace where buyers and sellers are connected for business. Having over 300 payment methods available on Paxful creates it unbelievably easy to find proper suggestions.&lt;br&gt;
The p2p system of Paxful removes limits. You can think of your Paxful account as your very own financial passport. Also, you can send money and buy things from halfway around the world. &lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--d7Otoweg--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/jlx35esq5rhfh0djw243.jpeg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--d7Otoweg--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/jlx35esq5rhfh0djw243.jpeg" alt="stats of paxful exchange"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As you can see, in this article, we supposed to analyze the process of functioning paxful exchange, paxful clone script, benefits, features, functions, white label paxful clone script and how to build exchange like paxful. Let‚Äôs find out what these are:&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#what-is-clone-script"&gt;
  &lt;/a&gt;
  What is clone script?
&lt;/h2&gt;

&lt;p&gt;A clone script is a replacement code or architecture of an existing website. The purpose of the website clone script is, it helps the entrepreneurs to start business rapidly with popular and unique features and minimize the startup costs. Actually The Clone scripts are the copy of famous online businesses out there in the world. These scripts can be used by entrepreneurs to start their online business at ease.&lt;br&gt;
Some business owners say clone scripts are not legal. But it isn‚Äôt. Because cloning a website doesn‚Äôt mean that the clone scripts are made from the exact code of the existing website.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#features-and-benefits-of-using-clone-script"&gt;
  &lt;/a&gt;
  Features and benefits of using clone script
&lt;/h3&gt;

&lt;p&gt;Scalable and Customizable:&lt;br&gt;
Clone scripts are used in developing the clone app and it is very easy to customize the clone scripts according to the requirement of the project of the client. &lt;br&gt;
Quick Launch:&lt;br&gt;
The clone scripts do not take a long time to run as they are predefined scripts and already written and capable to run quickly.&lt;br&gt;
Low Cost:&lt;br&gt;
the clone scripts are open source so we can get that from the original site of the existing app and can easily get that from there and use it in our app though we do not have to pay any amount hence results in it being cost-effective.&lt;br&gt;
High Success Rate:&lt;br&gt;
The clone scripts are very powerful and we know that these are already used on someone‚Äôs site or used by many others though it is bug-free and attracted by the users across the globe. &lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#whats-the-purpose-of-clone-scripts"&gt;
  &lt;/a&gt;
  What‚Äôs the purpose of clone scripts?
&lt;/h3&gt;

&lt;p&gt;The ultimate purpose of clone scripts is to help budding entrepreneurs to start their own online business hassle-free. Also eliminate the cost and time of development of the business applications. The entrepreneurs can buy the clone script from any of the service providers and customize them based on their preferences.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#white-label-paxful-clone-script-to-get-high-cryptocurrency"&gt;
  &lt;/a&gt;
  White label Paxful Clone Script - To Get High Cryptocurrency
&lt;/h2&gt;

&lt;p&gt;White label Paxful Clone Script is a set of source code that contains all trading functionalities of the Paxful exchange website. White label Paxful clone script allows you to customize the features according to the current digital trend &amp;amp; it allows you to change brand name, logo, theme, design according to your business needs at that moment. &lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--z9ZRypYM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1qg3en0b0uizwgsff0z7.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--z9ZRypYM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1qg3en0b0uizwgsff0z7.png" alt="steps to build a website like paxful"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#6-steps-to-build-website-like-paxful"&gt;
  &lt;/a&gt;
  6 steps to build website like paxful
&lt;/h2&gt;

&lt;h3&gt;
  &lt;a href="#step1-paxful-business-model"&gt;
  &lt;/a&gt;
  Step1: Paxful Business Model
&lt;/h3&gt;

&lt;p&gt;Paxful is one of the most advanced clone scripts that you can use for making a high-end crypto trading platform. Using this powerful solution, it is possible for any entrepreneur to create an exchange as impeccable as Paxful. It has made the &lt;strong&gt;&lt;a href="https://radindev.com/cryptocurrency-exchange-development/"&gt;cryptocurrency exchange website development&lt;/a&gt;&lt;/strong&gt; more valuable for all the parties involved. From the developers to the exchange owners, it is prolific for everyone. paxful clone script works on a very strong architectural design that paves way for some big changes. The replication gets easier only because the platform has allowed you to use its technology. Otherwise, the security aspects are unbeatable and the functionality is also matchless. With this program, it is even possible for you to have a very certain style of trade. It brings a string of plugins and features for the users. To guarantee an honest exchange on the website, smart contracts with escrow are used. To reduce fraud, with other methods of exchange on the site, a system of reviews and reputation ratings has been introduced.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#step-2-key-exchange-features"&gt;
  &lt;/a&gt;
  Step 2. Key Exchange Features
&lt;/h3&gt;

&lt;p&gt;Registration. To create a new Paxful account:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; Open a web browser and launch the Paxful webpage&lt;/li&gt;
&lt;li&gt; Click Create account on the top right corner of the main page. ...&lt;/li&gt;
&lt;li&gt; Complete the following fields on the signup form: ...&lt;/li&gt;
&lt;li&gt; Click Create Paxful account. ...&lt;/li&gt;
&lt;li&gt; Complete your captcha verification.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;User profiles.  Your public profile contains a summary of your account and your history on Paxful. Also, you can add an avatar (photo or any image), indicate the phone number, main currency and very briefly tell about yourself. In addition, you can configure notification settings in your profile. &lt;br&gt;
Remember that your public profile is visible to other Paxful users. On your public profile, other Paxful users will be able to view the following information about you:&lt;br&gt;
‚Ä¢ Username&lt;br&gt;
‚Ä¢ Profile picture&lt;br&gt;
‚Ä¢ Verification - information if your email, phone, ID or address are verified, and you were verified as a trusted vendor.&lt;br&gt;
‚Ä¢ Reputation - an aggregation of the positive and negative feedback that you have received on Paxful.&lt;br&gt;
‚Ä¢ Active offers - offers you created that are currently active.&lt;br&gt;
‚Ä¢ Your profile language&lt;br&gt;
‚Ä¢ Number of trade partners&lt;br&gt;
‚Ä¢ Number of trades&lt;br&gt;
‚Ä¢ Trade volume - total BTC you‚Äôve traded on Paxful.&lt;br&gt;
‚Ä¢ Number of users who trust you&lt;br&gt;
‚Ä¢ Number of users who have blocked you&lt;br&gt;
‚Ä¢ Time elapsed since you joined Paxful&lt;br&gt;
‚Ä¢ Last time you were online on Paxful&lt;br&gt;
Note: Your public profile will contain all the IDs you have earned on Paxful and will help other users decide if you are a safe trade partner or not.&lt;br&gt;
Verification, Know Your Customer (KYC). Paxful is one of the few crypto marketplaces that enforce KYC verification procedures. Verification is an important part of Paxful as we aim to make the trading experience on our platform as safe as possible. Users who fail to verify their identity can continue to use the exchanger, but a limit on the volume of transactions will be set for them.&lt;br&gt;
Cryptocurrency wallet.  The Paxful wallet is useful, protected, and easy to use on all your devices. You can simply manage your funds and top up directly through p2p marketplace, and send or receive Bitcoin, in just a few clicks. Over 3 million people have used the Paxful wallet to send and receive over 40,000 BTC. Its best-in-class security features make it one of the most trusted wallets in the world ‚Äî so you‚Äôll never have to choose between security and convenience.&lt;br&gt;
Security tools. Cryptocurrency holders and traders are especially vulnerable to cyber-attacks since digital currencies only run electronically. This is why choosing a secure and reliable online Bitcoin wallet is very essential. &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Choose a crypto wallet that fits your needs&lt;/li&gt;
&lt;li&gt;Enable two-factor authentication&lt;/li&gt;
&lt;li&gt;Encrypt your Bitcoin wallet&lt;/li&gt;
&lt;li&gt;Backup your entire wallet regularly&lt;/li&gt;
&lt;li&gt;Utilize the multi-signature feature&lt;/li&gt;
&lt;li&gt;Keep your software updated&lt;/li&gt;
&lt;li&gt;Use different passwords for different accounts&lt;/li&gt;
&lt;li&gt;Never give away your private key&lt;/li&gt;
&lt;li&gt;Don‚Äôt click on unknown or suspicious links&lt;/li&gt;
&lt;li&gt;Use a secure Internet connection&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--UVOdk95d--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ciu2fx27z5rcqr5zpqu2.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--UVOdk95d--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ciu2fx27z5rcqr5zpqu2.png" alt="paxful,a cryptocurrency platform purchase, sale and exchange"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Cryptocurrency purchase, sale and exchange. &lt;br&gt;
Over 350 ways to buy and sell Bitcoin: Select a payment method you like and trade directly with other people!&lt;br&gt;
1.Bank Transfers&lt;br&gt;
2.Exchange for Cash&lt;br&gt;
3.Other Wallet (Send to over 140 online wallets worldwide)&lt;br&gt;
4.Discounted Gift Cards&lt;br&gt;
5.Digital Currencies&lt;br&gt;
6.Goods &amp;amp; Services&lt;/p&gt;

&lt;p&gt;Escrow. Escrow in the financial sense means an arrangement where a third party (not the buyer or the seller)  holds funds in safekeeping pending the completion of a promised obligation. And enables users to get guaranteed transactons. It is best if it is open source software so that users can verify the integrity of the smart contract and the absence of errors in the code. &lt;br&gt;
Reviews and rating system. On the Paxful website, users can distinguish reliable counterparties from unscrupulous or scammers. They can be positive, neutral or negative. You can leave a response instantly after the successful completion of the transaction (or its failure). &lt;br&gt;
Customer support. &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; Customizable dashboard&lt;/li&gt;
&lt;li&gt; The ability to view site statistics (activity, trading volume, etc.)&lt;/li&gt;
&lt;li&gt; View user profiles&lt;/li&gt;
&lt;li&gt; Buy-Sell tab&lt;/li&gt;
&lt;li&gt; General information about the platform&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;
  &lt;a href="#step-3-monetization-of-the-cryptocurrency-exchange"&gt;
  &lt;/a&gt;
  Step 3. Monetization of the cryptocurrency exchange
&lt;/h3&gt;

&lt;p&gt;Publication fee. &lt;br&gt;
Buyer creates an escrow account&lt;br&gt;
One of the two parties, either the Buyer or Seller, will initiate the transaction. This process begins when the user inquires about the offering and creates an account on CryptoExchange. With an account set up, the two parties can solidify the terms of their agreement.&lt;br&gt;
Advertisements. Advertising promotion fees, posters, contextual advertising and paid links - all this is used on the site and in the Paxful application to increase the profitability of the platform.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#step-4-marketing-strategy"&gt;
  &lt;/a&gt;
  Step 4: Marketing Strategy
&lt;/h3&gt;

&lt;p&gt;The paxful cryptocurrency exchange was launched in 2014 and is a peer-to-peer Bitcoin marketplace, has recently entered India. In the first 21 weeks of 2020, Paxful has recorded a minimum of $1 million in weekly volumes. Since the beginning of May 2020, the weekly traded Bitcoin volumes have grown setting three consecutive all-time highs ‚Äì with the week ending 17th May recording a total of $1.521 million (ATH).&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#step-5-development-approaches"&gt;
  &lt;/a&gt;
  Step 5. Development approaches
&lt;/h3&gt;

&lt;p&gt;Template Solution. You can create a crypto exchange like Paxful using ready-made software. You can get it for free, for example, on GitHub, or buy for 300 - 1000 dollars. Free solutions usually have poor functionality and are not well tested for errors and other vulnerabilities. Paxful clones software sold may vary by manufacturer.&lt;br&gt;
Development from scratch. A more complex and expensive option to create a Paxful clone software, but it gives you more control over the development process and allows you to implement unique software solutions. The cost of creating a P2P crypto exchanger from scratch usually varies from 20 to 50 thousand dollars.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#step-6-get-the-consultation-from-the-experienced-clone-script-providers"&gt;
  &lt;/a&gt;
  Step 6. Get the consultation from the experienced clone script providers
&lt;/h3&gt;

&lt;p&gt;The script is usually developed by well-experienced and qualified experts. They take care of everything from development, design, testing, and deployment, allowing you to focus on just the customization part. There are many advantages involved with purchasing and deploying a Paxful clone script for your business.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#the-benefits-of-paxful-clone-script-to-start-a-p2p-cryptocurrency-exchange-software"&gt;
  &lt;/a&gt;
  The benefits of Paxful clone script to start a P2P cryptocurrency exchange software
&lt;/h2&gt;

&lt;p&gt;‚Ä¢ Ready to launch&lt;br&gt;
‚Ä¢ Skip development from scratch&lt;br&gt;
‚Ä¢ No technical assistance&lt;br&gt;
‚Ä¢ Easy customization&lt;br&gt;
‚Ä¢ Save time and money&lt;br&gt;
These are benefits you can get to develop a P2P crypto exchange with Paxful clone script.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--ylg0X72M--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/6pcsove2j4154zzhxym5.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ylg0X72M--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/6pcsove2j4154zzhxym5.png" alt="paxful clone app development"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#amazing-paxful-clone-app-to-buy-and-sell-cryptos"&gt;
  &lt;/a&gt;
  Amazing Paxful Clone App - To Buy and Sell Cryptos
&lt;/h2&gt;

&lt;p&gt;Paxful Clone App Development Company&lt;br&gt;
Paxful Clone App is the cryptocurrency exchange trading app that contains all the crypto trading features of the Paxful app and also the additional features that help you to develop your own Crypto Exchange App such as Paxful. Ultra-fast transaction permits you trade crypto coins in a matter of seconds with 100+ payment gateway support.&lt;/p&gt;

</description>
      <category>blockchain</category>
      <category>webdev</category>
      <category>cryptocurrency</category>
      <category>exchange</category>
    </item>
    <item>
      <title>Top Data Science competition platforms</title>
      <author>Vishnubhotla V D V Bharadwaj</author>
      <pubDate>Tue, 07 Sep 2021 10:37:50 +0000</pubDate>
      <link>https://dev.to/bharadwaj6262/top-data-science-competition-platforms-3g4n</link>
      <guid>https://dev.to/bharadwaj6262/top-data-science-competition-platforms-3g4n</guid>
      <description>&lt;p&gt;Hello, friends!! How are you? Hope you are doing well! In this blog, I am going to share some of the Top Data Science competition platforms that you should check. Ok then, let's go deep into it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.kaggle.com/"&gt;Kaggle&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kaggle is one of the most popular platforms in the world for Data Science!&lt;/strong&gt; And there are a lot of competitions on Kaggle that you can enter to sharpen your Data Science skills. These competitions range from identifying wheat using image analysis to predicting lung function decline due to pulmonary fibrosis.&lt;/p&gt;

&lt;p&gt;These competitions allow the brightest minds in data science to compete and obtain some solutions to serious problems in the world(while winning a cash prize is just a bonus!). So if you are new to data science competitions, then you should start with Kaggle.&lt;/p&gt;

&lt;p&gt;There are some easy competitions you can practice on and then move on to the active world-changing competitions with hefty cash prizes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href="https://idao.world/"&gt;International Data Analysis Olympiad (IDAO)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The International Data Analysis Olympiad is a data science competition that is open to everyone, whether they be undergraduate, postgraduate, or Ph.D. students or even company employees or new data scientists.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This competition aims to increase the skills of the professionals in data science so that they can adequately fill the industry demand in this field.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;There are two rounds of IDAO. The first round is a data science competition where the participants are provided a labeled training set and asked to predict the test data. The second round focuses more on efficiency and so the participants have to solve the same problem as the first round but with tight restrictions on time and memory.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.drivendata.org/"&gt;DrivenData&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DrivenData is an online platform that aims to solve some of the biggest social challenges in the world using innovations in data science&lt;/strong&gt;. consequently, it has various online challenges that last two or three months and various data scientists compete in these challenges to find the best solution for difficult predictive problems that occur in the real world.&lt;/p&gt;

&lt;p&gt;Some of the online challenges include detecting hateful content in memes, predicting dengue disease spread, predicting damage to buildings by earthquakes, etc. Science these challenges aim to solve problems and learn more about data science, the code submitted by the winners is released under an open-source license so that everyone can learn and improve.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.topcoder.com/"&gt;Topcoder&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Topcoder has many different challenges that allow participants to learn more about data science also win prices at the same time! Most of the challenges offer reward money but some are just there to learn and grow.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The most famous challenge is the annual Topcoder open which has various competition tracks based on data science, design, competitive programming, and software development&lt;/strong&gt;. The most successful candidates are invited for a free one-week trip on the on-site finals, where they can win lots of prizes also learn from each other.&lt;/p&gt;

&lt;p&gt;Topcoder also has smaller regional events throughout the year that are not as big as Topcoder Open but still allow different people to participate and improve their skills.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href="https://codalab.org/"&gt;Codalab&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Codalab is an open-source platform that has various data science competitions&lt;/strong&gt;. These competitions do not have a high range of cash prizes, but they still offer participants the opportunity to learn more about data science and create efficient code.&lt;/p&gt;

&lt;p&gt;These competitions are a great way to learn more about collaboration and finding solutions with a team as Codalab focuses on the programming and a code-building of data in the competitions.&lt;/p&gt;

&lt;p&gt;Currently, the most popular of these include the Liver Tumor segmentation challenge, Microsoft COCO image captioning challenge, MAFAT Radar Challenge, etc.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href="https://datahack.analyticsvidhya.com/"&gt;DataHack&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DataHack is a platform provided by Analytics Vidhya that hosts a lot of data science hackathons&lt;/strong&gt;. You can compete with expert data science and machine learning professionals from all over the world and work on real-life data science problems in these hackathons while learning a lot of new skills.&lt;/p&gt;

&lt;p&gt;There are a lot of prizes you can win in these hackathons and some even offer job opportunities at top companies. DataHack also hosts exclusive data science events by Analytics Vidhya where you can interact directly with leaders in the data science and machine learning community.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.tableau.com/community/iron-viz"&gt;Iron Viz&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;IronViz is a visualization competition that is hosted by Tableau&lt;/strong&gt;. It allows data scientists from all over the world to compete with each other in creating the best data visualization that is beautiful as well as informative. Iron Viz has 2 rounds, namely the Iron Viz Qualifier and the Iron Viz Championship. Everyone can participate in the iron Viz Qualifier which is an online competition based on a qualifier theme.&lt;/p&gt;

&lt;p&gt;The only thing that participants need to get started is access to the Tableau Desktop. &lt;strong&gt;The free version of the software, Tableau Desktop public edition is also available&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href="https://machinehack.com/"&gt;Machine Hack&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Machine Hack is an online platform that has various machine learning competitions that you can use to test and practice your ML skills. All the hackathons provide a unique opportunity to compete against data scientists from all over the world and enhance your data science skills.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A big advantage of these hackathons is that companies also scope unique talent from here so top performers may even get job offers!&lt;/strong&gt; Machine Hack also has an option for practicing your data science and machine learning skills so that you can compete when you are fully prepared.&lt;/p&gt;

&lt;p&gt;There is also a community contribution section where more than &lt;strong&gt;10,000&lt;/strong&gt; data scientists and machine learning developers share their experiences, tips, tutorials, etc so that other participants can learn from them.&lt;/p&gt;

&lt;p&gt;That's the end folks. Hope you enjoyed this. Comment below if I missed any. You can connect with me on &lt;a href="https://twitter.com/%20__Bharadwaj__"&gt;Twitter&lt;/a&gt; where I daily post a thread on Data Science or Machine Learning.&lt;/p&gt;

</description>
      <category>datascience</category>
      <category>machinelearning</category>
      <category>100daysofcode</category>
    </item>
    <item>
      <title>Best Software Solution Companies To Hire Mulesoft Dvelopers 2021</title>
      <author>Software Services</author>
      <pubDate>Tue, 07 Sep 2021 10:34:23 +0000</pubDate>
      <link>https://dev.to/tkxel/best-software-solution-companies-to-hire-mulesoft-dvelopers-2021-12p9</link>
      <guid>https://dev.to/tkxel/best-software-solution-companies-to-hire-mulesoft-dvelopers-2021-12p9</guid>
      <description>&lt;h2&gt;Tkxel&lt;/h2&gt;

&lt;p&gt;Tkxel is a leading software development company located in Reston, Virginia. We are committed to develop innovative software solutions for leading enterprises in the world, helping them grow their businesses using latest technology solutions. Delivering Industry Leading Integration Solutions.&lt;/p&gt; 

&lt;p&gt;Tkxel help you solve complex integration problems by leveraging our &lt;a href="https://tkxel.com/mulesoft-consulting-services/"&gt;Experts MuleSoft Developers&lt;/a&gt;. Tkxel Provides &lt;a href="https://tkxel.com/mulesoft-consulting-services/"&gt;expert MuleSoft development services&lt;/a&gt;, making your ecosystem more connected and integrated than ever, designing results-driven digital solutions.&lt;/p&gt;

&lt;h2&gt;Avogtal&lt;/h2&gt;

&lt;p&gt;We know you have a business to run, so why focus on the technicalities when you have us to help? Let us find the perfect tech sources for you at the right time and price.&lt;/p&gt;

&lt;p&gt;Everyone wants to show what they can contribute to their profession, and we can help you do that. Participate in an assessment to match your qualifications and skillsets with ideal, career-defining opportunities where you can make a difference.&lt;/p&gt;



&lt;p&gt;Integrate skilled and seasoned &lt;a&gt;Hire Mulesoft developers&lt;/a&gt; from us to connect applications, data, and devices ‚Äì quickly, efficiently, and cost-effectively. Our Mulesoft experts are skilled at helping businesses to connect their apps on-premise or in the cloud.&lt;/p&gt;

&lt;h2&gt;Appnovation&lt;/h2&gt;

&lt;p&gt;We help businesses advance and inspire, create positive transformation, and champion digital innovation. Look over the horizon of the digital landscape -- that's where we can take you.

&lt;/p&gt;
&lt;li&gt;End-to-end services, endless ideas. &lt;/li&gt;
&lt;br&gt;
&lt;p&gt;With a team of certified experts, Appnovation offers a full range of MuleSoft development services. Our expert MuleSoft developers deliver enterprise level integrations, which work within your existing database, allowing custom applications and results driven solutions. Our developers and consultants can also conduct architectural reviews and platform audits, to understand the API‚Äôs and touch points across the application network.&lt;/p&gt;

&lt;p&gt;Whether on-premise or cloud based, we will connect and integrate your application, data source, or API. Our &lt;a href="https://www.appnovation.com/services/mulesoft-development"&gt;expert MuleSoft&lt;/a&gt; enterprise architects design scalable architecture that supports multi-platform integrations, all based on your business requirements.&lt;/p&gt;

&lt;h2&gt;SilverLinecrm&lt;/h2&gt;

&lt;p&gt;The average organization uses 88 applications, with larger organizations using an average of 175 applications.&lt;/p&gt;


&lt;li&gt;That gets unwieldy, fast. &lt;/li&gt;
&lt;br&gt;

&lt;p&gt;For companies trying to deliver a seamless customer experience, working with so many different systems creates disjointed, distributed  customer data. Employees interacting with customers often have to jump from system to system to access the data they need, or simply lack access to it at all. It‚Äôs impossible to create a customer-centric experience without the right data in place.&lt;/p&gt;

&lt;p&gt;What organizations need is a way to easily and quickly connect these various systems. They also need a scalable strategy so that they can easily build new integrations as new systems are added to and subtracted from their tech stack.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://silverlinecrm.com/mulesoft/"&gt;Enter MuleSoft&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Girikon&lt;/h2&gt;

&lt;p&gt;We are a Salesforce Consulting Partner dedicated to providing full-suite of MuleSoft development services. Our company is committed to connecting the business applications of our clients through MuleSoft in the cloud or on-premise solutions. By leveraging our specialized MuleSoft consulting services, organizations can turn their data into digital assets through the integration of different systems.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.girikon.com/mulesoft-consulting/"&gt;Girikon MuleSoft consultants&lt;/a&gt; has expertise in developing integration strategies that can help companies get the desired business outcome. So, whether you wish to modernize your systems, systematize core processes, or migrate applications to the cloud, we follow API best-practices to identify, develop and implement solutions that meet the specific needs of your business today, as well as for future projects.&lt;/p&gt;

&lt;p&gt;We create a high-end architectural design and build API networks that pave way for seamless communication among your business applications. Our knowledge and expertise in the MuleSoft platform along with architectural best practices make us well-resourced to manage all types of integration scenarios including the most complex ones.&lt;/p&gt;

&lt;h2&gt;Toptal&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://www.toptal.com"&gt;Toptal&lt;/a&gt; is a marketplace for top MuleSoft developers, engineers, programmers, coders, architects, and consultants. Top companies and start-ups choose Toptal MuleSoft freelancers for their mission-critical software projects.&lt;/p&gt;

&lt;p&gt;Toptal offers top MuleSoft developers, programmers, and software engineers on an hourly, part-time, or full-time contract basis. Clients include Thumbtack, Bridgestone, and Motorola.&lt;/p&gt;

</description>
      <category>devops</category>
      <category>mulesofthackathon</category>
      <category>aws</category>
      <category>algorithms</category>
    </item>
    <item>
      <title>Reading and writing data across different AWS accounts with Amazon Managed Workflows for Apache Airflow v2.x</title>
      <author>Ricardo Sueiras</author>
      <pubDate>Tue, 07 Sep 2021 10:33:12 +0000</pubDate>
      <link>https://dev.to/aws/reading-and-writing-data-across-different-aws-accounts-with-amazon-managed-workflows-for-apache-airflow-v2-x-3319</link>
      <guid>https://dev.to/aws/reading-and-writing-data-across-different-aws-accounts-with-amazon-managed-workflows-for-apache-airflow-v2-x-3319</guid>
      <description>&lt;p&gt;&lt;strong&gt;Reading and writing data across different AWS accounts in you Apache Airflow DAGs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;As regular readers will know, I sometimes lurk in the Apache Airflow slack channel to see what is going on. If you are new to Apache Airflow, or want to get a deeper understanding then I highly recommend spending some time here. The community is super welcoming and eager to help new participants.&lt;/p&gt;

&lt;p&gt;It was during a recent session I came across an interesting problem that one of the builders was having, which was how to access (read/write) data in an S3 bucket which was in a different account to the one hosting Amazon Managed Workflows for Apache Airflow (MWAA). &lt;/p&gt;

&lt;p&gt;The rest of this post will be a quick look at the setup, the error that occurred and how to configure MWAA so that you can read/write data confidently across your different AWS accounts.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#the-problem"&gt;
  &lt;/a&gt;
  The problem
&lt;/h3&gt;

&lt;p&gt;A customer was using MWAA 2.0.2, and within their workflow, they were trying to upload data to an S3 bucket in a different AWS account to what their MWAA environment was running in. When they triggered their DAG, they were getting errors such as the following:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt; An error occurred (AccessDenied) when calling the PutObject operation: Access Denied
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;To help with troubleshooting, the customer had created a test DAG that would try and read/write files to a sample S3 bucket in three ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;using boto3, the Python SDK for interacting with AWS&lt;/li&gt;
&lt;li&gt;using Apache Airflow operators - airflow.providers.amazon.aws.hooks.s3&lt;/li&gt;
&lt;li&gt;using the pandas Python library - using s3fs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here is the test DAG that the customer put together&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;import logging
import random
from datetime import timedelta
import pandas as pd
import boto3
from airflow.models import Variable
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.amazon.aws.hooks.s3 import S3Hook
from airflow.utils.dates import days_ago


def save_file_to_s3():
    n = random.randint(100, 10000)
    filename = f'demo_{n}.csv'
    local_file_path = f'/tmp/{filename}'
    demo_data = pd.DataFrame({'num_legs': [2, 4, 8, 0],
                              'num_wings': [2, 0, 0, 0],
                              'num_specimen_seen': [10, 2, 1, 8]},
                             index=['falcon', 'dog', 'spider', 'fish'])
    demo_data.to_csv(local_file_path, index=False)

    bucket_name = Variable.get('TEST_BUCKET')
    folder_name = Variable.get('TEST_FOLDER')
    s3_key = f'{folder_name}/boto3_{filename}'
    logging.info(f'local_file_path: {local_file_path}, bucket_name: {bucket_name}, key: {s3_key}')

    logging.info('Uploading CSV to S3 with boto3')
    s3 = boto3.resource('s3')
    try:
        s3.meta.client.upload_file(local_file_path, bucket_name, s3_key, ExtraArgs={'ACL': 'bucket-owner-full-control'})
    except Exception as e:
        logging.info(e)
        pass
    logging.info('Done uploading CSV to S3 with boto3')
    logging.info('Uploading CSV to S3 with S3HOOK')
    s3_hook = S3Hook()
    s3_key = f'{folder_name}/s3hook_{filename}'
    try:
        s3_hook.load_file(local_file_path, bucket_name=bucket_name, key=s3_key, acl_policy='bucket-owner-full-control')
    except Exception as e:
        logging.info(e)
        pass
    logging.info('Done uploading CSV to S3 with S3HOOK')

    logging.info('Uploading CSV to S3 with pandas')
    demo_data.to_csv(f's3://{bucket_name}/{folder_name}/pandas_{filename}', index=False)
    logging.info('Done uploading CSV to S3 with pandas')


def run_dag():
    save_file_to_s3()


dag_default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email': ['airflow@example.com'],
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 0,
    'retry_delay': timedelta(minutes=2)
}

with DAG(
    'demo',
    default_args=dag_default_args,
    description='description',
    schedule_interval="0 10 * * *",
    start_date=days_ago(1),
    tags=['test'],
) as dag:
    test_dag = PythonOperator(
        task_id="test_dag",
        python_callable=run_dag
    )

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;What was interesting, was that when they ran the DAG, the boto3 function would write the file to the target S3 bucket, but the other two failed.&lt;/p&gt;

&lt;p&gt;Time to take a closer look.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#the-approach"&gt;
  &lt;/a&gt;
  The approach
&lt;/h3&gt;

&lt;p&gt;I wanted to see if I could reproduce this issue, so the approach I took was to &lt;/p&gt;

&lt;p&gt;1/ set up an environment running the same version of MWAA as the customer, but initially use an S3 bucket in the SAME account to make sure that everything works as expected, &lt;/p&gt;

&lt;p&gt;2/ setup a new S3 bucket on a different AWS account and repeat to see if I could reproduce the error, &lt;/p&gt;

&lt;p&gt;3/ review CloudTrail and MWAA logs to see if I could identify any issues and fix.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#the-setup"&gt;
  &lt;/a&gt;
  The setup
&lt;/h3&gt;

&lt;p&gt;The customer was running a standard MWAA 2.0.2 environment in one AWS account, so I quickly provisioned an environment (using my CDK application &lt;a href="https://dev.to/aws/using-aws-cdk-to-deploy-your-amazon-managed-workflows-for-apache-airflow-environment-12cf"&gt;which I have blogged about before&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;I deployed the above DAG, and then had to do a couple of things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;create a new S3 bucket (in my case, I called this "ricsue-airflow-s3hook" and within this bucket, I created a folder called "s3permissions")&lt;/li&gt;
&lt;li&gt;adjusted the permissions for the MWAA execution role (which you can find by opening up your MWAA environment in the AWS console) to include the new bucket I just created
&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;...
            "Resource": [
                "arn:aws:s3:::airflow-ricsue-cdk-demo/*",
                "arn:aws:s3:::airflow-ricsue-cdk-demo",
                "arn:aws:s3:::ricsue-airflow-s3hook/*",
                "arn:aws:s3:::ricsue-airflow-s3hook"
            ],
            "Effect": "Allow"
...
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;ul&gt;
&lt;li&gt;within the MWAA console, using the Admin menu option in the Apache Airflow UI, I created two new variables: TEST_BUKCET (with a value of "ricsue-airflow-s3hook") and TEST_FOLDER (with a value of "s3permissions")&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once I had completed that, I enabled it and then manually triggered it. It failed with the following error:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;[2021-09-06 12:36:26,255] {{customer-s3.py:26}} INFO - local_file_path: /tmp/demo_2025.csv, bucket_name: ricsue-airflow-s3hook, key: s3permissions/boto3_demo_2025.csv
[2021-09-06 12:36:26,284] {{customer-s3.py:28}} INFO - Uploading CSV to S3 with boto3
[2021-09-06 12:36:26,429] {{customer-s3.py:35}} INFO - Done uploading CSV to S3 with boto3
[2021-09-06 12:36:26,455] {{customer-s3.py:36}} INFO - Uploading CSV to S3 with S3HOOK
[2021-09-06 12:36:26,487] {{logging_mixin.py:104}} INFO - [2021-09-06 12:36:26,486] {{base_aws.py:368}} INFO - Airflow Connection: aws_conn_id=aws_default
[2021-09-06 12:36:26,545] {{logging_mixin.py:104}} INFO - [2021-09-06 12:36:26,545] {{base_aws.py:179}} INFO - No credentials retrieved from Connection
[2021-09-06 12:36:26,571] {{logging_mixin.py:104}} INFO - [2021-09-06 12:36:26,571] {{base_aws.py:87}} INFO - Creating session with aws_access_key_id=None region_name=None
[2021-09-06 12:36:26,613] {{logging_mixin.py:104}} INFO - [2021-09-06 12:36:26,613] {{base_aws.py:157}} INFO - role_arn is None
[2021-09-06 12:36:26,782] {{customer-s3.py:44}} INFO - Done uploading CSV to S3 with S3HOOK
[2021-09-06 12:36:26,813] {{customer-s3.py:46}} INFO - Uploading CSV to S3 with pandas
[2021-09-06 12:36:26,851] {{taskinstance.py:1482}} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1138, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1311, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1341, in _execute_task
    result = task_copy.execute(context=context)
  File "/usr/local/lib/python3.7/site-packages/airflow/operators/python.py", line 117, in execute
    return_value = self.execute_callable()
  File "/usr/local/lib/python3.7/site-packages/airflow/operators/python.py", line 128, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/usr/local/airflow/dags/customer-s3.py", line 52, in run_dag
    save_file_to_s3()
  File "/usr/local/airflow/dags/customer-s3.py", line 47, in save_file_to_s3
    demo_data.to_csv(f's3://{bucket_name}/{folder_name}/pandas_{filename}', index=False)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/generic.py", line 3403, in to_csv
    storage_options=storage_options,
  File "/usr/local/lib64/python3.7/site-packages/pandas/io/formats/format.py", line 1083, in to_csv
    csv_formatter.save()
  File "/usr/local/lib64/python3.7/site-packages/pandas/io/formats/csvs.py", line 234, in save
    storage_options=self.storage_options,
  File "/usr/local/lib64/python3.7/site-packages/pandas/io/common.py", line 563, in get_handle
    storage_options=storage_options,
  File "/usr/local/lib64/python3.7/site-packages/pandas/io/common.py", line 315, in _get_filepath_or_buffer
    fsspec = import_optional_dependency("fsspec")
  File "/usr/local/lib64/python3.7/site-packages/pandas/compat/_optional.py", line 109, in import_optional_dependency
    raise ImportError(msg) from None
ImportError: Missing optional dependency 'fsspec'.  Use pip or conda to install fsspec.
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Whilst the boto3 and Apache Airflow operators had worked, the Python library (pandas) had not. This is because they were not installed on the Apache Airflow worker nodes.&lt;/p&gt;

&lt;p&gt;I amended the requirements text to add the following:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;fsspec
s3fs
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Once uploaded, the MWAA environment had to be updated. This took approx 20 mins, but once it completed, I was then able to trigger the DAG successfully. No errors, and when I looked in the local S3 bucket, I could see the following files:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;boto3_demo_9977.csv
s3hook_demo_9977.csv
pandas_demo_9977.csv
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;So, the first step completed - we have everything working as expected. Now to change the DAG to write those files to an S3 bucket in a different AWS account.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#the-error"&gt;
  &lt;/a&gt;
  The error
&lt;/h3&gt;

&lt;p&gt;In order to reproduce the same setup as the customer, I had to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;create a new S3 bucket in a different AWS account - (in my case, I called this "ricsue-airflow-s3hook-diffawsaccount" and within this bucket, I kept the same folder called "s3permissions")&lt;/li&gt;
&lt;li&gt;I needed to UPDATE the Apache Airflow variable, TEST_BUCKET. From within the Apache Airflow UI, I edited the value to point to this new bucket and the different AWS account.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To make this easier, I had two browsers running with Chrome running my AWS account with MWAA, and Firefox running a different AWS account with just the Amazon S3 bucket.&lt;/p&gt;

&lt;p&gt;Once I had made those changes, I triggered the DAG again. I did not expect ANY of these ways to upload the file to work given that these are two separate AWS accounts, but I wanted to baseline. Sure enough, I got the following error with the DAG failing:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;[2021-09-06 13:18:54,317] {{customer-s3.py:26}} INFO - local_file_path: /tmp/demo_5839.csv, bucket_name: ricsue-airflow-s3hook-diffawsaccount, key: s3permissions/boto3_demo_5839.csv
[2021-09-06 13:18:54,344] {{customer-s3.py:28}} INFO - Uploading CSV to S3 with boto3
[2021-09-06 13:18:54,479] {{customer-s3.py:33}} INFO - Failed to upload /tmp/demo_5839.csv to ricsue-airflow-s3hook-diffawsaccount/s3permissions/boto3_demo_5839.csv: An error occurred (AccessDenied) when calling the PutObject operation: Access Denied
[2021-09-06 13:18:54,507] {{customer-s3.py:35}} INFO - Done uploading CSV to S3 with boto3
[2021-09-06 13:18:54,531] {{customer-s3.py:36}} INFO - Uploading CSV to S3 with S3HOOK
[2021-09-06 13:18:54,558] {{logging_mixin.py:104}} INFO - [2021-09-06 13:18:54,558] {{base_aws.py:368}} INFO - Airflow Connection: aws_conn_id=aws_default
[2021-09-06 13:18:54,602] {{logging_mixin.py:104}} INFO - [2021-09-06 13:18:54,602] {{base_aws.py:179}} INFO - No credentials retrieved from Connection
[2021-09-06 13:18:54,631] {{logging_mixin.py:104}} INFO - [2021-09-06 13:18:54,631] {{base_aws.py:87}} INFO - Creating session with aws_access_key_id=None region_name=None
[2021-09-06 13:18:54,673] {{logging_mixin.py:104}} INFO - [2021-09-06 13:18:54,673] {{base_aws.py:157}} INFO - role_arn is None
[2021-09-06 13:18:54,792] {{customer-s3.py:42}} INFO - An error occurred (403) when calling the HeadObject operation: Forbidden
[2021-09-06 13:18:54,818] {{customer-s3.py:44}} INFO - Done uploading CSV to S3 with S3HOOK
[2021-09-06 13:18:54,850] {{customer-s3.py:46}} INFO - Uploading CSV to S3 with pandas
[2021-09-06 13:18:56,049] {{taskinstance.py:1482}} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/s3fs/core.py", line 248, in _call_s3
    out = await method(**additional_kwargs)
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/aiobotocore/client.py", line 155, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the CreateBucket operation: Access Denied

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1138, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1311, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1341, in _execute_task
    result = task_copy.execute(context=context)
  File "/usr/local/lib/python3.7/site-packages/airflow/operators/python.py", line 117, in execute
    return_value = self.execute_callable()
  File "/usr/local/lib/python3.7/site-packages/airflow/operators/python.py", line 128, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/usr/local/airflow/dags/customer-s3.py", line 52, in run_dag
    save_file_to_s3()
  File "/usr/local/airflow/dags/customer-s3.py", line 47, in save_file_to_s3
    demo_data.to_csv(f's3://{bucket_name}/{folder_name}/pandas_{filename}', index=False)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/generic.py", line 3403, in to_csv
    storage_options=storage_options,
  File "/usr/local/lib64/python3.7/site-packages/pandas/io/formats/format.py", line 1083, in to_csv
    csv_formatter.save()
  File "/usr/local/lib64/python3.7/site-packages/pandas/io/formats/csvs.py", line 234, in save
    storage_options=self.storage_options,
  File "/usr/local/lib64/python3.7/site-packages/pandas/io/common.py", line 563, in get_handle
    storage_options=storage_options,
  File "/usr/local/lib64/python3.7/site-packages/pandas/io/common.py", line 345, in _get_filepath_or_buffer
    filepath_or_buffer, mode=fsspec_mode, **(storage_options or {})
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/fsspec/core.py", line 438, in open
    **kwargs,
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/fsspec/core.py", line 292, in open_files
    [fs.makedirs(parent, exist_ok=True) for parent in parents]
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/fsspec/core.py", line 292, in &amp;lt;listcomp&amp;gt;
    [fs.makedirs(parent, exist_ok=True) for parent in parents]
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/fsspec/asyn.py", line 88, in wrapper
    return sync(self.loop, func, *args, **kwargs)
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/fsspec/asyn.py", line 69, in sync
    raise result[0]
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/fsspec/asyn.py", line 25, in _runner
    result[0] = await coro
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/s3fs/core.py", line 731, in _makedirs
    await self._mkdir(path, create_parents=True)
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/s3fs/core.py", line 716, in _mkdir
    await self._call_s3("create_bucket", **params)
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/s3fs/core.py", line 268, in _call_s3
    raise err
PermissionError: Access Denied
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;As we can see, all three methods failed. Exactly what I expected.&lt;/p&gt;

&lt;p&gt;What was strange was that the customer was not seeing this issue, and was able to write to the target S3 bucket using boto3. Lets see how to reproduce that in my environment.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#the-fix"&gt;
  &lt;/a&gt;
  The fix
&lt;/h3&gt;

&lt;p&gt;Within your Amazon S3 bucket, you have the ability to define bucket policies that allow access to read/write files from other AWS accounts.&lt;/p&gt;

&lt;p&gt;In the NEW AWS account, I created the following bucket policy for the new bucket I had created ("ricsue-airflow-s3hook-diffawsaccount"). This is what I added:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::704533066374:role/mwaa-2-eks-role"
            },
            "Action": [
                "s3:GetObject*",
                "s3:GetBucket*",
                "s3:List*",
                "s3:PutObject*"
            ],
            "Resource": [
                "arn:aws:s3:::ricsue-airflow-s3hook-diffawsaccount/*",
                "arn:aws:s3:::ricsue-airflow-s3hook-diffawsaccount"
            ]
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The policy containers the arn of the MWAA execution role for my MWAA environment in my original AWS account, configures allowed actions (in this instance, I have narrowed it down to these actions - GetObject* , GetBucket* , List* , and PutObject* ) and then configured the target S3 buckets resources (here it is all resources under this bucket, but you could also reduce the scope to just certain folders if you wanted to)&lt;/p&gt;

&lt;p&gt;When I saved this, and then re-ran the DAG. Success, it all worked.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;[2021-09-06 18:09:15,305] {{customer-s3.py:26}} INFO - local_file_path: /tmp/demo_3455.csv, bucket_name: ricsue-airflow-s3hook-diffawsaccount, key: s3permissions/boto3_demo_3455.csv
[2021-09-06 18:09:15,335] {{customer-s3.py:28}} INFO - Uploading CSV to S3 with boto3
[2021-09-06 18:09:15,499] {{customer-s3.py:35}} INFO - Done uploading CSV to S3 with boto3
[2021-09-06 18:09:15,564] {{customer-s3.py:36}} INFO - Uploading CSV to S3 with S3HOOK
[2021-09-06 18:09:15,592] {{logging_mixin.py:104}} INFO - [2021-09-06 18:09:15,592] {{base_aws.py:368}} INFO - Airflow Connection: aws_conn_id=aws_default
[2021-09-06 18:09:15,632] {{logging_mixin.py:104}} INFO - [2021-09-06 18:09:15,632] {{base_aws.py:179}} INFO - No credentials retrieved from Connection
[2021-09-06 18:09:15,681] {{logging_mixin.py:104}} INFO - [2021-09-06 18:09:15,681] {{base_aws.py:87}} INFO - Creating session with aws_access_key_id=None region_name=None
[2021-09-06 18:09:15,719] {{logging_mixin.py:104}} INFO - [2021-09-06 18:09:15,719] {{base_aws.py:157}} INFO - role_arn is None
[2021-09-06 18:09:15,859] {{customer-s3.py:44}} INFO - Done uploading CSV to S3 with S3HOOK
[2021-09-06 18:09:15,887] {{customer-s3.py:46}} INFO - Uploading CSV to S3 with pandas
[2021-09-06 18:09:16,729] {{customer-s3.py:48}} INFO - Done uploading CSV to S3 with pandas
[2021-09-06 18:09:16,762] {{python.py:118}} INFO - Done. Returned value was: None
[2021-09-06 18:09:16,805] {{taskinstance.py:1192}} INFO - Marking task as SUCCESS. dag_id=demo, task_id=test_dag, execution_date=20210906T180913, start_date=20210906T180914, end_date=20210906T180916
[2021-09-06 18:09:16,901] {{taskinstance.py:1246}} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2021-09-06 18:09:16,943] {{logging_mixin.py:104}} INFO - [2021-09-06 18:09:16,943] {{local_task_job.py:146}} INFO - Task exited with return code 0
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;But wait, that does not describe the customer problem. They could get it working with boto3, so what is going on then?&lt;/p&gt;

&lt;p&gt;I altered the bucket policy so that it had fewer permissions, specifically removing the List* as follows:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::704533066374:role/mwaa-2-eks-role"
            },
            "Action": [
                "s3:GetObject*",
                "s3:GetBucket*",
                "s3:PutObject*"
            ],
            "Resource": [
                "arn:aws:s3:::ricsue-airflow-s3hook-diffawsaccount/*",
                "arn:aws:s3:::ricsue-airflow-s3hook-diffawsaccount"
            ]
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;And when I re-ran the DAG, boto3 worked, but the S3 Hook and the pandas failed with permissions errors:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;[2021-09-06 18:07:11,238] {{customer-s3.py:26}} INFO - local_file_path: /tmp/demo_6465.csv, bucket_name: ricsue-airflow-s3hook-diffawsaccount, key: s3permissions/boto3_demo_6465.csv
[2021-09-06 18:07:11,263] {{customer-s3.py:28}} INFO - Uploading CSV to S3 with boto3
[2021-09-06 18:07:11,420] {{customer-s3.py:35}} INFO - Done uploading CSV to S3 with boto3
[2021-09-06 18:07:11,454] {{customer-s3.py:36}} INFO - Uploading CSV to S3 with S3HOOK
[2021-09-06 18:07:11,481] {{logging_mixin.py:104}} INFO - [2021-09-06 18:07:11,481] {{base_aws.py:368}} INFO - Airflow Connection: aws_conn_id=aws_default
[2021-09-06 18:07:11,547] {{logging_mixin.py:104}} INFO - [2021-09-06 18:07:11,546] {{base_aws.py:179}} INFO - No credentials retrieved from Connection
[2021-09-06 18:07:11,571] {{logging_mixin.py:104}} INFO - [2021-09-06 18:07:11,571] {{base_aws.py:87}} INFO - Creating session with aws_access_key_id=None region_name=None
[2021-09-06 18:07:11,578] {{logging_mixin.py:104}} WARNING - /usr/local/airflow/.local/lib/python3.7/site-packages/watchtower/__init__.py:205 WatchtowerWarning: Failed to deliver logs: None
[2021-09-06 18:07:11,649] {{logging_mixin.py:104}} INFO - [2021-09-06 18:07:11,649] {{base_aws.py:157}} INFO - role_arn is None
[2021-09-06 18:07:11,761] {{customer-s3.py:42}} INFO - An error occurred (403) when calling the HeadObject operation: Forbidden
[2021-09-06 18:07:11,789] {{customer-s3.py:44}} INFO - Done uploading CSV to S3 with S3HOOK
[2021-09-06 18:07:11,817] {{customer-s3.py:46}} INFO - Uploading CSV to S3 with pandas
[2021-09-06 18:07:12,347] {{taskinstance.py:1482}} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/s3fs/core.py", line 248, in _call_s3
    out = await method(**additional_kwargs)
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/aiobotocore/client.py", line 155, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the CreateBucket operation: Access Denied

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1138, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1311, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1341, in _execute_task
    result = task_copy.execute(context=context)
  File "/usr/local/lib/python3.7/site-packages/airflow/operators/python.py", line 117, in execute
    return_value = self.execute_callable()
  File "/usr/local/lib/python3.7/site-packages/airflow/operators/python.py", line 128, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/usr/local/airflow/dags/customer-s3.py", line 52, in run_dag
    save_file_to_s3()
  File "/usr/local/airflow/dags/customer-s3.py", line 47, in save_file_to_s3
    demo_data.to_csv(f's3://{bucket_name}/{folder_name}/pandas_{filename}', index=False)
  File "/usr/local/lib64/python3.7/site-packages/pandas/core/generic.py", line 3403, in to_csv
    storage_options=storage_options,
  File "/usr/local/lib64/python3.7/site-packages/pandas/io/formats/format.py", line 1083, in to_csv
    csv_formatter.save()
  File "/usr/local/lib64/python3.7/site-packages/pandas/io/formats/csvs.py", line 234, in save
    storage_options=self.storage_options,
  File "/usr/local/lib64/python3.7/site-packages/pandas/io/common.py", line 563, in get_handle
    storage_options=storage_options,
  File "/usr/local/lib64/python3.7/site-packages/pandas/io/common.py", line 345, in _get_filepath_or_buffer
    filepath_or_buffer, mode=fsspec_mode, **(storage_options or {})
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/fsspec/core.py", line 438, in open
    **kwargs,
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/fsspec/core.py", line 292, in open_files
    [fs.makedirs(parent, exist_ok=True) for parent in parents]
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/fsspec/core.py", line 292, in &amp;lt;listcomp&amp;gt;
    [fs.makedirs(parent, exist_ok=True) for parent in parents]
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/fsspec/asyn.py", line 88, in wrapper
    return sync(self.loop, func, *args, **kwargs)
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/fsspec/asyn.py", line 69, in sync
    raise result[0]
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/fsspec/asyn.py", line 25, in _runner
    result[0] = await coro
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/s3fs/core.py", line 731, in _makedirs
    await self._mkdir(path, create_parents=True)
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/s3fs/core.py", line 716, in _mkdir
    await self._call_s3("create_bucket", **params)
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/s3fs/core.py", line 268, in _call_s3
    raise err
PermissionError: Access Denied
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;So, we can close that loop. We now understand under what scenarios this might work (target S3 bucket policy not having the right permissions for the various methods of uploading files) and we can address/solve this as needed.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#conclusion"&gt;
  &lt;/a&gt;
  Conclusion
&lt;/h3&gt;

&lt;p&gt;In this post I showed you how you can set up your S3 buckets so that you can use them to read and write data from your MWAA environment. I showed you how this works whether you are doing this via boto3, using the Apache Airflow S3 operator,  or doing this via a third party Python library.&lt;/p&gt;

&lt;p&gt;Please let me know via the comments of any additional questions or comments you have on this post.&lt;/p&gt;

&lt;p&gt;You can view/use the files that accompany this blog &lt;a href="https://github.com/094459/blog-mwaa-xaccount"&gt;via the GitHub repository link here&lt;/a&gt;&lt;/p&gt;

</description>
      <category>opensource</category>
      <category>aws</category>
    </item>
    <item>
      <title>Introducing Magic URL Login to Appwrite</title>
      <author>Torsten Dittmann</author>
      <pubDate>Tue, 07 Sep 2021 10:17:45 +0000</pubDate>
      <link>https://dev.to/appwrite/introducing-magic-url-login-to-appwrite-2l</link>
      <guid>https://dev.to/appwrite/introducing-magic-url-login-to-appwrite-2l</guid>
      <description>&lt;p&gt;Appwrite 0.10 introduces &lt;strong&gt;Magic URL&lt;/strong&gt; as an authentication method, which allows users to create an account without providing a password and login with a URL sent via an E-Mail.&lt;/p&gt;

&lt;p&gt;This feature is especially useful if you want to provide a passwordless authentication process for your application.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--XwPWEfwx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/koceo7503ykvehk3cibc.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--XwPWEfwx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/koceo7503ykvehk3cibc.png" alt="Appwrite Dashboard"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#setup"&gt;
  &lt;/a&gt;
  ‚öôÔ∏è Setup
&lt;/h1&gt;

&lt;p&gt;Let's learn how we can add Magic URL Authentication to a Web Application using our &lt;a href="https://appwrite.io/docs/getting-started-for-web"&gt;Web SDK&lt;/a&gt;. The same can be done with our &lt;a href="https://appwrite.io/docs/getting-started-for-flutter"&gt;Flutter SDK&lt;/a&gt; and &lt;a href="https://appwrite.io/docs/getting-started-for-android"&gt;Android SDK&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The first step is to add our Web SDK to our project with NPM like this:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;npm &lt;span class="nb"&gt;install &lt;/span&gt;appwrite &lt;span class="nt"&gt;--save&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;If you're using a bundler (like &lt;a href="https://rollupjs.org/"&gt;Rollup&lt;/a&gt; or &lt;a href="https://webpack.js.org/"&gt;webpack&lt;/a&gt;), you can import the Appwrite module when you need it:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;Appwrite&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;appwrite&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;To install with a CDN (content delivery network) add the following script to your HTML file before you use any Appwrite services:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight html"&gt;&lt;code&gt;&lt;span class="nt"&gt;&amp;lt;script &lt;/span&gt;&lt;span class="na"&gt;src=&lt;/span&gt;&lt;span class="s"&gt;"https://cdn.jsdelivr.net/npm/appwrite"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The next step is to initialize your SDK code with your project ID which can be found in your project settings page:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// Init your Web SDK&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;appwrite&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;Appwrite&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;

&lt;span class="nx"&gt;appwrite&lt;/span&gt;
    &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;setEndpoint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;http://localhost/v1&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;// Your Appwrite Endpoint&lt;/span&gt;
    &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;setProject&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;455x34dfkj&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;// Your Appwrite Project ID&lt;/span&gt;
&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h1&gt;
  &lt;a href="#create-a-magic-url"&gt;
  &lt;/a&gt;
  üé© Create a Magic URL
&lt;/h1&gt;

&lt;p&gt;Once your SDK is setup, access the &lt;strong&gt;Account service&lt;/strong&gt; and call the &lt;a href="https://appwrite.io/docs/client/account?sdk=web#accountCreateMagicURLSession"&gt;&lt;code&gt;createMagicURLSession()&lt;/code&gt;&lt;/a&gt; method. The method accepts an e-mail address and a redirect URL as arguments.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// Initiate the Magic URL login&lt;/span&gt;
&lt;span class="nx"&gt;appwrite&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;account&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;createMagicURLSession&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;name@example.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;http://localhost/&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;then&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// Success&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="nx"&gt;error&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;error&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// Failure&lt;/span&gt;
    &lt;span class="p"&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;If the &lt;a href="https://appwrite.io/docs/client/account?sdk=web#accountCreateMagicURLSession"&gt;&lt;code&gt;createMagicURLSession()&lt;/code&gt;&lt;/a&gt; method completes without error, the request sends the user an email with a URL containing a secret key for the next step. When the user clicks the link, they are redirected back to the URL you provided with the secret key and userId values attached to the URL query string. This link is valid for 1 hour. If the e-mail passed did not belong to any existing user - this request will also create a user for the passed e-mail address.&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#login-with-a-magic-url"&gt;
  &lt;/a&gt;
  üîê Login with a Magic URL
&lt;/h1&gt;

&lt;p&gt;Now that the user is able to initialize the authentication process, we need to complete it by handling the redirect from the URL provided in the e-mail.&lt;/p&gt;

&lt;p&gt;Use the &lt;a href="https://appwrite.io/docs/client/account?sdk=web#accountUpdateMagicURLSession"&gt;&lt;code&gt;updateMagicURLSession()&lt;/code&gt;&lt;/a&gt; method and call it with the secret and userId values from the URL's query string.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Please note that in order to avoid a &lt;a href="https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.md"&gt;Redirect Attack&lt;/a&gt; the only valid redirect URLs are the ones from domains you have set when adding your platforms in the console interface.&lt;br&gt;
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;urlParams&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;URLSearchParams&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;window&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;location&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;search&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;userId&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;urlParams&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;userId&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;secret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;urlParams&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;secret&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nx"&gt;promise&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;appwrite&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;account&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;updateMagicURLSession&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;userId&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;secret&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="nx"&gt;promise&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;then&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// Success&lt;/span&gt;
&lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;error&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;error&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;// Failure&lt;/span&gt;
&lt;span class="p"&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;If the &lt;a href="https://appwrite.io/docs/client/account?sdk=web#accountUpdateMagicURLSession"&gt;&lt;code&gt;updateMagicURLSession()&lt;/code&gt;&lt;/a&gt; succeeded, the user is now logged in. Note that once a link is used, it cannot be used again.&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#conclusion"&gt;
  &lt;/a&gt;
  üèÅ Conclusion
&lt;/h1&gt;

&lt;p&gt;If you need help or encounter any difficulties setting up Magic URL Login with Appwrite, please &lt;a href="https://appwrite.io/discord"&gt;join our Discord&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#references"&gt;
  &lt;/a&gt;
  üîñ References
&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://appwrite.io/discord"&gt;Appwrite Discord&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://appwrite.io/docs"&gt;Appwrite Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://appwrite.io"&gt;Appwrite Homepage&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
      <category>opensource</category>
      <category>webdev</category>
      <category>javascript</category>
      <category>news</category>
    </item>
    <item>
      <title>Making digital currency; How to create a new cryptocurrency
</title>
      <author>ahmadradindev</author>
      <pubDate>Tue, 07 Sep 2021 10:09:48 +0000</pubDate>
      <link>https://dev.to/ahmadradindev/making-digital-currency-how-to-create-a-new-cryptocurrency-2c7</link>
      <guid>https://dev.to/ahmadradindev/making-digital-currency-how-to-create-a-new-cryptocurrency-2c7</guid>
      <description>&lt;p&gt;In recent years, many startups have made a lot of money by creating a digital currency and selling tokens in the initial public offering. Creating a new digital currency may seem like an impossible process to most people. While making digital currency is possible if you have enough knowledge in this field. In this article, we will introduce you to the methods of making a digital currency and at the end, we will answer some common questions in this regard.&lt;/p&gt;

&lt;p&gt;Why are new digital currencies being created?&lt;br&gt;
Even if virtual money has been available to the public for a long time, Bitcoin is the first known and most successful cryptocurrency in the cryptocurrency market. Many cryptocurrencies have been created today, the most popular of which are Bitcoin, Ripple, and Atrium.&lt;/p&gt;

&lt;p&gt;Some unique features make companies and individuals think about creating cryptocurrencies. The most important features of digital currency are cryptography, security and confidentiality, no need to monitor a central institution, transparency of transactions, fast transactions, and ease of transfer.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#the-difference-between-coins-and-digital-currency-tokens"&gt;
  &lt;/a&gt;
  The difference between coins and digital currency tokens
&lt;/h2&gt;

&lt;p&gt;Some people mistakenly use tokens and quins as synonyms. While Token and Quinn are different. The most important thing that distinguishes a token from a quin is the lack of an independent blockchain. Tokens are created on the platform of other blockchains. But Quinn has an independent blockchain.&lt;/p&gt;

&lt;p&gt;Another important difference between coins and tokens is that coins are used to buy and sell and are considered a method of payment. While most tokens can be used for use in an application or as an asset. Bitcoin, Atrium, Ripple, and Light Coin are the most popular coins in the digital currency market. Tetra, Chainlink, Dai, and Avi are also in the category of tokens.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#digital-currency-making-training-introducing-3-methods"&gt;
  &lt;/a&gt;
  Digital currency making training; Introducing 3 methods
&lt;/h2&gt;

&lt;h3&gt;
  &lt;a href="#method-one-create-a-new-digital-currency-by-creating-tokens"&gt;
  &lt;/a&gt;
  Method one: Create a new digital currency by creating tokens
&lt;/h3&gt;

&lt;p&gt;One way to make digital currency is to create tokens. As we have said, a token is a digital currency that does not have its independent blockchain and has been created and launched in the context of another blockchain. For this reason, when a token is generated, there is no need to work on the rules of consensus.&lt;/p&gt;

&lt;p&gt;Making tokens is cost-effective for blockchain developers because they do not need the astronomical cost of designing a blockchain to achieve their goals. Of course, it is also important to note that many digital currencies, when in their infancy, are implemented on another blockchain platform to save costs, but once they have been sufficiently developed, a dedicated blockchain for They are used to launch.&lt;/p&gt;

&lt;p&gt;The token can be created on all blockchain platforms that use smart contracts. Atrium is one of the most popular token-building platforms. At the time of writing, Atrium has hosted more than 80% of the tokens on the market. Bainenschin, Ias, Kazmas, Thezos, and Theron are other common platforms for making tokens.&lt;/p&gt;

&lt;p&gt;Atrium's programming language is solidity. Solidarity uses concepts that exist in other programming languages ‚Äã‚Äãsuch as PHP. It is a high-level programming language that has all the capabilities and capabilities needed for blockchain software.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#method-2-create-digital-currency-by-copying-and-modifying-current-blockchains"&gt;
  &lt;/a&gt;
  Method 2: Create digital currency by copying and modifying current blockchains
&lt;/h3&gt;

&lt;p&gt;Another way to build digital currency is to use open-source blockchains. Open source blocks are made available to the public with programming code after they are created.&lt;/p&gt;

&lt;p&gt;Atrium and Bitcoin programming codes are also open source and can be accessed by anyone on GitHub. Many blockchains have been launched following the example of these two digital currencies. For example, by making a few changes to the Bitcoin blockchain, the LightCoin network is created.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#method-3-create-a-digital-currency-by-creating-a-new-blockchain"&gt;
  &lt;/a&gt;
  Method 3: Create a digital currency by creating a new blockchain
&lt;/h3&gt;

&lt;p&gt;Build digital currency through the new blockchain&lt;br&gt;
Building and designing a blockchain network is another way to create a new digital currency. In a blockchain, data is stored in blocks and forms an interconnected chain. This structure creates an immutable storage system. The blocks are connected using hashes.&lt;/p&gt;

&lt;p&gt;Creating a new blockchain requires deep programming knowledge and a lot of time. In the following, the steps of creating a new digital currency through making blockchain are outlined in general.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Select the consensus mechanism&lt;br&gt;
Consensus mechanisms are protocols for verifying transactions performed in blockchain without the need for a third party (intermediary). Proof of work and the stock proof is currently the most well-known and basic blockchain consensus mechanisms.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Select the blockchain platform&lt;br&gt;
The correct choice of blockchain platform depends on the consensus mechanism you have chosen. The best blockchain operating systems are:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Ethereum&lt;br&gt;
Waves (WAVES)&lt;br&gt;
Hyperledger Fabric&lt;br&gt;
NEM&lt;br&gt;
IBM blockchain&lt;br&gt;
Nxt (NXT)&lt;br&gt;
HydraChain&lt;br&gt;
BlockStarter&lt;br&gt;
BigChainDB&lt;br&gt;
EOS&lt;br&gt;
Quorum&lt;br&gt;
IOTA&lt;br&gt;
CoinList&lt;br&gt;
MultiChain&lt;br&gt;
Open chain&lt;br&gt;
Chain Core&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Design the nodes&lt;br&gt;
You need to decide how the blockchain works and design the nodes accordingly. For example, will the licenses be private or public? Will the hosting be on-premises web systems or cloud systems?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Specify the blockchain architecture&lt;br&gt;
Before launching a digital currency, you need to be sure of all aspects; Because you can not change multiple blockchain parameters after startup. For example, you need to specify what address blockchain will follow to track exchanges of different cryptocurrencies.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Design the user interface&lt;br&gt;
If your user interface is not good, the cipher project will fail. You need to make sure you are using the latest version of FTP servers, databases, etc.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;
  &lt;a href="#frequently-asked-questions-about-making-new-digital-currencies"&gt;
  &lt;/a&gt;
  Frequently Asked Questions about Making New Digital Currencies
&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Does making a digital currency always lead to profitability?&lt;br&gt;
No. More than a few hundred thousand digital currencies have been launched on various platforms, many of which have failed. For this reason, all aspects of work must be well weighed before creating a digital currency.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the reason for the failure of some new digital currencies?&lt;br&gt;
Unfortunately, this perspective often causes us to become overwhelmed when it's time to start a new digital currency. That's why we see so many teams being forgotten after spending so much money and energy to create a new digital currency, without gaining popularity. One of the main reasons for their failure is that they failed to do good marketing. Therefore, before any action, the marketing system must be well defined.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the first step in building a new digital currency?&lt;br&gt;
The first step in creating a new digital currency is to have a well-defined digital currency white paper. White paper in the world of digital currencies means a comprehensive and complete report of the problem that the introduced project seeks to solve. Project objectives should be clearly defined within the white paper. A standard and complete white paper include an abstract, introduction, problem definition, product description, technical details, descriptions of the new digital currency, details of the public offering, and introduction of the development team.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How much does it cost to create a new digital currency?&lt;br&gt;
Creating new passwords is not an easy task and will probably require some financial resources; Unless you can handle things like development, documentation, and marketing. The cost of building an encrypted currency depends on several factors, and no specific number can be specified.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;
  &lt;a href="#concluding-remarks"&gt;
  &lt;/a&gt;
  Concluding remarks
&lt;/h2&gt;

&lt;p&gt;Creating a new dedicated currency may seem like an attractive and profitable offer at first, but we must not forget that there are many challenges in this direction. For this reason, sufficient market research must be done before any action is taken. On the other hand, the necessary capital must be provided for manufacturing and marketing. Otherwise, the digital currency project is likely to fail in its infancy.&lt;/p&gt;

</description>
      <category>blockchain</category>
      <category>webdev</category>
      <category>cryptocurrency</category>
    </item>
  </channel>
</rss>
