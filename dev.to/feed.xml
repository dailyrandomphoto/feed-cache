<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>DEV Community</title>
    <author>DEV Community</author>
    <description>A constructive and inclusive social network for software developers. With you every step of your journey.</description>
    <link>https://dev.to</link>
    <language>en</language>
    <item>
      <title>How to add editable post angular</title>
      <author>Mateusz Tomczyk</author>
      <pubDate>Sat, 29 May 2021 15:21:54 +0000</pubDate>
      <link>https://dev.to/mateuszto/how-to-add-editable-post-angular-44el</link>
      <guid>https://dev.to/mateuszto/how-to-add-editable-post-angular-44el</guid>
      <description>&lt;p&gt;Hi, i got my app and now I try to make edit feature but I can't do you got any tutorials or tips?&lt;br&gt;
Here is my code: &lt;a href="https://stackblitz.com/edit/angular-ivy-qkhrjx?file=src%2Fapp%2Fnotes%2Fnotes.component.ts"&gt;https://stackblitz.com/edit/angular-ivy-qkhrjx?file=src%2Fapp%2Fnotes%2Fnotes.component.ts&lt;/a&gt;&lt;/p&gt;

</description>
      <category>angular</category>
      <category>javascript</category>
      <category>typescript</category>
    </item>
    <item>
      <title>Bias-Variance Tradeoff in Machine Learning</title>
      <author>AI Pool</author>
      <pubDate>Sat, 29 May 2021 14:54:23 +0000</pubDate>
      <link>https://dev.to/aipool3/bias-variance-tradeoff-in-machine-learning-3c8f</link>
      <guid>https://dev.to/aipool3/bias-variance-tradeoff-in-machine-learning-3c8f</guid>
      <description>&lt;h3&gt;
  &lt;a href="#hypothesis-space"&gt;
  &lt;/a&gt;
  Hypothesis Space
&lt;/h3&gt;

&lt;p&gt;Before speaking about bias and variance, let's understand what hypothesis set is and how we are going to define it. First of all, when you train a model, you are seeking a hypothesis function over the entire space. It does not matter you train a linear regression, logistic regression or a deep network, you always have to understand what a hypothesis set is and how you're going to find a function you are looking for. &lt;/p&gt;

&lt;p&gt;If we create a model to approximate the given target function, it means we define a hypothesis set. Our trained model is a point from it, which can be far or close to the target function.&lt;/p&gt;

&lt;p&gt;Now let's define our hypothesis set. Let's assume we have chosen a model, which defines hypothesis set &lt;strong&gt;H&lt;/strong&gt;.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#biasvariance-tradeoff"&gt;
  &lt;/a&gt;
  Bias-Variance Tradeoff
&lt;/h3&gt;

&lt;p&gt;There is an optimal point, where bias and variance are in a good position and their values are reasonable. To find that optimal point, we need to draw the curves for every value, which depends on the complexity of the model. By saying the complexity of the model, we mean the complexity of the hypothesis set, the size of it.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--VJn9ai8Y--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://files.ai-pool.com/a/c457c503205d0740d3efc553bdb74b0b.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--VJn9ai8Y--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://files.ai-pool.com/a/c457c503205d0740d3efc553bdb74b0b.png" alt="image"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Our goal is to minimize the total loss, which consists of bias, variance, and small noise. These curves show that increasing the complexity of the model, will decrease the bias, but the variance will increase and as a result, the total loss will be high.&lt;br&gt;
We can't take a too simple model, which can't even approximate the target function and can't take too big one either, because it has high variance.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--1oENvg9U--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://files.ai-pool.com/a/492989098d60c7a2e6a592efb70804f7.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--1oENvg9U--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://files.ai-pool.com/a/492989098d60c7a2e6a592efb70804f7.jpg" alt="image"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is a known problem in the machine learning sphere, specifically in deep learning. Every specialist knows about Underfitting or High Bias and Overfitting or High Variance. These are the main problems everybody faces and there are a lot of approaches to fix them. People tried to solve this in the following ways.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model Selection / Early Stopping&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cross-Validation&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Normalization Functions&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Augmentation Techniques&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Others&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can find more in the &lt;a href="https://ai-pool.com/a/s/bias-variance-tradeoff-in-machine-learning"&gt;Following Article&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#other-resources"&gt;
  &lt;/a&gt;
  Other Resources
&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ai-pool.com/a/s/confidence-interval-understanding"&gt;Confidence Interval Understanding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ai-pool.com/a/s/introduction-of-fast-fourier-transformation--fft"&gt;Introduction of Fast Fourier Transformation (FFT)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ai-pool.com/d/why_network_overfits_too_early_"&gt;Why network overfits too early?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ai-pool.com/d/give_some_suggestions_to_avoid_overfitting"&gt;Give some suggestions to avoid overfitting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
      <category>aipool</category>
      <category>ai</category>
      <category>machinelearning</category>
      <category>math</category>
    </item>
    <item>
      <title>How to start with competitive coding...?</title>
      <author>Ankita</author>
      <pubDate>Sat, 29 May 2021 14:14:16 +0000</pubDate>
      <link>https://dev.to/ankita2002/how-to-start-with-competitive-coding-aml</link>
      <guid>https://dev.to/ankita2002/how-to-start-with-competitive-coding-aml</guid>
      <description>&lt;p&gt;Everyone is aware about so many competitive platforms but don't really know which one to choose. We all have been told by our seniors teachers to start with competitive coding and with that motivation we create an account and start solving, but we don't really understand those problems and the we either give up or copy.&lt;br&gt;
But what's the right way...&lt;/p&gt;

&lt;p&gt;According to me the right way is...To know where you Stand. &lt;br&gt;
To understand how much of the basics you know...&lt;br&gt;
Are you comfortable with all those starters problem like palindrome, min-max, Even-odd-prime nos, Binary Sort etc. If you are not comfortable with these you know now where to work. Understand them, Practice them. Make sure you practice it concept wise while knowing its applications too. This will help you identify problems where you can use these concepts.&lt;/p&gt;

&lt;p&gt;Once your basics are clear I'll suggest you to start with your journey and simultaneously start learning Data Structures and Algorithms.&lt;br&gt;
This will be enough to start. &lt;/p&gt;

</description>
      <category>cpp</category>
      <category>computerscience</category>
    </item>
    <item>
      <title>Diving into Object Detection Basics</title>
      <author>AI Pool</author>
      <pubDate>Sat, 29 May 2021 13:57:47 +0000</pubDate>
      <link>https://dev.to/aipool3/diving-into-object-detection-basics-1ak</link>
      <guid>https://dev.to/aipool3/diving-into-object-detection-basics-1ak</guid>
      <description>&lt;h3&gt;
  &lt;a href="#intro"&gt;
  &lt;/a&gt;
  Intro
&lt;/h3&gt;

&lt;p&gt;The prospects of Artificial Intelligence (AI) are not just limited to predicting if a person will get a loan or not by giving his credit history, annual income, annual expenses, criminal records, etc. Computer Vision is a trending topic for AI enthusiasts of any experience level.&lt;/p&gt;

&lt;p&gt;Let me give you a brief idea about Computer Vision. It is nothing but when a machine identifies an 'object' in an image/video after learning from the data that was fed to it. For example, when we see an object first time, we are mostly aware of it like what it is called. But after getting to know its name, the next time we see it we know exactly what it is. Exactly like our brain, Computer Vision, to be specific Object Detection works.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--ua_qiuxX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://files.ai-pool.com/a/bcdb850b5e8c7f7082ca5f4857aa6a55.undefined" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ua_qiuxX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://files.ai-pool.com/a/bcdb850b5e8c7f7082ca5f4857aa6a55.undefined" alt="intro"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#introduction-of-object-detection"&gt;
  &lt;/a&gt;
  Introduction of Object Detection
&lt;/h3&gt;

&lt;p&gt;Object detection is locating and identifying an object in an image or in a video. Locating an object is nothing but giving the exact position where the object resides in the frame. (Here frame can be a single image or a sequence of frames that is a video). To locate an object, we can either use a bounding box or any other geometrical shape like a circle. The easiest and standard approach is by using the bounding box, where we first obtain the center coordinates (x, y) and the width (w) and height (h) of the box.&lt;/p&gt;

&lt;p&gt;To identify an object, the network must be trained on data, for example, images of the person. This step is called the classification of objects and it is very essential for the bounding box to be formed correctly. To ensure the correct training of the network, ensure the data is correct.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--FZ9XWXPh--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://files.ai-pool.com/a/c933f0514293b8447bb725da690d7eb1.undefined" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--FZ9XWXPh--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://files.ai-pool.com/a/c933f0514293b8447bb725da690d7eb1.undefined" alt="image"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#anchor-boxes"&gt;
  &lt;/a&gt;
  Anchor Boxes
&lt;/h3&gt;

&lt;p&gt;How does the network predict or identify the box?&lt;/p&gt;

&lt;p&gt;The network first makes a random guess of the coordinates and assigns them a value w for width and h for height. It assigns (0, 0) for the center of the box (x, y). Of course, this is not the actual prediction. So after every step of training, which is termed as an iteration, the network performs regression to get the correct estimates.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#datasets-to-start-with"&gt;
  &lt;/a&gt;
  Datasets to start with
&lt;/h3&gt;

&lt;p&gt;There are many datasets to start training your first object detection model. These datasets are open source meaning anyone is free to use them. These datasets have a large collection of classes of objects to choose from. So have fun while exploring these datasets&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;COCO Dataset&lt;/li&gt;
&lt;li&gt;ImageNet&lt;/li&gt;
&lt;li&gt;Open Image Dataset V6&lt;/li&gt;
&lt;li&gt;Labelme&lt;/li&gt;
&lt;li&gt;CelebFaces&lt;/li&gt;
&lt;li&gt;50 other datasets&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can find more in the &lt;a href="https://ai-pool.com/a/s/diving-into-object-detection-basics"&gt;Following Article&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#other-resources"&gt;
  &lt;/a&gt;
  Other Resources
&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ai-pool.com/a/s/dropout-in-deep-learning"&gt;Dropout in Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ai-pool.com/a/s/normalization-in-deep-learning"&gt;Normalization in Deep learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ai-pool.com/a/s/yolov3-and-yolov4-in-object-detection"&gt;Yolov3 and Yolov4 in Object Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ai-pool.com/d/how-can-i-find-the-paper-of-yolov5"&gt;How can I find the paper of yolov5?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
      <category>aipool</category>
      <category>ai</category>
      <category>objectdetection</category>
      <category>computervision</category>
    </item>
    <item>
      <title>Introduction of Fast Fourier Transformation (FFT)</title>
      <author>AI Pool</author>
      <pubDate>Sat, 29 May 2021 13:45:45 +0000</pubDate>
      <link>https://dev.to/aipool3/introduction-of-fast-fourier-transformation-fft-555k</link>
      <guid>https://dev.to/aipool3/introduction-of-fast-fourier-transformation-fft-555k</guid>
      <description>&lt;h4&gt;
  &lt;a href="#introduction"&gt;
  &lt;/a&gt;
  Introduction
&lt;/h4&gt;

&lt;p&gt;Suppose you have an audio file, or even a video file, or let's say you have an image file. But the only problem is it has lots of noise. You can't distinguish between the required audio, frames, or the object in the three files respectively. So how are you supposed to distinguish between the &lt;strong&gt;noise&lt;/strong&gt; and the actual &lt;strong&gt;signal&lt;/strong&gt;?&lt;/p&gt;

&lt;p&gt;The odds are quite high that the file may contain a term called noise. Though the terms are of the communication domain, they are also involved in the AI domain.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#noise"&gt;
  &lt;/a&gt;
  Noise
&lt;/h4&gt;

&lt;p&gt;Noise is a random signal which consists of equal intensities or powers at every frequency. In computing, it is statistically defined as a sequence of random variables. So basically, in very simple terms, it is a random thing that may be a part of your signal.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#fourier-transformation-ft"&gt;
  &lt;/a&gt;
  Fourier Transformation (FT)
&lt;/h4&gt;

&lt;p&gt;Fourier Transformation which is the main highlight of this article is a very useful tool for analyzing signals, especially noisy signals. It transforms or converts complex mathematical equations into simpler trigonometric functions in terms of sin or cos. Sin or Cos are used because the signal is easier to analyze in their format. In other terms, Fourier transformation is used to convert time signals into frequency signals and power signals. You are using the applications of Fourier Transformation unknowingly every day.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#implementation-of-fft"&gt;
  &lt;/a&gt;
  Implementation of FFT
&lt;/h4&gt;

&lt;p&gt;Note: The codes are written and tested by the author. The outputs are the screenshots of Jupyter Notebook cells.&lt;/p&gt;

&lt;p&gt;For this implementation, we will be using scipy library as a Fourier transformation calculator.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#1-lets-import-the-libraries-for-python-fft"&gt;
  &lt;/a&gt;
  1. Let's import the libraries for python fft
&lt;/h5&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.fftpack&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;fft&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fftfreq&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Note: If you have the latest package of scipy, use scipy.fft instead of scipy.fftpack&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#2-defining-a-random-signal"&gt;
  &lt;/a&gt;
  2. Defining a random signal
&lt;/h5&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt; &lt;span class="c1"&gt;# Number of data points
&lt;/span&gt;&lt;span class="n"&gt;dx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;5.0&lt;/span&gt; &lt;span class="c1"&gt;# Sampling period (in meters)
&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dx&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# x coordinates
&lt;/span&gt;&lt;span class="n"&gt;w1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;100.0&lt;/span&gt; &lt;span class="c1"&gt;# wavelength (meters)
&lt;/span&gt;&lt;span class="n"&gt;w2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;50.0&lt;/span&gt; &lt;span class="c1"&gt;# wavelength (meters)
&lt;/span&gt;
&lt;span class="n"&gt;fx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;w1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Signal as a function of time"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h5&gt;
  &lt;a href="#3-getting-the-discrete-fourier-transform-dft-using-fft"&gt;
  &lt;/a&gt;
  3. Getting the Discrete Fourier Transform (DFT) using FFT
&lt;/h5&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;Fk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fft&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="c1"&gt;# Fourier coefficients (divided by n)
&lt;/span&gt;
&lt;span class="c1"&gt;# To plot in the frequency domain
&lt;/span&gt;&lt;span class="n"&gt;Fk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;fftshift&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Fk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Shift zero frequency to center
&lt;/span&gt;&lt;span class="n"&gt;nu&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fftfreq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;dx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Natural frequencies
&lt;/span&gt;&lt;span class="n"&gt;nu&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fftshift&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nu&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Shift zero frequency to center
&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'DFT of the signal'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Fk&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;# Get the absolute values of DFT
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;As you can see in the above image, the DFT of our signal is a simple graph in which we have a single pair of frequencies as I had mentioned earlier that DFTs are symmetrical. As the signal is a simple continuous signal and contains only one frequency component, it was expected to get a single pair of frequencies.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#4-adding-a-random-noise"&gt;
  &lt;/a&gt;
  4. Adding a random noise
&lt;/h5&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;new_fx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;w1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;w2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="c1"&gt;# new = old + random signal/noise
&lt;/span&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'Modified Signal'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_fx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h5&gt;
  &lt;a href="#5-getting-the-dft-for-the-modified-signal"&gt;
  &lt;/a&gt;
  5. Getting the DFT for the modified signal
&lt;/h5&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;new_Fk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fft&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_fx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;  &lt;span class="c1"&gt;# Fourier coefficients (divided by n)
&lt;/span&gt;&lt;span class="n"&gt;new_Fk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fftshift&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_Fk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Shift zero frequency to center
&lt;/span&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'DFT of Modified Signal'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_Fk&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;# Get the absolute values of DFT
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;You can find more details with plotted images in &lt;a href="https://ai-pool.com/a/s/introduction-of-fast-fourier-transformation--fft"&gt;this article&lt;/a&gt;&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#other-resources"&gt;
  &lt;/a&gt;
  Other Resources
&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ai-pool.com/a/s/visualization-with-seaborn"&gt;Visualization with Seaborn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ai-pool.com/a/s/understanding-of-probability-distribution-and-normal-distribution"&gt;Understanding of Probability Distribution and Normal Distribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ai-pool.com/a/s/understanding-of-regularization-in-neural-networks"&gt;Understanding of Regularization in Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
      <category>aipool</category>
      <category>fft</category>
      <category>ai</category>
      <category>machinelearning</category>
    </item>
    <item>
      <title>GitUI - v0.16 supports merging!</title>
      <author>Stephan Dilly</author>
      <pubDate>Sat, 29 May 2021 13:21:45 +0000</pubDate>
      <link>https://dev.to/extrawurst/gitui-v0-16-supports-merging-711</link>
      <guid>https://dev.to/extrawurst/gitui-v0-16-supports-merging-711</guid>
      <description>&lt;p&gt;&lt;a href="https://github.com/extrawurst/gitui"&gt;GitUI&lt;/a&gt; is a terminal UI for git written in Rust. We aim to simplify common git tasks in a fast, keyboard-only and cross platform way without leaving your beloved command line.&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#release-highlights"&gt;
  &lt;/a&gt;
  Release Highlights
&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;merge branch, commit merge &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--2vpCqh4_--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hhcrcjqimfd6n292i8g7.gif" alt="Alt Text"&gt;
&lt;/li&gt;
&lt;li&gt;list and manage all your tags &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i9i9SZKN--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/zjoogd35nl2wk3ckt78v.gif" alt="Alt Text"&gt;
&lt;/li&gt;
&lt;li&gt;file browser (incl. syntax highlighting) &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--xeHV8sls--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/b453xw804odetiaqzvn3.gif" alt="Alt Text"&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/extrawurst/gitui/releases/tag/v0.16.0"&gt;much more&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thanks for your interest and support!‚ù§Ô∏è&lt;/p&gt;

</description>
      <category>github</category>
      <category>terminal</category>
      <category>productivity</category>
      <category>rust</category>
    </item>
    <item>
      <title>#30DaysOfAppwrite: Grafana Integration</title>
      <author>Christy Jacob</author>
      <pubDate>Sat, 29 May 2021 13:13:04 +0000</pubDate>
      <link>https://dev.to/appwrite/grafana-integration-50p9</link>
      <guid>https://dev.to/appwrite/grafana-integration-50p9</guid>
      <description>&lt;h2&gt;
  &lt;a href="#intro"&gt;
  &lt;/a&gt;
  Intro
&lt;/h2&gt;

&lt;p&gt;Appwrite is an open-source, self-hosted Backend-as-a-Service that makes app development &lt;strong&gt;easier&lt;/strong&gt; with a suite of SDKs and APIs to accelerate app development. &lt;a href="http://30days.appwrite.io/"&gt;#30DaysOfAppwrite&lt;/a&gt; is a month long event focused at giving developers a walk through of all of Appwrite's features, starting from the basics to more advanced features like Cloud Functions! Alongside we will also be building a fully featured Medium Clone to demonstrate how these concepts can be applied when building a real world app. We also have some exciting prizes for developers who follow along with us!&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#grafana-integration"&gt;
  &lt;/a&gt;
  Grafana Integration
&lt;/h2&gt;

&lt;p&gt;Welcome to Day 29 üëã - today marks the last day of #30DaysOfAppwrite, and we thought it would be a fun little exercise to show you how you can add external services to the Appwrite stack and make it work seamlessly! We love Dashboards, and we thought it would be great to add Grafana support to Appwrite. &lt;/p&gt;

&lt;p&gt;Appwrite doesn't come with Grafana out of the box and for a couple of reasons. First, you may already have your own set of monitoring tools in your stack, and we believe that our stack should be un-opinionated and allow you to work with the tools you feel comfortable with. The second reason is that we try to ship the Appwrite setup with minimal components to make Appwrite easy to start, but still flexible enough to grow.  &lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#add-grafana-to-appwrite"&gt;
  &lt;/a&gt;
  Add Grafana to Appwrite
&lt;/h2&gt;

&lt;p&gt;We will be creating two Dashboards: one for monitoring Appwrite's usage stats and one for monitoring your Server stats. &lt;/p&gt;

&lt;p&gt;The first step is to add the Grafana service to Appwrite's &lt;a href="https://github.com/appwrite/appwrite/blob/master/docker-compose.yml#L476"&gt;&lt;code&gt;docker-compose.yml&lt;/code&gt; file&lt;/a&gt;.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight yaml"&gt;&lt;code&gt;  &lt;span class="na"&gt;grafana&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
    &lt;span class="na"&gt;image&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;grafana/grafana&lt;/span&gt;
    &lt;span class="na"&gt;container_name&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;appwrite-grafana&lt;/span&gt;
    &lt;span class="na"&gt;ports&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
      &lt;span class="pi"&gt;-&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="s"&gt;3000:3000"&lt;/span&gt;
    &lt;span class="na"&gt;networks&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
      &lt;span class="pi"&gt;-&lt;/span&gt; &lt;span class="s"&gt;appwrite&lt;/span&gt;
    &lt;span class="na"&gt;volumes&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
      &lt;span class="pi"&gt;-&lt;/span&gt; &lt;span class="s"&gt;appwrite-grafana:/var/lib/grafana&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Next you need to add the &lt;code&gt;appwrite-grafana&lt;/code&gt; volume to the &lt;a href="https://github.com/appwrite/appwrite/blob/master/docker-compose.yml#L532"&gt;list of all volumes&lt;/a&gt;. This will allow your Grafana container to persist data.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight yaml"&gt;&lt;code&gt;&lt;span class="na"&gt;volumes&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
  &lt;span class="na"&gt;appwrite-mariadb&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
  &lt;span class="na"&gt;appwrite-redis&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
  &lt;span class="na"&gt;appwrite-cache&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
  &lt;span class="na"&gt;appwrite-uploads&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
  &lt;span class="na"&gt;appwrite-certificates&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
  &lt;span class="na"&gt;appwrite-functions&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
  &lt;span class="na"&gt;appwrite-influxdb&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
  &lt;span class="na"&gt;appwrite-config&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
  &lt;span class="na"&gt;appwrite-grafana&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now run&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;docker-compose up &lt;span class="nt"&gt;-d&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h2&gt;
  &lt;a href="#dashboard-1-appwrite-metrics"&gt;
  &lt;/a&gt;
  Dashboard #1 - Appwrite Metrics
&lt;/h2&gt;

&lt;p&gt;For your first Dashboard, we don't need any additional configuration in our services. Now head over to &lt;code&gt;http://localhost:3000&lt;/code&gt; to configure Grafana. You can login using the default credentials&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;username : admin
password : admin
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;You will be prompted to enter a new password and it is highly recommended that you change it. Learn more about managing users and passwords in their &lt;a href="https://grafana.com/docs/grafana/latest/manage-users/user-admin/change-your-password/"&gt;official guide&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;The first step is to configure your Data Source. In our case, we will be using the InfluxDB plugin. &lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--LK_L_xPv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ypjrquqblpg0ak8eowpg.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--LK_L_xPv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ypjrquqblpg0ak8eowpg.png" alt="add-datasource"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Once you add the InfluxDB data source, it's time to configure it. Here, you need to fill in the values of 2 fields, &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;URL&lt;/strong&gt; - &lt;a href="http://influxdb:8086"&gt;http://influxdb:8086&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;Database&lt;/strong&gt; - telegraf&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Finally click &lt;strong&gt;Save and Test&lt;/strong&gt; to check your database connection. If all goes well, you will see a success message.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--0kgxknoV--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/mzei9hu1b7dk8yd66cnh.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--0kgxknoV--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/mzei9hu1b7dk8yd66cnh.png" alt="configure-datasource"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The next step is to import the Dashboard we created for you. Head to the &lt;a href="https://grafana.com/grafana/dashboards/14508"&gt;Grafana's Dashboard Library&lt;/a&gt; and copy the ID of our Dashboard .&lt;/p&gt;

&lt;p&gt;You can then &lt;strong&gt;Import the Dashboard&lt;/strong&gt; in your Grafana instance like so. &lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--yaiX_gX2--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/tlwcpwcymgarh8kl429k.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--yaiX_gX2--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/tlwcpwcymgarh8kl429k.png" alt="import-appwrite-dashboard"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And that's it! You should now see this fancy Dashboard&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--QGg2puen--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/cr8ia36av8dxlktfxfpj.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--QGg2puen--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/cr8ia36av8dxlktfxfpj.png" alt="row-1-col-1"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--1m3OHa93--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nplx21xf6902lrk3e6yq.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--1m3OHa93--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nplx21xf6902lrk3e6yq.png" alt="row-2-col-1"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;
  &lt;a href="#dashboard-2-server-metrics"&gt;
  &lt;/a&gt;
  Dashboard #2 - Server Metrics
&lt;/h2&gt;

&lt;p&gt;The &lt;a href="https://grafana.com/grafana/dashboards/5955"&gt;next Dashboard&lt;/a&gt; is one that that will monitor our server metrics. This includes the CPU usage, Disk I/O, Network I/O and much more. This Dashboard requires some additional info, so we need to make a few changes in our &lt;code&gt;telegraf&lt;/code&gt; Docker image to make this information available.   &lt;/p&gt;

&lt;p&gt;We'll start by cloning Appwrite's &lt;code&gt;telegraf&lt;/code&gt; image&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;git clone https://github.com/appwrite/docker-telegraf.git 
&lt;span class="nb"&gt;cd &lt;/span&gt;docker-telegraf
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We need to make more metrics available to the collector. Add the following lines to &lt;a href="https://github.com/appwrite/docker-telegraf/blob/master/telegraf.conf#L83"&gt;line 83&lt;/a&gt;&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="o"&gt;[[&lt;/span&gt;inputs.cpu]]
    percpu &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;true
    &lt;/span&gt;totalcpu &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;true
    &lt;/span&gt;collect_cpu_time &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;false
    &lt;/span&gt;report_active &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;false&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;inputs.disk]]
    ignore_fs &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"tmpfs"&lt;/span&gt;, &lt;span class="s2"&gt;"devtmpfs"&lt;/span&gt;, &lt;span class="s2"&gt;"devfs"&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;inputs.io]]
&lt;span class="o"&gt;[[&lt;/span&gt;inputs.mem]]
&lt;span class="o"&gt;[[&lt;/span&gt;inputs.net]]
&lt;span class="o"&gt;[[&lt;/span&gt;inputs.system]]
&lt;span class="o"&gt;[[&lt;/span&gt;inputs.swap]]
&lt;span class="o"&gt;[[&lt;/span&gt;inputs.netstat]]
&lt;span class="o"&gt;[[&lt;/span&gt;inputs.processes]]
&lt;span class="o"&gt;[[&lt;/span&gt;inputs.kernel]]
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now we need to build a new Docker image using the changes we made.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;docker build &lt;span class="nt"&gt;-t&lt;/span&gt; telegraf-local &lt;span class="nb"&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Once this build is complete, we can make use of our new &lt;code&gt;telegraf-local&lt;/code&gt; image in the main Appwrite &lt;code&gt;docker-compose.yml&lt;/code&gt;. Replace the &lt;code&gt;appwrite/telegraf:1.1.0&lt;/code&gt; image in &lt;a href="https://github.com/appwrite/appwrite/blob/master/docker-compose.yml#L434"&gt;line 434&lt;/a&gt; with our &lt;code&gt;telegraf-local&lt;/code&gt; image.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight yaml"&gt;&lt;code&gt;  &lt;span class="na"&gt;telegraf&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
    &lt;span class="na"&gt;image&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;telegraf-local&lt;/span&gt;
    &lt;span class="na"&gt;container_name&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;appwrite-telegraf&lt;/span&gt;
    &lt;span class="na"&gt;networks&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
      &lt;span class="pi"&gt;-&lt;/span&gt; &lt;span class="s"&gt;appwrite&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now run &lt;code&gt;docker-compose up -d --remove-orphans&lt;/code&gt; from your appwrite directory to restart your services.&lt;br&gt;
Now head over to your Grafana Dashboard and import &lt;a href="https://grafana.com/grafana/dashboards/5955"&gt;this new Dashboard&lt;/a&gt; the same way as you did the previous one and if everything goes well, you should see the following Dashboard!&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--0XJci_C5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4htxeb1ybbvl8fl55jrx.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--0XJci_C5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4htxeb1ybbvl8fl55jrx.png" alt="row-1-col-1"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--07maqL4i--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/h2ayaep2ajosahk36a1m.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--07maqL4i--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/h2ayaep2ajosahk36a1m.png" alt="row-2-col-1"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--T0stWInC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9aodvde4jnpp18erofhi.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--T0stWInC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9aodvde4jnpp18erofhi.png" alt="row-3-col-1"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And just like that, you now have access to all your server information in one place! This was just the tip of the iceberg! Grafana has many more amazing features. It's completely open-source, has support for over 30 Data Sources, has support for Alerting etc. You can setup custom alerts and Grafana will continuously evaluate and send notifications to systems like Slack, PagerDuty, VictorOps and OpsGenie. You can learn more about all of Grafana's features in their dedicated &lt;a href="https://grafana.com/tutorials/"&gt;tutorials section&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#credits"&gt;
  &lt;/a&gt;
  Credits
&lt;/h2&gt;

&lt;p&gt;We hope you liked this write up. You can follow &lt;a href="https://twitter.com/search?q=%2330daysofappwrite"&gt;#30DaysOfAppwrite&lt;/a&gt; on Social Media to keep up with all of our posts. The complete event timeline can be found &lt;a href="http://30days.appwrite.io"&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://appwrite.io/discord"&gt;Discord Server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://appwrite.io/"&gt;Appwrite Homepage&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/appwrite"&gt;Appwrite's Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Feel free to reach out to us on Discord if you would like to learn more about Appwrite, Aliens or Unicorns ü¶Ñ. Stay tuned for tomorrow's article! Until then üëã&lt;/p&gt;

</description>
      <category>javascript</category>
      <category>webdev</category>
      <category>flutter</category>
      <category>30daysofappwrite</category>
    </item>
    <item>
      <title>Writing An Operating System - The Boot Process (Part 1)</title>
      <author>Farhan</author>
      <pubDate>Sat, 29 May 2021 13:04:46 +0000</pubDate>
      <link>https://dev.to/arriqaaq/writing-an-operating-system-the-boot-process-part-1-48p0</link>
      <guid>https://dev.to/arriqaaq/writing-an-operating-system-the-boot-process-part-1-48p0</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;This post was originally published &lt;a href="https://aly.arriqaaq.com/wos1/"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;My journey on learning to build a simple OS&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;How many times have you read an OS book but not been able to code one?Operating System (OS) books are tedious, but only theory makes it hard to understand how an OS actually works. Here is my attempt to write a simple OS and document some of the concepts learned.&lt;br&gt;
‚Äå&lt;br&gt;
‚Äå&lt;/p&gt;
&lt;h2&gt;
  &lt;a href="#before-you-start"&gt;
  &lt;/a&gt;
  Before You Start
&lt;/h2&gt;

&lt;p&gt;On a mac, install Homebrew and then brew install qemu nasm&lt;br&gt;
On some systems qemu is split into multiple binaries. You may want to call qemu-system-x86_64 binfile&lt;/p&gt;
&lt;h4&gt;
  &lt;a href="#qemu"&gt;
  &lt;/a&gt;
  QEmu
&lt;/h4&gt;

&lt;p&gt;For testing these low-level programs without continuously having to reboot a machine or risk scrubbing your important data off a disk, we will use a CPU emulator QEmu. &lt;br&gt;
I'm working on a Mac (with M1 chip). QEmu has some issues with M1 chip, so you can run these experiements inside a docker container. &lt;code&gt;docker run -it ubuntu bash&lt;/code&gt;.&lt;br&gt;
Run QEmu with -nographic and -curses arguments inside docker container to display the VGA output when in text mode&lt;/p&gt;
&lt;h4&gt;
  &lt;a href="#nasm"&gt;
  &lt;/a&gt;
  NASM
&lt;/h4&gt;

&lt;p&gt;NASM is an assembler and disassembler for the Intel x86 architecture. It can be used to write 16-bit, 32-bit (IA-32) and 64-bit (x86-64) programs. &lt;br&gt;
‚Äå&lt;br&gt;
‚Äå&lt;br&gt;
When we start our computer, initially, it has no notion of an operating system. Somehow, it must load the operating system --- whatever variant that may be --- from some permanent storage device that is currently attached to the computer (e.g. a floppy disk, a hard disk, a USB dongle, etc.).&lt;/p&gt;
&lt;h2&gt;
  &lt;a href="#the-boot-process"&gt;
  &lt;/a&gt;
  The Boot Process
&lt;/h2&gt;

&lt;p&gt;Booting an operating system consists of transferring control along a chain of small programs, each one more ‚Äúpowerful‚Äù than the previous one, where the operating system is the last ‚Äúprogram‚Äù.&lt;br&gt;&lt;br&gt;
‚Äå&lt;/p&gt;
&lt;h3&gt;
  &lt;a href="#bios"&gt;
  &lt;/a&gt;
  BIOS
&lt;/h3&gt;

&lt;p&gt;When the PC is turned on, the computer will start a small program that adheres to the Basic Input Output System (BIOS) [16] standard. This program is usually stored on a read only memory chip on the motherboard of the PC. BIOS is a collection of software routines that are initially loaded from a chip into memory and initialised when the computer is switched on. BIOS provides auto-detection and basic control of your computer‚Äôs essential devices, such as the screen, keyboard, and hard disks. &lt;/p&gt;

&lt;p&gt;Note: Modern operating systems do not use the BIOS‚Äô functions, they use drivers that interact directly with the hardware, bypassing the BIOS. Today, BIOS mainly runs some early diagnostics (power-on-self-test) and then transfers control to the bootloader.&lt;br&gt;
‚Äå&lt;/p&gt;
&lt;h3&gt;
  &lt;a href="#%E2%80%8Cboot-sector%E2%80%8C"&gt;
  &lt;/a&gt;
  ‚ÄåBoot Sector‚Äå
&lt;/h3&gt;

&lt;p&gt;‚Äå&lt;br&gt;
BIOS cannot simply load a file that represents your operating system from a disk, since BIOS has no notion of a file- system. BIOS must read specific sectors of data (usually 512 bytes in size) from specific physical locations of the disk devices, such as Cylinder 2, Head 3, Sector 5.&lt;br&gt;
So, the easiest place for BIOS to find our OS is in the first sector of one of the disks (i.e. Cylinder 0, Head 0, Sector 0), known as the boot sector. To make sure that the "disk is bootable", the BIOS checks that bytes 511 and 512 of the alleged boot sector are bytes 0xAA55. If so, the BIOS loads the first sector to the address 7C00h, set the program counter to that address and let the CPU executing code from there. This is the simplest boot sector ever:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;e9 fd ff 00 00 00 00 00 00 00 00 00 00 00 00 00
00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
[ 29 more lines with sixteen zero-bytes each ]
00 00 00 00 00 00 00 00 00 00 00 00 00 00 55 aa
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;‚Äå&lt;br&gt;
Note that, in the above boot sector, the three important features are:&lt;/p&gt;

&lt;p&gt;1) The initial three bytes, in hexadecimal as 0xe9, 0xfd and 0xff, are actually machine code instructions, as defined by the CPU manufacturer, to perform an endless jump.&lt;br&gt;
2) The last two bytes, 0x55 and 0xaa, make up the magic number, which tells BIOS that this is indeed a boot block and not just data that happens to be on a drive‚Äôs boot sector. (in little-endian format)&lt;br&gt;
3) The file is padded with zeros (‚Äô*‚Äô indicates zeros omitted for brevity), basically to position the magic BIOS number at the end of the 512 byte disk sector.&lt;/p&gt;

&lt;p&gt;The first sector is called Master Boot Record, or MBR. The program in the first sector is called MBR Bootloader.&lt;/p&gt;

&lt;p&gt;So, BIOS loops through each storage device (e.g. floppy drive, hard disk, CD drive, etc.), reads the boot sector into memory, and instructs the CPU to begin executing the first boot sector it finds that ends with the magic number. This is where we seize control of the computer.&lt;br&gt;
‚Äå&lt;/p&gt;
&lt;h2&gt;
  &lt;a href="#%E2%80%8Cthe-bootloader"&gt;
  &lt;/a&gt;
  ‚ÄåThe Bootloader
&lt;/h2&gt;

&lt;p&gt;The BIOS program will transfer control of the PC to a program called a bootloader. A bootloader loads an OS, or an application that runs and communicate directly with hardware. To run an OS, the first thing to write is a bootloader. Here is a simple bootloader.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;;
; A simple boot sector program that loops forever. ;
9

; Define a label, "loop", that will allow ; us to jump back to it, forever.
; Use a simple CPU instruction that jumps
; to a new memory address to continue execution. ; In our case, jump to the address of the current ; instruction.



loop:
    jmp loop


; When compiled, our program must fit into 512 bytes,
; with the last two bytes being the magic number,
; so here, tell our assembly compiler to pad out our
; program with enough zero bytes (db 0) to bring us to the ; 510th byte.


times 510-($-$$) db 0


; Last two bytes (one word) form the magic number, ; so BIOS knows we are a boot sector.

dw 0xaa55
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;‚Äå&lt;br&gt;
We compile the code with nasm and write it to a bin file:&lt;br&gt;
&lt;/p&gt;

&lt;p&gt;&lt;code&gt;nasm -f bin boot_sect_simple.asm -o boot_sect_simple.bin&lt;/code&gt;&lt;br&gt;
&lt;/p&gt;

&lt;p&gt;Let's try it out, so let's do it:&lt;br&gt;
&lt;/p&gt;

&lt;p&gt;&lt;code&gt;qemu boot_sect_simple.bin&lt;/code&gt;&lt;br&gt;
&lt;/p&gt;

&lt;p&gt;On some systems, you may have to run &lt;/p&gt;

&lt;p&gt;You will see a window open which says "Booting from Hard Disk..." and nothing else. There you go, a simple boot loader is ready!&lt;/p&gt;

&lt;p&gt;Continue reading more &lt;a href="https://aly.arriqaaq.com/wos1/"&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Sorry, copy pasting it from ghost was tough!&lt;/p&gt;

</description>
      <category>linux</category>
      <category>computerscience</category>
      <category>opensource</category>
      <category>operatingsystems</category>
    </item>
    <item>
      <title>Cartographing Jetpack Compose: foundation</title>
      <author>Thomas K√ºnneth</author>
      <pubDate>Sat, 29 May 2021 12:43:55 +0000</pubDate>
      <link>https://dev.to/tkuenneth/cartographing-jetpack-compose-foundation-5c0</link>
      <guid>https://dev.to/tkuenneth/cartographing-jetpack-compose-foundation-5c0</guid>
      <description>&lt;p&gt;Welcome to the second installment of &lt;em&gt;Cartographing Jetpack Compose&lt;/em&gt;. In the first part we looked at &lt;code&gt;androidx.compose.compiler&lt;/code&gt; and &lt;code&gt;androidx.compose.runtime&lt;/code&gt;. Both provide essential groundwork and keep the compose machinery working, for example by modifying or amending composable functions during compile time, and by bringing on screen what has been emitted by a composable during runtime.&lt;/p&gt;

&lt;p&gt;This time we will be looking at &lt;code&gt;androidx.compose.foundation&lt;/code&gt;. The docs describe is like this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Write Jetpack Compose applications with ready to use building&lt;br&gt;
blocks and extend foundation to build your own design system&lt;br&gt;
pieces.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As of May 2021 we see quite a few subpackages: &lt;em&gt;layout&lt;/em&gt;, &lt;em&gt;shape&lt;/em&gt;, &lt;em&gt;gestures&lt;/em&gt;, &lt;em&gt;selection&lt;/em&gt;, &lt;em&gt;lazy&lt;/em&gt;, &lt;em&gt;interaction&lt;/em&gt; and &lt;em&gt;text&lt;/em&gt;. Before we turn to them in the next episode, let's look at the base package, &lt;code&gt;androidx.compose.foundation&lt;/code&gt;. We have a few interfaces, &lt;code&gt;Indication&lt;/code&gt; and &lt;code&gt;IndicationInstance&lt;/code&gt;. They deal with visual effects that occur when certain interactions happens. Both sort of accompany a Top-level property called &lt;code&gt;LocalIndication&lt;/code&gt;, a &lt;code&gt;CompositionLocal&lt;/code&gt; that provides an Indication through the hierarchy.&lt;/p&gt;

&lt;p&gt;We also see a few classes, for example &lt;code&gt;BorderStroke&lt;/code&gt; (to specify the stroke to draw borders with) and &lt;code&gt;ScrollState&lt;/code&gt; (state of the scroll). Here's how to use them.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight kotlin"&gt;&lt;code&gt;&lt;span class="nd"&gt;@Composable&lt;/span&gt;
&lt;span class="nd"&gt;@Preview&lt;/span&gt;
&lt;span class="k"&gt;fun&lt;/span&gt; &lt;span class="nf"&gt;Sandbox&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nc"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;modifier&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Modifier&lt;/span&gt;
      &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;border&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="nc"&gt;BorderStroke&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nc"&gt;Color&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;Red&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;padding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"Hello Compose"&lt;/span&gt;
  &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--B1Tl9bpL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nlj9eklzifp4m5okxltq.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--B1Tl9bpL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nlj9eklzifp4m5okxltq.png" alt="A simple border"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As you can see I use &lt;code&gt;BorderStroke&lt;/code&gt; to create a simple border around a &lt;code&gt;Text()&lt;/code&gt;. Please be aware that &lt;code&gt;BorderStroke&lt;/code&gt; is both a class and a Top-level function. &lt;/p&gt;

&lt;p&gt;Next: &lt;code&gt;ScrollState&lt;/code&gt;. The docs say:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Create and &lt;code&gt;remember&lt;/code&gt; the &lt;code&gt;ScrollState&lt;/code&gt; based on the currently&lt;br&gt;
appropriate scroll configuration to allow changing scroll&lt;br&gt;
position or observing scroll behavior.&lt;br&gt;
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight kotlin"&gt;&lt;code&gt;&lt;span class="nd"&gt;@Composable&lt;/span&gt;
&lt;span class="nd"&gt;@Preview&lt;/span&gt;
&lt;span class="k"&gt;fun&lt;/span&gt; &lt;span class="nf"&gt;Sandbox&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;val&lt;/span&gt; &lt;span class="py"&gt;state&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;rememberScrollState&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="kd"&gt;val&lt;/span&gt; &lt;span class="py"&gt;text&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"${(1..100).joinToString("") { "&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="s"&gt;" }}- end -"&lt;/span&gt;
  &lt;span class="nc"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;textAlign&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;TextAlign&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;Center&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;modifier&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Modifier&lt;/span&gt;
      &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fillMaxSize&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
      &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;verticalScroll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Uokq2WMl--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qifqtdy74f67ixxuwjzd.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Uokq2WMl--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qifqtdy74f67ixxuwjzd.png" alt="App showing a scrollable text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My composable first creates a string consisting of 100 lines with ascending numbers followed by a final line &lt;code&gt;- end -&lt;/code&gt;. This string is passed to &lt;code&gt;Text()&lt;/code&gt;. Spot the &lt;code&gt;modifier&lt;/code&gt;. The text wants all available size (&lt;code&gt;fillMaxSize()&lt;/code&gt;). Also, &lt;code&gt;verticalScroll()&lt;/code&gt; makes it scrollable vertically. The docs say:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Modify element to allow to scroll vertically when height of the&lt;br&gt;
content is bigger than max constraints allow.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Naturally, &lt;code&gt;verticalScroll()&lt;/code&gt; is an extension function to &lt;code&gt;Modifier&lt;/code&gt;. It receives the state of the scroll, which is created using &lt;code&gt;rememberScrollState()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now let's look at the Top-level functions. They include very important basic composables, for example &lt;code&gt;Image()&lt;/code&gt; and &lt;code&gt;Canvas()&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#displaying-images"&gt;
  &lt;/a&gt;
  Displaying images
&lt;/h3&gt;

&lt;p&gt;Displaying static images is super easy:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight kotlin"&gt;&lt;code&gt;&lt;span class="nd"&gt;@Composable&lt;/span&gt;
&lt;span class="k"&gt;fun&lt;/span&gt; &lt;span class="nf"&gt;Sandbox&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nc"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;modifier&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Modifier&lt;/span&gt;
            &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fillMaxSize&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;padding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;verticalArrangement&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Arrangement&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;Center&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;horizontalAlignment&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Alignment&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;CenterHorizontally&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nc"&gt;Image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;painter&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;painterResource&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nc"&gt;R&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drawable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ic_launcher_foreground&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
            &lt;span class="s"&gt;"An image"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;modifier&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Modifier&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;requiredSize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;96&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nc"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Hello Image"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;As you can see I obtain a &lt;code&gt;painter&lt;/code&gt; through &lt;code&gt;painterResource()&lt;/code&gt;. The docs say:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Create a &lt;code&gt;Painter&lt;/code&gt; from an Android resource id. This can load&lt;br&gt;
either an instance of &lt;code&gt;BitmapPainter&lt;/code&gt; or &lt;code&gt;VectorPainter&lt;/code&gt; for&lt;br&gt;
&lt;code&gt;ImageBitmap&lt;/code&gt; based assets or vector based assets respectively.&lt;br&gt;
The resources with the given id must point to either fully&lt;br&gt;
rasterized images (ex. PNG or JPG files) or VectorDrawable xml&lt;br&gt;
assets. API based xml Drawables are not supported here.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There is one caveat, though.&lt;/p&gt;

&lt;p&gt;If you try this:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight kotlin"&gt;&lt;code&gt;&lt;span class="nc"&gt;Image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="n"&gt;painter&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;painterResource&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nc"&gt;R&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mipmap&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ic_launcher&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
  &lt;span class="s"&gt;"An image"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="n"&gt;modifier&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Modifier&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;requiredSize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;96&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;you will get a &lt;code&gt;IllegalArgumentException: Only VectorDrawables and rasterized asset types are supported ex. PNG, JPG&lt;/code&gt; at runtime if your app icon is an adaptive icon. This is the case if your have a file &lt;em&gt;ic_launcher.xml&lt;/em&gt; in &lt;em&gt;mipmap-anydpi-v26&lt;/em&gt;. Yet, it's easy to load adaptive icons:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight kotlin"&gt;&lt;code&gt;&lt;span class="nd"&gt;@Composable&lt;/span&gt;
&lt;span class="k"&gt;fun&lt;/span&gt; &lt;span class="nf"&gt;Sandbox&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nc"&gt;ResourcesCompat&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;getDrawable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="nc"&gt;LocalContext&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;current&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;resources&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nc"&gt;R&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mipmap&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ic_launcher&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nc"&gt;LocalContext&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;current&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;theme&lt;/span&gt;
  &lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;?.&lt;/span&gt;&lt;span class="nf"&gt;let&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;drawable&lt;/span&gt; &lt;span class="p"&gt;-&amp;gt;&lt;/span&gt;
    &lt;span class="kd"&gt;val&lt;/span&gt; &lt;span class="py"&gt;bitmap&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Bitmap&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;createBitmap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
      &lt;span class="n"&gt;drawable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intrinsicWidth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;drawable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intrinsicHeight&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="nc"&gt;Bitmap&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;Config&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;ARGB_8888&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="kd"&gt;val&lt;/span&gt; &lt;span class="py"&gt;canvas&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Canvas&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bitmap&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;drawable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;setBounds&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;drawable&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nc"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
      &lt;span class="n"&gt;modifier&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Modifier&lt;/span&gt;
        &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fillMaxSize&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;padding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
      &lt;span class="n"&gt;verticalArrangement&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Arrangement&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;Center&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="n"&gt;horizontalAlignment&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Alignment&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;CenterHorizontally&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nc"&gt;Image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="c1"&gt;// painter = painterResource(R.mipmap.ic_launcher),&lt;/span&gt;
        &lt;span class="n"&gt;bitmap&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bitmap&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;asImageBitmap&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
        &lt;span class="s"&gt;"An image"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;modifier&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Modifier&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;requiredSize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;96&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="nc"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Hello Image"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;So, we just need to...&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;get a &lt;code&gt;Drawable&lt;/code&gt; using &lt;code&gt;ResourcesCompat.getDrawable()&lt;/code&gt;
&lt;/li&gt;
&lt;li&gt;create an empty &lt;code&gt;android.graphics.Bitmap&lt;/code&gt;
&lt;/li&gt;
&lt;li&gt;create an &lt;code&gt;android.graphics.Canvas&lt;/code&gt; that operates on this bitmap&lt;/li&gt;
&lt;li&gt;draw the drawable on the canvas (into our bitmap)&lt;/li&gt;
&lt;li&gt;get an &lt;code&gt;androidx.compose.ui.graphics.ImageBitmap&lt;/code&gt; instance using the extension function &lt;code&gt;asImageBitmap()&lt;/code&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Quite easy, isn't it? üòé&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#drawing-with-raw-canvas-endraw-"&gt;
  &lt;/a&gt;
  Drawing with &lt;code&gt;Canvas()&lt;/code&gt;
&lt;/h3&gt;

&lt;p&gt;Just like &lt;code&gt;Image()&lt;/code&gt;, &lt;code&gt;Canvas()&lt;/code&gt; is a Top-level function in &lt;code&gt;androidx.compose.foundation&lt;/code&gt;. Please do not confuse it with the class we saw moments ago, &lt;code&gt;android.graphics.Canvas&lt;/code&gt; (which belongs to the Android framework). I have written a complete series called &lt;a href="https://dev.to/tkuenneth/series/10525"&gt;Drawing and painting in Jetpack Compose&lt;/a&gt;, so here I will show you just one example.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight kotlin"&gt;&lt;code&gt;&lt;span class="nd"&gt;@Composable&lt;/span&gt;
&lt;span class="nd"&gt;@Preview&lt;/span&gt;
&lt;span class="k"&gt;fun&lt;/span&gt; &lt;span class="nf"&gt;Sandbox&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nc"&gt;Canvas&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;modifier&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nc"&gt;Modifier&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;fillMaxSize&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
    &lt;span class="n"&gt;onDraw&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nf"&gt;drawLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="nc"&gt;Color&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;Black&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nc"&gt;Offset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0f&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="nc"&gt;Offset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="p"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="p"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="nf"&gt;drawLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="nc"&gt;Color&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;Black&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nc"&gt;Offset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="p"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="nc"&gt;Offset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="p"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="nf"&gt;drawCircle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="nc"&gt;Color&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;Red&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;64f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="nc"&gt;Offset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="p"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="p"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--NyNY4Cv6--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/iqvwgu4ii7div6xy328x.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--NyNY4Cv6--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/iqvwgu4ii7div6xy328x.png" alt="Drawing on a canvas"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You specify an area on the screen and perform drawing operations on it. These instructions are given inside &lt;code&gt;onDraw()&lt;/code&gt;. My example produces two lines and a filled circle.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#wrap-up"&gt;
  &lt;/a&gt;
  Wrap up
&lt;/h3&gt;

&lt;p&gt;I hope you like this series. Please share your thoughts in the comments. In the next installment we will turn to the subpackages of &lt;code&gt;androidx.compose.foundation&lt;/code&gt;. So stay tuned.&lt;/p&gt;

</description>
      <category>android</category>
      <category>jetpackcompose</category>
      <category>kotlin</category>
    </item>
    <item>
      <title>Day 10/30 : Responsive Image Gallery using HTML and CSS</title>
      <author>Somanath Goudar</author>
      <pubDate>Sat, 29 May 2021 12:39:39 +0000</pubDate>
      <link>https://dev.to/somanathgoudar/day-10-30-responsive-image-gallery-using-html-and-css-44eo</link>
      <guid>https://dev.to/somanathgoudar/day-10-30-responsive-image-gallery-using-html-and-css-44eo</guid>
      <description>&lt;p&gt;Welcome to Day 10 of this &lt;a href="https://dev.to/somanathgoudar/30dayschallenge-30-days-extreme-html-css-challenge-50k1"&gt;Challenge&lt;/a&gt;. This is what I created today. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;‚ûú Here is the Demo :&lt;/strong&gt;&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--uA5zLkOD--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://1.bp.blogspot.com/-uUVvdN4yZlQ/YKOfmRfDysI/AAAAAAAAACs/SBl7p6CJHyANP1ZYgKCVIlp47Cy-ggq4QCLcBGAsYHQ/s600/p10.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--uA5zLkOD--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://1.bp.blogspot.com/-uUVvdN4yZlQ/YKOfmRfDysI/AAAAAAAAACs/SBl7p6CJHyANP1ZYgKCVIlp47Cy-ggq4QCLcBGAsYHQ/s600/p10.gif" alt="Responsive Image Gallery"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;‚ûú Video Tutorial :&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;iframe width="710" height="399" src="https://www.youtube.com/embed/6VgThhxrTdk"&gt;
&lt;/iframe&gt;
&lt;br&gt;
&lt;strong&gt;‚ûú Source Code :&lt;/strong&gt;&lt;br&gt;
&lt;a href="https://www.mrwebwolf.com/2021/05/how-to-create-responsive-image-gallery.html"&gt;https://www.mrwebwolf.com/2021/05/how-to-create-responsive-image-gallery.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;‚ûú Instagram Post and Reel for Day 10 :&lt;/strong&gt;&lt;br&gt;
&lt;a href="https://www.instagram.com/future_coderss/"&gt;See Post and Reel&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;Hey, If You don't know what is happening here. Don't Worry, I am doing a crazy challenge üòÖ. Read More about it from the post below.&lt;/p&gt;


&lt;div class="ltag__link"&gt;
  &lt;a href="/somanathgoudar" class="ltag__link__link"&gt;
    &lt;div class="ltag__link__pic"&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--KnNEMcDo--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://res.cloudinary.com/practicaldev/image/fetch/s--15QGQnyq--/c_fill%2Cf_auto%2Cfl_progressive%2Ch_150%2Cq_auto%2Cw_150/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/600953/fdee0195-6d25-410d-9d97-c10ffaa4eb7d.jpeg" alt="somanathgoudar image"&gt;
    &lt;/div&gt;
  &lt;/a&gt;
  &lt;a href="/somanathgoudar/30dayschallenge-30-days-extreme-html-css-challenge-50k1" class="ltag__link__link"&gt;
    &lt;div class="ltag__link__content"&gt;
      &lt;h2&gt;ü§Ø 30DaysChallenge - 30 Days Extreme HTML &amp;amp; CSS CHALLENGE ü§Ø&lt;/h2&gt;
      &lt;h3&gt;Somanath Goudar „Éª May 19 „Éª 3 min read&lt;/h3&gt;
      &lt;div class="ltag__link__taglist"&gt;
        &lt;span class="ltag__link__tag"&gt;#html&lt;/span&gt;
        &lt;span class="ltag__link__tag"&gt;#webdev&lt;/span&gt;
        &lt;span class="ltag__link__tag"&gt;#frontend&lt;/span&gt;
        &lt;span class="ltag__link__tag"&gt;#30daysofcode&lt;/span&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/a&gt;
&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Support Me :&lt;/strong&gt;&lt;br&gt;
üëâ Buy me a Coffee: &lt;a href="https://www.buymeacoffee.com/somanathgoudar"&gt;https://www.buymeacoffee.com/somanathgoudar&lt;/a&gt;&lt;br&gt;
üëâ &lt;a href="https://www.instagram.com/somanath_goudar/"&gt;Follow Me on Instagram&lt;/a&gt;&lt;br&gt;
üëâ &lt;a href="https://www.instagram.com/future_coderss/"&gt;Follow Future Coders on Instagram&lt;/a&gt;&lt;br&gt;
üëâ &lt;a href="https://www.youtube.com/channel/UC_nTrhTr5fnBGjOxnkPUmmA"&gt;Subscribe to My Main Channel&lt;/a&gt;&lt;br&gt;
üëâ &lt;a href="https://www.youtube.com/channel/UCzGSyMOf2jPt1MkNBB3SJ3g"&gt;Subscribe to Channel Created for this Challenge&lt;/a&gt;&lt;/p&gt;




</description>
      <category>html</category>
      <category>css</category>
      <category>webdev</category>
      <category>tutorial</category>
    </item>
    <item>
      <title>What to do next ?</title>
      <author>Amritanshu Dev Rawat</author>
      <pubDate>Sat, 29 May 2021 12:23:09 +0000</pubDate>
      <link>https://dev.to/amritanshu/what-to-do-next-o4o</link>
      <guid>https://dev.to/amritanshu/what-to-do-next-o4o</guid>
      <description>&lt;p&gt;Like, Comment, Share.&lt;/p&gt;

</description>
      <category>discuss</category>
      <category>codenewbie</category>
    </item>
    <item>
      <title>Python Open Source projects in GitHub</title>
      <author>Vishnubhotla V D V Bharadwaj</author>
      <pubDate>Sat, 29 May 2021 12:08:14 +0000</pubDate>
      <link>https://dev.to/bharadwaj6262/python-open-source-projects-in-github-3jgk</link>
      <guid>https://dev.to/bharadwaj6262/python-open-source-projects-in-github-3jgk</guid>
      <description>&lt;p&gt;Hello everyone. How is it going? Hope you all doing well. Let's dive into the topic. Nowadays we are hearing a lot of buzz about Open Source. So, let's see the evergreen Python's top Open Source projects in Github. In this blog, I am going to share 10 amazing Open Source projects.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Manim&lt;/strong&gt; (‚≠ê33.9k)&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--npHYEC-9--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622286758061/LG6xfDNlU.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--npHYEC-9--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622286758061/LG6xfDNlU.png" alt="Screenshot (166).png"&gt;&lt;/a&gt;Manim - Mathematical Animation Engine&lt;/p&gt;

&lt;p&gt;Manim is an animation engine for explanatory math videos. It is basically used to create precise animations programmatically and runs on Python 3.6 and above. Manim uses Python to generate animations programmatically, which makes it possible to specify exactly how each one should run.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DeepFaceLab&lt;/strong&gt; (‚≠ê26.5k)&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--dtgSSVbM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622286795505/8jmWEzqW3.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--dtgSSVbM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622286795505/8jmWEzqW3.png" alt="Screenshot (167).png"&gt;&lt;/a&gt;DeepFaceLab is an open-source deep fake system created by iperov for face swapping. It provides an imperative and easy-to-use pipeline for people to use with no comprehensive understanding of the deep learning framework or with model implementation required. This system provides a flexible and loose coupling structure for people who needs to strengthen their own pipeline with other features without writing complicated boilerplate code.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Airflow&lt;/strong&gt; (‚≠ê21.6k)&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--j1hcnYet--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622286851704/zSzP2i21H.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--j1hcnYet--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622286851704/zSzP2i21H.png" alt="apache.png"&gt;&lt;/a&gt;Airflow is a platform to programmatically author, schedule, and monitor workflows. The pipelines in Airflow allow for writing code that instantiates pipelines dynamically. to use this platform, you will need Python versions 3.5 and above. It allows users to use Python features to create workflows, monitor, schedule, and manage the workflows using the web app. Anyone with Python knowledge can deploy a workflow. It also has plug-and-play operators that are ready to handle your task on Google Cloud Platform, AWS, Microsoft Azure, and many other services.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GPT-2&lt;/strong&gt; (‚≠ê14.6k)&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--RCHuSKJM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622286865695/51qw569Lhc.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--RCHuSKJM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622286865695/51qw569Lhc.png" alt="openai.png"&gt;&lt;/a&gt;GPT-2 is a large transformer-based language model with 1.5 billion parameters, which is trained with a simple objective to predict the next word, given all of the previous words within some text. GPT-2 generates synthetic text samples in response to the model being primed with arbitrary input. It is a large-scale unsupervised language model which generates coherent paragraphs of text, performs rudimentary reading comprehension and machine translation. It can also perform question answering and summarization. It can generate conditional synthetic text samples of unprecedented quality.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Horovod&lt;/strong&gt; (‚≠ê11.3k)&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--1fjdzqJH--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622286879830/1uNyWIYgn.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--1fjdzqJH--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622286879830/1uNyWIYgn.png" alt="Screenshot (168).png"&gt;&lt;/a&gt;Horovod is an open-source distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet. Developed by Uber, the goal of Horovod is to make distributed deep learning fast and easy to use. The primary motivation for this project is to make it easy to take a single-GPU training script and successfully scale it to train across many GPUs in parallel. It is fast and easy to use, achieves 90% scaling efficiency for both Inception V3 and ResNet-101, and 68% scaling efficiency for VGG-16.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ML-Agents&lt;/strong&gt; (‚≠ê11.1k)&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--qfqZp4-5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622289891346/fqLtyFQWsF.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--qfqZp4-5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622289891346/fqLtyFQWsF.png" alt="Screenshot (169).png"&gt;&lt;/a&gt;The Unity Machine Learning Agents ToolKit(ML-Agents) is an open-source project that enables games and simulations to serve as environments for training intelligent agents. The agents can be trained using reinforcement learning, imitation learning, neuroevolution, or other machine learning methods through a simple-to-use Python API. Some of its features include support for multiple environment configurations and training scenarios, flexible Unity SDK, built-in support for imitation learning, among others.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;XSStrike&lt;/strong&gt; (‚≠ê9.3k)&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--pK60uYrp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622289901746/L13DT2uzp.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--pK60uYrp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622289901746/L13DT2uzp.png" alt="Screenshot (170).png"&gt;&lt;/a&gt;XSStrike is a Cross-Site Scripting detection suite equipped with four handwritten parsers. It is an intelligent payload generator, a powerful fuzzing engine as well as an incredibly fast crawler. The key features of XSStrike include multi-threaded crawling, configurable core, WAF detection, complete HTTP support, and more.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NeuralTalk&lt;/strong&gt; (‚≠ê5.2k)&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--PJHehtAL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622289914563/xZcwGhLeK.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--PJHehtAL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622289914563/xZcwGhLeK.png" alt="Screenshot (171).png"&gt;&lt;/a&gt;NeuralTalk is a Python and Numpy source code for learning Multimodal Recurrent Neural Networks that describe images with sentences. NeuralTalk2 is written in Torch and runs on the GPU. It also supports CNN finetuning, which helps a lot of performance.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Xonsh&lt;/strong&gt; (‚≠ê4.9k)&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--gbHSEea---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622289927831/5Oa7leSRc.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--gbHSEea---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622289927831/5Oa7leSRc.png" alt="Screenshot (172).png"&gt;&lt;/a&gt;Xonsh is a Python-powered, cross-platform, Unix-gazing shell language and command prompt. It is a superset of Python 3.6+ with additional shell primitives from Bash and IPython. The language is meant for the daily use of experts and novices. It works on all major systems, including Linux, Mac OS, and Windows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Optuna&lt;/strong&gt; (4.6k)&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--zNdeS6Hw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622289938976/gqTmgUq-9.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--zNdeS6Hw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn.hashnode.com/res/hashnode/image/upload/v1622289938976/gqTmgUq-9.png" alt="Screenshot (173).png"&gt;&lt;/a&gt;Optuna is an automatic hyperparameter optimization software framework, particularly designed for machine learning. It features an imperative, define-by-run style user API. It allows for an automated search for optimal hyperparameters using Python conditionals, loops, and syntax. It can also parallelize hyperparameter searches over multiple threads or processes, without modifying code.&lt;/p&gt;

&lt;p&gt;That's a wrap. Thanks for reading. Follow me on &lt;a href="https://twitter.com/Bharadwaj6262"&gt;Twitter&lt;/a&gt; where I regularly post some great content.&lt;/p&gt;

</description>
      <category>python</category>
      <category>github</category>
      <category>opensource</category>
      <category>machinelearning</category>
    </item>
  </channel>
</rss>
