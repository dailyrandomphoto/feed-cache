<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>DEV Community</title>
    <author>DEV Community</author>
    <description>A constructive and inclusive social network for software developers. With you every step of your journey.</description>
    <link>https://dev.to</link>
    <language>en</language>
    <item>
      <title>Cypress Commands (Get, Click, Find)</title>
      <author>Automation Bro</author>
      <pubDate>Wed, 21 Apr 2021 12:18:54 +0000</pubDate>
      <link>https://dev.to/automationbro/cypress-commands-get-click-find-51ig</link>
      <guid>https://dev.to/automationbro/cypress-commands-get-click-find-51ig</guid>
      <description>&lt;p&gt;In this tutorial, we will cover some commonly used Cypress Commands such as Get, Click and Find. We will also take a look at how to find the text of a particular element.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#cypress-get-amp-click-command"&gt;
  &lt;/a&gt;
  Cypress Get &amp;amp; Click Command
&lt;/h3&gt;

&lt;p&gt;One of the most commands that you will use in Cypress is the ‚ÄòGet‚Äô command. The ‚Äòget‚Äô command is used to access one or more DOM elements by a selector.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt;&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--8m-olCam--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3xekt9mgrb63g3b5dxxg.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--8m-olCam--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3xekt9mgrb63g3b5dxxg.png" alt="commands-get"&gt;&lt;/a&gt;&lt;/p&gt;


&lt;h3&gt;
  &lt;a href="#cypress-get-text-of-an-element"&gt;
  &lt;/a&gt;
  Cypress Get Text of an Element
&lt;/h3&gt;

&lt;p&gt;There are multiple ways to get the text of an element in Cypress.&lt;/p&gt;

&lt;p&gt;1 ‚Äì Easiest option is via the assertion method:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--wEfdUyXw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1uwut5ejkqxkv675lvor.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--wEfdUyXw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1uwut5ejkqxkv675lvor.png" alt="commands-text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2 ‚Äì This option you can use if you need to manipulate the text first:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--pOFa9Ve8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/c3mujly4gsldaheyfvmy.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--pOFa9Ve8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/c3mujly4gsldaheyfvmy.png" alt="carbon-gettext"&gt;&lt;/a&gt;&lt;/p&gt;


&lt;h3&gt;
  &lt;a href="#cypress-find-command"&gt;
  &lt;/a&gt;
  Cypress Find Command
&lt;/h3&gt;

&lt;p&gt;The ‚Äòfind‚Äô command is used to get the descendant of a particular selector. For example, in the below code we are first accessing the nav menu by the id selector and then finding all the list items within the nav using the ‚Äòfind‚Äô command.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--4gchKxj---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ohlogw38izyib0gct7r8.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--4gchKxj---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ohlogw38izyib0gct7r8.png" alt="find-command"&gt;&lt;/a&gt;&lt;/p&gt;


&lt;h4&gt;
  &lt;a href="#check-out-the-video-below-to-see-learn-more-about-the-get-click-and-the-find-commands-"&gt;
  &lt;/a&gt;
  Check out the video below to see learn more about the Get, Click, and the Find commands ‚Äì
&lt;/h4&gt;

&lt;p&gt;&lt;iframe width="710" height="399" src="https://www.youtube.com/embed/jyDr97ubWMQ"&gt;
&lt;/iframe&gt;
&lt;/p&gt;




&lt;p&gt;üìß Subscribe to my &lt;a href="https://automationbro.com/mailing-list"&gt;mailing list&lt;/a&gt; to get access to more content like this &lt;/p&gt;

&lt;p&gt;üëç Follow &lt;a href="https://twitter.com/automationbro"&gt;automationbro&lt;/a&gt; on Twitter for the latest updates&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;I love coffees! And, if this post helped you out and you would like to support my work, you can do that by clicking on the button below and buying me a cup of coffee -&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.buymeacoffee.com/automationbro"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--lUHFj71T--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/4aw2ub3f4qkyjk0ivwt4.png" alt="Buy me a coffee"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can also support me by liking and sharing this content.&lt;/p&gt;

&lt;p&gt;Thanks for reading!&lt;/p&gt;

</description>
      <category>testing</category>
      <category>javascript</category>
      <category>webdev</category>
      <category>tutorial</category>
    </item>
    <item>
      <title>‚ú® 3D Card Hover Effect With Modern CSS Properties üòç</title>
      <author>Satish Naikawadi</author>
      <pubDate>Wed, 21 Apr 2021 12:17:56 +0000</pubDate>
      <link>https://dev.to/satishnaikawadi2001/3d-card-hover-effect-with-modern-css-properties-24fk</link>
      <guid>https://dev.to/satishnaikawadi2001/3d-card-hover-effect-with-modern-css-properties-24fk</guid>
      <description>&lt;p&gt;In this post , we are going to create very üíñ beautiful and unique 3D card hover effect with HTML and CSS. We will use some modern properties in CSS to achieve this effect. Below is the demo of what we will create in this post -&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--M0giFgkl--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://res.cloudinary.com/dh1srz69c/image/upload/v1615993587/3d_card_gif_310405a9bf.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--M0giFgkl--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://res.cloudinary.com/dh1srz69c/image/upload/v1615993587/3d_card_gif_310405a9bf.gif" alt="3d-card-gif.gif"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We will proceed as below:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Creating a HTML Markup.&lt;/li&gt;
&lt;li&gt;Adding Basic Styling For All Elements.&lt;/li&gt;
&lt;li&gt;Creating Actual Hover Effect.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So lets first add all the HTML code to build required structure.&lt;/p&gt;
&lt;h1&gt;
  &lt;a href="#creating-html-markup"&gt;
  &lt;/a&gt;
  üöß Creating HTML Markup
&lt;/h1&gt;


&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight html"&gt;&lt;code&gt;&lt;span class="nt"&gt;&amp;lt;body&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;h1&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"heading"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;3D Card Hover Effect&lt;span class="nt"&gt;&amp;lt;/h1&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"container"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"item"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;img&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__img"&lt;/span&gt;
                        &lt;span class="na"&gt;src=&lt;/span&gt;&lt;span class="s"&gt;"https://images.unsplash.com/photo-1588392382834-a891154bca4d?ixid=MXwxMjA3fDB8MHxzZWFyY2h8NXx8bmF0dXJlfGVufDB8fDB8&amp;amp;ixlib=rb-1.2.1&amp;amp;auto=format&amp;amp;fit=crop&amp;amp;w=500&amp;amp;q=60"&lt;/span&gt;
                        &lt;span class="na"&gt;alt=&lt;/span&gt;&lt;span class="s"&gt;"Green Forests"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__content"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;h1&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__header"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Green Forests&lt;span class="nt"&gt;&amp;lt;/h1&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;p&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__text"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi id sem sit
                            amet massa aliquet aliquet. Phasellus at ipsum
                            congue urna commodo gravidas&lt;span class="nt"&gt;&amp;lt;/p&amp;gt;&amp;lt;button&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__btn"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Explore
                            &lt;span class="nt"&gt;&amp;lt;span&amp;gt;&lt;/span&gt;&lt;span class="ni"&gt;&amp;amp;rarr;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;/span&amp;gt;&amp;lt;/button&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"item"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;img&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__img"&lt;/span&gt;
                        &lt;span class="na"&gt;src=&lt;/span&gt;&lt;span class="s"&gt;"https://images.unsplash.com/photo-1505245208761-ba872912fac0?ixid=MXwxMjA3fDB8MHxzZWFyY2h8Mzd8fG5hdHVyZXxlbnwwfHwwfA%3D%3D&amp;amp;ixlib=rb-1.2.1&amp;amp;auto=format&amp;amp;fit=crop&amp;amp;w=500&amp;amp;q=60"&lt;/span&gt;
                        &lt;span class="na"&gt;alt=&lt;/span&gt;&lt;span class="s"&gt;"Beutiful Oceans"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__content"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;h1&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__header"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Beautiful Oceans&lt;span class="nt"&gt;&amp;lt;/h1&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;p&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__text"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi id sem sit
                            amet massa aliquet aliquet. Phasellus at ipsum
                            congue urna commodo gravida&lt;span class="nt"&gt;&amp;lt;/p&amp;gt;&amp;lt;button&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__btn"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Explore
                            &lt;span class="nt"&gt;&amp;lt;span&amp;gt;&lt;/span&gt;&lt;span class="ni"&gt;&amp;amp;rarr;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;/span&amp;gt;&amp;lt;/button&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"item"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;img&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__img"&lt;/span&gt;
                        &lt;span class="na"&gt;src=&lt;/span&gt;&lt;span class="s"&gt;"https://images.unsplash.com/photo-1431512284068-4c4002298068?ixid=MXwxMjA3fDB8MHxzZWFyY2h8OTB8fG5hdHVyZXxlbnwwfHwwfA%3D%3D&amp;amp;ixlib=rb-1.2.1&amp;amp;auto=format&amp;amp;fit=crop&amp;amp;w=500&amp;amp;q=60s"&lt;/span&gt;
                        &lt;span class="na"&gt;alt=&lt;/span&gt;&lt;span class="s"&gt;"Snowy Mountains"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__content"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;h1&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__header"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Snowy Mountains&lt;span class="nt"&gt;&amp;lt;/h1&amp;gt;&lt;/span&gt;
                        &lt;span class="nt"&gt;&amp;lt;p&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__text"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi id sem sit
                            amet massa aliquet aliquet. Phasellus at ipsum
                            congue urna commodo gravida&lt;span class="nt"&gt;&amp;lt;/p&amp;gt;&amp;lt;button&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"card__btn"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;Explore
                            &lt;span class="nt"&gt;&amp;lt;span&amp;gt;&lt;/span&gt;&lt;span class="ni"&gt;&amp;amp;rarr;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;/span&amp;gt;&amp;lt;/button&amp;gt;&lt;/span&gt;
                    &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
                &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
            &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;


&lt;p&gt;Here we have &lt;code&gt;div&lt;/code&gt; with &lt;code&gt;class&lt;/code&gt; 'container'  which will be the parent of all the three cards. Then we are having each 'card' inside &lt;code&gt;div&lt;/code&gt; with &lt;code&gt;class&lt;/code&gt;&lt;br&gt;
'item'. Each 'card' &lt;code&gt;div&lt;/code&gt; has its image,its header and some text related to it. It also has one &lt;code&gt;button&lt;/code&gt; inside it.&lt;br&gt;
So that's the basic HTML markup of the webpage we are going to build.&lt;br&gt;
Now lets see add some styling for all the elements like 'card',&lt;code&gt;img&lt;/code&gt;,text inside card, button and also some styling for layouting of card.&lt;/p&gt;
&lt;h1&gt;
  &lt;a href="#basic-styling-for-all-elements"&gt;
  &lt;/a&gt;
  ü¶ãBasic Styling For All Elements
&lt;/h1&gt;

&lt;p&gt;Below is the CSS code for styling of these elemets -&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight css"&gt;&lt;code&gt;&lt;span class="o"&gt;*,&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nd"&gt;::before&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nd"&gt;::after&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;margin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;padding&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;box-sizing&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;inherit&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nt"&gt;html&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;box-sizing&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;border-box&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;font-size&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;62.5%&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nt"&gt;body&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;padding&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;6rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;background-color&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;#15202b&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;color&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="no"&gt;white&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;font-family&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;"Inter"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;sans-serif&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nc"&gt;.heading&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;font-size&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;4rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;text-align&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;center&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;margin-bottom&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;3rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;text-shadow&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;3px&lt;/span&gt; &lt;span class="m"&gt;4px&lt;/span&gt; &lt;span class="m"&gt;5px&lt;/span&gt; &lt;span class="no"&gt;pink&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nc"&gt;.container&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;display&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;flex&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;justify-content&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;space-around&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;align-items&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;center&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;flex-wrap&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;wrap&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nc"&gt;.item&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;background-color&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;#192734&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;border-radius&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0.4rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;overflow&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;pointer&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;width&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;30%&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;transition&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;.5s&lt;/span&gt; &lt;span class="n"&gt;all&lt;/span&gt; &lt;span class="n"&gt;ease&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;box-shadow&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0px&lt;/span&gt; &lt;span class="m"&gt;20px&lt;/span&gt; &lt;span class="m"&gt;50px&lt;/span&gt; &lt;span class="m"&gt;#555&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nc"&gt;.card__img&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;display&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;block&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;width&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;100%&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;height&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;18rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;object-fit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;cover&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nc"&gt;.card__content&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;padding&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;3rem&lt;/span&gt; &lt;span class="m"&gt;3rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nc"&gt;.card__header&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;font-size&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;3rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;font-weight&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;500&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;color&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;#fff&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;margin-bottom&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;1.5rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nc"&gt;.card__text&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;font-size&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;1.5rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;letter-spacing&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0.1rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;line-height&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;1.7&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;color&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;#8899a6&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;margin-bottom&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;2.5rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nc"&gt;.card__btn&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;display&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;block&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;width&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;100%&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;padding&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;1.5rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;font-size&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;2rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;text-align&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;center&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;color&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;#3363ff&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;background-color&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;#e6ecff&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;border&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;none&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;border-radius&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0.4rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;transition&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0.2s&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;pointer&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nc"&gt;.card__btn&lt;/span&gt; &lt;span class="nt"&gt;span&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;margin-left&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;1rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;transition&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0.2s&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nc"&gt;.card__btn&lt;/span&gt;&lt;span class="nd"&gt;:hover&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
&lt;span class="nc"&gt;.card__btn&lt;/span&gt;&lt;span class="nd"&gt;:active&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;background-color&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;#dce4ff&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nc"&gt;.card__btn&lt;/span&gt;&lt;span class="nd"&gt;:hover&lt;/span&gt; &lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
&lt;span class="nc"&gt;.card__btn&lt;/span&gt;&lt;span class="nd"&gt;:active&lt;/span&gt; &lt;span class="nt"&gt;span&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;margin-left&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;1.5rem&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;@media&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max-width&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;992px&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nc"&gt;.item&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nl"&gt;width&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;45%&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;@media&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max-width&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;768px&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nc"&gt;.item&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nl"&gt;width&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;80%&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;


&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;So this is the all basic styling needed to style our webpage. After this we will now see how we can create the actual &lt;strong&gt;3D Card Hover Effect&lt;/strong&gt;&lt;br&gt;
with some interesting CSS properties.&lt;/p&gt;
&lt;h1&gt;
  &lt;a href="#creating-actual-3d-hover-effect"&gt;
  &lt;/a&gt;
  üòâ Creating Actual 3D Hover Effect
&lt;/h1&gt;

&lt;p&gt;Firstly , for giving starting position to our cards , we will add &lt;code&gt;transform&lt;/code&gt; property to it which will have value as &lt;code&gt;rotateX(45deg) scale(0.7)&lt;/code&gt;. Now here&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;code&gt;rotateX()&lt;/code&gt; - The &lt;code&gt;rotateX()&lt;/code&gt; method rotates an element around its X-axis at a given degree in 3 dimensions.&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;scale()&lt;/code&gt; -  The &lt;code&gt;scale()&lt;/code&gt; method increases or decreases the size of an element (according to the parameters given for the width and height).
these methods will make our item to be rotated along X-axis with 45 degrees with its size decreased to 0.7 of its original size.
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight css"&gt;&lt;code&gt;&lt;span class="nt"&gt;transform&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;rotateX&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;45&lt;/span&gt;&lt;span class="nt"&gt;deg&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="nt"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;0&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="err"&gt;7&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;


&lt;p&gt;Now by adding this line we won't get our initial positions of our card , instead we will get it as below - &lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--xDkQHyIT--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://res.cloudinary.com/dh1srz69c/image/upload/v1616006321/unwanted_ad9baa21cc.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--xDkQHyIT--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://res.cloudinary.com/dh1srz69c/image/upload/v1616006321/unwanted_ad9baa21cc.jpg" alt="unwanted.jpg"&gt;&lt;/a&gt;&lt;br&gt;
 from which it looks like item is scaled down to 0.7 of its original size but it doesn't look like it has rotated through 45 degrees around X-axis. But it did. It doesn't look like rotated because while doing 3D transformation we have tell browser that how far is that item from the user's eyes. And to do that we can use &lt;code&gt;perspective&lt;/code&gt; property in CSS.&lt;/p&gt;
&lt;h3&gt;
  &lt;a href="#perspective-in-css"&gt;
  &lt;/a&gt;
  üßêPerspective In CSS
&lt;/h3&gt;

&lt;p&gt;1.The &lt;code&gt;perspective&lt;/code&gt; property is used to give a 3D-positioned element some perspective.&lt;br&gt;
2.The &lt;code&gt;perspective&lt;/code&gt; property defines how far the object is away from the user. So, a lower value will result in a more intensive 3D effect than a higher value.&lt;br&gt;
3.When defining the &lt;code&gt;perspective&lt;/code&gt; property for an element, it is the CHILD elements that get the perspective view, NOT the element itself.&lt;br&gt;
To learn more about &lt;code&gt;perspective&lt;/code&gt; in CSS and other properties related to it like &lt;code&gt;perspective-origin&lt;/code&gt; &lt;a href="https://developer.mozilla.org/en-US/docs/Web/CSS/perspective"&gt;Click Here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So now to get desired positioning of our items , we will add &lt;code&gt;perspective&lt;/code&gt; property to container which is a parent of item components and set its value to &lt;code&gt;900px&lt;/code&gt;(While using perspective you should try and test values to get desired look).&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight css"&gt;&lt;code&gt;&lt;span class="nc"&gt;.container&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;perspective&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;900px&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;So now we will get correct initial look for our cards which is as below - &lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Yg4OBl3w--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://res.cloudinary.com/dh1srz69c/image/upload/v1616008197/desired_cc8e8c1d77.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Yg4OBl3w--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://res.cloudinary.com/dh1srz69c/image/upload/v1616008197/desired_cc8e8c1d77.jpg" alt="desired.jpg"&gt;&lt;/a&gt;&lt;br&gt;
So that's hard part done. Now we only have to add hover state to our item which will be its normal position for which we will set &lt;code&gt;transform&lt;/code&gt; property as &lt;code&gt;rotate(0deg) scale(1)&lt;/code&gt;.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight css"&gt;&lt;code&gt;&lt;span class="nc"&gt;.item&lt;/span&gt;&lt;span class="nd"&gt;:hover&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;cursor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;pointer&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;transform&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;rotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0deg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;scale&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="nl"&gt;transition&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;.5s&lt;/span&gt; &lt;span class="n"&gt;all&lt;/span&gt; &lt;span class="n"&gt;ease&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;z-index&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;400&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nl"&gt;box-shadow&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;2px&lt;/span&gt; &lt;span class="m"&gt;2px&lt;/span&gt; &lt;span class="n"&gt;rgba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0.16&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;And with that we have completed our beautiful and awesome &lt;strong&gt;3D Hover Effect&lt;/strong&gt;. I know &lt;code&gt;perspective&lt;/code&gt; property is little difficult to understand. But with practicing more examples and reading docs you will get comfortable with it.&lt;br&gt;
For more articles related to programming do visit my&lt;br&gt;
&lt;a href="https://satishnaikawadi.me/posts"&gt;Personal Blog&lt;/a&gt;. &lt;br&gt;
I Hope this will help you guys. Thanks üòá for reading as always.  &lt;/p&gt;

</description>
      <category>html</category>
      <category>css</category>
      <category>webdev</category>
      <category>beginners</category>
    </item>
    <item>
      <title>Broaden the view</title>
      <author>Hendrik</author>
      <pubDate>Wed, 21 Apr 2021 12:14:54 +0000</pubDate>
      <link>https://dev.to/hendr_ik/broaden-the-view-21h7</link>
      <guid>https://dev.to/hendr_ik/broaden-the-view-21h7</guid>
      <description>&lt;p&gt;We develop &lt;a href="https://www.offen.dev/?utm_source=forum"&gt;Offen&lt;/a&gt;, a fair and self hosted web analytics software that treats operators and users as equal parties. Here's what's been happening over the past eight weeks. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Widescreen&lt;/strong&gt;&lt;br&gt;
We have further optimized our display features. The Auditorium for operators now makes better use of screen real estate on desktop devices. Also, we have optimized the display of bar charts in mobile view.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Offen is now available in German, English and recently also in French.&lt;/strong&gt;&lt;br&gt;
Our consent banner and the Auditorium for operators and users are available in the respective language. If you would like to support our fair approach to web analytics by contributing Spanish, Portuguese or other language versions, please do not hesitate to &lt;a href="https://www.offen.dev/?utm_source=forum"&gt;request an invite.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;More secure&lt;/strong&gt;&lt;br&gt;
Our Docker image of the application are so far running as &lt;code&gt;root.&lt;/code&gt; This would theoretically give the possibility to inject malicious code into Offen.&lt;br&gt;
&lt;em&gt;This did not happen in any Offen version.&lt;/em&gt; But to fix this possible vulnerability, all images published from now on will run the application as a non-privileged &lt;code&gt;offen&lt;/code&gt; user.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Coming up&lt;/strong&gt;&lt;br&gt;
We want to present Offen and the idea of fair data transfer behind it to a professional audienc. Recommendations for relevant talks and conferences worldwide are very welcome. Got something in mind that we should apply for?¬†&lt;a href="https://www.offen.dev/?utm_source=forum"&gt;Let us know.&lt;/a&gt;&lt;/p&gt;

</description>
      <category>watercooler</category>
      <category>webdev</category>
      <category>opensource</category>
      <category>privacy</category>
    </item>
    <item>
      <title>13 VSCode Extensions That Every Web Developer Should Use</title>
      <author>Programming Facts</author>
      <pubDate>Wed, 21 Apr 2021 12:08:37 +0000</pubDate>
      <link>https://dev.to/programmingfac1/13-vscode-extensions-that-every-web-developer-should-use-474k</link>
      <guid>https://dev.to/programmingfac1/13-vscode-extensions-that-every-web-developer-should-use-474k</guid>
      <description>&lt;p&gt;Almost every Web-Developer knows what VSCode is and why is it so important to use its extensions, they help us to debug our code, make it more readable and prettier, and just add more useful features to our workspace&lt;br&gt;
Of course, there‚Äôs not every useful extension, however, I have added 13 extensions without which I just can‚Äôt live.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Auto Close Tag
It‚Äôs one of the most important extensions, As you may have noticed from the title, it automatically adds a close tag that you wanted to write. You don‚Äôt need any command to activate this extension&lt;/li&gt;
&lt;li&gt;Auto Rename tag
When you want to change your  tag to &lt;a&gt; you just will need to change the first(opening) tag and the second will change automatically&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Beautify
The function of it is straightforward‚Äî when you have an ugly file without any ‚Äúspaces‚Äù and ‚Äútabs‚Äù, where every tag goes right after earlier, beautify will really help you&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Read More :: &lt;a href="https://cmsinstallation.blogspot.com/2021/03/13-vscode-extensions-that-every-web.html"&gt;https://cmsinstallation.blogspot.com/2021/03/13-vscode-extensions-that-every-web.html&lt;/a&gt;&lt;/p&gt;

</description>
      <category>programming</category>
      <category>webdev</category>
      <category>php</category>
      <category>design</category>
    </item>
    <item>
      <title>E-commerce modules worth extracting in the code</title>
      <author>Andrzej Krzywda</author>
      <pubDate>Wed, 21 Apr 2021 11:58:36 +0000</pubDate>
      <link>https://dev.to/andrzejkrzywda/e-commerce-modules-worth-extracting-in-the-code-1a57</link>
      <guid>https://dev.to/andrzejkrzywda/e-commerce-modules-worth-extracting-in-the-code-1a57</guid>
      <description>&lt;p&gt;When you work on a non-trivial e-commerce application the complexity is usually, well non-trivial too.&lt;/p&gt;

&lt;p&gt;E-commerce is one of this kind of apps, where just following a CRUD approach may not be enough.&lt;/p&gt;

&lt;p&gt;Here is a list of modules (definitely not a full list) that might be worth having as separate, in order to avoid coupling.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#ordering"&gt;
  &lt;/a&gt;
  Ordering
&lt;/h2&gt;

&lt;p&gt;This is a classic one. If you have no modules in your e-commerce code then you can call it Ordering anyway, because that's the most important. &lt;br&gt;
Some possible operations (commands) here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;initiate an order (usually with some items from the cart)&lt;/li&gt;
&lt;li&gt;confirm the order (so that other modules are aware)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;
  &lt;a href="#ecommerce"&gt;
  &lt;/a&gt;
  Ecommerce
&lt;/h2&gt;

&lt;p&gt;I recently like to call this Ecommerce - a module which contains the logic around the cart concept.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#catalog"&gt;
  &lt;/a&gt;
  Catalog
&lt;/h2&gt;

&lt;p&gt;This module allows adding products to the offer visible to the clients.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#inventory"&gt;
  &lt;/a&gt;
  Inventory
&lt;/h2&gt;

&lt;p&gt;Keep track of how many items are left. Sometimes booking too.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#pricing"&gt;
  &lt;/a&gt;
  Pricing
&lt;/h2&gt;

&lt;p&gt;Pricing is usually not as trivial as just assigning a price to one product. USually we have a whole range of pricing strategies that change over time. It's nice to encapsulate them and keep it separate from other modules.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#payments"&gt;
  &lt;/a&gt;
  Payments
&lt;/h2&gt;

&lt;p&gt;Keep track of what was paid for. Sometimes your order will be paid in multiple payments, sometimes it's not fully paid. Sometimes you pay for multiple orders with one payment - hadle this logic here.&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#sample-application-with-ecommerce-modules"&gt;
  &lt;/a&gt;
  Sample application with ecommerce modules
&lt;/h1&gt;

&lt;p&gt;I'm working on sample application which shows some of those concepts. It started as a ordering system, but now it's in a process of becoming an e-commerce app too.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/RailsEventStore/cqrs-es-sample-with-res"&gt;https://github.com/RailsEventStore/cqrs-es-sample-with-res&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Are there any other modules that you like to extract in ecommerce apps? Share them in the comments :)&lt;/p&gt;

</description>
      <category>programming</category>
      <category>watercooler</category>
    </item>
    <item>
      <title>Building TikTok's record button using Framer Motion &amp; React</title>
      <author>Sam Piggott</author>
      <pubDate>Wed, 21 Apr 2021 11:51:44 +0000</pubDate>
      <link>https://dev.to/sam_piggott/building-tiktok-s-record-button-using-framer-motion-react-5e4p</link>
      <guid>https://dev.to/sam_piggott/building-tiktok-s-record-button-using-framer-motion-react-5e4p</guid>
      <description>&lt;p&gt;&lt;iframe width="710" height="399" src="https://www.youtube.com/embed/UnTBtDDyN2M"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#summary"&gt;
  &lt;/a&gt;
  Summary
&lt;/h2&gt;

&lt;p&gt;The TikTok record button is a deceivingly complicated UI element with some interesting moving parts, so I thought it would be perfect for a tutorial. In the guide above, we'll build a fully animated record button using nothing but React, Framer Motion (a fantastic animation library), and TypeScript.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#project-files"&gt;
  &lt;/a&gt;
  Project Files
&lt;/h2&gt;

&lt;p&gt;All the project files are available to download and use yourself over on my website, &lt;a href="https://codesnap.io/course/react-bites/tiktok-record-button"&gt;CodeSnap.io.&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#demo"&gt;
  &lt;/a&gt;
  Demo
&lt;/h2&gt;

&lt;p&gt;&lt;iframe src="https://codesandbox.io/embed/agitated-shockley-cdzuy"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#thanks"&gt;
  &lt;/a&gt;
  Thanks!
&lt;/h2&gt;

&lt;p&gt;Thanks for watching - any and all feedback is greatly appreciated, and please share it around if you think it'll be useful to anybody else. If you're interested in learning more, I've got loads more video and written content over on my website, &lt;a href="https://codesnap.io"&gt;CodeSnap.io.&lt;/a&gt;.&lt;/p&gt;

</description>
      <category>react</category>
      <category>javascript</category>
      <category>webdev</category>
      <category>tutorial</category>
    </item>
    <item>
      <title>15 Project Ideas for Web Developers üí°</title>
      <author>1nj3ct0r</author>
      <pubDate>Wed, 21 Apr 2021 11:27:18 +0000</pubDate>
      <link>https://dev.to/1nj3ct0r/15-project-ideas-for-web-developers-a96</link>
      <guid>https://dev.to/1nj3ct0r/15-project-ideas-for-web-developers-a96</guid>
      <description>&lt;p&gt;Most people think they don't know enough to start building a project ü•¥ so they decide to spend months watching or reading tutorials üòÅ However üòâ building projects improves one's programming skills because learning by building things is more efficient üòÑ&lt;/p&gt;

&lt;p&gt;To help you overcome tutorial hell üôÇüôÉ I've curated 15 programming project ideas for web developers üë®‚Äçüíª This article includes project ideas for frontend / backend and full-stack web developers üòé&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#frontend"&gt;
  &lt;/a&gt;
  Frontend üé®
&lt;/h2&gt;

&lt;p&gt;Here are some project ideas if you want to improve  your skills in front-end technologies üëá&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#color-guesser-game"&gt;
  &lt;/a&gt;
  Color Guesser Game üéÆ
&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;Color Guesser Game&lt;/strong&gt; is a simple game where players have to guess the background color of a box on the page üñåÔ∏è&lt;br&gt;
The app starts by creating a series of boxes with different colors based on user input üòÅ Once the game begins üòÑ the color boxes re flipped over and their colors are hidden üë•&lt;br&gt;
In each round üòÑ the game shuffles the positions of the color boxes üôÇüôÉ After shuffling one of the colors is displayed on the screen and the player has to guess in which of the color boxes the color is displayed by clicking on it ü§î&lt;br&gt;
The player wins the game if he can guess the colors correctly üèÜ Below is a sample mockup of the app üëá&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Y2CmCC1H--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://lh5.googleusercontent.com/z8sTjoYUQIKz9kNomA4fXO5Aqyj_1Ei3M4H8R-e4Q4iKES0qYy-P29vxRyWJOgbihCcuISmEH1mQIogzJkzyx5RJ16BR80c2QK0XxX2L8d8LW3Mpe4AMSkOnoC4JxPTjxJer92DP" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Y2CmCC1H--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://lh5.googleusercontent.com/z8sTjoYUQIKz9kNomA4fXO5Aqyj_1Ei3M4H8R-e4Q4iKES0qYy-P29vxRyWJOgbihCcuISmEH1mQIogzJkzyx5RJ16BR80c2QK0XxX2L8d8LW3Mpe4AMSkOnoC4JxPTjxJer92DP" alt="Color Guesser Game"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Working on this game will improve your knowledge of DOM (Document Object Model) and functions in JavaScript üòä&lt;/p&gt;
&lt;h3&gt;
  &lt;a href="#music-playlist-app"&gt;
  &lt;/a&gt;
  Music Playlist App üé∂
&lt;/h3&gt;

&lt;p&gt;If you've ever thought of creating a combined playlist of songs that you and your friends think are cool ü§© then this might be an interesting project idea for you üòâ&lt;br&gt;
In this project you can build a simple interface that allows you and anyone else to add a song to your playlist üëç  Working on this project will deepen your understanding of DOM event handlers in JavaScript and in the framework you are learning (React) üòú&lt;/p&gt;
&lt;h3&gt;
  &lt;a href="#number-guessing-game-app"&gt;
  &lt;/a&gt;
  Number Guessing Game App üî¢
&lt;/h3&gt;

&lt;p&gt;The numbers guessing game app is another interesting idea for those who want to expand their front-end development skills üë®‚Äçüíª&lt;/p&gt;

&lt;p&gt;The app will provide a number between a certain minimum number and a certain maximum number ü§î For example üëâ the random number between 1 and 10 is 6 üòÅ&lt;/p&gt;

&lt;p&gt;&lt;a href="https://i.giphy.com/media/3o6Mbb2RepU5Pn54fC/giphy.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://i.giphy.com/media/3o6Mbb2RepU5Pn54fC/giphy.gif" alt="Number Guessing Game"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The user is then supposed to guess this number within a certain number of tries üòé The player loses the game if he is not correct after the given number of tries üí™&lt;/p&gt;
&lt;h3&gt;
  &lt;a href="#character-count-app"&gt;
  &lt;/a&gt;
  Character Count App
&lt;/h3&gt;

&lt;p&gt;If you've used Twitter before you will know that Twitter has a maximum number of characters for each tweet üëç For this project idea you will build something similar ü§î&lt;br&gt;
For this app idea you will provide a text box where a user can type something ‚å®Ô∏è As the user types üëâ the number of characters typed so far will be displayed on the screen üñ•Ô∏è But much more than that ‚¨ÜÔ∏è the background color of the app changes based on the number of characters below üëá&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;0 - 10: black
11 - 20: red
21 - 30: yellow
Above 31: green
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This project idea deepens your knowledge of events in JavaScript üë©‚Äçüíª build your algorithms and helps expand your knowledge of CSS üé®&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#image-slider-app"&gt;
  &lt;/a&gt;
  Image Slider App üñºÔ∏è
&lt;/h3&gt;

&lt;p&gt;This project idea is about building an image slider app ü§î kind of like the image sliders on Instagram üòÅ The app will have a list of images that change after a number of seconds with a sliding transition üëç something similar to a carousel&lt;/p&gt;

&lt;p&gt;For those interested in making this more complex üëâ you can implement directional arrows buttons to allow the user to move forward or backward instead of following the default transition ü§©&lt;/p&gt;

&lt;p&gt;This is a fascinating project idea because you will learn a lot about asynchronous operations in JavaScript like setInterval while also strengthening your CSS skills through the implemented transitions üôÇüôÉ&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#backend"&gt;
  &lt;/a&gt;
  Back-end üîô
&lt;/h2&gt;

&lt;p&gt;For those who are more interested in project ideas that leverage back-end technologies üëâ here are a couple&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#simple-web-crawler"&gt;
  &lt;/a&gt;
  Simple Web Crawler üåê
&lt;/h3&gt;

&lt;p&gt;A web crawler is an application that indexed the content of page üòÅ This project idea is about creating a simple web crawler service that takes a page URL and returns the HTML markup of that page&lt;/p&gt;

&lt;p&gt;This project is not language specific and can be implemented in any language from Node.JS to Python ü§î Working on this project will help you deepen your knowledge of building APIs and services ü§©&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#anagram-generator-api"&gt;
  &lt;/a&gt;
  Anagram Generator API üòÅ
&lt;/h3&gt;

&lt;p&gt;An anagram is a word or phrase formed by rearranging the letters of another word ü§î For example üëâ priest and stripes are anagrams because each word is formed by rearranging the letters of the other&lt;/p&gt;

&lt;p&gt;The Anagram Generator API takes a source word such as priest and returns all the anagrams for that word&lt;/p&gt;

&lt;p&gt;Working on this project deepens your knowledge of creating services and strengthens your knowledge of algorithms üôÇüôÉ&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#covid-stats-api"&gt;
  &lt;/a&gt;
  Covid stats API üò∑
&lt;/h3&gt;

&lt;p&gt;This project is about using existing data about the COVID-19 and creating a Restful endpoint to serve that data &lt;/p&gt;

&lt;p&gt;Working on this project will reinforce your knowledge of what makes a good API while also teaching you how to define the structure of an API response üòÅ&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#random-name-generator-api"&gt;
  &lt;/a&gt;
  Random Name Generator API üòé
&lt;/h3&gt;

&lt;p&gt;A simple API to generate a random name each time the API is called üòÅ This service can be useful for people who want to name their newborn children&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#browser-version-api"&gt;
  &lt;/a&gt;
  Browser Version API üåê
&lt;/h3&gt;

&lt;p&gt;This project idea is about building a back-end service that provides detailed browser information about the browser that initiated the request üòÉ&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#fullstack"&gt;
  &lt;/a&gt;
  Full-Stack üè¢
&lt;/h2&gt;

&lt;p&gt;Sometimes you don't want to limit your learning to just front-end or just the back-end üëâ If you want to expand your skills in both the front-end and the back-end ü§î below are a number of interesting project ideas üëá&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#simple-chat-messaging-app"&gt;
  &lt;/a&gt;
  Simple Chat Messaging App üí¨
&lt;/h3&gt;

&lt;p&gt;An interesting project you can work on to improve your front-end and back-end skills is a chat messaging app üòÅ&lt;/p&gt;

&lt;p&gt;It doesn't have to have sophisticated features like image sharing but it should provide the ability for one user to message another user üëç&lt;/p&gt;

&lt;p&gt;The ability to implement this offers many learning opportunities in a variety of technologies üë©‚Äçüíª including WebSockets&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#travel-app-bucket-list"&gt;
  &lt;/a&gt;
  Travel app Bucket List üßæ
&lt;/h3&gt;

&lt;p&gt;If you have a list of places you'd like to travel to ü§î it might be a good idea to work on this project which is basically an app that allows you to add a new place of interest to your bucket list&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#motivational-quotes-app"&gt;
  &lt;/a&gt;
  Motivational Quotes app üí¨
&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://i.giphy.com/media/OZbGrdp7FiDiE/giphy.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://i.giphy.com/media/OZbGrdp7FiDiE/giphy.gif" alt="Quote"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We all need some motivation in our lives üòÅ So building an app that send you and your friends random motivational quotes is golden üò≤ You should definitely try to build this&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#twitter-clone"&gt;
  &lt;/a&gt;
  Twitter clone üïäÔ∏è
&lt;/h3&gt;

&lt;p&gt;I bet you already know Twitter üòé Building a Twitter clone is a great way to improve your front-end and back-end skills&lt;/p&gt;

&lt;p&gt;You don't have to include all the features of Twitter in this clone üòÅ Just the basic functionalities of Twitter is a perfect way to improve your web development skills&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#project-management-dashboard"&gt;
  &lt;/a&gt;
  Project Management Dashboard üôÇüôÉ
&lt;/h3&gt;

&lt;p&gt;The idea here is to build a tool that helps you manage projects üòé I think this is an interesting idea because you can benefit from using it to manage your projects as well&lt;/p&gt;

&lt;p&gt;Working on this project will help you understand how to implement CRUD and also improve your CSS skills since you will have to create a dashboard&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#conclusion"&gt;
  &lt;/a&gt;
  Conclusion
&lt;/h2&gt;

&lt;p&gt;I hope you found an interesting project idea in this article üòÅ&lt;/p&gt;

&lt;p&gt;&lt;a href="https://hashnode.com/post/15-project-ideas-for-web-developers-ckmg1p6vc00ialds1cmtl870c"&gt;&lt;em&gt;Also Published on HashNode üîó&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;

</description>
      <category>idea</category>
      <category>web</category>
      <category>programming</category>
      <category>project</category>
    </item>
    <item>
      <title>Basic concepts of Android-Part 1</title>
      <author>Chetan</author>
      <pubDate>Wed, 21 Apr 2021 11:23:40 +0000</pubDate>
      <link>https://dev.to/csj5483/basic-concepts-of-android-part-1-1eb7</link>
      <guid>https://dev.to/csj5483/basic-concepts-of-android-part-1-1eb7</guid>
      <description>&lt;p&gt;In this article, we are going to discuss some concepts of Android that you might face in your interview or during the project.&lt;/p&gt;

&lt;h2&gt;Package Name:&lt;/h2&gt;

&lt;p&gt;The package name is used for unique identification for your application.&lt;br&gt;
Android uses the package name to determine if the application has been installed or not. Generally, the package name of an app is in the format&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;domian.company.appname
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Here domain portion is the domain extension like¬†.com,¬†.org, or¬†.eu. The company portion is generally the name of the developer's company and appname describe the app itself. Appname could be of a single word or multiple words separated by a dot. For example&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;com.google.android.apps.photos
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;In the above code snippet:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;com is the domain&lt;/li&gt;
&lt;li&gt;google is the developer's company name&lt;/li&gt;
&lt;li&gt;android.app.photos is the app name&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Minimum SDK:&lt;/h2&gt;

&lt;p&gt;It is an integer that defines the minimum API level(version of the Android operating system) required to run your application. If the system's API Level is lower than the value specified in this attribute, then the Android system will prevent the user from installing the application.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--gmLZYfY---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/in0mcpfl9ijq8cqgk85u.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--gmLZYfY---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/in0mcpfl9ijq8cqgk85u.png" alt="image"&gt;&lt;/a&gt; &lt;br&gt;
In the above image, we had selected the Minimum SDK as 27 and Android Studio shows us that it will run on 53.5% of devices.&lt;/p&gt;

&lt;h2&gt;Activity:&lt;/h2&gt;

&lt;p&gt;Activity class is one of the most important parts of Android. No matter how small an app is, it will have at least an Activity. An Android activity is one screen of the Android app's user interface. An app can have multiple activities means multiple screens. Android activity is the subclass of ContextThemeWrapper class.¬†&lt;br&gt;
Every activity contains a layout, which has a user interface to interact with the user. In this layout, we define what a user will see when (s)he open this activity and in Java/Kotlin we define the functionality of the activity.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--BJUFCnM9--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/obip7fdtkg1vsahgf8lj.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--BJUFCnM9--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/obip7fdtkg1vsahgf8lj.png" alt="image"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the above image, we had setContentView method and in this, we had set R.layout.activity_main as the layout for this activity.&lt;/p&gt;

&lt;h5&gt;Activity Life¬†Cycle:&lt;/h5&gt;

&lt;p&gt;Unlike other programming languages where &lt;strong&gt;main()&lt;/strong&gt; method is the entry point of the program, the android operating system initiates the code in an Activity instance by invoking specific callback methods that correspond to specific stages of its lifecycle. In the below diagram we can see the life cycle of an Activity.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--LH321E-1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/n6rcpidtoq70hlawcodk.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--LH321E-1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/n6rcpidtoq70hlawcodk.png" alt="image"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;b&gt;onCreate()-&lt;/b&gt; This is the first callback and called when the activity is first created.&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;onStart()-&lt;/b&gt; This is called when the activity becomes visible to the user.&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;onResume()-&lt;/b&gt; This is called when the user starts interacting with the application.&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;onPause()-&lt;/b&gt; The paused activity does not receive user input and cannot execute any code and called when the current activity is being paused and the previous activity is being resumed.&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;onStop()-&lt;/b&gt; This callback is called when the activity is no longer visible.&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;onDestroy()-&lt;/b&gt; This callback is called before the activity is destroyed by the system.&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;onRestart()-&lt;/b&gt; This callback is called when the activity restarts after stopping it.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Service:&lt;/h2&gt;

&lt;p&gt;A service is a component that runs in the background to perform long-running operations such as playing music, handle network transactions, interacting with content providers without needing to interact with the user and it works even if the application is destroyed. It doesn't have any UI (user interface). The android.app.Service is a subclass of ContextWrapper class.&lt;/p&gt;

&lt;p&gt;A service can essentially take two states:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;b&gt;Started:&lt;/b&gt; A service is started when a component (like activity) calls the startService() method, now it runs in the background indefinitely. It is stopped by the stopService() method. The service can stop itself by calling the stopSelf() method.&lt;/li&gt;

&lt;li&gt;
&lt;b&gt;Bound:&lt;/b&gt; A service is bound when another component (e.g. client) calls the bindService() method. A bound service offers a client-server interface that allows components to interact with the service, send requests, get results, and even do so across processes with interprocess communication (IPC). The client can unbind the service by calling the unbindService() method.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--CAK2IBGD--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/jbkl0kf57nzq3i23077s.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--CAK2IBGD--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/jbkl0kf57nzq3i23077s.png" alt="image"&gt;&lt;/a&gt;&lt;br&gt;
 While creating a service following are the most important callback methods that you should override:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;b&gt;onStartCommand()-&lt;/b&gt; The system calls this method when another component, such as an activity, requests that the service be started, by invoking startService(). When this method executes, the service is started and can run in the background indefinitely. If you implement make sure to stop the service when its work is done, by calling stopSelf() or stopService() methods.&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;onBind()-&lt;/b&gt; The system calls this method when another component wants to bind with the service by calling bindService(). If you implement this method, you must provide an interface that clients use to communicate with the service, by returning an IBinder object. You must always implement this method, but if you don't want to allow binding, then you should return null.
&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;onUnbind()-&lt;/b&gt; The system calls this method when all clients have disconnected from a particular interface published by the service.&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;onRebind()-&lt;/b&gt; The system calls this method when new clients have connected to the service after it had previously been notified that all had disconnected in its onUnbind(Intent).&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;onCreate()-&lt;/b&gt; The system calls this method when the service is first created using onStartCommand() or onBind(). This call is required to perform a one-time set-up.&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;onDestroy()-&lt;/b&gt; The system calls this method when the service is no longer used and is being destroyed. Your service should implement this to clean up any resources such as threads, registered listeners, receivers, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will continue this in the next article.&lt;br&gt;
Happy Learning!&lt;/p&gt;

</description>
      <category>android</category>
      <category>computerscience</category>
      <category>programming</category>
      <category>devops</category>
    </item>
    <item>
      <title>Generics In Java</title>
      <author>yash sugandh</author>
      <pubDate>Wed, 21 Apr 2021 11:20:13 +0000</pubDate>
      <link>https://dev.to/yashsugandh/generics-in-java-3mb5</link>
      <guid>https://dev.to/yashsugandh/generics-in-java-3mb5</guid>
      <description>&lt;h2&gt;
  &lt;a href="#what-is-the-meaning-of-generics"&gt;
  &lt;/a&gt;
  What is the meaning of Generics?
&lt;/h2&gt;

&lt;p&gt;One of the definitions from Java docs :&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Generics allow you to abstract over types. The most common examples are container types, such as those in the Collections hierarchy.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In English:&lt;/p&gt;

&lt;p&gt;Abstract over type means to group together similar and generalize them.&lt;/p&gt;

&lt;p&gt;For Example: what do we do if we need to save firstName, lastName and email of multiple people do we create n number of variables to store and retrieve them manually OR &lt;br&gt;
we create an Abstraction over it known as &lt;strong&gt;Class&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Great!, Now we know what abstract over type means, but I still don't get how is it beneficial to us???&lt;/p&gt;

&lt;p&gt;In short: Generics provides us with compile time type-checking and saves the need of manual type-casting.&lt;/p&gt;

&lt;p&gt;In depth: Let's find out&lt;/p&gt;

&lt;p&gt;Let's take an example of how Collection's used to work before introduction of generics.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;List numList = new ArrayList(); // 1
numList.add(new Integer(1)); // 2
Integer x = (Integer) numList.iterator().next(); // 3    
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Line 1 and Line 2 are simple, we created an ArrayList and added an Integer.&lt;/p&gt;

&lt;p&gt;On Line 3 we have something that looks painful and will probably make you a little irritated &lt;strong&gt;Manual Type Conversion&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;Just imagine doing that every single time.&lt;/p&gt;

&lt;p&gt;In the above case even though the developer knows that the data is Integer at compile time we still need to manually convert it to Integer.&lt;/p&gt;

&lt;p&gt;This was the best case scenario where even though it looks bad it still works &lt;strong&gt;what if&lt;/strong&gt;&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;List list = new ArrayList(); //1
list.add("abc"); //2
list.add(new Integer(5)); //3 

for(Object obj : list){
    Integer numbers=(Integer) obj; 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Line 1 we created an ArrayList&lt;br&gt;
Line 2 we add a String to list&lt;br&gt;
Line 3 we add an Integer to the list&lt;/p&gt;

&lt;p&gt;Wait what!!&lt;br&gt;
We first added a String and now an Integer to the same list&lt;/p&gt;

&lt;p&gt;Okay what's next&lt;br&gt;
we iterate over List and try to manually type cast it to Integer &lt;/p&gt;

&lt;p&gt;So, we added a String and an Integer, and now we are expecting both of them to be type-casted to an Integer &lt;/p&gt;

&lt;p&gt;You know what's coming&lt;/p&gt;
&lt;h3&gt;
  &lt;a href="#classcastexception-fireworks-boom"&gt;
  &lt;/a&gt;
  ClassCastException üéÜ üí•
&lt;/h3&gt;

&lt;p&gt;We all know someone who is capable of doing this üòâ&lt;/p&gt;

&lt;p&gt;What were the problems we found till now:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We need an abstraction over these so that we don't need to manually convert it every time&lt;/li&gt;
&lt;li&gt;We need a compile time check to save us from &lt;strong&gt;ClassCastException&lt;/strong&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This is what our savior Generics helps us with &lt;/p&gt;

&lt;p&gt;How? Let's find out&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;List&amp;lt;String&amp;gt; listOfString = new ArrayList&amp;lt;&amp;gt;(); //1
listOfString.add("Generics"); //2
listOfString.add("are"); //3
listOfString.add("Awesome"); //4

for(String str : listOfString){ //5
     //no type casting needed, avoids ClassCastException
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Most of the lines in the above code looks just as before except the manual typecast is gone üòå .&lt;/p&gt;

&lt;p&gt;There is also something new on line 1&lt;br&gt;
&lt;code&gt;List&amp;lt;String&amp;gt; listOfString = new ArrayList&amp;lt;&amp;gt;();&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt; is used in generics to help us define the type of data we are going to store in the list.&lt;/p&gt;

&lt;p&gt;That's it that all we need to do for adding a compile time type safety.&lt;/p&gt;

&lt;p&gt;What if someone tries to add an Integer to the above list?&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--JbhLfdFf--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i.imgur.com/2ODmFsk.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--JbhLfdFf--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i.imgur.com/2ODmFsk.png" alt=""&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If we try to add an Integer we get a compile time error.&lt;/p&gt;

&lt;p&gt;So, can we use Generics only with Collections?&lt;/p&gt;

&lt;p&gt;No, Collections is just one of the places where we can use Generics. Let's look at other places where we can use Generics.&lt;/p&gt;

&lt;p&gt;Let's start small &lt;/p&gt;
&lt;h2&gt;
  &lt;a href="#generic-interface"&gt;
  &lt;/a&gt;
  Generic Interface
&lt;/h2&gt;


&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;interface Print&amp;lt;T&amp;gt;{
  void display(T input);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;


&lt;p&gt;We can create generic interfaces which can be implemented by Classes with their respective data-type&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;class PrintInteger implements Print&amp;lt;Integer&amp;gt;{

  @Override
  public void display(Integer input) {
    System.out.println("Printing an int "+input);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We have implemented Print interface and specified the data-type as Integer.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#generics-class-and-generic-methods"&gt;
  &lt;/a&gt;
  Generics Class and Generic methods
&lt;/h2&gt;

&lt;p&gt;Let's take a situation where we want to store firstName, lastName and an id of an employee but the data-type of id can be an int or long or String.&lt;/p&gt;

&lt;p&gt;Code without Generics&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;class EmployeeWithIntegerId {
private String firstName;
private String lastName;
private int id;
}

class EmployeeWithLongId {
private String firstName;
private String lastName;
private long id;
}

class EmployeeWithStringId {
private String firstName;
private String lastName;
private String id;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We can see that without using generics we have to create 3 different classes to cater the situation.&lt;/p&gt;

&lt;p&gt;Now, let's use generics to get us out of this situation&lt;/p&gt;

&lt;p&gt;Code with Generics&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;class Employee&amp;lt;T&amp;gt;{
  private String firstName;
  private String lastName;
  private T id;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;T&lt;/strong&gt; in the above code represents the data-type of our id which will be decided by us while creating the instance of the class.&lt;/p&gt;

&lt;p&gt;Is &lt;strong&gt;T&lt;/strong&gt; mandatory to use?&lt;/p&gt;

&lt;p&gt;No, &lt;strong&gt;T&lt;/strong&gt; is just the most commonly used one, but it is not mandatory. We can use any alphabet we like in place of &lt;strong&gt;T&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For people who are interested in the best practices in naming convention&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;The most commonly used type parameter names are:

E - Element (used extensively by the Java Collections Framework)
K - Key
N - Number
T - Type
V - Value
S,U,V etc. - 2nd, 3rd, 4th types
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;courtesy of java docs&lt;/p&gt;

&lt;p&gt;Now, when we use generics we only needed to create a single class where the only thing that needs to be decided was the type of our variable id.&lt;/p&gt;

&lt;p&gt;Okay, but how will the getters, setters and constructor work ??&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#constructor"&gt;
  &lt;/a&gt;
  Constructor
&lt;/h3&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;  public Employee(String firstName, String lastName, T id) {
    this.firstName = firstName;
    this.lastName = lastName;
    this.id = id;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The constructor will look the same as before. It is one of the best and easy to understand example of generic methods.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#getters-and-setters"&gt;
  &lt;/a&gt;
  Getters and Setters
&lt;/h3&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;  public T getId() {
    return id;
  }

  public void setId(T id) {
    this.id = id;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Okay, so we have defined the class, so how can we use it??&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;Employee&amp;lt;String&amp;gt; employee= new Employee&amp;lt;&amp;gt;("yash","sugandh","1234"); 
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;In the above example we created an object of the class Employee and while creating it we used &lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt; operator to define the data-type of &lt;strong&gt;T&lt;/strong&gt; as String.&lt;/p&gt;

&lt;p&gt;There is a restriction on data-type that we cannot use primitive data-types, so we cannot use int we have to Integer, Long instead of long and so on.&lt;/p&gt;

&lt;p&gt;Now, we know about generics and how it helps us in Collections, Interface, Classes and methods.&lt;/p&gt;

&lt;p&gt;But, there are still few questions left&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;What are wildcards in generics ?&lt;/li&gt;
&lt;li&gt;What is the meaning of bounded and unbounded wildcard ?&lt;/li&gt;
&lt;li&gt;How does Java ensure backward compatibility from code with generics to code without generics?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let's cover all these topics in the next post.&lt;/p&gt;

&lt;p&gt;Please let me know if there are any questions in the comments below.&lt;/p&gt;

&lt;p&gt;See you in the funny papers üöÄ &lt;/p&gt;

</description>
      <category>java</category>
      <category>computerscience</category>
      <category>programming</category>
      <category>beginners</category>
    </item>
    <item>
      <title>Edit PDF files with Python</title>
      <author>Stokry</author>
      <pubDate>Wed, 21 Apr 2021 11:13:27 +0000</pubDate>
      <link>https://dev.to/stokry/edit-pdf-files-with-python-1e1j</link>
      <guid>https://dev.to/stokry/edit-pdf-files-with-python-1e1j</guid>
      <description>&lt;p&gt;I like to test Python in different situations, it just makes my life easier in many situations. Python allows me to automate things that are normally repeated and boring, so I can focus on important aspects of my job. Today I will show you how can you edit PDF files with python.&lt;/p&gt;

&lt;p&gt;In this example I will be using &lt;a href="https://pypi.org/project/reportlab/"&gt;ReportLab&lt;/a&gt;. &lt;br&gt;
The ReportLab Toolkit. An Open Source Python library for generating PDFs and graphics.&lt;/p&gt;

&lt;p&gt;This is our original pdf:&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--bR7wYFeL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i.ibb.co/VS34xP9/org.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--bR7wYFeL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i.ibb.co/VS34xP9/org.png" alt="enter image description here"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let's jump to the code!&lt;/p&gt;

&lt;p&gt;First we need to import dependencies&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PyPDF2&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PdfFileWriter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;PdfFileReader&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;io&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;reportlab.pdfgen&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;canvas&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;reportlab.lib.pagesizes&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;letter&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;First we will create a new PDF with Reportlab, in this part we will also define our &lt;code&gt;font color&lt;/code&gt; and the &lt;code&gt;font size&lt;/code&gt;:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;packet&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BytesIO&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;can&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Canvas&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;packet&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pagesize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;letter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;can&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setFillColorRGB&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;can&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setFont&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Times-Roman"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;can&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drawString&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;72&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;655&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"Hello from Python"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;can&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Then we move to the beginning of the StringIO buffer:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;packet&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seek&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;new_pdf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PdfFileReader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;packet&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;read your existing PDF&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;existing_pdf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PdfFileReader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"original.pdf"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"rb"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PdfFileWriter&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The we add the "watermark" (which is the new pdf) on the existing page;&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;existing_pdf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getPage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mergePage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_pdf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getPage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;addPage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;And finally, write "output" to a real file:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;outputStream&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"destination.pdf"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"wb"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;outputStream&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;outputStream&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This is our result:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--n4EJHVOz--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i.ibb.co/6DyZXFg/dest.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--n4EJHVOz--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i.ibb.co/6DyZXFg/dest.png" alt="enter image description here"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thank you all. &lt;/p&gt;

</description>
      <category>python</category>
      <category>productivity</category>
      <category>tutorial</category>
      <category>showdev</category>
    </item>
    <item>
      <title>Automating your ELT Workflows with Managed Workflows for Apache Airflow - Part Two</title>
      <author>Ricardo Sueiras</author>
      <pubDate>Wed, 21 Apr 2021 11:07:42 +0000</pubDate>
      <link>https://dev.to/aws/automating-your-elt-workflows-with-managed-workflows-for-apache-airflow-1h1m</link>
      <guid>https://dev.to/aws/automating-your-elt-workflows-with-managed-workflows-for-apache-airflow-1h1m</guid>
      <description>&lt;h3&gt;
  &lt;a href="#part-two-automating-amazon-emr"&gt;
  &lt;/a&gt;
  Part Two - Automating Amazon EMR
&lt;/h3&gt;

&lt;p&gt;In &lt;a href="https://dev.to/aws/automating-your-elt-workflows-with-managed-workflows-for-apache-airflow-4bjg"&gt;Part One&lt;/a&gt;, we automated an example ELT workflow on Amazon Athena using Apache Airflow. In this post, Part Two, we will do the same thing but automate the same example ELT workflow using Amazon EMR.&lt;/p&gt;

&lt;p&gt;Make sure you recap the setup from Part One. All the code so you can reproduce this yourself can be found in the &lt;a href="https://github.com/094459/devday-elt-automation"&gt;GitHub repository here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Automating Amazon EMR&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To recap: We are using the Movielens dataset, loaded it into our data lake on Amazon S3 and we have been asked to a) create a new table with a subset of the information we care about, in this instance a particular genre of films, and b) create a new file with the same subset of information available in the data lake.&lt;/p&gt;

&lt;p&gt;As part of the set of manual steps we are trying to automate, we are using Amazon EMR (again as for the previous post, if you want to see those manual steps, refer to the documentation in the GitHub repository) together with some Apache Hive and Presto SQL scripts to create tables and export files . As we are automating this, a lot of the stuff we would not need to do because we absorb that as part of the manual work (for example, I already have a database called XX, so I do not need to re-create that) we need to build into the workflow. So at a high level the steps look like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create our Apache Hive and Presto SQL scripts and upload those to a location on Amazon S3&lt;/li&gt;
&lt;li&gt;Check to see if a database exists and create it if it does not exist&lt;/li&gt;
&lt;li&gt;Create tables to import the movie and ratings data (using the scripts we uploaded)&lt;/li&gt;
&lt;li&gt;Create a new table that just contains the information we are looking for (in this example, films of a particular genre)&lt;/li&gt;
&lt;li&gt;Export the new table as a csv file (again using the scripts we already uploaded)&lt;/li&gt;
&lt;li&gt;Move the export csv file to a new location in the data lake&lt;/li&gt;
&lt;li&gt;Clean up and shut down any resources so we can minimise the cost of running this operation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Not surprisingly, this workflow begins in a very similar way to the previous one. However, this time we are using Amazon EMR and if we look at the available Apache Airflow operators we can see that there is an Amazon EMR operator which will make our life easy. We can take a look at the documentation for this operator at the Apache Airflow website, &lt;a href="https://airflow.apache.org/docs/apache-airflow-providers-amazon/stable/operators/emr.html"&gt;Amazon EMR Operators&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As part of our workflow, we want to create an Amazon EMR cluster, add some steps to run some of the Presto and Apache Hive queries, and then terminate the cluster so we need to add those operators (EmrCreateJobFlowOperator, EmrAddStepsOperator, EmrTerminateJobFlowOperator and EmrStepSensor) in our DAG&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;from airflow import DAG, settings, secrets
from airflow.operators.python_operator import PythonOperator, BranchPythonOperator
from airflow.operators.dummy_operator import DummyOperator
from airflow.contrib.secrets.aws_secrets_manager import SecretsManagerBackend
from airflow.contrib.operators.emr_add_steps_operator import EmrAddStepsOperator
from airflow.contrib.operators.emr_create_job_flow_operator import EmrCreateJobFlowOperator
from airflow.contrib.operators.emr_terminate_job_flow_operator import EmrTerminateJobFlowOperator
from airflow.contrib.sensors.emr_step_sensor import EmrStepSensor
from airflow.contrib.hooks.aws_hook import AwsHook
from airflow.models import Variable
from airflow.utils.trigger_rule import TriggerRule
from airflow.utils.dates import days_ago
import os
import sys
import boto3
import time
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;I next part of our workflow is the same, except this time we have added some more variables. In the previous workflow I had hardcoded the genre so this time I wanted to add it as a variable meaning we could create a single workflow, parameterise it and then run it as many times as we needed, just having to change that variable "genre" and "genre_t"&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;s3_dlake = Variable.get("s3_dlake", default_var="undefined")
emr_db = Variable.get("emr_db", default_var="undefined")
emr_output = Variable.get("emr_output", default_var="undefined")
genre = Variable.get("emr_genre", default_var="undefined")
genre_t = Variable.get("emr_genre_table", default_var="undefined")
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;If we look at the steps we are looking to automate, the first one is to upload our Apache Hive and Presto scripts to a location on Amazon S3 where we can run them from our Amazon EMR steps. We could just create these outside of Apache Airflow and upload them, and this is an option. In this walkthrough however, I am going to create those scripts using the same variables we have defined to make sure that those scripts change dynamically as our needs change.&lt;/p&gt;

&lt;p&gt;To do this I am going to define a new task called "create_emr_scripts" using the PythonOperator.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;create_emr_scripts = PythonOperator (
    task_id='create_emr_scripts',
    provide_context=True,
    python_callable=py_create_emr_scripts,
    dag=dag
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;I need to create a supporting function called "py_create_emr_scripts" so lets take a look at this code. This code writes five files to the Amazon S3 location {s3_dlake}/scripts, each file corresponding to the SQL we created as part of the manual steps.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;def py_create_emr_scripts(**kwargs):
    s3 = boto3.resource('s3')
    print("Creating scripts which will be executed by Amazon EMR - will overwrite existing scripts")
    # create create-film-db.hql
    object1 = s3.Object(s3_dlake, 'scripts/create-film-db.hql')
    object1.put(Body=HIVE_CREATE_DB)
    # create create-film-db-tables.hql
    object2 = s3.Object(s3_dlake, 'scripts/create-film-db-tables.hql')
    object2.put(Body=HIVE_CREATE_DB_TABLES)
    # create create-genre-film-table.hql
    object3 = s3.Object(s3_dlake, 'scripts/create-genre-film-table.hql')
    object3.put(Body=HIVE_CREATE_GENRE_TABLE)
    # create create-genre.sql
    object4 = s3.Object(s3_dlake, 'scripts/create-genre.sql')
    object4.put(Body=PRESTO_SQL_GEN_GENRE_CSV)
    # create run-presto-query.sh
    object5 = s3.Object(s3_dlake, 'scripts/run-presto-query.sh')
    object5.put(Body=PRESTO_SCRIPT_RUN_EXPFILE) 
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;These variables (HIVE_CREATE_DB, HIVE_CREATE_DB_TABLES, etc) are just defined as follows in the workflow:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;HIVE_CREATE_DB = """
create database {database}; 
""".format(database=emr_db)

HIVE_CREATE_DB_TABLES = """
CREATE EXTERNAL TABLE {database}.movies (
    movieId INT,
    title   STRING,
    genres  STRING

) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
  LOCATION 's3://{datalake}/movielens/movies/';

CREATE EXTERNAL TABLE {database}.ratings (
    userId INT,
    movieId INT,
    rating INT,
    timestampId TIMESTAMP

) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
  LOCATION 's3://{datalake}/movielens/ratings-alt/';
""".format(database=emr_db,datalake=s3_dlake)

HIVE_CREATE_GENRE_TABLE = """
CREATE EXTERNAL TABLE {database}.{genre_t} (
    title   STRING,
    year    INT,
    rating  INT

) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
  LOCATION 's3://{datalake}/movielens/{genre}/';
""".format(database=emr_db,genre=genre,datalake=s3_dlake,genre_t=genre_t)

PRESTO_SCRIPT_RUN_EXPFILE = """
#!/bin/bash
aws s3 cp s3://{datalake}/scripts/create-genre.sql .
presto-cli --catalog hive -f create-genre.sql --output-format TSV &amp;gt; {genre_t}-films.tsv
aws s3 cp {genre_t}-films.tsv s3://{datalake}/movielens/{genre}/
""".format(database=emr_db,genre=genre,datalake=s3_dlake,genre_t=genre_t)

PRESTO_SQL_GEN_GENRE_CSV = """
WITH {genre}data AS (
SELECT REPLACE ( m.title , '"' , '' ) as title, r.rating
FROM {database}.movies m
INNER JOIN (SELECT rating, movieId FROM {database}.ratings) r on m.movieId = r.movieId WHERE REGEXP_LIKE (genres, '{genre}')
  )
SELECT substr(title,1, LENGTH(title) -6) as title, replace(substr(trim(title),-5),')','') as year, AVG(rating) as avrating from {genre}data GROUP BY title ORDER BY year DESC,  title ASC ;
""".format(database=emr_db,genre=genre)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;As you can see, we are using standard python to substitute values in the variables so we have dynamically generated scripts which will launch when our Amazon EMR steps start.&lt;/p&gt;

&lt;p&gt;If we now add at the bottom of the workflow the dependency/relationship details (we only have one task defined so far, the rest is just supporting functions and code) we end up with:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;from airflow import DAG, settings, secrets
from airflow.operators.python_operator import PythonOperator, BranchPythonOperator
from airflow.operators.dummy_operator import DummyOperator
from airflow.contrib.secrets.aws_secrets_manager import SecretsManagerBackend
from airflow.contrib.operators.emr_add_steps_operator import EmrAddStepsOperator
from airflow.contrib.operators.emr_create_job_flow_operator import EmrCreateJobFlowOperator
from airflow.contrib.operators.emr_terminate_job_flow_operator import EmrTerminateJobFlowOperator
from airflow.contrib.sensors.emr_step_sensor import EmrStepSensor
from airflow.contrib.hooks.aws_hook import AwsHook
from airflow.models import Variable
from airflow.utils.trigger_rule import TriggerRule
from airflow.utils.dates import days_ago
import os
import sys
import boto3
import time

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email': ['airflow@example.com'],
    'email_on_failure': False,
    'email_on_retry': False,
}

DAG_ID = os.path.basename(__file__).replace('.py', '')

dag = DAG(
    dag_id=DAG_ID,
    default_args=default_args,
    description='DevDay EMR DAG',
    schedule_interval=None,
    start_date=days_ago(2),
    tags=['devday','demo'],
)

s3_dlake = Variable.get("s3_dlake", default_var="undefined")
emr_db = Variable.get("emr_db", default_var="undefined")
emr_output = Variable.get("emr_output", default_var="undefined")
genre = Variable.get("emr_genre", default_var="undefined")
genre_t = Variable.get("emr_genre_table", default_var="undefined")

HIVE_CREATE_DB = """
create database {database}; 
""".format(database=emr_db)

HIVE_CREATE_DB_TABLES = """
CREATE EXTERNAL TABLE {database}.movies (
    movieId INT,
    title   STRING,
    genres  STRING

) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
  LOCATION 's3://{datalake}/movielens/movies/';

CREATE EXTERNAL TABLE {database}.ratings (
    userId INT,
    movieId INT,
    rating INT,
    timestampId TIMESTAMP

) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
  LOCATION 's3://{datalake}/movielens/ratings-alt/';
""".format(database=emr_db,datalake=s3_dlake)

HIVE_CREATE_GENRE_TABLE = """
CREATE EXTERNAL TABLE {database}.{genre_t} (
    title   STRING,
    year    INT,
    rating  INT

) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
  LOCATION 's3://{datalake}/movielens/{genre}/';
""".format(database=emr_db,genre=genre,datalake=s3_dlake,genre_t=genre_t)

PRESTO_SCRIPT_RUN_EXPFILE = """
#!/bin/bash
aws s3 cp s3://{datalake}/scripts/create-genre.sql .
presto-cli --catalog hive -f create-genre.sql --output-format TSV &amp;gt; {genre_t}-films.tsv
aws s3 cp {genre_t}-films.tsv s3://{datalake}/movielens/{genre}/
""".format(database=emr_db,genre=genre,datalake=s3_dlake,genre_t=genre_t)

PRESTO_SQL_GEN_GENRE_CSV = """
WITH {genre}data AS (
SELECT REPLACE ( m.title , '"' , '' ) as title, r.rating
FROM {database}.movies m
INNER JOIN (SELECT rating, movieId FROM {database}.ratings) r on m.movieId = r.movieId WHERE REGEXP_LIKE (genres, '{genre}')
  )
SELECT substr(title,1, LENGTH(title) -6) as title, replace(substr(trim(title),-5),')','') as year, AVG(rating) as avrating from {genre}data GROUP BY title ORDER BY year DESC,  title ASC ;
""".format(database=emr_db,genre=genre)

def py_create_emr_scripts(**kwargs):
    s3 = boto3.resource('s3')
    print("Creating scripts which will be executed by Amazon EMR - will overwrite existing scripts")
    # create create-film-db.hql
    object1 = s3.Object(s3_dlake, 'scripts/create-film-db.hql')
    object1.put(Body=HIVE_CREATE_DB)
    # create create-film-db-tables.hql
    object2 = s3.Object(s3_dlake, 'scripts/create-film-db-tables.hql')
    object2.put(Body=HIVE_CREATE_DB_TABLES)
    # create create-genre-film-table.hql
    object3 = s3.Object(s3_dlake, 'scripts/create-genre-film-table.hql')
    object3.put(Body=HIVE_CREATE_GENRE_TABLE)
    # create create-genre.sql
    object4 = s3.Object(s3_dlake, 'scripts/create-genre.sql')
    object4.put(Body=PRESTO_SQL_GEN_GENRE_CSV)
    # create run-presto-query.sh
    object5 = s3.Object(s3_dlake, 'scripts/run-presto-query.sh')
    object5.put(Body=PRESTO_SCRIPT_RUN_EXPFILE) 

create_emr_scripts = PythonOperator (
    task_id='create_emr_scripts',
    provide_context=True,
    python_callable=py_create_emr_scripts,
    dag=dag
    )

create_emr_scripts
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The order these are in is important as you might see errors if something you use/call has not been defined in the workflow code.&lt;/p&gt;

&lt;p&gt;When we commit this code, a few seconds later we will see just a single task in our workflow, called "create_emr_scripts" which we can enable (turn on) and then trigger. If we now go to the scripts folder of our Amazon S3 data lake, we should see our new scripts ready to go.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--XiLvwu2j--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/devday-elt-automation/blob/main/images/blog-3.png%3Fraw%3Dtrue" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--XiLvwu2j--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/devday-elt-automation/blob/main/images/blog-3.png%3Fraw%3Dtrue" alt="scripts"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Every time we re-run this task the scripts will be overwritten to make sure they contain the right values.&lt;/p&gt;

&lt;p&gt;Now that we have our scripts, then next thing we need to do is to run those scripts via Amazon EMR. We could use an existing Amazon EMR cluster if we wanted, and then submit the steps to that cluster, but in this walk through I will create an auto terminating Amazon EMR cluster, add the steps and then terminate that cluster.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you wanted to use an existing Amazon EMR cluster, you would need to change the code to take an input value of the Amazon EMR cluster id. There are lots of ways you could do this: via a configuration value when you trigger the DAG, via a variable you store in something like AWS Secrets manager, or perhaps by using some code within a PythonOperator to find that cluster id.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To kick off our cluster we use the EmrCreateJobFlowOperator operator, which takes just one value, "job_flow_overrides" which is a variable you need to define that contains the configuration details of your Amazon EMR cluster (the applications you want to use, the size and number of clusters, the configuration details, etc)&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;create_emr_database_cluster = EmrCreateJobFlowOperator(
    task_id='create_emr_database_cluster', 
    job_flow_overrides=JOB_FLOW_OVERRIDES,
    dag=dag
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;As we can see we have defined a variable called JOB_FLOW_OVERRIDES which contains our Amazon EMR cluster details. You can also see that we are again substituting variables so that the Amazon EMR cluster uses the correct configuration details based on our use case. This allows us to use a standard template across many different applications.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;JOB_FLOW_OVERRIDES = {
    'Name': 'devday-demo-cluster-airflow',
    'ReleaseLabel': 'emr-5.32.0',
    'LogUri': 's3n://{{ var.value.s3_dlake }}/logs',
    'Applications': [
        {
            'Name': 'Spark',
        },
        {
            'Name': 'Pig',
        },
        {
            'Name': 'Hive',
        },
        {
            'Name': 'Presto',
        }
    ],
    'Instances': {
        'InstanceFleets': [
            {
                'Name': 'MASTER',
                'InstanceFleetType': 'MASTER',
                'TargetSpotCapacity': 1,
                'InstanceTypeConfigs': [
                    {
                        'InstanceType': 'm5.xlarge',
                    },
                ]
            },
            {
                'Name': 'CORE',
                'InstanceFleetType': 'CORE',
                'TargetSpotCapacity': 1,
                'InstanceTypeConfigs': [
                    {
                        'InstanceType': 'r5.xlarge',
                    },
                ],
            },
        ],
        'KeepJobFlowAliveWhenNoSteps': True,
        'TerminationProtected': False,
        'Ec2KeyName': 'ec2-rocket',
    },
    'Configurations': [
        {
            'Classification': 'hive-site',
            'Properties': {'hive.metastore.client.factory.class': 'com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory'}
        },
        {
            'Classification': 'presto-connector-hive',
            'Properties': {'hive.metastore.glue.datacatalog.enabled': 'true'}
        },
        {
            'Classification': 'spark-hive-site',
            'Properties': {'hive.metastore.client.factory.class': 'com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory'}
        }
    ],
    'VisibleToAllUsers': True,
    'JobFlowRole': 'EMR_EC2_DefaultRole',
    'ServiceRole': 'EMR_DefaultRole',
    'EbsRootVolumeSize': 32,
    'StepConcurrencyLevel': 1,
    'Tags': [
        {
            'Key': 'Environment',
            'Value': 'Development'
        },
        {
            'Key': 'Name',
            'Value': 'Airflow EMR Demo Project'
        },
        {
            'Key': 'Owner',
            'Value': 'Data Analytics Team'
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;In order to achieve my objectives, I have created an Amazon EMR cluster that has the Apache Hive and Presto applications, and for simplicity I am using the AWS Glue data catalog as the metastore (you could easily change this to what your environment uses, something like a MySQL instance perhaps). One thing we do configure in our configuration is the value "KeepJobFlowAliveWhenNoSteps': True" as we want the Amazon EMR cluster running until it has completed all our steps before we terminate it.&lt;/p&gt;

&lt;p&gt;So this step will now launch our Amazon EMR cluster. Let us add it to the workflow dependency graph.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;create_emr_scripts &amp;gt;&amp;gt; create_emr_database_cluster 
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;If we commit the code and then launch this workflow, we should now start to see our Amazon EMR cluster start up. From the UI, take a look at the logs for the "create_emr_database_cluster", you will see something similar to this in the log file:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;[2021-04-19 14:59:18,888] {{standard_task_runner.py:78}} INFO - Job 116460: Subtask create_emr_database_cluster
[2021-04-19 14:59:18,994] {{logging_mixin.py:112}} INFO - Running %s on host %s &amp;lt;TaskInstance: devday-emr-create.create_emr_database_cluster 2021-04-19T14:58:50.688217+00:00 [running]&amp;gt; ip-10-192-21-41.eu-west-1.compute.internal
[2021-04-19 14:59:19,138] {{emr_create_job_flow_operator.py:66}} INFO - Creating JobFlow using aws-conn-id: s3_default, emr-conn-id: emr_default
[2021-04-19 14:59:19,437] {{emr_create_job_flow_operator.py:73}} INFO - JobFlow with id j-2JRII3WTAD9PG created
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The Amazon EMR cluster id is displayed (here it is "j-2JRII3WTAD9PG") and this is important as we will see in a minute. Before proceeding, make sure you terminate this cluster manually via the console. We do not want to leave our Amazon EMR cluster running, so we create a new task using a different operator to do this, the EmrTerminateJobFlowOperator.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;terminate_emr_cluster = EmrTerminateJobFlowOperator(
    task_id='terminate_emr_cluster',
    job_flow_id="{{ task_instance.xcom_pull('create_emr_database_cluster', key='return_value') }}",
    aws_conn_id='aws_default',
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;There are a couple of new things here. First we have the "aws_conn_id" parameter, which is required by this operator and we set to this value when using Managed Workflows for Apache Airflow. If you are hosting/using your own version of Apache Airflow, this will correspond to the name of the Connection you have defined in the Apache Airflow UI. The next thing to notice is the "job_flow_id" which is using another feature of Apache Airflow, xcom. Xcoms is the feature in Apache Airflow that lets tasks exchange information, and in this instance we are "pulling" the details of the Amazon EMR cluster ID (as we saw in the previous task) so that we can terminate the right cluster.&lt;/p&gt;

&lt;p&gt;We can now add this task to the workflow:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;create_emr_scripts &amp;gt;&amp;gt; create_emr_database_cluster &amp;gt;&amp;gt; terminate_emr_cluster

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Commit and the launch the DAG when it appears in the UI. At this stage, it is not doing anything interesting other than launching and the terminating the Amazon EMR cluster. Next, we need to add the steps we want to execute on that running cluster.&lt;/p&gt;

&lt;p&gt;If we look at the task we are trying to automate, the first one is creating the database. We have our script (a simple Apache Hive script) uploaded in the /scripts folder on Amazon S3. But as before in the Amazon Athena walkthrough, we need to add some logic here to skip this creation of the database already exists. Our workflow will be check to see if the database exists, and if not create the database and import the Movielens tables we need, skipping this step if the database already exists.&lt;/p&gt;

&lt;p&gt;As we have already covered the branching logic in the previous post, I will just cover the Amazon EMR step this time. To add a step, in this case to run the hive script, we use the EmrAddStepsOperator which will kick off a new step to be executed by the Amazon EMR cluster we want to run this on. When we use the EmrAddStepsOperator operator, we use a corresponding operator called EmrStepSensor, which tracks the status of the task (whether it was successful or failed). Here is the code for these two new tasks.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;create_emr_database_step = EmrAddStepsOperator(
    task_id='create_emr_database_step',
    job_flow_id="{{ task_instance.xcom_pull(task_ids='create_emr_database_cluster', key='return_value') }}",
    aws_conn_id='aws_default',
    on_failure_callback=cleanup_emr_cluster_if_steps_fail,
    steps=CREATE_DATABASE,
    )
create_emr_database_sensor = EmrStepSensor(
    task_id='create_emr_database_sensor',
    job_flow_id="{{ task_instance.xcom_pull('create_emr_database_cluster', key='return_value') }}",
    step_id="{{ task_instance.xcom_pull(task_ids='create_emr_database_step', key='return_value')[0] }}",
    on_failure_callback=cleanup_emr_cluster_if_steps_fail,
    aws_conn_id='aws_default',
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;In the "create_emr_database_step" task you can see we are using Xcoms again, to get the name of the Amazon EMR cluster id when we use the EmrAddStepsOperator. In the "create_emr_database_sensor" task you can see we are using XComs to additionally get the name of the task we need to keep a track of - in this case, the "create_emr_database_step" task. This will ensure that this task is monitoring the right step.&lt;/p&gt;

&lt;p&gt;The next thing to notice is the "steps=" parameter in the "create_emr_database_step" task. This is where we define the actual step to submit to Amazon EMR, and we define this in a variable, in this case called CREATE_DATABASE. Here is the code.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;CREATE_DATABASE = [
    {
        'Name': 'Create Genre Database',
        'ActionOnFailure': 'CONTINUE',
        'HadoopJarStep': {
            'Jar': 'command-runner.jar',
            'Args': [
                'hive-script',
                '--run-hive-script',
                '--args',
                '-f',
                's3://{{ var.value.s3_dlake }}/scripts/create-film-db.hql'
            ]
        }
    }
]
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This is the same process we would follow if we were manually submitting the task via the Amazon EMR console. You will notice that we are using variables again in order to ensure that we do not hardcode anything.&lt;/p&gt;

&lt;p&gt;We are not quite ready to submit this yet. When submitting steps to be executed by the Amazon EMR cluster, there is the possibility that sometimes these will fail. If that happens, the workflow will stall/stop, and this will leave our Amazon EMR cluster running (which we have to pay for). We need a way of short circuiting this, and for this we use the "on_failure_callback" feature of Apache Airflow that allows us to call a function we define in the case where this task has failed. In the example above, we have defined a cleanup function called "cleanup_emr_cluster_if_steps_fail" which looks like:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;def cleanup_emr_cluster_if_steps_fail(context):
    print("This is invoked when a running EMR cluster has a step running that fails.")
    print("If we do not do this, the DAG will stop but the cluster will still keep running")

    early_terminate_emr_cluster = EmrTerminateJobFlowOperator(
        task_id='terminate_emr_cluster',
        job_flow_id=context["ti"].xcom_pull('create_emr_database_cluster'),
        aws_conn_id='aws_default',
        )
    return early_terminate_emr_cluster.execute(context=context)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;As you can see, we are using Xcoms to grab the Amazon EMR cluster ID and then terminate this. Now, if our scripts go rogue, we will still terminate the cluster.&lt;/p&gt;

&lt;p&gt;If we now take these new tasks, together with the branching logic we now have this additional code:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;CREATE_DATABASE = [
    {
        'Name': 'Create Genre Database',
        'ActionOnFailure': 'CONTINUE',
        'HadoopJarStep': {
            'Jar': 'command-runner.jar',
            'Args': [
                'hive-script',
                '--run-hive-script',
                '--args',
                '-f',
                's3://{{ var.value.s3_dlake }}/scripts/create-film-db.hql'
            ]
        }
    }
]

def check_emr_database(**kwargs):
    ath = boto3.client('athena')
    try:
        response = ath.get_database(
            CatalogName='AwsDataCatalog',
            DatabaseName=emr_db
        )
        print("Database already exists - skip creation")
        return "skip_emr_database_creation"
    except:
        print("No EMR Database Found")
        return "create_emr_database_step"

def cleanup_emr_cluster_if_steps_fail(context):
    print("This is invoked when a running EMR cluster has a step running that fails.")
    print("If we do not do this, the DAG will stop but the cluster will still keep running")

    early_terminate_emr_cluster = EmrTerminateJobFlowOperator(
        task_id='terminate_emr_cluster',
        job_flow_id=context["ti"].xcom_pull('create_emr_database_cluster'),
        aws_conn_id='aws_default',
        )
    return early_terminate_emr_cluster.execute(context=context)

check_emr_database = BranchPythonOperator(
    task_id='check_emr_database',
    provide_context=True,
    python_callable=check_emr_database,
    retries=1,
    dag=dag,
)

skip_emr_database_creation = DummyOperator(
    task_id="skip_emr_database_creation",
    trigger_rule=TriggerRule.NONE_FAILED,
    dag=dag,
)

emr_database_checks_done = DummyOperator(
    task_id="emr_database_checks_done",
    trigger_rule=TriggerRule.NONE_FAILED,
    dag=dag,
)

create_emr_database_step = EmrAddStepsOperator(
    task_id='create_emr_database_step',
    job_flow_id="{{ task_instance.xcom_pull(task_ids='create_emr_database_cluster', key='return_value') }}",
    aws_conn_id='aws_default',
    on_failure_callback=cleanup_emr_cluster_if_steps_fail,
    steps=CREATE_DATABASE,
    )
create_emr_database_sensor = EmrStepSensor(
    task_id='create_emr_database_sensor',
    job_flow_id="{{ task_instance.xcom_pull('create_emr_database_cluster', key='return_value') }}",
    step_id="{{ task_instance.xcom_pull(task_ids='create_emr_database_step', key='return_value')[0] }}",
    on_failure_callback=cleanup_emr_cluster_if_steps_fail,
    aws_conn_id='aws_default',
    )

create_emr_scripts &amp;gt;&amp;gt; create_emr_database_cluster &amp;gt;&amp;gt; check_emr_database

check_emr_database &amp;gt;&amp;gt; skip_emr_database_creation &amp;gt;&amp;gt; emr_database_checks_done  
check_emr_database &amp;gt;&amp;gt; create_emr_database_step &amp;gt;&amp;gt; create_emr_database_sensor &amp;gt;&amp;gt; emr_database_checks_done 

&amp;gt;&amp;gt; emr_database_checks_done &amp;gt;&amp;gt; terminate_emr_cluster

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;If we check this code in, and then trigger the DAG, we should now see now see the the Amazon EMR cluster start, run the step to create the database, and then terminate the cluster.&lt;/p&gt;

&lt;p&gt;The rest of the workflow repeats the above process, adding addition steps. You can check the full workflow out &lt;a href="https://github.com/094459/devday-elt-automation/blob/main/dags/devday-emr-create.py"&gt;here in the GitHub repository&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Running the workflow&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;After committing the code you should have the workflows available in the Apache Airflow UI and can then trigger them via the UI. As each step starts, runs and then completes, you should be able to see the information and logs produced (including any of the Print statements included in the DAG).&lt;/p&gt;

&lt;p&gt;Once the workflow has completed, you can now take a look at the outcome. If we use Hue, we can connect to the new database and view the new information using standard SQL in Presto. If we look at the Amazon S3 data lake, we can see we have our new files.&lt;/p&gt;

&lt;p&gt;&lt;iframe width="710" height="399" src="https://www.youtube.com/embed/e4EN8L8HiXs"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#what-next"&gt;
  &lt;/a&gt;
  What Next?
&lt;/h3&gt;

&lt;p&gt;Thanks for sticking with me to the end, and I hope you have found it useful to understand how you might use open source tools like Apache Airflow to automate your ELT (or for that matter ETL) tasks. Watch out for a future DevDay Data event where I walk you through the end to end building of this, but I hope that you will have enough information here to try this out for yourself.&lt;/p&gt;

&lt;p&gt;It is not hard to see how you might build upon this example. Some examples might be:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;using a function you deploy on AWS Lambda to trigger the automated workflow - for example, a new data update you receive can lead to automatically these tables/export files being refreshed&lt;/li&gt;
&lt;li&gt;using other Airflow operators such as the ones to Amazon SageMaker that allow you to trigger automatic machine learning model training/tuning&lt;/li&gt;
&lt;li&gt;using additional workflows as part of the ingestion workflows to get the movielens database into the data lake, which then triggers the ELT workflows&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As always, feel free to get in touch and provide comments/questions.&lt;/p&gt;

</description>
      <category>opensource</category>
      <category>aws</category>
    </item>
    <item>
      <title>Automating your ELT Workflows with Managed Workflows for Apache Airflow - Part One</title>
      <author>Ricardo Sueiras</author>
      <pubDate>Wed, 21 Apr 2021 10:55:44 +0000</pubDate>
      <link>https://dev.to/aws/automating-your-elt-workflows-with-managed-workflows-for-apache-airflow-4bjg</link>
      <guid>https://dev.to/aws/automating-your-elt-workflows-with-managed-workflows-for-apache-airflow-4bjg</guid>
      <description>&lt;h3&gt;
  &lt;a href="#part-one-automating-amazon-athena"&gt;
  &lt;/a&gt;
  Part One - Automating Amazon Athena
&lt;/h3&gt;

&lt;p&gt;As part of an upcoming DevDay event, I have been working on  how you can use Apache Airflow to help automate your Extract, Load and Transform (ELT) Workflows. Amazon Athena and Amazon EMR are two AWS services that help customers who have existing SQL skills/expertise and are looking at tools such as Presto or Apache Hive when undertaking those transformations.&lt;/p&gt;

&lt;p&gt;This is a two part post, in this post I focus on Amazon Athena, and in &lt;a href="https://dev.to/aws/automating-your-elt-workflows-with-managed-workflows-for-apache-airflow-1h1m"&gt;Part Two&lt;/a&gt;, I look at Amazon EMR, Apache Hive and Presto.&lt;/p&gt;

&lt;p&gt;In this post I want to share how you can use open source tools like Apache Airflow to automate the manual steps your developers might run when using tools like Presto or Apache Hive. If you want to learn more about Apache Airflow, then head over to the project's website at &lt;a href="https://airflow.apache.org"&gt;https://airflow.apache.org&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I guess a good question to ask is Why, Why do we need to automate these tasks? Here are some of the things that come to mind (this is not intended to be a comprehensive list but some of the reasons that for me, make sense):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;the ability to reproduce and repurpose the work these developers create so that it can be run when and at scale&lt;/li&gt;
&lt;li&gt;so you can separate the development of the code to it running&lt;/li&gt;
&lt;li&gt;reducing the time it takes to get value from your data by enabling code to be run on demand, for example being triggered when a new data payload is received&lt;/li&gt;
&lt;li&gt;adopting of modern development practices such as creation of data pipelines that check your code into source code, validate/test it and then deploy it automatically&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are probably many more, but the outcome is the same - automating those pesky manual tasks is a good thing, and Apache Airflow is our friend here. &lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#scenarios"&gt;
  &lt;/a&gt;
  Scenarios
&lt;/h4&gt;

&lt;p&gt;In this post I will use two simple scenarios that are typical in many organisations looking at putting data in the hands of their builders. Imagine you have been asked to do any of the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create some new tables from data in your data lake, which is going to be used by the data visualisation and reporting team to create some dashboards and graphs from that data.&lt;/li&gt;
&lt;li&gt;Create some new data files in the data lake the data scientists need as they want to experiment and create new machine learning models.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The persona that has been asked to do this will have database expertise, with a good understanding of SQL and looking to leverage that as part of the solution.&lt;/p&gt;

&lt;p&gt;You will find all the code for this demo at &lt;a href="https://github.com/094459/devday-elt-automation"&gt;my repo location here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I will not cover the manual steps that we will automate as they are detailed in the GitHub repo. The key takeaways from reading this post will (hopefully) be a clearer understanding of how you can automate the tasks you do in Amazon Athena and Amazon EMR using Apache Airflow. This should give you a good understanding of how to approach automating your own tasks.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#setup"&gt;
  &lt;/a&gt;
  Setup
&lt;/h4&gt;

&lt;p&gt;I am going to setup and use Managed Workflows for Apache Airflow (MWAA). I have documented in the past how to get this up and running in these blog posts, &lt;a href="https://dev.to/aws/automating-the-installation-of-managed-workflows-for-apache-airflow-5h8a"&gt;Automating the installation and configuration of Amazon Managed Workflows for Apache Airflow&lt;/a&gt; and I will be using a CI/CD setup that I shared how to setup in, &lt;a href="https://dev.to/aws/a-simple-ci-cd-system-for-your-development-workflow-30b4"&gt;A simple CI/CD system for your Amazon Managed Workflows for Apache Airflow development workflow&lt;/a&gt;. This setup gives me a super easy way to author my Apache Airflow workflows from my local IDE (Visual Studio Code as you asked so nicely:-) and then push this to a git repository and then deployed onto MWAA.&lt;/p&gt;

&lt;p&gt;There were a number of things I did need to do however, before I could automate these workflows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Storing variables&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I wanted to use AWS Secrets Manager to store variables that I would use in the workflows so as to not hardcode anything. Following on from this blog post, &lt;a href="https://aws-oss.beachgeek.co.uk/b3"&gt;Move your Apache Airflow connections and variables to AWS Secrets Manager&lt;/a&gt; I added the following Airflow configuration options (when you do this, your MWAA environment will update)&lt;/p&gt;

&lt;div class="table-wrapper-paragraph"&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Configuration Option&lt;/th&gt;
&lt;th&gt;Custom Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;secrets.backend&lt;/td&gt;
&lt;td&gt;airflow.contrib.secrets.aws_secrets_manager.SecretsManagerBackend&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;secrets.backend_kwargs&lt;/td&gt;
&lt;td&gt;{"connections_prefix" : "devday-mwaa/conxns", "variables_prefix" : "devday-mwaa/variables"}&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/div&gt;

&lt;p&gt;If I want to define a variable in my DAG called "task-variable" then I would need to create a secret in AWS Secrets Manager as follows: "devday-mwaa/variables/task-variable". I can then access these values as variables after importing the supporting Python library to make this happen:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;import from airflow.contrib.secrets.aws_secrets_manager
import SecretsManagerBackend
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Note! If you want to try this using standard Apache Airflow, all you need to do is replace the variable statements in the code with the standard Apache Airflow variable (and of course, add the variables via the UI as well)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Permissions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;From a permissions perspective I did have to make a couple of changes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I needed to increase the scope of the permissions that the MWAA execution role had within the Amazon S3 buckets. I do not provide a blanket access, so needed to add a few more resources. If you get any Access Denied errors, then make sure you have the right permissions&lt;/li&gt;
&lt;li&gt;I needed to add new permissions to allow the MWAA worker nodes to kick off and then terminate jobs on Amazon EMR. I scoped down the permissions to the minimum needed for the worker nodes to execute the workflows. I use the default policies when using Amazon EMR (EMR_DefaultRole and EC2_DefaultRole, so change yours as needed):
&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ssm:GetParameter"
            ],
            "Resource": "arn:aws:ssm:*: XXXXXXXXXXXX:parameter/*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "elasticmapreduce:DescribeStep",
                "elasticmapreduce:AddJobFlowSteps",
                "elasticmapreduce:RunJobFlow",
                "elasticmapreduce:TerminateJobFlows"
            ],
            "Resource": "arn:aws:elasticmapreduce:*: XXXXXXXXXXXX:cluster/*"
        },
        {
            "Effect": "Allow",
            "Action": "iam:PassRole",
            "Resource": [
                "arn:aws:iam::XXXXXXXXXXXX:role/EC2_DefaultRole",
                "arn:aws:iam::XXXXXXXXXXXX:role/EMR_DefaultRole"
            ]
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;ul&gt;
&lt;li&gt;I needed to add new permissions to allow the MWAA worker nodes to access Amazon Athena, which required creating a new policy to scope down access to only what it needed. I used this page of the Amazon Athena documentation to help me scope what I needed - &lt;a href="https://docs.aws.amazon.com/athena/latest/ug/fine-grained-access-to-glue-resources.html"&gt;Fine-Grained Access to Databases and Tables in the AWS Glue Data Catalog&lt;/a&gt;. This is the one I used during my demo (the Amazon S3 bucket I was using as my data lake was devday-demo-airflow-sql, and the initial database in Amazon Athena was called Movielens. I set a prefix for all new Athena resources to be devday*. You might want to experiment further locking these permissions down if you want more control.
&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "athena:*"
            ],
            "Resource": [
                "*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "glue:CreateDatabase",
                "glue:DeleteDatabase",
                "glue:GetDatabase",
                "glue:GetDatabases",
                "glue:UpdateDatabase",
                "glue:CreateTable",
                "glue:DeleteTable",
                "glue:BatchDeleteTable",
                "glue:UpdateTable",
                "glue:GetTable",
                "glue:GetTables",
                "glue:BatchCreatePartition",
                "glue:CreatePartition",
                "glue:DeletePartition",
                "glue:BatchDeletePartition",
                "glue:UpdatePartition",
                "glue:GetPartition",
                "glue:GetPartitions",
                "glue:BatchGetPartition"
            ],
            "Resource": [
                "arn:aws:glue:*:XXXXXXXXXXXX:catalog",
                "arn:aws:glue:*:XXXXXXXXXXXX:database/default",
                "arn:aws:glue:*:XXXXXXXXXXXX:database/movielens",
                "arn:aws:glue:*:XXXXXXXXXXXX:database/devday-*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:ListMultipartUploadParts",
                "s3:AbortMultipartUpload",
                "s3:CreateBucket",
                "s3:PutObject"
            ],
            "Resource": [
                "arn:aws:s3:::aws-athena-query-results-*",
                "arn:aws:s3:::devday-demo-airflow-sql",
                "arn:aws:s3:::devday-demo-airflow-sql/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::devday-demo-airflow-sql",
                "arn:aws:s3:::devday-demo-airflow-sql/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket",
                "s3:GetBucketLocation",
                "s3:ListAllMyBuckets"
            ],
            "Resource": [
                "arn:aws:s3:::devday-demo-airflow-sql",
                "arn:aws:s3:::devday-demo-airflow-sql/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "sns:ListTopics",
                "sns:GetTopicAttributes"
            ],
            "Resource": [
                "*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "cloudwatch:PutMetricAlarm",
                "cloudwatch:DescribeAlarms",
                "cloudwatch:DeleteAlarms"
            ],
            "Resource": [
                "*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "lakeformation:GetDataAccess"
            ],
            "Resource": [
                "*"
            ]
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;ul&gt;
&lt;li&gt;As I am using AWS Secrets Managers to hold variables, I needed to allow the MWAA worker nodes permissions, so using the standard SecretsManagerReadWrite policy&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is what the environment looks like - it is an approximation but hopefully lets you see visually all the moving parts.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--d6_j7Zhx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/devday-elt-automation/blob/main/images/demo-arch.png%3Fraw%3Dtrue" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--d6_j7Zhx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/devday-elt-automation/blob/main/images/demo-arch.png%3Fraw%3Dtrue" alt="arch"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Automating Amazon Athena&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To recap: We are using the Movielens dataset, loaded it into our data lake on Amazon S3 and we have been asked to a) create a new table with a subset of the information we care about, in this instance a particular genre of films, and b) create a new file with the same subset of information available in the data lake.&lt;/p&gt;

&lt;p&gt;As part of the set of manual steps we are trying to automate, we are creating Athena databases as well as creating tables and export files. As we are automating this, a lot of the stuff we would not need to do because we absorb that as part of the manual work (for example, I already have a database called XX, so I do not need to re-create that) we need to build into the workflow. So at a high level the steps look like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Check to see if a database exists and create it if it does not exist&lt;/li&gt;
&lt;li&gt;Create tables to import the movie and ratings data&lt;/li&gt;
&lt;li&gt;Create a new table that just contains the information we are looking for (in this example, films of a particular genre)&lt;/li&gt;
&lt;li&gt;Export the new table as a csv file, checking first to see if any old data exists and clearing it&lt;/li&gt;
&lt;li&gt;Move the export csv file to a new location in the data lake&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For this blog post, it doesn't really matter whether these are the best steps to achieve the task. Any task you set out to do will have a set of steps, with logic and conditions you need to think about, and interactions with external systems and data. So how do we go from that set of steps to a workflow?&lt;/p&gt;

&lt;p&gt;In Apache Airflow, you write your automation as a Directed Acylic Graph (or simply DAG) file, which is a file written in Python where you import Apache Airflow operators (either out of the box ones, third party open source or you can create your own) together with your own helper libraries. There are lots of tutorials and getting started guides that will help you understand more, and the one on the Apache Airflow documentation site is pretty good.&lt;/p&gt;

&lt;p&gt;When using Apache Airflow to automate tasks with Amazon Athena we can &lt;a href="https://airflow.apache.org/docs/apache-airflow-providers-amazon/stable/_modules/airflow/providers/amazon/aws/operators/athena.html"&gt;use the Amazon Athena operator&lt;/a&gt; which makes it super easy to submit queries as all we need to do is pass a query to the operator and it will take care of the rest. &lt;/p&gt;

&lt;p&gt;All we need to do is import the Python libraries and Apache Airflow operators we want to use. Here is my starting DAG code, importing the Apache Airflow operators I think I am going to use, as well as some addition Python libraries which I need as part of my code. How you know which ones to use will be determined by what you are trying to achieve in your tasks, although there are some typical ones you will tend to see in many workflows (for example, PythonOperator or DAG)&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;from airflow import DAG, settings, secrets
from airflow.models import Variable
from airflow.utils.trigger_rule import TriggerRule
from airflow.utils.dates import days_ago

from airflow.operators.python_operator import PythonOperator, BranchPythonOperator
from airflow.operators.dummy_operator import DummyOperator

from airflow.contrib.operators.aws_athena_operator import AWSAthenaOperator
from airflow.contrib.secrets.aws_secrets_manager import SecretsManagerBackend
from airflow.contrib.hooks.aws_hook import AwsHook

import os
import sys
import boto3
import time
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;blockquote&gt;
&lt;p&gt;Note! As I am using MWAA, I know these libraries are already available to me. If you are using your own instance of Apache Airflow, you will need to make sure these libraries are installed (pip install...)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Apache Airflow operators use a number of arguments, and so to reduce the amount of code we need to write, we can specify these in a section called "default_args" which will be used by each operator we define in our workflow. In our workflow we do not need to set any default arguments other then the typical defaults, so we can use the following.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email': ['airflow@example.com'],
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1
}

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Next up we need to create a DAG object in which our tasks will live. There are a number of ways you can do this, so explore the different options. I am keeping it simple here for the purposes of explaining this workflow. &lt;/p&gt;

&lt;p&gt;When creating the DAG object that will represent our workflow, we set things like a name (you can use a string if you wanted, but here I am just assigning the filename to keep things simple), selecting the default_args which we just defined in the previous step, provide a description and then do a few other things. In the schedule, we can define how and when we want this workflow to run - you can think of this like a crontab. In this post I do not want to schedule this and just run it on demand, so I select None. If I wanted to run this daily, I might select @daily or @hourly - check the documentation to find out more. Finally, I can assign tags to the workflow so they are easy to find/search for.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;DAG_ID = os.path.basename(__file__).replace('.py', '')
dag = DAG(
    dag_id=DAG_ID,
    default_args=default_args,
    description='DevDay Athena export SciFi DAG',
    schedule_interval=None,
    start_date=days_ago(2),
    tags=['devday','demo'],
)

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Next we define some variables, and grab the values from AWS Secrets Manager. I am defining these three variables (assigning the value of "undefined" if it cannot grab the value):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;s3_dlake - is the location of my Amazon S3 data lake&lt;/li&gt;
&lt;li&gt;athena_db - is the name of the database we will create in Amazon Athena&lt;/li&gt;
&lt;li&gt;athena_output - this is the name of the folder under the s3_dlake where Amazon Athena queries are saved, these being generated when we use the Amazon Athena operator.
&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;s3_dlake = Variable.get("s3_dlake", default_var="undefined")
athena_db = Variable.get("athena_db", default_var="undefined")
athena_output = Variable.get("athena_output", default_var="undefined")
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now onto the actual workflow. A workflow is just a series of tasks that are orchestrated. Using the list above, the first task we need to do is create the database. But what if the database already exists (perhaps this is the nth time we are running this workflow)? We need some basic decision making logic in our workflow.&lt;/p&gt;

&lt;p&gt;One of the ways we can achieve this is to use an Apache Airflow operator called BranchPythonOperator. We define our steps (check the database/create the database/skip the database creation) so what now. We can create this branch code using that operator as follows:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;check_athena_database = BranchPythonOperator(
    task_id='check_athena_database',
    provide_context=True,
    python_callable=check_athena_database,
    dag=dag,
)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We give this task a name as well as a task_id which we will use when we come to creating the dependency graph. We want to associate this task with the DAG object we instantiated above, so we use the dag=dag. We use the provide_context=True to enable Apache Airflow to pass keyword arguments in our functions and then we need to point to some code, so we define a function (in this example, it is called check_athena_database). But wait, where is this function? &lt;/p&gt;

&lt;p&gt;We need to create it, and importantly, we need to create it before this piece of code. This code is where we will put our logic for testing whether a database exists, and the logic that allows us to return a task within the workflow for either path of our branch. &lt;/p&gt;

&lt;p&gt;To check for the existence of the database, I use boto3 and some simple code which will return true if it finds it (the try: loop) and then return "skip_athena_database_creation" and generate an exception (the except: loop) and return "create_athena_database" - we have not created these Apache Airflow tasks yet, so lets do that next.&lt;/p&gt;

&lt;p&gt;Before we do that though, you may notice that we use the print statement here to help you log which branch the workflow will take. Any output from tasks will show up when you view logs as the workflow is running. Apache Airflow operators may emit their own information, but you can also add your own. Here is what the logs look like after this task has run:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;[2021-04-19 13:30:48,996] {{standard_task_runner.py:78}} INFO - Job 116421: Subtask check_athena_database
[2021-04-19 13:30:49,119] {{logging_mixin.py:112}} INFO - Running %s on host %s &amp;lt;TaskInstance: devday-athena-create.check_athena_database 2021-04-19T13:30:30.821655+00:00 [running]&amp;gt; ip-10-192-21-41.eu-west-1.compute.internal
[2021-04-19 13:30:49,352] {{logging_mixin.py:112}} INFO - No Database Found
[2021-04-19 13:30:49,411] {{python_operator.py:114}} INFO - Done. Returned value was: create_athena_database
[2021-04-19 13:30:49,440] {{skipmixin.py:123}} INFO - Following branch create_athena_database
[2021-04-19 13:30:49,507] {{skipmixin.py:149}} INFO - Skipping tasks ['skip_athena_database_creation']
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Back to the code that checks to see whether the Amazon Athena database exists.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;def check_athena_database(**kwargs):
    ath = boto3.client('athena')
    try:
        response = ath.get_database(
            CatalogName='AwsDataCatalog',
            DatabaseName=athena_db
        )
        print("Database already exists - skip creation")
        return "skip_athena_database_creation"
    except:
        print("No Database Found")
        return "create_athena_database"

check_athena_database = BranchPythonOperator(
    task_id='check_athena_database',
    provide_context=True,
    python_callable=check_athena_database,
    dag=dag,
)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We create the "skip_athena_database_creation" task first as this is the easiest as there is nothing to do. Here we use the DummyOperator, that does nothing. It is useful when we put these kinds of branches however.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;skip_athena_database_creation = DummyOperator(
    task_id="skip_athena_database_creation",
    trigger_rule=TriggerRule.NONE_FAILED,
    dag=dag,
)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;You will notice that we have "trigger_rule=TriggerRule.NONE_FAILED". Trigger Rules are used by Apache Airflow to help you define rules that allow you to control the workflow based on how upstream (previous tasks) have completed in your workflow. The NONE_FAILED means that all previous steps must have been successful or skipped. This is all this task does.&lt;/p&gt;

&lt;p&gt;If we look at the "create_athena_database" task code, we can see this is a PythonOperator (rather than the BranchPythonOperator) and calls a python function called "create_db"&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;create_athena_database = PythonOperator (
    task_id='create_athena_database',
    provide_context=True,
    python_callable=create_db,
    dag=dag
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;If we look at the code for "create_db" we can see it is again using boto3 to create the database. In the function we pass in "**kwargs" which allows us to access within the code Apache Airflow arguments, such as variables we have defined and task information. You will also notice that in this code we are accessing the variables we defined earlier. We run this query (the CREATE DATABASE IF NOT EXISTS) with an output location that is "s3://" plus the value of the variable {s3_dlake}. This allows us to create re-usable tasks that are driven by input parameters/variables.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;def create_db(**kwargs):
    print("Creating the database if it does not exist")
    ath = boto3.client('athena')
    ath.start_query_execution(
        QueryString='CREATE DATABASE IF NOT EXISTS '+ athena_db,
        ResultConfiguration={'OutputLocation': 's3://{s3_dlake}/queries/'.format(s3_dlake=s3_dlake)},
        WorkGroup="devday-demo"
        )
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;So no we have one final task to create. We have two flow so far - one that is for the creation of the database, and the other is for the skipping of the database. We used the BranchPythonOperator to direct which task to execute. We now need another task that both of these tasks converge towards, and we again use the DummyTask for this.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;athena_database_checks_done = DummyOperator(
    task_id="athena_database_checks_done",
    trigger_rule=TriggerRule.NONE_FAILED,
    dag=dag,
)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We now have four tasks in our workflow. The next thing is to create the relationship of these tasks within the workflow. There are a few ways we can do this, but the way we will do it here is to use the "&amp;gt;&amp;gt;" to define the relationship.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;check_athena_database &amp;gt;&amp;gt; skip_athena_database_creation &amp;gt;&amp;gt; athena_database_checks_done
check_athena_database &amp;gt;&amp;gt; create_athena_database &amp;gt;&amp;gt; athena_database_checks_done
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;When we save our workflow (DAG) and check it into source control (a reminder I am using my Simple CI/CD setup here) approx 20-30 seconds we will see our workflow appear in the Apache Airflow UI.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--hp6hxE8P--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/devday-elt-automation/blob/main/images/blog-1.png%3Fraw%3Dtrue" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--hp6hxE8P--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/devday-elt-automation/blob/main/images/blog-1.png%3Fraw%3Dtrue" alt="flow"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So far so good. The next step we want to automate is the population of the movies and ratings tables within this database. For this we can use the AWSAthenaOperator. Before we can use this, we need to define the query we want to run. As we want to create two tables, we need two queries, so our code looks like this:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;create_athena_movie_table_query="""
CREATE EXTERNAL TABLE IF NOT EXISTS {database}.movies (
  `movieId` int,
  `title` string,
  `genres` string 
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
WITH SERDEPROPERTIES (
  'serialization.format' = ',',
  'field.delim' = ','
) LOCATION 's3://{s3_dlake}/movielens/movies/'
TBLPROPERTIES (
  'has_encrypted_data'='false',
  'skip.header.line.count'='1'
); 
""".format(database=athena_db, s3_dlake=s3_dlake)

create_athena_ratings_table_query="""
CREATE EXTERNAL TABLE IF NOT EXISTS {database}.ratings (
  `userId` int,
  `movieId` int,
  `rating` int,
  `timestamp` bigint 
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
WITH SERDEPROPERTIES (
  'serialization.format' = ',',
  'field.delim' = ','
) LOCATION 's3://{s3_dlake}/movielens/ratings/'
TBLPROPERTIES (
  'has_encrypted_data'='false',
  'skip.header.line.count'='1'
); 
""".format(database=athena_db, s3_dlake=s3_dlake)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We have assigned two variables, "create_athena_movie_table_query" and "create_athena_ratings_table_query". As you can see, we are again using variables so we do not need to hard code the references (the code could be improved by adding more variables for the source data in movielens/* - it is in my backlog!). These queries should look familiar as they are the same ones we ran via the Amazon Athena console.&lt;/p&gt;

&lt;p&gt;We now create the task that will create these tables using the AWSAthenaOperator as follows:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;create_athena_movie_table = AWSAthenaOperator(
    task_id="create_athena_movie_table",
    query=create_athena_movie_table_query, 
    workgroup = "devday-demo", 
    database=athena_db,
    output_location='s3://'+s3_dlake+"/"+athena_output+'create_athena_movie_table'
    )
create_athena_ratings_table = AWSAthenaOperator(
    task_id="create_athena_movie_ratings",
    query=create_athena_ratings_table_query, 
    workgroup = "devday-demo", 
    database=athena_db,
    output_location='s3://'+s3_dlake+"/"+athena_output+'create_athena_ratings_table'
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;These should begin to look familiar now. Each Operator can have different arguments, and this one requires a "query=" which we point to the variables we defined in the previous step, we define the. Amazon Athena workgroup we want to run this query in, the Amazon Athena database and then the location where the queries will be saved.&lt;/p&gt;

&lt;p&gt;Now we have defined these, we need to include them in the actual workflow. We add these to the original so we end up with the following:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;check_athena_database &amp;gt;&amp;gt; skip_athena_database_creation &amp;gt;&amp;gt; athena_database_checks_done
check_athena_database &amp;gt;&amp;gt; create_athena_database &amp;gt;&amp;gt; athena_database_checks_done

athena_database_checks_done &amp;gt;&amp;gt; create_athena_movie_table &amp;gt;&amp;gt; create_athena_ratings_table 
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;After committing our code, a few seconds later our workflow now looks like:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--uIfg2pIT--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/devday-elt-automation/blob/main/images/blog-2.png%3Fraw%3Dtrue" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--uIfg2pIT--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/devday-elt-automation/blob/main/images/blog-2.png%3Fraw%3Dtrue" alt="flow"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I will not repeat for the remaining tasks, as you should have the idea by now. You can check out the full code in the GitHub repository. I did end up breaking this workflow into two workflows, but they could have been combined into a single one. How you decide will be down to what you are trying to automate, whether there are any tasks that make sense to group together (perhaps they might be run more frequently, or need to be run first or in a specific order).&lt;/p&gt;

&lt;p&gt;One thing however that I do want to point out is that in the second workflow (devday-athena-export.py) you will notice that rather than the "&amp;gt;&amp;gt;" to define the relationship between the tasks, we use the following:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;check_athena_export_table.set_upstream(disp_variables)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;you can use ".set_upstream" or ".set_downstream" to define the relationship between the tasks if you prefer.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Running the workflow&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;After committing the code you should have the workflows available in the Apache Airflow UI and can then trigger them via the UI. As each step starts, runs and then completes, you should be able to see the information and logs produced (including any of the Print statements included in the DAG).&lt;/p&gt;

&lt;p&gt;Once the workflow has completed, you should now see back in the Amazon Athena console a new database (in my case, a new database called devdays_scifimovies) and within this I have a new table (in my case, I had a table called scifi which contained just a subset of the Movielens data that had been tagged with the scifi genre). If I explore the data lake on Amazon S3, and go to the Movielens folder, I notice that I now also have a new exported csv file which contains the same data. &lt;/p&gt;

&lt;p&gt;&lt;iframe width="710" height="399" src="https://www.youtube.com/embed/I0ghfwIL1ps"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;p&gt;This completes the automation of those manual tasks. We have the new tables and we have exported new data into the data lake. Now that we have covered how to do this for Amazon Athena, in the next post we will cover Amazon EMR.&lt;/p&gt;

&lt;p&gt;Take me to &lt;a href="https://dev.to/aws/automating-your-elt-workflows-with-managed-workflows-for-apache-airflow-1h1m"&gt;Post Two&lt;/a&gt;&lt;/p&gt;

</description>
      <category>opensource</category>
      <category>aws</category>
    </item>
  </channel>
</rss>
