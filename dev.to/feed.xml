<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>DEV Community</title>
    <author>DEV Community</author>
    <description>A constructive and inclusive social network for software developers. With you every step of your journey.</description>
    <link>https://dev.to</link>
    <language>en</language>
    <item>
      <title>15000+ Premium design resources Lifetime Only 99$ </title>
      <author>Kamal Ahmed</author>
      <pubDate>Sat, 02 Oct 2021 10:23:27 +0000</pubDate>
      <link>https://dev.to/marketerkamal/15000-premium-design-resources-lifetime-only-99-52m3</link>
      <guid>https://dev.to/marketerkamal/15000-premium-design-resources-lifetime-only-99-52m3</guid>
      <description>&lt;p&gt;15000+ Premium design resources Web template, Illustrations, Mobile app, Free icon and Web app elements from the worldâ€™s best designers&lt;/p&gt;

&lt;p&gt;15000+ Premium design resources Web template, Illustrations, Mobile app, Free icon and Web app elements from the worldâ€™s best designers&lt;/p&gt;

&lt;p&gt;Lifetime Access Only 99$ Party popper&lt;br&gt;
Get 10% Discount Use this coupon code: SPI10&lt;/p&gt;

&lt;p&gt;From : &lt;a href="https://uihut.com"&gt;https://uihut.com&lt;/a&gt;&lt;/p&gt;

</description>
      <category>webpack</category>
      <category>webdesign</category>
      <category>designresorces</category>
      <category>offer</category>
    </item>
    <item>
      <title>Awesome Card Design for Website with HTML CSS</title>
      <author>Sadee</author>
      <pubDate>Sat, 02 Oct 2021 09:41:39 +0000</pubDate>
      <link>https://dev.to/codewithsadee/awesome-card-design-for-website-with-html-css-46i</link>
      <guid>https://dev.to/codewithsadee/awesome-card-design-for-website-with-html-css-46i</guid>
      <description>&lt;p&gt;&lt;iframe width="710" height="399" src="https://www.youtube.com/embed/g9VdvKx8fuM"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;p&gt;How to Create Awesome Card Design for Website with HTML CSS&lt;/p&gt;

&lt;p&gt;In this video I will show you how to create creative card design with hover effect step by step&lt;br&gt;
Website Component Design&lt;/p&gt;

&lt;p&gt;âŒ›ï¸ | ğ€ğ«ğ ğ²ğ¨ğ® ğ¢ğ§ğ­ğğ«ğğ¬ğ­ğğ ğ¢ğ§ ğš ğœğğ«ğ­ğšğ¢ğ§ ğ¬ğğœğ­ğ¢ğ¨ğ§? ğ”ğ¬ğ ğ“ğ¢ğ¦ğğ¬ğ­ğšğ¦ğ©ğ¬&lt;br&gt;
  â†’  0:00 Demo&lt;br&gt;
  â†’  0:17 File Structure &amp;amp; Code&lt;br&gt;
  â†’  8:05 Final Preview&lt;/p&gt;

&lt;p&gt;ğŸ“¥ | ğ†ğğ­ ğšğ¥ğ¥ ğ¢ğ¦ğšğ ğğ¬ ğ­ğ¡ğšğ­ ğˆ ğ®ğ¬ğğ&lt;br&gt;
  â†’  &lt;a href="https://drive.google.com/file/d/1P31-"&gt;https://drive.google.com/file/d/1P31-&lt;/a&gt;... (.zip)&lt;/p&gt;

&lt;p&gt;ğŸ…°ï¸ | ğ†ğğ­ ğ­ğ¡ğ ğŸğ¨ğ§ğ­ ğˆ ğ®ğ¬ğğ&lt;br&gt;
  â†’  Open Sans : &lt;a href="https://fonts.google.com/specimen/Ope"&gt;https://fonts.google.com/specimen/Ope&lt;/a&gt;...&lt;/p&gt;

&lt;p&gt;ğŸ“¥ | ğˆğœğ¨ğ§ ğ‹ğ¢ğ§ğ¤&lt;br&gt;
  â†’  &lt;a href="https://ionic.io/ionicons/usage"&gt;https://ionic.io/ionicons/usage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;â¤ï¸ | ğˆğ§ğ­ğğ«ğğ¬ğ­ğğ ğ¢ğ§ ğ¬ğğğ¢ğ§ğ  ğ¦ğ¨ğ«ğ ğ¯ğ¢ğğğ¨ğ¬? ğ’ğ”ğğ’ğ‚ğ‘ğˆğğ„ ğğğ–&lt;br&gt;
  â†’  &lt;a href="https://bit.ly/3m4UgF5"&gt;https://bit.ly/3m4UgF5&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ğŸ‘¤ | ğ‹ğ¢ğ¤ğ - ğ…ğ¨ğ¥ğ¥ğ¨ğ° &amp;amp; ğ’ğ®ğ›ğ¬ğœğ«ğ¢ğ›ğ ğŒğ&lt;br&gt;
  â†’  Twitter : &lt;a href="https://twitter.com/codewithsadee"&gt;https://twitter.com/codewithsadee&lt;/a&gt;&lt;br&gt;
  â†’  Github : &lt;a href="https://github.com/codewithsadee"&gt;https://github.com/codewithsadee&lt;/a&gt;&lt;br&gt;
  â†’  YouTube : &lt;a href="https://bit.ly/3m4UgF5"&gt;https://bit.ly/3m4UgF5&lt;/a&gt;&lt;/p&gt;

</description>
      <category>css</category>
      <category>tutorial</category>
      <category>webdev</category>
      <category>beginners</category>
    </item>
    <item>
      <title>Open Sourcing URL Shortener</title>
      <author>Rishabh Rawat</author>
      <pubDate>Sat, 02 Oct 2021 09:26:42 +0000</pubDate>
      <link>https://dev.to/rishabh570/open-sourcing-url-shortener-2g3d</link>
      <guid>https://dev.to/rishabh570/open-sourcing-url-shortener-2g3d</guid>
      <description>&lt;p&gt;Open Source Software (OSS) has been the main driving force in democratizing access to so many awesome tools with way more transparency than ever possible. Itâ€™s never too late to start giving back to the community and contribute towards a better OSS culture. Thatâ€™s why we started this journey by open-sourcing our in-house URL Shortener service.  The reason for choosing this is to assess the road ahead and be in a better position to embark on our open source journey.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#road-to-open-sourcing-url-shortener"&gt;
  &lt;/a&gt;
  Road to Open Sourcing URL Shortener
&lt;/h2&gt;

&lt;p&gt;Letâ€™s take a look at the steps involved in open sourcing this service.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#1-business-logic-abstraction"&gt;
  &lt;/a&gt;
  1. Business logic abstraction
&lt;/h3&gt;

&lt;p&gt;Being an internal service, the URL Shortener was strongly tied with our tracking API which is used for, as the name suggests, tracking purposes. We needed to decouple these services before open-sourcing URL Shortener as having internal dependencies in an open-source project is unfeasible for obvious reasons. This called for refactoring.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--iza1cifd--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/u1dpcte9ppsa3ez8juzw.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--iza1cifd--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/u1dpcte9ppsa3ez8juzw.png" alt="URL shortener initial setup"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As shown in the diagram, CTA (Call To Action) token is generated in the notifications service and is passed down to the URL shortener whenever a notification needs to be sent. URL Shortener then stores the CTA token &amp;lt;&amp;gt; original URL mapping in a separate table. And, it simply passes the CTA token and the original URL to the tracking API whenever someone clicks on the short link. As you might guess, the CTA token has nothing to do with a URL shortening service and therefore it should not have any context of such tokens.&lt;/p&gt;

&lt;p&gt;This presented before us, the quest to pull URL Shortener out of the loop and stop passing any redundant data to it. Letâ€™s take a look at the steps involved:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--MtCqGEP1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/s6kund78e8img1e90hrd.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--MtCqGEP1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/s6kund78e8img1e90hrd.png" alt="URL Shortener Business Logic Abstraction HLD"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As you can see, the above HLD proposes a different way of passing down the CTA Token in a way where URL Shortener is not bothered with unnecessary data. Letâ€™s go through it step-by-step:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Notification services hit the URL Shortener to get the short URL whenever a notification needs a short link (eg. referral emails, market open reminder SMS, order updates SMS, etc.).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; URL Shortener generates the short URL, maps it with the corresponding original (or â€œlongâ€) URL, and returns the result to the notification service.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; After sending the notification, the shortener forwards the CTA token &amp;amp; the corresponding original URL to our tracking API service when someone clicks on the short URL.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 4:&lt;/strong&gt; Tracking API stores this original URL to CTA token mapping in the PostgreSQL.&lt;/p&gt;

&lt;p&gt;Forwarding the data to tracking API happens like this:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--9Tvy9pPY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9jlu3oks6w698nwd3bh5.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--9Tvy9pPY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9jlu3oks6w698nwd3bh5.png" alt="URL Shortener Modified Tracking HLD"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; User clicks on the short link received through email or SMS notification.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; URL Shortener receives the short URL user clicked and redirects him/her to the original URL.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Before redirecting the user to the original URL, the shortener also emits a kafka event that contains the short URL that the user clicked.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 4:&lt;/strong&gt; Tracking API, upon receiving the short URL, stores the data corresponding to that in the PostgreSQL table for analytics purposes. No user-specific data is used in any shape &amp;amp; form. We only use the metadata to understand the delivery, click rates, etc.&lt;/p&gt;

&lt;p&gt;And that is it for the business logic abstraction. Following these steps, we were able to make the URL Shortener loosely coupled with our tracking API and free from internal dependencies.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#2-refactor"&gt;
  &lt;/a&gt;
  2. Refactor
&lt;/h3&gt;

&lt;p&gt;The URL Shortener service was created a little more than 2 years ago to fulfil the needs of an internal URL shortening service. It was just a bare-bone HTTP server with SQLite as the database. But with the increase in the notification sent from smallcase, the number of requests to the shortener has increased significantly over time, it gets around 500k (read + write) requests per month. There were a couple of things that need addressal:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Simple &amp;amp; non-scalable nature of the service&lt;/li&gt;
&lt;li&gt;No logging pipeline to debug when something goes wrong.&lt;/li&gt;
&lt;li&gt;No way to avoid getting duplicate short keys for different URLs.&lt;/li&gt;
&lt;li&gt;No purging of stale entries from the database.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;
  &lt;a href="#moving-to-fastify"&gt;
  &lt;/a&gt;
  Moving to Fastify
&lt;/h4&gt;

&lt;p&gt;As I mentioned, the initial setup was not reliable enough for the growing needs. There were some major changes required in the implementation. There were three options we had in mind:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Using S3, AWS Lambda, and CloudFront&lt;/li&gt;
&lt;li&gt;Using AWS API Gateway and Dynamo DB&lt;/li&gt;
&lt;li&gt;Fastify with MongoDB &amp;amp; Redis&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Letâ€™s talk about each one of them.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#using-s3-aws-lambda-and-cloudfront"&gt;
  &lt;/a&gt;
  Using S3, AWS Lambda, and CloudFront
&lt;/h5&gt;

&lt;p&gt;This approach aims to use S3 as a redirection engine by activating website hosting on the bucket. This way, for each short URL we can create a new empty object with a long URL attached in the website redirect metadata. On top of this, we can create a bucket lifecycle policy to purge the entries older than a set timeframe.&lt;/p&gt;

&lt;p&gt;To create an admin page, all we need is a basic page hosted on S3 which will trigger a POST request to API Gateway invoking a lambda function which will:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;create a short key&lt;/li&gt;
&lt;li&gt;create an empty S3 object&lt;/li&gt;
&lt;li&gt;store the short URL (/) as the redirection destination in the object properties.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While going ahead with this approach meant we didnâ€™t have to worry about scalability or &lt;a href="https://www.digitalocean.com/community/tutorials/what-is-high-availability"&gt;High Availability&lt;/a&gt;, it certainly ties us with AWS offerings and implicitly denies any flexibility when it comes to change of service vendor.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#using-aws-api-gateway-with-dynamo-db"&gt;
  &lt;/a&gt;
  Using AWS API Gateway with Dynamo DB
&lt;/h5&gt;

&lt;p&gt;If we observe closely, all that lambda function is doing is storing the short URL in the empty S3 object. Hence, we can cut out on the resources &amp;amp; cost using this approach. Letâ€™s take a look at how API Gateway combined with Dynamo DB would work here.&lt;/p&gt;

&lt;p&gt;There are four phases a request goes through when using the API Gateway:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Method Request&lt;/li&gt;
&lt;li&gt;Integration Request&lt;/li&gt;
&lt;li&gt;Integration Response&lt;/li&gt;
&lt;li&gt;Method Response&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-method-settings-method-request.html"&gt;Method Request&lt;/a&gt; involves creating API method resources, attaching HTTP verbs, authorisation, validation, etc.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-integration-settings-integration-request.html"&gt;Integration Request&lt;/a&gt; is responsible for setting up the integration between API Gateway &amp;amp; DynamoDB. One thing to note here, we need to modify the request &amp;amp; change it to a format that DynamoDB understands.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-method-settings-method-response.html"&gt;Method Response&lt;/a&gt; is configured to send the response back to the client which can be 200, 400, or some other.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-integration-settings-integration-response.html"&gt;Integration Response&lt;/a&gt; is what we get from DynamoDB but again, we need to convert this back into the format that the client understands.&lt;/p&gt;

&lt;p&gt;Again, while this approach allows us to get rid of the lambda and uses Apache VTL to communicate with DynamoDB, this presents the vendor lock-in we saw in the previous approach as it is strongly tied to AWS offerings. Also, it leaves us with us zero-control over the execution.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#fastify-with-mongodb-amp-redis"&gt;
  &lt;/a&gt;
  Fastify with MongoDB &amp;amp; Redis
&lt;/h5&gt;

&lt;p&gt;It is immediately noticeable that this approach gives us complete control over the service with no vendor lock-in. We can choose any data storage solution as per our needs, custom logging setup, and even in-house key generation service if we want.&lt;/p&gt;

&lt;p&gt;Looking at the &lt;a href="https://www.fastify.io/benchmarks/"&gt;benchmarks&lt;/a&gt;, Fastify is the clear winner among other Nodejs frameworks. It has &lt;a href="https://github.com/delvedor/find-my-way"&gt;faster routing&lt;/a&gt;, &lt;a href="https://github.com/fastify/fast-json-stringify"&gt;JSON handling with faster rendering&lt;/a&gt; and a bunch of ready-made &lt;a href="https://www.fastify.io/ecosystem/"&gt;plugins&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While this is perfect in terms of what we wanted, it also means we now have to make sure that MongoDB and Redis are highly available otherwise it directly affects our service. This means developersâ€™ bandwidth is extensively required which was not the case in the previous approaches.&lt;/p&gt;

&lt;p&gt;With our Fastify application in place, we were able to plug our improved custom logging pipeline which is a huge benefit to the developer experience because the old pipeline was not reliable for the scale we now operate at.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#adding-logging-pipeline"&gt;
  &lt;/a&gt;
  Adding logging pipeline
&lt;/h4&gt;

&lt;p&gt;With the increasing number of requests and possibly errors, we needed a proper logging setup to debug and monitor the service. Thatâ€™s why we chose &lt;a href="https://www.npmjs.com/package/bunyan"&gt;bunyan&lt;/a&gt; to log insightful data in our application. These logs sit conveniently on our new logging pipeline running on EFK (or, Elasticsearch Fluentd Kibana) stack. While this deserves a separate blog post on its own, letâ€™s take a brief look at how the logs travel from our application to the &lt;a href="https://www.elastic.co/guide/en/kibana/current/dashboard.html"&gt;kibana dashboard&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--wHc_dSbh--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3e3euqz7u5twhzko1dk4.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--wHc_dSbh--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3e3euqz7u5twhzko1dk4.png" alt="Logging pipeline used for URL shortener"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The logs that we have written inside the application are produced to the standard output. The fluentd collector (which is present in all the applications using the EFK logging pipeline) takes all the logs from the stdout and forwards them to the fluentd aggregator.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The aggregator is simply where all the logs get collected from various &lt;a href="https://aws.amazon.com/ec2/"&gt;AWS EC2&lt;/a&gt; application instances. All the logs then go through the &lt;a href="https://www.fluentd.org/plugins"&gt;plugins&lt;/a&gt; installed to process the logs.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;These potentially transformed logs are then sent to the Elasticsearch nodes over the network where this data gets stored. The structure of the logs needs to follow a predetermined pattern and thatâ€™s why Elasticsearch needs an index mapping to understand the structure of logs comings its way. This helps in &lt;a href="https://www.elastic.co/blog/what-is-an-elasticsearch-index"&gt;indexing&lt;/a&gt; and storing data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Kibana uses the structured logs data to show the logs nicely on a &lt;a href="https://www.elastic.co/guide/en/kibana/current/dashboard.html"&gt;dashboard&lt;/a&gt;. Since the data is structured, Kibana enables us to create visualisations and custom dashboards (a collection of different visualisations) on top of it.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;
  &lt;a href="#generating-unique-short-key"&gt;
  &lt;/a&gt;
  Generating unique short key
&lt;/h4&gt;

&lt;p&gt;With the increasing number of short key generations, thereâ€™s a higher probability that the key generation service can spit out the same short keys for two different original (or long) URLs, if not handled correctly. The solution to this problem is simply not let a short key get reused. Now there are two ways to achieve this:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Do not generate a duplicate short key&lt;/li&gt;
&lt;li&gt;Retry until a unique short key is generated&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Letâ€™s take a look at both approaches.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#do-not-generate-a-duplicate-short-key"&gt;
  &lt;/a&gt;
  Do not generate a duplicate short key
&lt;/h5&gt;

&lt;p&gt;To make sure we donâ€™t generate a duplicate short key ever, we need to know what keys have been generated already. One approach could be creating two tables in PostgreSQL, one for the available keys (letâ€™s say AvlK) and one for the keys that are occupied (letâ€™s say OccK).&lt;/p&gt;

&lt;p&gt;So while creating a short URL, we would fetch one unused key from AvlK table, add it to OccK table and return it. Two database operations, one short URL. Not fair.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#retry-until-a-unique-short-key-is-generated"&gt;
  &lt;/a&gt;
  Retry until a unique short key is generated
&lt;/h5&gt;

&lt;p&gt;Instead of maintaining two tables just to get one short key, we can work with just one PostgreSQL table which will store the keys already occupied. We can then simply generate a random key, check if it is occupied, and assign it if it is not.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--T4N_LiIQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/6eoo54yt30p5uaboiz9k.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--T4N_LiIQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/6eoo54yt30p5uaboiz9k.png" alt="NanoId Collision Calculator"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Looking at the results on &lt;a href="https://zelark.github.io/nano-id-cc/"&gt;nanoId collision calculator&lt;/a&gt;, we can see that after three days of generating short keys at rate of 70/hr, there is 1% probability of encountering at least one collision.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;70 keys generation per hour * 24 hours * 3 days = 5040 short keys
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;So 1% probability means, having at least &lt;strong&gt;one collision in every 5k short keys generation&lt;/strong&gt;.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#passively-purging-the-url-mappings"&gt;
  &lt;/a&gt;
  Passively purging the URL mappings
&lt;/h4&gt;

&lt;p&gt;Short URLs are not supposed to have a lifetime of decades or even more than 1 year depending upon the use case. As it is not practical to store the entries forever. Thatâ€™s why purging is required. But the implementation can be flexible. At smallcase, short URLs are majorly generated for two broad categories:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;For transactional notifications&lt;/li&gt;
&lt;li&gt;For campaigns&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The short links generated for the transactional notifications are not supposed to be active forever whereas the links that are generated for the campaigns are supposed to be active till the campaign is active. Considering the differences in the lifespan of different short links, they needed to be treated differently when it comes to purging the entries from the database.&lt;/p&gt;

&lt;p&gt;One approach was to run a job that would remove all the entries which are older than a set timeframe. But turns out there was a better way with minimal additional effort. Instead of running a dedicated job to purge entries, we could simply handle this when weâ€™re creating short URLs. Remember we were doing retries to land upon a key that was not already occupied? A minor change in that process handled purging for us. Just when you get an already occupied key, allow overwriting to that key only if it has hit the expiration date (which is also stored during the creation of the short key along with the mapping). This increases the time of creating short links comparatively but this is the trade-off you need to make to ensure unique keys.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#3-documentation"&gt;
  &lt;/a&gt;
  3. Documentation
&lt;/h3&gt;

&lt;p&gt;Lastly, the crucial part of an open-source project. Documentation. These were the following things that were on the checklist:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;README.md&lt;/li&gt;
&lt;li&gt;CONTRIBUTING.md&lt;/li&gt;
&lt;li&gt;CODE_OF_CONDUCT.md&lt;/li&gt;
&lt;li&gt;LICENCE&lt;/li&gt;
&lt;li&gt;CODEOWNERS&lt;/li&gt;
&lt;li&gt;Templates for creating issues &amp;amp; submitting PRs for streamlined flow.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And finally, making the project public! ğŸ‰&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#what-next"&gt;
  &lt;/a&gt;
  What Next?
&lt;/h2&gt;

&lt;p&gt;This was our journey to open-sourcing the URL shortener service that we use at smallcase. I believe open source not only helps in building a better tool, but it also builds a community of people that care about equal access to software. At the end of the day, we learn from each other.&lt;/p&gt;

&lt;p&gt;The project is available here: &lt;a href="//github.com/smallcase/smalllinks"&gt;github.com/smallcase/smalllinks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Please feel free to create an issue on Github if you find any improvement opportunities or bugs present in the project. Iâ€™ll be happy to connect ğŸ˜ƒ.&lt;/p&gt;

</description>
      <category>fastify</category>
      <category>urlshortener</category>
      <category>opensource</category>
    </item>
    <item>
      <title>How Internet Message Access Protocol(IMAP) works in Node JS</title>
      <author>Venkat3750</author>
      <pubDate>Sat, 02 Oct 2021 09:18:11 +0000</pubDate>
      <link>https://dev.to/venkat3750/how-internet-message-access-protocol-imap-works-in-node-js-1jh5</link>
      <guid>https://dev.to/venkat3750/how-internet-message-access-protocol-imap-works-in-node-js-1jh5</guid>
      <description>&lt;p&gt;Hello my dear peers ğŸ˜ƒ! Hope you're doing well. Welcome to my tech blog and this time we are discussing about &lt;strong&gt;IMAP&lt;/strong&gt; package and it's uses in Node JS with real time code snippet examples. In this, first will only focus on reading emails.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#nodeimap-is-an-imap-client-module-for-nodejs"&gt;
  &lt;/a&gt;
  node-imap is an IMAP client module for node.js.
&lt;/h4&gt;

&lt;p&gt;Let's open our terminal and hit &lt;strong&gt;npm install node-imap.&lt;/strong&gt; to install IMAP package.&lt;/p&gt;

&lt;p&gt;In this blog, we are mainly focusing on how to read email attachments based on the &lt;strong&gt;DATE RANGE&lt;/strong&gt;, &lt;strong&gt;FROM&lt;/strong&gt; particular email address and it's &lt;strong&gt;SUBJECT&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Let's see from the below example code which fetches first 3 email messages from the mail box.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;var Imap = require('node-imap'),
    inspect = require('util').inspect;

var imap = new Imap({
  user: 'mygmailname@gmail.com',
  password: 'mygmailpassword',
  host: 'imap.gmail.com',
  port: 993,
  tls: true
});

function openInbox(cb) {
  imap.openBox('INBOX', true, cb);
}

imap.once('ready', function() {
  openInbox(function(err, box) {
    if (err) throw err;
    var f = imap.seq.fetch('1:3', {
      bodies: 'HEADER.FIELDS (FROM TO SUBJECT DATE)',
      struct: true
    });
    f.on('message', function(msg, seqno) {
      console.log('Message #%d', seqno);
      var prefix = '(#' + seqno + ') ';
      msg.on('body', function(stream, info) {
        var buffer = '';
        stream.on('data', function(chunk) {
          buffer += chunk.toString('utf8');
        });
        stream.once('end', function() {
          console.log(prefix + 'Parsed header: %s', inspect(Imap.parseHeader(buffer)));
        });
      });
      msg.once('attributes', function(attrs) {
        console.log(prefix + 'Attributes: %s', inspect(attrs, false, 8));
      });
      msg.once('end', function() {
        console.log(prefix + 'Finished');
      });
    });
    f.once('error', function(err) {
      console.log('Fetch error: ' + err);
    });
    f.once('end', function() {
      console.log('Done fetching all messages!');
      imap.end();
    });
  });
});

imap.once('error', function(err) {
  console.log(err);
});

imap.once('end', function() {
  console.log('Connection ended');
});

imap.connect();
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;There are scenarios where you need to fetch only the attachments from the email and process it for a different purpose. In such cases, please refer below code example.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;var imap = new Imap({
  user: 'mygmailname@gmail.com',
  password: 'mygmailpassword',
  host: 'imap.gmail.com',
    port: 993,
    tls: true,
  });
  imap.once("ready", function () {
    var fs = require("fs"),
      fileStream;
    imap.openBox("INBOX", true, function (err, box) {
      if (err) throw err;
      try {
        imap.search(
          [
            ["FROM", FROM_MAIL],
            ["HEADER", "SUBJECT", SUBJECT],
            ["UNSEEN", ["SINCE", "Day, Year"]],
          ],
          function (err, results) {
            if (err) throw err;
            try {
              var f = imap.fetch(results, {
                bodies: ["HEADER.FIELDS (FROM TO SUBJECT DATE)"],
                struct: true,
              });
              f.on("message", function (msg, seqno) {
                console.log("Message #%d", seqno);

                var prefix = "(#" + seqno + ") ";
                msg.on("body", function (stream, info) {
                  var buffer = "";
                  stream.on("data", function (chunk) {
                    buffer += chunk.toString("utf8");
                  });
                  stream.once("end", function () {
                    console.log(
                      prefix + "Parsed header: %s",
                      Imap.parseHeader(buffer)
                    );
                  });
                });
                msg.once("attributes", function (attrs) {
                  // console.log("test", attrs);
                  var attachments = findAttachmentParts(attrs.struct);
                  console.log(
                    prefix + "Has attachments: %d",
                    attachments.length
                  );
                  for (var i = 0, len = attachments.length; i &amp;lt; len; ++i) {
                    var attachment = attachments[i];

                    var f = imap.fetch(attrs.uid, {
                      //do not use imap.seq.fetch here
                      bodies: [attachment.partID],
                      struct: true,
                    });
                    //build function to process attachment message
                    f.on("message", processAttachment(attachment));
                  }
                });
                msg.once("end", function () {
                  console.log(prefix + "Finished email");
                });
              });
              f.once("error", function (err) {
                console.log("Fetch error: " + err);
              });
              f.once("end", function () {
                console.log("Done fetching all messages!");
                imap.end();
              });
            } catch (e) {
              console.log("err", e);
            }
          }
        );
      } catch (e) {
        console.log("log", e);
      }
    });
  });

  imap.once("error", function (err) {
    console.log(err);
  });

  imap.once("end", function () {
    console.log("Connection ended");
  });
  imap.connect();
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The downloaded email attachment must be decoded using &lt;strong&gt;Base64Decode()&lt;/strong&gt; method.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;function processAttachment(attachment) {
  var filename = attachment.params.name;
  var encoding = attachment.encoding;
  var name = filename.split(".")[1];
  console.log("log", name);

  return function (msg, seqno) {
    if (name === "pdf") {
      var prefix = "(#" + seqno + ") ";
      msg.on("body", function (stream, info) {
        //Create a write stream so that we can stream the attachment to file;
        console.log(
          prefix + "Streaming this attachment to file",
          filename,
          info
        );
        var path = require("path");
       // var dirPath = path.join(__dirname, "/attachments");
        var writeStream = fs.createWriteStream(filename);
        writeStream.on("finish", function () {
          console.log(prefix + "Done writing to file %s", filename);
        });

        if (toUpper(encoding) === "BASE64") {
          stream.pipe(new base64.Base64Decode()).pipe(writeStream);
        } else {
          stream.pipe(writeStream);
        }
      });
      msg.once("end", function () {
        console.log(prefix + "Finished attachment %s", filename);
      });
    }
  };
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The above process attachment method has a condition check of having only PDF docs.&lt;/p&gt;

&lt;p&gt;So, after processing the email attachments would you recommend those emails still be present in same inbox? No not at all, because we need to move that to some other folder so that we can differentiate the newly arrived emails. &lt;/p&gt;

&lt;p&gt;So, you can move the processed email to specific folder from the inbox using below code example.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt; imap.seq.move(seqno, "Processed", function (err) {
                  if (!err) {
                    console.log(seqno + ": move success");
                  }
                });
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Hope you got atleast an idea how to work with imap package and with emails in Node JS ğŸ‰ğŸ‰. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;br&gt;
&lt;a href="https://www.npmjs.com/package/node-imap"&gt;https://www.npmjs.com/package/node-imap&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/mikebevz/node-imap"&gt;https://github.com/mikebevz/node-imap&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thank you for sticking around and holding on to the end.&lt;/p&gt;

&lt;p&gt;Until next time!&lt;/p&gt;

</description>
      <category>node</category>
      <category>javascript</category>
      <category>imap</category>
    </item>
    <item>
      <title>Why you should avoid using abstraction and interface</title>
      <author>Muhammad Fauzan</author>
      <pubDate>Sat, 02 Oct 2021 09:07:40 +0000</pubDate>
      <link>https://dev.to/fncolon/why-you-should-avoid-using-abstraction-and-interface-1cag</link>
      <guid>https://dev.to/fncolon/why-you-should-avoid-using-abstraction-and-interface-1cag</guid>
      <description>&lt;p&gt;Using &lt;strong&gt;abstraction&lt;/strong&gt; lead us to write another &lt;strong&gt;higher-level of abstraction&lt;/strong&gt; if it's not leads, then your abstraction is bad.&lt;/p&gt;

&lt;p&gt;e.g&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight php"&gt;&lt;code&gt;&lt;span class="k"&gt;abstract&lt;/span&gt; &lt;span class="kd"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CrazyExample&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;abstract&lt;/span&gt; &lt;span class="k"&gt;protected&lt;/span&gt; &lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;getValue&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
    &lt;span class="k"&gt;abstract&lt;/span&gt; &lt;span class="k"&gt;protected&lt;/span&gt; &lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;getOptions&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
    &lt;span class="k"&gt;abstract&lt;/span&gt; &lt;span class="k"&gt;protected&lt;/span&gt; &lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="n"&gt;getValueAndOptions&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt; &lt;span class="c1"&gt;//??&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;what is the benefit of hiding the complexity of a system? is it just to waste your time, you would be find the way back to your complexity during development again.&lt;/p&gt;

</description>
      <category>oop</category>
    </item>
    <item>
      <title>Why can't I see my post stats on DEV?</title>
      <author>Keff</author>
      <pubDate>Sat, 02 Oct 2021 08:58:14 +0000</pubDate>
      <link>https://dev.to/nombrekeff/why-can-t-i-see-my-post-stats-on-dev-2hp2</link>
      <guid>https://dev.to/nombrekeff/why-can-t-i-see-my-post-stats-on-dev-2hp2</guid>
      <description>&lt;p&gt;I see there is a stats section for posts and for my whole account, but they never show anything, they appear blank.&lt;/p&gt;

&lt;p&gt;Is there any way of getting access to them? Or should I do something else?&lt;/p&gt;

&lt;p&gt;Regards!&lt;/p&gt;

</description>
      <category>meta</category>
      <category>question</category>
      <category>help</category>
    </item>
    <item>
      <title>Why I stopped using APIÂ Platform</title>
      <author>Alessandro Chitolina</author>
      <pubDate>Sat, 02 Oct 2021 08:38:40 +0000</pubDate>
      <link>https://dev.to/alekitto/why-i-stopped-using-api-platform-2eki</link>
      <guid>https://dev.to/alekitto/why-i-stopped-using-api-platform-2eki</guid>
      <description>&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;: Though Iâ€™m listing here what make my life harder when using API Platform, I still consider it a great solution to build rapid CRUD prototypes. This article is addressed to those who want build a long-term api-based solution.&lt;/p&gt;




&lt;p&gt;In principle there was FOSRestBundle, a shiny little magic box to create something similar to a REST API. Actually, there was too much magic in it..&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#and-then-api-platform-came-and-headaches-with-it"&gt;
  &lt;/a&gt;
  And then API Platform came, and headaches with it.
&lt;/h2&gt;

&lt;p&gt;Despite the documentation states th&lt;span id="rmm"&gt;a&lt;/span&gt;t â€œEverything is fully customizable through a powerful event system and strong OOPâ€, the truth is that is nearly impossibile to customise deep behaviours and logic inside the api component and the choice to tightly couple it to the Symfony Serializer (probably the less powerful and poor of configuration options serializers I ever seen) make it even worse. But this is what I discovered only at the end of this incredible journey into API Platform..&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#the-journey-begins"&gt;
  &lt;/a&gt;
  The journey begins
&lt;/h3&gt;

&lt;p&gt;The first thing I noted when I began to use API Platform was its no support for versioning. You can put a prefix in your path and pretend that is a versioning system, but the fact is that the tool does not help you at all. Ultimately I didnâ€™t like versions in path: it is not so RESTy, Iâ€™d rather prefer to pass it through a request header (a custom one or an attribute of the Accept header).&lt;/p&gt;

&lt;p&gt;So I began to start exploring services, normalizers, final classes with twelve (!) required dependencies and four optional dependencies to discover that everything in API Platform revolves around the OpenAPI specification.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#openapi-oh-my"&gt;
  &lt;/a&gt;
  OpenAPI, oh my!
&lt;/h3&gt;

&lt;p&gt;I consider OpenAPI a great example on how NOT to write a specification. Partly because it tries to derive a protocol from an architectural standard (which REST is) and this is a nearly impossible task. And partly because of the limitations it puts upon a great designed protocol such as the HTTP.&lt;/p&gt;

&lt;p&gt;For example: OpenAPI limits the HTTP methods you can use to the standardised ones (not even &lt;em&gt;all&lt;/em&gt; the standardised methods, but this is another story), although the HTTP specification clearly states that a method is simply a group of US-ASCII characters. It does not even mandates the registration of non-standard methods to IANA, so why a specification used to define how to write your own API protocol should limit it?&lt;/p&gt;

&lt;p&gt;Anyway, the extraordinary effort to produce an OpenAPI schema leads to the impossibility to have a versioned API for real. When I realised that, my mind blown up.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--gju0wQVB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uxry52qnxj16grxkiiiw.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--gju0wQVB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uxry52qnxj16grxkiiiw.gif" alt="Mind blown"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After overriding something like 14 services just to modify a single call contained in a final class which is required throughout all the API Platform codebase without specifying an interface, I started doubting..&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#the-journey-continues-dtos-serializer-and-validation"&gt;
  &lt;/a&gt;
  The journey continues: DTOs, Serializer and validation
&lt;/h2&gt;

&lt;p&gt;One of the most important things I learned from my work on monolithic projects was the use of DTOs and the rich model entities. They allowed me to avoid errors in database, simplifies the logics of dynamic forms and started to be a sort of holy grail of my projects: it was simply too convenient to use it.&lt;/p&gt;

&lt;p&gt;I thought that maybe the DTOs could help me with this problem too. I was wrong.&lt;/p&gt;

&lt;p&gt;API Platform does support DTOs, but not very well (to be honest, one of my colleagues told me that the DTOs support is better now, but when I tried, it was very very bad). There was not so much documentation, so I had to try to use them directly on code.&lt;/p&gt;

&lt;p&gt;First try: write a simple DTO, declare it in input and output of the ApiResource annotation, add validation annotations on DTOs properties, write the transformer, send correct data, everythingâ€™s ok. Then I tried to pass invalid data: 500.&lt;/p&gt;

&lt;p&gt;Umm.. I opened the web profiler, went to validation section andâ€¦ surprise! API Platform called validation on the entity. WTF?!&lt;/p&gt;

&lt;p&gt;That approach is bad for multiple reasons, but is obviously incompatible with the rich model entities as invalid data will throw exceptions when trying to set them into the entity. In addition, if a field is invalid on the entity, but is not present on the DTO (or is present with an aliased name), an error with an unknown field is returned to the client. No way!&lt;br&gt;&lt;br&gt;
&lt;strong&gt;Edit:&lt;/strong&gt; someone told me that this behaviour is fixed now, but it was present at the time and anyway the DTOs support is still limited.&lt;/p&gt;

&lt;p&gt;What makes it worse, is the use of Symfony Serializer which is impossible to replace. Its scarcity of configuration options (at the time a basic functionality such as the ignore attribute was not present) and the lack of control about the attributes to be exposed and the object construction was frustrating.&lt;br&gt;&lt;br&gt;
Additionally, the use of deserialisers which can throw an exception on invalid data makes everything really unstable and unreliable because those errors are returned to the client in a completely different way than the validation errors.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--AZomEDUv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2rhmi7cmwksoyx4c52wm.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--AZomEDUv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2rhmi7cmwksoyx4c52wm.jpg" alt="Headache"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#headaches-platform-the-end-of-the-journey"&gt;
  &lt;/a&gt;
  Headaches Platform: the end of the journey
&lt;/h2&gt;

&lt;p&gt;What makes everything more and more complicated was the intensive use of hydra and jsonld. The aim of API Platform is to be the only one, the only API present in the system. But in the real world you are probably working on one API exposed by one service developed alongside other services and other APIs. These APIs are probably communicating each other and expose foreign references and data.&lt;/p&gt;

&lt;p&gt;Producing only ONE documentation for the whole architecture canâ€™t be done from one of these services as it cannot know the architecture of the other ones.&lt;/p&gt;

&lt;p&gt;Out-of-scope functionalities (JWT authentication, admin generators, etc), bad designed filters (cannot be aliased for example), pagination with pages (which are a frontend concept) and a limited support for PATCH requests gave me only the confirmation of my doubts:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;API Platform is not ready and is not designed to be a reliable API tool in a world of microservices.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;
  &lt;a href="#so-what"&gt;
  &lt;/a&gt;
  So what?
&lt;/h2&gt;

&lt;p&gt;So I started from scratch. Started a new Symfony project, begin writing stuff to have a powerful versioning system, to be compatible with rich model entities, without the limitations of OpenAPI and with DTOs to be a central point of the API architecture.&lt;/p&gt;

&lt;p&gt;Now I decided to open my code and publish it on GitHub. I wanted this project to be a rock solid toolbox to write REST APIs which are maintenable in a long long term project, learning from all the things I donâ€™t like in other API toolsets.&lt;/p&gt;

&lt;p&gt;I called it Solido, and hereâ€™s the doc: &lt;a href="https://solid-o.github.io/docs/"&gt;https://solid-o.github.io/docs/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Itâ€™s obviously under active development and Iâ€™m looking for others to join me building a very strong, well written and useful open source API toolbox.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--hVHtSA3w--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/33afgcm6ympyq5j87esy.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--hVHtSA3w--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/33afgcm6ympyq5j87esy.jpg" alt="Github"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thank you for reading,&lt;br&gt;
A.&lt;/p&gt;

</description>
      <category>php</category>
      <category>apiplatform</category>
      <category>symfony</category>
    </item>
    <item>
      <title>Get started with github</title>
      <author>Nikhil Bobade </author>
      <pubDate>Sat, 02 Oct 2021 07:43:13 +0000</pubDate>
      <link>https://dev.to/nikhil27b/get-started-with-github-2647</link>
      <guid>https://dev.to/nikhil27b/get-started-with-github-2647</guid>
      <description>&lt;p&gt;Hey guys hacktoberfest is started if you donâ€™t know about GitHub or what is GitHub how its use so this is useful post for you.&lt;br&gt;
In this post you learn how to use GitHub and create your 1st pull request with using GitHub. and also after 4 successful pull request you will be get free t-shirt from hacktoberfest event. so learn and participate in event.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#what-is-github"&gt;
  &lt;/a&gt;
  What is GitHub:-
&lt;/h3&gt;

&lt;p&gt;GitHub is a web-based interface that uses Git, the open source version control software that lets multiple people make separate changes to web pages at the same time. As Carpenter notes, because it allows for real-time collaboration, GitHub encourages teams to work together to build and edit their site content.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#github-account-and-create-repo-"&gt;
  &lt;/a&gt;
  GitHub Account and create repo :-
&lt;/h3&gt;

&lt;p&gt;1.go to github.com and simple create your account .&lt;br&gt;
2.Create a new repository&lt;br&gt;
3.To create a new repository, select New Repository from the + sign dropdown menu (you can see I've selected it in the upper-right corner in the image above).&lt;br&gt;
4.Enter a name for your repository (e.g., "portfolio") and click Create Repository).&lt;br&gt;
5.Your 1st repo is created. ğŸ˜ŠğŸ‰&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#now-we-are-moved-to-next-step-"&gt;
  &lt;/a&gt;
  Now we are moved to next step :-
&lt;/h4&gt;

&lt;p&gt;1.Download git from browser.&lt;br&gt;
2.&lt;a href="https://git-scm.com/"&gt;https://git-scm.com/&lt;/a&gt; .&lt;br&gt;
3.simple download and install the git software&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#simple-now-open-your-command-prompt-or-powershell"&gt;
  &lt;/a&gt;
  Simple now open your command prompt or PowerShell ğŸ’»
&lt;/h5&gt;

&lt;p&gt;1.Now we are Create folder for your project folder use this command (mkdir Demo).&lt;br&gt;
2.Change your terminal to the Demo directory with the command (cd Demo).&lt;br&gt;
3.Now create your 1st file readme file and save as (readme.md)&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#yeah-now-its-time-to-add-our-file-in-github"&gt;
  &lt;/a&gt;
  yeah ğŸ˜€ Now its time to add our file in GitHub
&lt;/h5&gt;

&lt;p&gt;1.Use command ( git init  )in terminal .&lt;br&gt;
2.and add that file in git like git add (filename) or git add . there are to add multiple file we are use ( git add . ).&lt;br&gt;
3.add your remote URL &lt;br&gt;
4.git remote add origin &lt;a href="https://github.com/"&gt;https://github.com/&lt;/a&gt;/Demo.git&lt;br&gt;
5.then use command for commit the changes ( git commit -m â€œfirst commitâ€&lt;br&gt;
6.After this you can be use git status to check the your files .&lt;br&gt;
if you want to change the branch use this command (git branch -m main)&lt;br&gt;
7.now its time to push your code  or files to GitHub&lt;br&gt;
8.Use git push  -u origin main &lt;/p&gt;

&lt;p&gt;Congratulations! ğŸ‰ğŸ‰ğŸ‰ You have create your 1st requst to git now if you want to learn more comment git at this post or simple check github docs .&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#thank-you"&gt;
  &lt;/a&gt;
  Thank You.
&lt;/h5&gt;

&lt;p&gt;A collabration with Geeky4u Did you find it helpful let me know in comments.&lt;/p&gt;

</description>
      <category>devops</category>
      <category>beginners</category>
      <category>html</category>
      <category>webdev</category>
    </item>
    <item>
      <title>Hacktoberfest 2021 is here!</title>
      <author>Shivam Jha</author>
      <pubDate>Sat, 02 Oct 2021 07:35:31 +0000</pubDate>
      <link>https://dev.to/shivamjjha/hacktoberfest-2021-is-here-4e83</link>
      <guid>https://dev.to/shivamjjha/hacktoberfest-2021-is-here-4e83</guid>
      <description>&lt;h3&gt;
  &lt;a href="#following-are-links-to-get-you-started"&gt;
  &lt;/a&gt;
  Following are links to get you started:
&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://hacktoberfest.digitalocean.com/"&gt;Hacktoberfest Website&lt;/a&gt;&lt;br&gt;
&lt;a href="https://hacktoberfest.digitalocean.com/register"&gt;Register for Hacktoberfest 2021&lt;/a&gt;&lt;br&gt;
&lt;a href="https://hacktoberfest.digitalocean.com/resources/qualitystandards"&gt;Hacktoberfest 2021 - Quality Standards&lt;/a&gt;&lt;br&gt;
&lt;a href="https://hacktoberfest.digitalocean.com/resources#values"&gt;Values&lt;/a&gt;&lt;br&gt;
&lt;a href="https://hacktoberfest.digitalocean.com/resources/participation"&gt;Hacktoberfest 2021 - Participation&lt;/a&gt;&lt;br&gt;
&lt;a href="https://hacktoberfest.digitalocean.com/faq"&gt;FAQs&lt;/a&gt;&lt;br&gt;
&lt;a href="https://dev.to/devteam/hacktoberfest-2021-is-here-4a3l"&gt;A great dev post summing up Hacktoberfest 2021&lt;/a&gt;&lt;/p&gt;

</description>
      <category>hacktoberfest</category>
    </item>
    <item>
      <title>blocked by CORS policy? CORS Proxy is Solution ğŸ˜</title>
      <author>Rajesh Joshi</author>
      <pubDate>Sat, 02 Oct 2021 07:18:27 +0000</pubDate>
      <link>https://dev.to/rajeshj3/blocked-by-cors-policy-cors-proxy-is-solution-5ck8</link>
      <guid>https://dev.to/rajeshj3/blocked-by-cors-policy-cors-proxy-is-solution-5ck8</guid>
      <description>&lt;h2&gt;
  &lt;a href="#what-is-cors"&gt;
  &lt;/a&gt;
  â“ What is CORS?
&lt;/h2&gt;

&lt;p&gt;Cross-Origin Resource Sharing (CORS) is an HTTP-header based mechanism that allows a server to indicate any origins (domain, scheme, or port) other than its own from which a browser should permit loading of resources. CORS also relies on a mechanism by which browsers make a â€œpreflightâ€ request to the server hosting the cross-origin resource, in order to check that the server will permit the actual request. In that preflight, the browser sends headers that indicate the HTTP method and headers that will be used in the actual request.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Uv8vudaC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0kiupwc46knz12xffdvk.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Uv8vudaC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0kiupwc46knz12xffdvk.png" alt="CORS Error Example"&gt;&lt;/a&gt;&lt;/p&gt;




&lt;h3&gt;
  &lt;a href="#what-is-the-solution"&gt;
  &lt;/a&gt;
  ğŸ¤” What is the Solution?
&lt;/h3&gt;

&lt;p&gt;The solution to bypass CORS is to use a &lt;strong&gt;Proxy&lt;/strong&gt;. A Proxy server, that forwards your request &lt;strong&gt;as it is&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;But, problems with a Proxy Server is to manage the server, optimize the server, handle traffic, use of Kubernetes to minimize bills, and what not.&lt;/p&gt;

&lt;p&gt;ğŸ˜­ğŸ˜­ So what is the solution to this?&lt;/p&gt;




&lt;h3&gt;
  &lt;a href="#cors-proxy"&gt;
  &lt;/a&gt;
  âœ¨ CORS Proxy âœ¨
&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://rapidapi.com/joshirajesh448@gmail.com/api/cors-proxy1/"&gt;CORS Proxy&lt;/a&gt; provides &lt;strong&gt;Free Service&lt;/strong&gt; to bypass CORS.&lt;/p&gt;

&lt;p&gt;CORS Proxy API uses backend technologies to complete your request for any third party resource . You are just required to send all request data (ie. URL, params, body, headers, cookies, etc.) to CORS Proxy API End-Point in the body, CORS Proxy will then forward your request in an optimized manner.&lt;/p&gt;




&lt;h3&gt;
  &lt;a href="#sample-code"&gt;
  &lt;/a&gt;
  Sample Code
&lt;/h3&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;axios&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;axios&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="k"&gt;default&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;options&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="na"&gt;method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;POST&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="na"&gt;url&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;https://cors-proxy1.p.rapidapi.com/v1&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="na"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;content-type&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;application/json&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;x-rapidapi-host&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;cors-proxy1.p.rapidapi.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;x-rapidapi-key&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;YOUR-x-rapidapi-key&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;
  &lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="na"&gt;data&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="na"&gt;url&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;https://api.gymslate.ml/auth/login/&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;POST&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="na"&gt;params&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{},&lt;/span&gt;
    &lt;span class="na"&gt;data&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="na"&gt;email&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;user@mail.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="na"&gt;password&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;SecurePassword&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="na"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{},&lt;/span&gt;
    &lt;span class="na"&gt;cookies&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;

&lt;span class="nx"&gt;axios&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;options&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;then&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}).&lt;/span&gt;&lt;span class="k"&gt;catch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;error&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;error&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;






&lt;h3&gt;
  &lt;a href="#free-to-use"&gt;
  &lt;/a&gt;
  &lt;strong&gt;Free&lt;/strong&gt; to use
&lt;/h3&gt;

&lt;p&gt;CORS Proxy offers &lt;strong&gt;FREEMIUM&lt;/strong&gt; pricing model. So Yes, we can start with the &lt;a href="https://rapidapi.com/joshirajesh448@gmail.com/api/cors-proxy1/pricing"&gt;&lt;strong&gt;Free Plan&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Di5zNYVX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/adfdogvx8ofx9rxhaoe2.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Di5zNYVX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/adfdogvx8ofx9rxhaoe2.png" alt="CORS Proxy"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Step 1. Create a Free Account at &lt;a href="https://rapidapi.com/"&gt;Rapid API&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Step 2. Freely Subscribe to &lt;a href="https://rapidapi.com/joshirajesh448@gmail.com/api/cors-proxy1/pricing"&gt;Basic Plan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Step 3: Test API End Points&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--MwxSEK9k--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/m1lz6k6g823hd2e61gsf.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--MwxSEK9k--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/m1lz6k6g823hd2e61gsf.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Step 4: Integrate with your Frontend Project&lt;/p&gt;




&lt;h3&gt;
  &lt;a href="#no-more-cors-errors"&gt;
  &lt;/a&gt;
  ğŸ¥³ No more CORS Errors ğŸ¥³
&lt;/h3&gt;




&lt;p&gt;Cheers&lt;/p&gt;

&lt;p&gt;ğŸ¤“ Happy Coding&lt;/p&gt;

</description>
      <category>javascript</category>
      <category>cors</category>
      <category>webdev</category>
      <category>node</category>
    </item>
    <item>
      <title>Video vs. Interactive and Multi-Media Content for Programming Courses</title>
      <author>GrÃ©gory D'Angelo</author>
      <pubDate>Sat, 02 Oct 2021 06:38:12 +0000</pubDate>
      <link>https://dev.to/alterclass/video-vs-interactive-and-multi-media-content-for-programming-courses-5bie</link>
      <guid>https://dev.to/alterclass/video-vs-interactive-and-multi-media-content-for-programming-courses-5bie</guid>
      <description>&lt;p&gt;At some point in our career, we all have watched coding tutorials on YouTube or followed some coding courses on Udemy to stay up to date on a specific technology or learn completely new skills. Myself, included.&lt;/p&gt;

&lt;p&gt;And as an instructor, creating those video-based and coding-along courses/tutorials are great as it helps to quickly and easily share our knowledge on a topic by screencasting our code on VS Code.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;But here's the catch.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The resources created this way that we share for free on YouTube or through paid courses on Udemy (or elsewhere) are passive learning and do not help our viewers.&lt;/p&gt;

&lt;p&gt;Who wants in 2021 to sit for hours in front of a screen watching someone coding, especially after being forced at home during the COVID-19 pandemic?&lt;/p&gt;

&lt;p&gt;Plus, I'm asking you. Have you ever applied the skills taught in these videos in a real-world project?&lt;/p&gt;

&lt;p&gt;Are you even able to remember what you have seen from those videos a few weeks later?&lt;/p&gt;

&lt;p&gt;Or, in other words, are you really learning something from those video-based courses apart from a few tips here and there?&lt;/p&gt;

&lt;p&gt;Finally, I want you to think about it. Is the coding-along format really efficient to teach a new skill in software development?&lt;/p&gt;

&lt;p&gt;It is what I will explore in this article and provide you with a better alternative based on interactive and multi-media content where your students can learn at their own pace and practice along the way.&lt;/p&gt;

&lt;p&gt;I will cover:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#whats-wrong-with-video-based-and-coding-along-courses"&gt;What's wrong with video-based and coding-along courses?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#why-should-you-use-interactive-and-multi-media-content"&gt;Why should you use interactive and multi-media content?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#getting-started"&gt;Getting started&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;
  &lt;a href="#whats-wrong-with-videobased-and-codingalong-courses"&gt;
  &lt;/a&gt;
  What's wrong with video-based and coding-along courses?
&lt;/h2&gt;

&lt;p&gt;In some way, video-based only courses are a double-edged sword. Let me explain.&lt;/p&gt;

&lt;p&gt;On one side, platforms like YouTube or Udemy have allowed people to share an incredible amount of high-skilled knowledge on the internet, either for free or a few bucks. In addition, creating videos has become very easy and inexpensive as anyone with a smartphone can do it.&lt;/p&gt;

&lt;p&gt;As a consequence, it has allowed more and more people across the globe to access this knowledge and acquire some kind of education through those resources.&lt;/p&gt;

&lt;p&gt;However, on the other side, video-based only courses are by far not the best way to learn any skill as practical as programming or software development in general.&lt;/p&gt;

&lt;p&gt;As I often say, &lt;strong&gt;you don't learn how to drive a car or be a better driver only by watching others&lt;/strong&gt; unless you are an artificial intelligence. Software development is no different.&lt;/p&gt;

&lt;p&gt;Coding requires a significant amount of practice to really acquire the skill and being able to use it in different situations outside of the classroom.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://i.giphy.com/media/J9UXcyVW6OYN2fH0Sr/giphy.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://i.giphy.com/media/J9UXcyVW6OYN2fH0Sr/giphy.gif" alt="Let's practice!"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Indeed, if you just stay passive in front of your screen, watching the instructor building an application with X and Y technologies, then there is a good chance that you won't remember anything. And even if you try to code along by pausing the video several times along the way and reproducing instruction-by-instruction what the instructor is typing, I bet you won't be able to apply what you've "&lt;em&gt;learned&lt;/em&gt;" in another context/project.&lt;/p&gt;

&lt;p&gt;Learning this way is not practical at all, let alone fun.&lt;/p&gt;

&lt;p&gt;In summary, &lt;strong&gt;in video-based only (or coding-along) courses, the skill taught do not stick for long or at all, and worst than that, you rarely can use it elsewhere&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Moreover, for an instructor, producing high-quality video content can be challenging and sometimes requires expensive gear (such as a good microphone, a decent camera if you plan to film yourself, etc...). I don't even mention the time needed to film and edit all those videos. Plus, if you need to update some content of your course because the web framework you are teaching about has released a new version, you'll have to re-record entire videos.&lt;/p&gt;

&lt;p&gt;Nevertheless, videos are an excellent medium as part of a multi-media content course to emphasize or show something specific such as before asking your students to complete an exercise or to give them your solution of a coding assignment.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#why-should-you-use-interactive-and-multimedia-content"&gt;
  &lt;/a&gt;
  Why should you use interactive and multi-media content?
&lt;/h2&gt;

&lt;p&gt;From now on, you should be convinced (I hope so) that videos only is not great to teach and learn technical skills.&lt;/p&gt;

&lt;p&gt;Students need high-quality content which is interactive, practical, and allows them to learn at their own pace by practicing over and over again until they get it.&lt;/p&gt;

&lt;p&gt;In case you are still not convinced about it, check out &lt;a href="https://www.failory.com/interview/css-for-js-developers"&gt;how Josh Comeau made $550k in revenue&lt;/a&gt; when he opened the pre-orders for his CSS for JS Developers online course that combines videos, articles, interactive widgets, and mini-games.&lt;/p&gt;

&lt;p&gt;Impressive, isn't it?&lt;/p&gt;

&lt;p&gt;So, why using several media types and building an interactive online course is so important?&lt;/p&gt;

&lt;p&gt;One of the main reasons is that people are not looking to learn a new skill or stay up to date just for fun. No, people are looking to acquire real employable skills which could help them scale up their careers.&lt;/p&gt;

&lt;p&gt;When creating an online course, you have to think about the value you provide to your students, right from the &lt;a href="https://alterclass.io/blog/how-to-make-money-selling-courses-online-in-2021-as-a-developer#1-choose-the-right-topic"&gt;choice of the course topic&lt;/a&gt; to the &lt;a href="https://alterclass.io/blog/how-to-make-money-selling-courses-online-in-2021-as-a-developer#2-create-your-online-course"&gt;content creation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It is essential you always think about what problem(s) you are solving with your online course for your students and how they could get the most out of it in their career.&lt;/p&gt;

&lt;p&gt;All this to say that you need way more than just passive learning. Indeed, no one will want to recruit someone that claims to know how to create web applications with React JS only after watching videos passively on YouTube or Udemy and reproducing every keystroke from the instructor without thinking by himself.&lt;/p&gt;

&lt;p&gt;You need to make your students think and really get a grasp of what you are teaching. The only way I know is by making your students practice by themself (with some guidance from you, of course), make mistakes, think and try again, and build something meaningful that they would be proud of. &lt;strong&gt;Large and real-world projects&lt;/strong&gt; are a great way to do that.&lt;/p&gt;

&lt;p&gt;Also, they need to learn gradually and be reassured that they completely understand everything from what they are learning. As the instructor, you could do that by providing them with &lt;strong&gt;practical exercises&lt;/strong&gt;, &lt;strong&gt;quizzes&lt;/strong&gt;, and &lt;strong&gt;mini-challenges&lt;/strong&gt; for example.&lt;/p&gt;

&lt;p&gt;So, instead of showing everything to your students through videos only, and giving them no time to think and assess their knowledge, &lt;strong&gt;use several types of media throughout your online course and make your course as interactive as possible&lt;/strong&gt;. Your students will thank you for that as their learning experience will be richer and more fun, and they will feel more engaged.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--ejnmku9X--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://alterclass.io/assets/blog/interactive-multi-media-content.jpeg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ejnmku9X--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://alterclass.io/assets/blog/interactive-multi-media-content.jpeg" alt="Interactive and multi-media content"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#getting-started"&gt;
  &lt;/a&gt;
  Getting started ğŸš€
&lt;/h2&gt;

&lt;p&gt;Alright! Now that you know how important it is to create online courses based on interactive multi-media content, you can start building your own online course.&lt;/p&gt;

&lt;p&gt;The easiest way to get started is to &lt;a href="https://alterclass.io/teaching"&gt;sign up&lt;/a&gt; for a &lt;strong&gt;free&lt;/strong&gt; account on &lt;a href="https://alterclass.io/teaching"&gt;AlterClass&lt;/a&gt; and start creating your online courses right away!&lt;/p&gt;

</description>
    </item>
    <item>
      <title>What is a difference between git pull and git fetch?</title>
      <author>Dhruv Rajkotia</author>
      <pubDate>Sat, 02 Oct 2021 06:18:57 +0000</pubDate>
      <link>https://dev.to/dhruv_rajkotia/what-is-a-difference-between-git-pull-and-git-fetch-4iop</link>
      <guid>https://dev.to/dhruv_rajkotia/what-is-a-difference-between-git-pull-and-git-fetch-4iop</guid>
      <description>&lt;p&gt;As we all know that git commands become mandatory if you are software developer. So here today I wanted to share basic understanding of the git two commands. &lt;strong&gt;Git pull vs fetch.&lt;/strong&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#situation"&gt;
  &lt;/a&gt;
  Situation:
&lt;/h3&gt;

&lt;p&gt;If there were some changes recently made to your remote repository and you want to incorporate them into your local copy. then you have basically a 2 options one is git pull and another one is git fetch. &lt;/p&gt;

&lt;p&gt;So, Now question arise whatâ€™s the difference between Git pull vs fetch.&lt;/p&gt;

&lt;p&gt;Now letâ€™s understand with some diagram so probably you will never forgot the difference :) &lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--NNoAIsvr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/5uwwl60idrpjm4zruse4.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--NNoAIsvr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/5uwwl60idrpjm4zruse4.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As per the above diagram TheÂ &lt;code&gt;git fetch&lt;/code&gt;Â command downloads commits, files, and refs from a remote repository into your local repo but not update your local repo's working state. Fetching is what you do when you want to see what everybody else has been working on.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git pull&lt;/code&gt;Â is the more aggressive alternative;Â it will download the remote content for the active local branch and immediately executeÂ &lt;code&gt;git merge&lt;/code&gt;Â to create a merge commit for the new remote content. If you have pending changes in progress this will cause conflicts and kick-off the merge conflict resolution flow.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#when-we-should-use-git-fetch"&gt;
  &lt;/a&gt;
  When we should use git fetch?
&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;If you only want to see all of the current branches and changes in your remote repository without affecting your current local copy then Git fetch can get you all of the information you need.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#when-we-should-use-git-pull"&gt;
  &lt;/a&gt;
  When we should use git pull?
&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;when you are ready to get latest updates from your remote repository and adding to your local copy. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That's all folks, Hope you got the idea regarding Git pull vs fetch. Please like the post if you loved it and please let me know if you have any question in comments. &lt;/p&gt;

</description>
      <category>git</category>
    </item>
  </channel>
</rss>
