<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>DEV Community</title>
    <author>DEV Community</author>
    <description>A constructive and inclusive social network for software developers. With you every step of your journey.</description>
    <link>https://dev.to</link>
    <language>en</language>
    <item>
      <title>Automagically  REST and GraphQL endpoints  from your Azure SQL database</title>
      <author>Davide Mauri</author>
      <pubDate>Wed, 19 Jan 2022 01:18:54 +0000</pubDate>
      <link>https://dev.to/azure/automagically-rest-and-graphql-endpoints-from-your-azure-sql-database-40j9</link>
      <guid>https://dev.to/azure/automagically-rest-and-graphql-endpoints-from-your-azure-sql-database-40j9</guid>
      <description>&lt;p&gt;I'm pretty sure that at some point of your developer career you have wished - dreamed! - to have &lt;strong&gt;something that could turn your database tables exposed as a REST or GraphQL endpoint, automatically&lt;/strong&gt;, just by expressing that intention (maybe via a configuration file or some other conventions).&lt;/p&gt;

&lt;p&gt;Such a thing could make your life so much easier and your work more efficient for certain projects.&lt;/p&gt;

&lt;p&gt;Well...dream no more, &lt;em&gt;now there is a solution&lt;/em&gt; for that and it is free and open source!&lt;/p&gt;

&lt;p&gt;And yes, for solution I really mean creating a GraphQL and REST endpoint starting from a database (maybe even from an existing table) without the need to write &lt;em&gt;any&lt;/em&gt; code at all. &lt;/p&gt;

&lt;p&gt;Curious? Well, I'm sure. So, if you want to go head down to the code and the details, you can just head to this GitHub repo: &lt;/p&gt;


&lt;div class="ltag-github-readme-tag"&gt;
  &lt;div class="readme-overview"&gt;
    &lt;h2&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--566lAguM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/github-logo-5a155e1f9a670af7944dd5e12375bc76ed542ea80224905ecaf878b9157cdefc.svg" alt="GitHub logo"&gt;
      &lt;a href="https://github.com/Azure-Samples"&gt;
        Azure-Samples
      &lt;/a&gt; / &lt;a href="https://github.com/Azure-Samples/azure-sql-db-rest-graphql-directus"&gt;
        azure-sql-db-rest-graphql-directus
      &lt;/a&gt;
    &lt;/h2&gt;
    &lt;h3&gt;
      A full end-to-end demo using Vue, Directus, REST, GraphQL and Azure SQL database to create a modern Todo list solution
    &lt;/h3&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;where you can create a full-stack / Jamstack end-to-end solution, to store a To-Do list in an Azure SQL database, and present it via Vue.JS, communicating entirely via REST or JSON. &lt;/p&gt;

&lt;p&gt;The sample implementation uses:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Azure Web App: to run the Directus container&lt;/li&gt;
&lt;li&gt;Vue.Js as front-end client&lt;/li&gt;
&lt;li&gt;Directus to provide GraphQL and REST endpoints automatically from the Azure SQL database&lt;/li&gt;
&lt;li&gt;Azure SQL as database to store ToDo data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="https://directus.io/"&gt;Directus&lt;/a&gt; is a Node application you can run in Azure using, for example, a container. Once it is running, you just have to configure which tables you want to expose via REST and GraphQL, configure the permission level (I'm quite sure you don't want to make all your table publicly available) and...nothing else, you're done. Of course, you can do much more, but if you don't need any additional complexity, this is really all you have to do.&lt;/p&gt;

&lt;p&gt;You can go from a completely no-code/low-code approach to a more developer oriented one (as I did, for example, in the deployment script, where I also create sample To-Do items via the REST endpoint), so depending on where you are in our career or position, you can decide what is best for you. As a developer I'm just glad that I don't have to write any plubming code anymore (unless I really need to, in that case I may want to use &lt;a href="https://dev.to/azure/graphql-rest-with-prisma-and-azure-sql-love-at-first-sight-12ni"&gt;Prisma&lt;/a&gt; or &lt;a href="https://dev.to/azure/10k-rps-rest-api-with-azure-sql-dapper-and-json-3me2"&gt;Dapper&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Aside from the aforementioned GitHub post, you can also learn more about Azure SQL and Directus via this nice blog post that we just published:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://devblogs.microsoft.com/azure-sql/automatic-graphql-and-rest-endpoint-for-azure-sql-with-directus/"&gt;https://devblogs.microsoft.com/azure-sql/automatic-graphql-and-rest-endpoint-for-azure-sql-with-directus/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Enjoy! (I surely enjoyed it A LOT!)&lt;/p&gt;

</description>
      <category>javascript</category>
      <category>webdev</category>
      <category>beginners</category>
      <category>azure</category>
    </item>
    <item>
      <title>Caching In Node.js Applications</title>
      <author>Honeybadger Staff</author>
      <pubDate>Tue, 18 Jan 2022 23:52:20 +0000</pubDate>
      <link>https://dev.to/honeybadger/caching-in-nodejs-applications-b33</link>
      <guid>https://dev.to/honeybadger/caching-in-nodejs-applications-b33</guid>
      <description>&lt;p&gt;&lt;em&gt;This article was originally written by &lt;a href="https://www.honeybadger.io/blog/nodejs-caching/#authorDetails"&gt;Ayooluwa Isaiah&lt;/a&gt; on the &lt;a href="https://www.honeybadger.io/blog/nodejs-caching/"&gt;Honeybadger Developer Blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Caching is the process of storing data in a high-speed storage layer so that future requests for such data can be fulfilled much faster than is possible through accessing its primary storage location. An example of caching that you may be familiar with is the browser cache, which stores frequently accessed website resources locally so that it does not have to retrieve them over the network each time they are needed. By maintaining a cache of objects on the user's hardware, retrieval of the cached data is almost instantaneous, leading to increased speed and user satisfaction.&lt;/p&gt;

&lt;p&gt;In the context of server-side applications, caching aims to improve the application's response times by reusing previously retrieved or computed data. For example, instead of repeating network requests for data that do not change often or at all (such as a list of banks in your country), you could store the data in the cache after the initial request and retrieve it from there in subsequent requests. This makes the subsequent requests for that data an order of magnitude faster leading to improved application performance, decreased costs, and faster transactions.&lt;/p&gt;

&lt;p&gt;This article aims to provide an overview of caching, caching strategies, and the solutions currently available on the market. After reading this post, you should have a better idea of when to cache, what to cache, and the appropriate techniques to use in your Node.js applications, depending on the use–case.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#benefits-of-caching"&gt;
  &lt;/a&gt;
  Benefits of caching
&lt;/h2&gt;

&lt;p&gt;The primary benefit of caching is that it improves the speed of data retrieval by reducing the need to recompute a result or access the underlying processing or storage layer. Faster data access significantly boosts application responsiveness and performance without adding new hardware resources. Other benefits include the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Reduced server load&lt;/strong&gt;: Certain requests can require considerable processing time on the server. If the result of the query is already present in the cache, this processing can be skipped entirely so that the response time is faster, which frees up server resources to do other work.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Increased reliability&lt;/strong&gt;: Higher latencies when retrieving data is the usual effect of spikes in application usage causing slower performance across the board. Redirecting a significant portion of the load to the cache layer helps performance become much more predictable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Decreased network costs&lt;/strong&gt;: Placing frequently accessed objects in the cache reduces the amount of network activity that has to be performed beyond the cache. This results in far less data being transferred to and from the content origin, leading to lower transfer costs, less congestion in the queues at network switches, fewer dropped packets, etc.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Improved database performance&lt;/strong&gt;: A common finding when investigating application performance is that a significant portion of the overall response time is spent in the database layer. Even if the queries are efficient, the cost of processing each query (especially for frequently accessed objects) can quickly add up to higher latencies. A great way to mitigate this issue is to bypass the query processing altogether and use a precomputed result from the cache.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Increased availability of content&lt;/strong&gt;: Caching can be used as a way to preserve the availability of certain data, even when the origin data storage is down temporarily.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;
  &lt;a href="#when-should-you-cache"&gt;
  &lt;/a&gt;
  When should you cache?
&lt;/h2&gt;

&lt;p&gt;Caching is a great tool for improving performance, as evidenced by the benefits discussed in the previous section. So, when should you consider adding a cache layer to your application architecture? There are several factors to consider.&lt;/p&gt;

&lt;p&gt;Most applications have data hot spots that are queried regularly but seldom updated. For example, if you are running an online forum, there may be a steady stream of new posts, but old posts will remain the same and many old threads will stay unchanged for a long time. In this scenario, the application can receive hundreds or thousands of requests for the same unchanged data, which makes it an ideal candidate for caching. Generally speaking, data that are accessed frequently and do not change often or at all should be stored in a cache.&lt;/p&gt;

&lt;p&gt;Another consideration when deciding what to cache is whether the application needs to perform complex queries or calculations before returning or rendering some data. For high-volume websites, even the simple act of rendering some HTML output after retrieving and computing the required data can consume a significant amount of resources and increase latency. If the returned output, once computed, can be reused across multiple queries and operations, it is usually a good idea to store it in a cache.&lt;/p&gt;

&lt;p&gt;The rate at which a piece of data changes and how long outdated data can be tolerated also contribute to how cachable it is. If the data changes frequently such that it cannot be reused for subsequent queries, then it is likely not worth the overhead required to place it in a cache. Other types of optimizations should be considered in this case.&lt;/p&gt;

&lt;p&gt;Caching can be a great way to improve application performance, but it's not necessarily the right thing to do in every scenario. As with all performance optimization techniques, it's important to measure first before making substantial changes to avoid wasting time optimizing the wrong thing.&lt;/p&gt;

&lt;p&gt;The first step is to observe the state and performance of the system in question at a given request rate. If the system cannot keep up with the anticipated load, or if it throttles or suffers high latency, it might be a good idea to cache the data that the system is working with if such a cache would yield a high hit-ratio across several requests.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#caching-strategies-to-consider"&gt;
  &lt;/a&gt;
  Caching strategies to consider
&lt;/h2&gt;

&lt;p&gt;A caching strategy is a pattern employed to manage cached information, including how the cache is populated and maintained. There are several strategies to explore, and choosing the right one is crucial to getting the greatest performance benefits. The strategy employed for a gaming service that aggregates and returns a real-time leaderboard will differ considerably from a service that provides other types of data, such as COVID-19 statistics, which are updated a few times a day.&lt;/p&gt;

&lt;p&gt;Before you choose a caching solution, there are three three main things consider:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The type of data being cached.&lt;/li&gt;
&lt;li&gt;How the data is read and written (the data access strategy).&lt;/li&gt;
&lt;li&gt;How the cache evicts old or outdated data (the eviction policy).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the next section, we’ll discuss the various data access strategies that can be employed depending on the type of data being cached.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#data-access-patterns"&gt;
  &lt;/a&gt;
  Data access patterns
&lt;/h3&gt;

&lt;p&gt;The data access pattern employed determines the relationship between the data source and the caching layer. Therefore, it's important to get this part right, as it can make a significant difference in the effectiveness of your caching. In the rest of this section, we'll discuss common data access patterns, along with their advantages and disadvantages.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Cache-aside pattern&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In the cache-aside pattern, data is loaded to the cache only when necessary. Whenever a client requests data, the application checks the cache layer first to see if the data is present. If the data is found in the cache, it is retrieved and returned to the client. This is known as a &lt;em&gt;cache hit&lt;/em&gt;. If the data is not present in the cache (a &lt;em&gt;cache miss&lt;/em&gt;), the application will query the database to read the requested data and return it to the client. Afterwards, the data is stored in cache so that subsequent requests for the same data can be resolved more quickly.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--ftW5c4ns--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/cache-aside.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ftW5c4ns--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/cache-aside.png" alt="The cache-aside pattern" width="880" height="455"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The following is a pseudocode example of cache-aside logic.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;makeAQuery&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="c1"&gt;// Try to get the entity from the cache.&lt;/span&gt;
  &lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="c1"&gt;// If there's a cache miss, get the data from the original store and cache it.&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;data&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;// then store the data to cache with an appropriate expiry time&lt;/span&gt;
    &lt;span class="c1"&gt;// to prevent staleness&lt;/span&gt;
    &lt;span class="nx"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;defaultTTL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="c1"&gt;// return the data to the application&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;// application code that gets the data&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;makeAQuery&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;12345&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Only the requested data is cached. This means that the cache is not filled up with data that never get used.&lt;/li&gt;
&lt;li&gt;It works best for read-heavy workflows in which data is written once and read several times before being updated again (if at all).&lt;/li&gt;
&lt;li&gt;It is resilient to cache failures. If the cache layer is not available, the system will fall back to the data store. Bear in mind that an extended period of cache failure can lead to increased latency.&lt;/li&gt;
&lt;li&gt;The data model in the cache does not have to map to the one in the database. For example, the results of multiple database queries can be stored under the same id in the cache.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A cache miss may increase latency because three operations are performed:

&lt;ol&gt;
&lt;li&gt;Request data from the cache.&lt;/li&gt;
&lt;li&gt;Read data from data store.&lt;/li&gt;
&lt;li&gt;Write the data to the cache.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;It does not guarantee consistency between the data store and the cache. If data is updated in the database, it may not be reflected in the cache immediately, which leads to stale data being served up by the application. To prevent this from happening, the cache-aside pattern is often combined with the write-through strategy (discussed below), in which the data is updated in the database and the cache simultaneously to prevent the cached data from going stale.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2. Read-through pattern&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In read-through caching, data is always read from the cache. When an application asks the cache for an entry, and it is not already in the cache, it is loaded from the underlying data store and added to the cache for future use. Unlike the cache-aside pattern, the application is relieved of the responsibility of reading and writing directly to the database.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Td-ME62E--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/read-through.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Td-ME62E--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/read-through.png" alt="Diagram of the read-through pattern" width="880" height="301"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In most cases, you need to implement a read-through handler provided by the cache, which allows it to read data directly from the database in the event of a cache miss. Here's some pseudocode that demonstrates how it may be done:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// register the function that will be executed on cache misses.&lt;/span&gt;
&lt;span class="nx"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;onmiss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;// return data from the database&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;

&lt;span class="c1"&gt;// Actual data from the cache or onmiss handler&lt;/span&gt;
&lt;span class="c1"&gt;// A cache entry is created automatically on cache misses&lt;/span&gt;
&lt;span class="c1"&gt;// through the key and time-to-live values after the data&lt;/span&gt;
&lt;span class="c1"&gt;// is retrieved from the database&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;readThrough&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;ttl&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Like cache-aside, it works well for read-heavy workloads where the same data is requested many times.&lt;/li&gt;
&lt;li&gt;Only requested data is cached, supporting the efficient use of resources.&lt;/li&gt;
&lt;li&gt;This model allows the cache to auto-refresh an object from the database when the data is updated or when the cache entry expires.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The data model in the cache cannot be different from the data model in the database.&lt;/li&gt;
&lt;li&gt;It is not resilient to cache failures, unlike cache-aside.&lt;/li&gt;
&lt;li&gt;Latency may be increased when the requested data is not present in the cache.&lt;/li&gt;
&lt;li&gt;It's possible for the cached data to become stale, but this problem can be solved by using one of the write strategies considered below.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3. Write-through pattern&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;When the write-through strategy is employed, the cache layer is treated as the main data store for the application. This means that new or updated data is added or updated directly to the cache while the task of persisting the data to the underlying data store is delegated to the cache layer. Both write operations must be completed in a single transaction to prevent the cached data from going out of sync with the database.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--_vhrNSXj--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/write-through-pattern.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--_vhrNSXj--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/write-through-pattern.png" alt="The write through pattern" width="880" height="312"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The following is a pseudocode example of write-through logic.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;updateCustomer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;customerId&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;customerData&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="c1"&gt;// the callback function will be executed after updating the&lt;/span&gt;
  &lt;span class="c1"&gt;// record in the cache&lt;/span&gt;
  &lt;span class="nx"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;writeThrough&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;customerId&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;customerData&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;defaultTTL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;// save updated data to db&lt;/span&gt;
  &lt;span class="p"&gt;});&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;// A variant is of this pattern is when updated in the db first&lt;/span&gt;
&lt;span class="c1"&gt;// and immediately updated in the cache&lt;/span&gt;
&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;updateCustomer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;customerId&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;customerData&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="c1"&gt;// update the record in the database first&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;record&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;findAndUpdate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;customerId&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;customerData&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;// then set or update the record in the cache&lt;/span&gt;
  &lt;span class="nx"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;customerId&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;record&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;defaultTTL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data in the cache are never stale by virtue of it being synchronized with the database after each write operation.&lt;/li&gt;
&lt;li&gt;It is suitable for systems that cannot tolerate staleness in the cache.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It adds latency when writing data because more work is being done by writing to the data store first and then to the cache.&lt;/li&gt;
&lt;li&gt;The write operation will fail if the cache layer becomes unavailable.&lt;/li&gt;
&lt;li&gt;The cache may accumulate data that are never read, which wastes resources. This can be mitigated by combining this pattern with the cache-aside pattern or by adding a time-to-live (TTL) policy.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;4. Write-behind pattern&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In the write-behind pattern (also known as write-back), data is inserted or modified directly in the cache and later asynchronously written to the data source after a configured delay, which could be as brief as a few seconds or as long as several days. The main implication of adopting this caching pattern is that database updates are applied sometime after the cache transaction is completed, which means you have to guarantee that the database writes will be completed successfully or provide a way to roll back the updates.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--cFb97Mlf--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/write-behind.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--cFb97Mlf--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/write-behind.png" alt="The write-behind pattern" width="880" height="259"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Improved write performance compared to write-through since the application does not have to wait for the data to be written to the underlying data store.&lt;/li&gt;
&lt;li&gt;The database load is reduced since multiple writes are often batched into a single database transaction, which can also reduce costs if the number of requests is a factor in the pricing of the database provider.&lt;/li&gt;
&lt;li&gt;The application is somewhat protected against temporary database failures since failed writes can be re-queued.&lt;/li&gt;
&lt;li&gt;It is best suited for write-heavy workloads.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If there's a cache failure, the data may be lost permanently. Therefore, it may not be suitable for sensitive data.&lt;/li&gt;
&lt;li&gt;Operations performed directly on the database may utilize stale data since the cache and data store cannot be guaranteed to be consistent at any given point in time.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;5. Refresh-ahead pattern&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In the refresh-ahead pattern, frequently accessed cached data is refreshed before they expire. This happens asynchronously so that the application does not feel the effect of a slow read when an object is being retrieved from the data store in the event of its expiry.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--FnLOkcoO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/refresh-ahead.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--FnLOkcoO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/refresh-ahead.png" alt="The refresh-ahead pattern" width="880" height="248"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ideal when reading data from the data store is costly.&lt;/li&gt;
&lt;li&gt;Helps to keep frequently accessed cache entries always in sync.&lt;/li&gt;
&lt;li&gt;Ideal for latency sensitive workloads, such as live sports scoring sites and stock market financial dashboards.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The cache needs to accurately predict which cache items are likely to be needed in the future because inaccurate predictions can incur unnecessary database reads.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#cache-eviction-policy"&gt;
  &lt;/a&gt;
  Cache Eviction Policy
&lt;/h3&gt;

&lt;p&gt;The size of a cache is usually limited compared to the size of the database, so it is necessary to store only the items that are needed and remove redundant entries. A cache eviction policy ensures that the cache does not exceed its maximum limit by removing older objects from the cache as new ones are added. There are several eviction algorithms to choose from, and the best one will depend upon the needs of your application.&lt;/p&gt;

&lt;p&gt;When choosing an eviction policy, keep in mind that it isn't always appropriate to apply a global policy to every item in the cache. If a cached object is very expensive to retrieve from the data store, it may be beneficial to retain this item in the cache, regardless of whether is meets the requirements for eviction. A combination of eviction policies may also be required to achieve the optimal solution for your use case. In this section, we'll take a look at some of the most popular algorithms used in production environments.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Least Recently Used (LRU)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A cache that implements the LRU policy organizes its items in the order of use. Therefore, the most recently used items will be at the top of the cache, while the least recently used ones will be at the bottom. This makes it easy to identify which items should be evicted when it’s time to clean up the cache.&lt;/p&gt;

&lt;p&gt;Every time you access an entry, the LRU algorithm will update the timestamp on the object and move it to the top of the cache. When it's time to evict some items from the cache, it will analyze the state of the cache and remove items at the bottom of the list.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Least Frequently Used (LFU)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The least frequently used algorithm evicts items from the cache based on how frequently they are accessed. The analysis is performed by incrementing a counter on a cached object each time it is accessed so that it can be compared to other objects when it’s time to evict items from the cache.&lt;/p&gt;

&lt;p&gt;LFU shines in cases where the access patterns of the cached objects do not change often. For example, assets are cached on a CDN based on usage patterns so that the most frequently used objects are never evicted. It also helps to evict items that see a spike in requests at a certain period but whose access frequency drops drastically thereafter.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Most Recently Used (MRU)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The Most Recently Used eviction policy is essentially the reverse of the LRU algorithm because it also analyzes the cache items based on the recency of their last access. The difference is that it discards the most recently used objects from the cache instead of the least recently used ones.&lt;/p&gt;

&lt;p&gt;A good use case for MRU is when it is unlikely that a recently accessed object will be used again soon. An example could be removing booked flight seats from the cache immediately after booking, as they are no longer relevant for a subsequent booking application.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. First In, First Out (FIFO)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A cache that implements FIFO evicts items in the order they were added, without any regard for how often or how many times they were accessed.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#cache-expiration"&gt;
  &lt;/a&gt;
  Cache expiration
&lt;/h3&gt;

&lt;p&gt;The expiration policy employed by a cache is another factor that helps determine how long a cached item is retained. The expiration policy is usually assigned to the object when it is added to the cache and is often customized for the type of object being cached. A common strategy involves assigning an absolute time of expiration to each object when it is added to the cache. Once that time elapses, the item is expired and removed from the cache accordingly. This expiration time is chosen based on client requirements, such as how quickly the data change and how tolerant the system is to stale data.&lt;/p&gt;

&lt;p&gt;A sliding expiration policy is another common way to invalidate cached objects. This policy favors the retention items frequently used by the application by extending their expiration time by a specified interval each time they are accessed. For example, an item whose sliding expiration time is 15 minutes will not be removed from the cache as long as it is accessed at least once every 15 minutes.&lt;/p&gt;

&lt;p&gt;You need to be deliberate when choosing a TTL value for cache entries. After the initial implementation of the cache, it is important to monitor the effectiveness of the chosen values so that they may be re-evaluated if necessary. Note that most caching frameworks may not removed expired items immediately for performance reasons. They normally use a scavenging algorithm, which is typically invoked when referencing the cache, looks for expired entries, and flushes them. This prevents having to constantly track expiration events to determine when items should be removed from the cache.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#caching-solutions"&gt;
  &lt;/a&gt;
  Caching solutions
&lt;/h2&gt;

&lt;p&gt;There are multiple ways to implement caching in a web application. Often, once the need to cache is identified, an in-process cache is employed for the task since it is conceptually straightforward, relatively simple to implement, and can yield significant performance improvements with minimal effort. The major downside of in-process caches is that cached objects are limited to the current process alone. If employed in a distributed system with several instances that are load balanced, you'd end up with as many caches as application instances, leading to a cache coherence problem since requests from a client may use newer or older data depending on which server was used to process it. This problem does not apply if you're only caching immutable objects.&lt;/p&gt;

&lt;p&gt;Another shortcoming of in-process caches is that they utilize the same resources and memory space as the application itself. This can cause out-of-memory failures if the upper limits of the cache are not carefully considered while setting it up. In-process caches are also flushed whenever the application is restarted, which causes the downstream dependency to receive more load while the cache is being repopulated. This is an important consideration if a continuous deployment strategy is utilized in your application.&lt;/p&gt;

&lt;p&gt;Many of the issues with in-process caches can be solved by employing a distributed caching solution that offers a single view into the cache, even if it is deployed on a cluster of multiple nodes. This means that cached objects are written to and read from the same place, regardless of the number of servers employed, reducing the occurrence of cache coherence issues. A distributed cache also remains populated during deployments since it is independent of the application itself and uses its own storage space so that you are not limited to the available server memory.&lt;/p&gt;

&lt;p&gt;With that being said, the use of a distributed cache presents its own challenges. It increases system complexity by adding a new dependency that needs to be monitored and scaled appropriately, and it is slower than an in-process cache due to network latency and object serialization. A distributed cache may also be unavailable from time to time (for example, due to maintenance and upgrades), leading to notable performance degradations, especially during periods of prolonged outages. This issue can be mitigated by falling back to an in-process cache if the distributed cache is unavailable.&lt;/p&gt;

&lt;p&gt;In-process caching may be implemented in a Node.js application through libraries, such as &lt;a href="https://github.com/node-cache/node-cache"&gt;node-cache&lt;/a&gt;, &lt;a href="https://github.com/ptarjan/node-cache"&gt;memory-cache&lt;/a&gt;, &lt;a href="https://github.com/kwhitley/apicache"&gt;api-cache&lt;/a&gt;, and others. There is a wide variety of distributed caching solutions, but the most popular ones are &lt;a href="https://redis.io/"&gt;Redis&lt;/a&gt; and &lt;a href="https://memcached.org/"&gt;Memcached&lt;/a&gt;. They are both in-memory key-value stores and optimal for read-heavy workloads or compute-intensive workloads due to their use of memory rather than the slower on-disk storage mechanisms found in traditional database systems.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#inprocess-caching-with-nodecache"&gt;
  &lt;/a&gt;
  In-process Caching with Node-cache
&lt;/h3&gt;

&lt;p&gt;Below is an example that demonstrates how effective in-process caching can be performed without requiring a convoluted setup process. This simple NodeJS application utilizes &lt;code&gt;node-cache&lt;/code&gt; and the cache-aside pattern discussed earlier in this post to speed up subsequent requests for a list of posts from an external API.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;express&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;express&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;fetch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;node-fetch&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;NodeCache&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;node-cache&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;// stdTTL is the default time-to-live for each cache entry&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;myCache&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nx"&gt;NodeCache&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt; &lt;span class="na"&gt;stdTTL&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;600&lt;/span&gt; &lt;span class="p"&gt;});&lt;/span&gt;

&lt;span class="c1"&gt;// retrieve some data from an API&lt;/span&gt;
&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;getPosts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="nx"&gt;fetch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;`https://jsonplaceholder.typicode.com/posts`&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ok&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;throw&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;statusText&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;json&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;express&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="nx"&gt;app&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;/posts&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="c1"&gt;// try to get the posts from the cache&lt;/span&gt;
    &lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nx"&gt;posts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;myCache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;allPosts&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

    &lt;span class="c1"&gt;// if posts does not exist in the cache, retrieve it from the&lt;/span&gt;
    &lt;span class="c1"&gt;// original source and store it in the cache&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;posts&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="nx"&gt;posts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="nx"&gt;getPosts&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
      &lt;span class="c1"&gt;// time-to-live is set to 300 seconds. After this period&lt;/span&gt;
      &lt;span class="c1"&gt;// the entry for `allPosts` will be removed from the cache&lt;/span&gt;
      &lt;span class="c1"&gt;// and the next request will hit the API again&lt;/span&gt;
      &lt;span class="nx"&gt;myCache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;allPosts&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;posts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;status&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;send&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;posts&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sendStatus&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;});&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;port&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3000&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nx"&gt;app&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;port&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;`Server listening on http://localhost:&lt;/span&gt;&lt;span class="p"&gt;${&lt;/span&gt;&lt;span class="nx"&gt;port&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;`&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;When the first request is made to the &lt;code&gt;/posts&lt;/code&gt; route, the cache is empty, so we have to reach out to an external API to retrieve the necessary data. When I tested the response time for the initial request, it took about 1.2 seconds to receive a response.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--9NzoMuHz--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/initial-request-postman.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--9NzoMuHz--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/initial-request-postman.png" alt="Initial request took 1.2 seconds" width="880" height="478"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After data is retrieved from the API, it is stored in the cache, which causes subsequent requests to take significantly less time to be resolved. In my tests, I consistently got about 20-25 ms response times on subsequent requests, which represents approximately 6,000% performance improvement over making a network request for the data.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--3JxQD1ix--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/subsequent-request-postman.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--3JxQD1ix--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/subsequent-request-postman.png" alt="Subsequent requests took 20-25 ms" width="880" height="478"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#caching-with-redis"&gt;
  &lt;/a&gt;
  Caching with Redis
&lt;/h3&gt;

&lt;p&gt;Redis is pretty much the go-to distributed caching solution for not only Node.js but also other languages. This example showcases how a cache layer may be added to a Node.js application using Redis. Similar to the previous example using &lt;code&gt;node-cache&lt;/code&gt;, the data to be cached will be retrieved from an API.&lt;/p&gt;

&lt;p&gt;Ensure that you have Redis installed before trying out the sample code below. You may follow the &lt;a href="https://redis.io/topics/quickstart"&gt;official quickstart guide&lt;/a&gt; to learn how to get it up and running. Furthermore, make sure to install the necessary dependencies before running the program. This example utilizes the &lt;a href="https://github.com/NodeRedis/node-redis"&gt;node-redis&lt;/a&gt; library.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;express&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;express&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;fetch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;node-fetch&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;redis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;redis&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="nx"&gt;promisify&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;util&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;redisClient&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;redis&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;createClient&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;redisGetAsync&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;promisify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;redisClient&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;redisClient&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;getCovid19Stats&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="nx"&gt;fetch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;`https://disease.sh/v3/covid-19/all`&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ok&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;throw&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;statusText&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;json&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;express&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="nx"&gt;app&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;/covid&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;req&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nx"&gt;stats&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="c1"&gt;// try to get the data from the cache&lt;/span&gt;
    &lt;span class="nx"&gt;stats&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="nx"&gt;redisGetAsync&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;covidStats&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="c1"&gt;// if data is in cache, send data to client&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;stats&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;status&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;send&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;JSON&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;stats&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="k"&gt;try&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="c1"&gt;// otherwise, fetch data from API&lt;/span&gt;
    &lt;span class="nx"&gt;stats&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="nx"&gt;getCovid19Stats&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;

    &lt;span class="c1"&gt;// and store it in Redis. 3600 is the time to live in seconds&lt;/span&gt;
    &lt;span class="nx"&gt;redisClient&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;setex&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;covidStats&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3600&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;JSON&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;stringify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;stats&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
    &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;status&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;send&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;stats&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;err&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="nx"&gt;res&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sendStatus&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;});&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;port&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3000&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nx"&gt;app&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;port&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;`Example app listening at http://localhost:&lt;/span&gt;&lt;span class="p"&gt;${&lt;/span&gt;&lt;span class="nx"&gt;port&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;`&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;In the example above, global COVID-19 statistics are retrieved from an API and returned to the client via the &lt;code&gt;/covid&lt;/code&gt; route. These statistics are cached in Redis for 1 hour (3,600 seconds) to ensure that network requests are kept to a minimum. Redis stores everything as a string, so you have to convert objects to a string with &lt;code&gt;JSON.stringify()&lt;/code&gt; when storing it in the cache and then back to an object with &lt;code&gt;JSON.parse()&lt;/code&gt; after retrieving it from the cache, as shown above.&lt;/p&gt;

&lt;p&gt;Notice how the &lt;code&gt;setex&lt;/code&gt; method is used to store data in the cache instead of the regular &lt;code&gt;set&lt;/code&gt; method. It's preferred here because it allows us to set an expiration time for the cached object. When the set amount of time elapses, Redis will automatically get rid of the object from the cache so that it may be refreshed by calling the API again.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Jpb9OvxJ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/redis-test.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Jpb9OvxJ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.honeybadger.io/images/blog/posts/nodejs-caching/redis-test.png" alt="Testing caching performance with Curl" width="880" height="398"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#other-considerations"&gt;
  &lt;/a&gt;
  Other considerations
&lt;/h2&gt;

&lt;p&gt;Here are some general best practices to consider before implementing a cache in your application:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ensure that the data is cachable and will yield a hit rate high enough to justify the additional resources used to cache it.&lt;/li&gt;
&lt;li&gt;Monitor the metrics of your caching infrastructure (such as hit rates and resource consumption) to ensure that it is appropriately tuned. Use the insights gained to inform subsequent decisions regarding cache size, expiration, and eviction policies.&lt;/li&gt;
&lt;li&gt;Ensure that your system is resilient to cache failure. Deal with scenarios like cache unavailability, cache put/get failures, and downstream errors directly in your code.&lt;/li&gt;
&lt;li&gt;Mitigate security risks by utilizing encryption techniques if sensitive data is retained in the cache.&lt;/li&gt;
&lt;li&gt;Ensure that your application is resilient to changes in the storage format used for cached data. New versions of your app should be able to read the data that a previous version wrote to the cache.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;
  &lt;a href="#conclusion"&gt;
  &lt;/a&gt;
  Conclusion
&lt;/h2&gt;

&lt;p&gt;Caching is a complex topic that should not be treated lightly. When implemented correctly, you will reap huge rewards, but it can easily be a source of grief if you adopt the wrong solution. I hope this article has helped steer you in the right direction regarding setting up, managing, and administering your application cache.&lt;/p&gt;

&lt;p&gt;Thanks for reading, and happy coding!&lt;/p&gt;

</description>
      <category>node</category>
      <category>javascript</category>
    </item>
    <item>
      <title>Angular 13 + NestJs + NX</title>
      <author>wlucha</author>
      <pubDate>Tue, 18 Jan 2022 23:24:10 +0000</pubDate>
      <link>https://dev.to/wlucha/angular-13-nestjs-nx-3113</link>
      <guid>https://dev.to/wlucha/angular-13-nestjs-nx-3113</guid>
      <description>&lt;p&gt;This is an Angular 13 Starter project with Ngx-admin, NestJs, Nx Workspace, Jest, Cypress, ESLint &amp;amp; Prettier&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Project: &lt;a href="https://github.com/wlucha/angular-nest-nx"&gt;https://github.com/wlucha/angular-nest-nx&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#features"&gt;
  &lt;/a&gt;
  Features
&lt;/h2&gt;

&lt;p&gt;✅ &lt;a href="https://angular.io/"&gt;Angular 13&lt;/a&gt;&lt;br&gt;&lt;br&gt;
✅ &lt;a href="https://akveo.github.io/ngx-admin/"&gt;Ngx-admin&lt;/a&gt;&lt;br&gt;&lt;br&gt;
✅ &lt;a href="https://nestjs.com/"&gt;NestJS 8&lt;/a&gt;&lt;br&gt;&lt;br&gt;
✅ Next generation build system with &lt;a href="https://nx.dev/"&gt;Nx&lt;/a&gt;&lt;br&gt;&lt;br&gt;
✅ Unit Testing with &lt;a href="https://jestjs.io/"&gt;Jest&lt;/a&gt;&lt;br&gt;&lt;br&gt;
✅ End-to-End Testing with &lt;a href="https://www.cypress.io/"&gt;Cypress&lt;/a&gt;&lt;br&gt;&lt;br&gt;
✅ &lt;a href="https://eslint.org/"&gt;ESLint&lt;/a&gt;&lt;br&gt;&lt;br&gt;
✅ &lt;a href="https://prettier.io/"&gt;Prettier&lt;/a&gt;  &lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#frontend-app"&gt;
  &lt;/a&gt;
  Frontend App
&lt;/h2&gt;

&lt;p&gt;The Angular 13 frontend app is based on the &lt;a href="https://github.com/akveo/ngx-admin"&gt;ngx-admin&lt;/a&gt; starter kit.  &lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--eQ-ToEpb--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://user-images.githubusercontent.com/7531596/148551080-de61fdb5-ffa4-496e-a26b-4bbf9dd35e9e.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--eQ-ToEpb--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://user-images.githubusercontent.com/7531596/148551080-de61fdb5-ffa4-496e-a26b-4bbf9dd35e9e.png" alt="image" width="880" height="460"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#install-development"&gt;
  &lt;/a&gt;
  Install / Development
&lt;/h2&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="c"&gt;# Clone the project&lt;/span&gt;
&lt;span class="nv"&gt;$ &lt;/span&gt;git clone https://github.com/wlucha/angular-nest-nx
&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;cd &lt;/span&gt;angular-starter

&lt;span class="c"&gt;# Install dependencies&lt;/span&gt;
&lt;span class="nv"&gt;$ &lt;/span&gt;npm &lt;span class="nb"&gt;install&lt;/span&gt;

&lt;span class="c"&gt;# Start frontend server&lt;/span&gt;
&lt;span class="nv"&gt;$ &lt;/span&gt;npm run start

&lt;span class="c"&gt;# Start backend server&lt;/span&gt;
&lt;span class="nv"&gt;$ &lt;/span&gt;npm run api

&lt;span class="c"&gt;# Open in browser: http://localhost:4200&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h2&gt;
  &lt;a href="#commands"&gt;
  &lt;/a&gt;
  Commands
&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;code&gt;npm run start&lt;/code&gt; - Start the ngx-admin frontend app&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;npm run api&lt;/code&gt; - Start the NestJS backend&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;npm run lint&lt;/code&gt; - Lint the project&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;npm run test&lt;/code&gt; - Run tests&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;
  &lt;a href="#license"&gt;
  &lt;/a&gt;
  License
&lt;/h2&gt;

&lt;p&gt;MIT License&lt;/p&gt;

&lt;p&gt;Copyright (c) 2022 Wilfried Lucha&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Project: &lt;a href="https://github.com/wlucha/angular-nest-nx"&gt;https://github.com/wlucha/angular-nest-nx&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

</description>
      <category>angular</category>
      <category>nestjs</category>
      <category>nx</category>
      <category>ngxadmin</category>
    </item>
    <item>
      <title>Static website + Wordpress blog - Hosting on AWS</title>
      <author>Shaharyar Ahmed</author>
      <pubDate>Tue, 18 Jan 2022 22:22:52 +0000</pubDate>
      <link>https://dev.to/shaharyarahmed/static-website-wordpress-blog-hosting-on-aws-pl4</link>
      <guid>https://dev.to/shaharyarahmed/static-website-wordpress-blog-hosting-on-aws-pl4</guid>
      <description>&lt;p&gt;Basic AWS knowledge is required.&lt;/p&gt;




&lt;p&gt;A static website + WordPress blog 🤔&lt;/p&gt;

&lt;p&gt;A very very common scenario where you want to keep your website static or build with Nextjs SSG, or probably with Reactjs. On the other hand, your marketing team wants WordPress to write blogs because it's in their conform zone and they don't want to learn anything new.&lt;/p&gt;

&lt;p&gt;In a startup, where you don't have much time to deal with all these. You might choose one of the three following options:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Build your entire website with WordPress using a theme so your content writers feel at home&lt;/li&gt;
&lt;li&gt;Create static pages for each blog and deploy them with the static site&lt;/li&gt;
&lt;li&gt;Create a custom blogging tool&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;But hold on, you have another option. It requires a bit of a hassle though for the first time. But it will make your life much easier on the long run.&lt;/p&gt;

&lt;p&gt;Serve your website statically using Nginx from one server, and run WordPress on another server. Now use AWS load balancer's smart routing to load blogs whenever someone goes to &lt;code&gt;/blog&lt;/code&gt; on your site.&lt;/p&gt;

&lt;p&gt;Feeling overwhelmed? 🤯 Let's break it down and understand it in more detail.&lt;/p&gt;

&lt;p&gt;But first, look at an example&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;a href="http://www.teamingway.com"&gt;www.teamingway.com&lt;/a&gt; (Main website is built with Nextjs SSG (static site generation) and statically deployed on an EC2)&lt;/li&gt;
&lt;li&gt;
&lt;a href="http://www.teamingway.com/blog/"&gt;www.teamingway.com/blog/&lt;/a&gt; (A WordPress site, running on another EC2, routed using AWS load balancer)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will set up the same thing.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#deploy-static-website"&gt;
  &lt;/a&gt;
  Deploy static website
&lt;/h2&gt;

&lt;p&gt;Create a &lt;code&gt;t2.micro&lt;/code&gt; EC2 instance with the following Nginx config:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight nginx"&gt;&lt;code&gt;&lt;span class="c1"&gt;# filename: example.com&lt;/span&gt;
&lt;span class="c1"&gt;# location: /etc/nginx/sites-enabled&lt;/span&gt;

&lt;span class="c1"&gt;# redirect http to https&lt;/span&gt;
&lt;span class="c1"&gt;# redirect example.com to www.example.com&lt;/span&gt;
&lt;span class="k"&gt;server&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kn"&gt;listen&lt;/span&gt; &lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kn"&gt;server_name&lt;/span&gt; &lt;span class="s"&gt;example.com&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kn"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;301&lt;/span&gt; &lt;span class="s"&gt;https://www.example.com&lt;/span&gt;&lt;span class="nv"&gt;$request_uri&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# main block&lt;/span&gt;
&lt;span class="k"&gt;server&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kn"&gt;listen&lt;/span&gt; &lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="kn"&gt;server_name&lt;/span&gt; &lt;span class="s"&gt;www.example.com&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="c1"&gt;# path to the static website folder&lt;/span&gt;
    &lt;span class="kn"&gt;root&lt;/span&gt; &lt;span class="n"&gt;/srv/www/your-website-folder&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kn"&gt;index&lt;/span&gt; &lt;span class="s"&gt;index.html&lt;/span&gt; &lt;span class="s"&gt;index.htm&lt;/span&gt; &lt;span class="s"&gt;index.nginx-debian.html&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="kn"&gt;location&lt;/span&gt; &lt;span class="n"&gt;/&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="c1"&gt;# serve static website files, throw "nginx 404 error" if file not found&lt;/span&gt;
        &lt;span class="kn"&gt;try_files&lt;/span&gt; &lt;span class="nv"&gt;$uri&lt;/span&gt; &lt;span class="nv"&gt;$uri&lt;/span&gt;&lt;span class="s"&gt;.html&lt;/span&gt; &lt;span class="nv"&gt;$uri&lt;/span&gt;&lt;span class="n"&gt;/&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;404&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;blockquote&gt;
&lt;p&gt;Notice, we only handled "HTTP" and not "HTTPS", because we will handle HTTPS at Load Balancer level and attach &lt;code&gt;ssl&lt;/code&gt; certificate there too.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Restart &lt;code&gt;Nginx&lt;/code&gt;:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="nb"&gt;sudo &lt;/span&gt;service nginx restart
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Our static website is now up and running.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#deploy-wordpress-site"&gt;
  &lt;/a&gt;
  Deploy WordPress site
&lt;/h2&gt;

&lt;p&gt;We will not go into the details of creating a WordPress instance on AWS because we're solving a different problem here. We will only explore things that are relevant to our goal.&lt;/p&gt;

&lt;p&gt;To create a WordPress instance, go to &lt;code&gt;Launch Instances&lt;/code&gt; on the main instances page. Search &lt;code&gt;WordPress&lt;/code&gt; and select a &lt;code&gt;Bitnami&lt;/code&gt; WordPress instance (as shown in the image below):&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--ktMDaTi0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/slskk4exqpovujazqp2y.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ktMDaTi0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/slskk4exqpovujazqp2y.png" alt="AWS create Wordpress instance" width="880" height="275"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Or you can manually set up one, it's all up to you. Once your WordPress instance is up and running, move to the next step.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#set-up-redirection-using-aws-load-balancer-and-route-53"&gt;
  &lt;/a&gt;
  Set up redirection using "AWS Load Balancer" and "Route 53"
&lt;/h2&gt;

&lt;h3&gt;
  &lt;a href="#1-create-load-balancer"&gt;
  &lt;/a&gt;
  1) Create Load Balancer
&lt;/h3&gt;

&lt;p&gt;On your EC2 dashboard, go to &lt;code&gt;Load Balancers&lt;/code&gt; from the left sidebar:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--YiNy1phq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bn6rn57yqs81cmbx1zbz.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--YiNy1phq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bn6rn57yqs81cmbx1zbz.png" alt="Select load balancer from sidebar" width="216" height="106"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;and then create a new load balancer, make sure you select &lt;strong&gt;Application Load Balancer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--93VHyruV--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vna61b0twz8y8jzi472k.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--93VHyruV--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vna61b0twz8y8jzi472k.png" alt="Create AWS load balancer" width="880" height="456"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It should be:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Internet-facing&lt;/li&gt;
&lt;li&gt;In the same &lt;code&gt;VPC&lt;/code&gt; as your website and WordPress instance&lt;/li&gt;
&lt;li&gt;In the same &lt;code&gt;Availability zone&lt;/code&gt; as your website and WordPress instance&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Add &lt;code&gt;default listener&lt;/code&gt; as your website instance with port 80 and complete the load balancer creation. We'll change it later anyway.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#2-set-up-alb-routing"&gt;
  &lt;/a&gt;
  2) Set up ALB routing
&lt;/h3&gt;

&lt;p&gt;Add the first listener for &lt;code&gt;port 80&lt;/code&gt;. Add one rule to permanently redirect to &lt;code&gt;HTTPS 443&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--BTkfBqgj--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2brvr2uhrhj3c7p3uodc.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--BTkfBqgj--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2brvr2uhrhj3c7p3uodc.png" alt="AWS load balancer - http to https redirect" width="880" height="360"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Add the second listener for &lt;code&gt;port 443&lt;/code&gt;. Now there will be two rules (See the image below for reference)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rule 1:&lt;/strong&gt; Default action will be to forward all the traffic to our static website.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Explanation:&lt;/em&gt; This means all requests coming on &lt;code&gt;example.com&lt;/code&gt; or &lt;code&gt;example.com/anypage&lt;/code&gt; will be forwarded to our static website instance. The instance name is &lt;code&gt;website-static&lt;/code&gt; in the image below.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rule 2:&lt;/strong&gt; If the &lt;code&gt;path&lt;/code&gt; matches the pattern &lt;code&gt;/blog*&lt;/code&gt;, forward the request to our &lt;code&gt;WordPress instance&lt;/code&gt;. &lt;/p&gt;

&lt;p&gt;&lt;em&gt;Explanation:&lt;/em&gt; This means if the request URL contains &lt;code&gt;/blog&lt;/code&gt; in it, the request will now be forwarded to our WordPress instance instead of the static website instance. If a request does not contain &lt;code&gt;/blog&lt;/code&gt;, it will satisfy &lt;code&gt;Rule 1&lt;/code&gt; and will be forwarded to the static website instance.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--lSg5KdlX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/e4du6flxft5t64v6g8h1.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--lSg5KdlX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/e4du6flxft5t64v6g8h1.png" alt="aws-load-balancer-listener-to-https" width="880" height="289"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: You will need to add your SSL certificate to the &lt;strong&gt;AWS Certificate Manager (ACM)&lt;/strong&gt; and attach it to the load balancer. We will not go into its details as well.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--dgFiUejg--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/rcicai2yhfy3uo6jx46s.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--dgFiUejg--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/rcicai2yhfy3uo6jx46s.png" alt="Add ssl to AWS load balancer" width="880" height="115"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#3-add-load-balancer-to-route-53"&gt;
  &lt;/a&gt;
  3) Add Load Balancer to Route 53
&lt;/h3&gt;

&lt;p&gt;We have everything ready now:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Static website instance&lt;/li&gt;
&lt;li&gt;WordPress site instance&lt;/li&gt;
&lt;li&gt;Load Balancer with https and rules to redirect based on URL&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The next and final step is to make a DNS entry for our website so we can access it via domain name.&lt;/p&gt;

&lt;p&gt;Go to your AWS Route 53 directory and create a new Route:&lt;/p&gt;

&lt;p&gt;Choose &lt;code&gt;Record type&lt;/code&gt; = &lt;code&gt;A&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Turn on the &lt;code&gt;Alias&lt;/code&gt; toggle in the &lt;code&gt;Route Traffic to&lt;/code&gt; section and select &lt;code&gt;Alias to Application and Classic Load Balancer&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--GgMF7Zaf--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/z7912vrpzimw9o636w5p.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--GgMF7Zaf--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/z7912vrpzimw9o636w5p.png" alt="aws-route-53-entry-for-load-balancer" width="349" height="365"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Select your zone i.e. &lt;code&gt;us-west-1&lt;/code&gt; and your load balancer will automatically appear, select and create the record.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#add-sub-path-to-your-wordpress-posts"&gt;
  &lt;/a&gt;
  Add sub path to your wordpress posts
&lt;/h2&gt;

&lt;p&gt;Change your site name and url, add &lt;code&gt;/blog&lt;/code&gt; at the end:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--1drwakXq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/y1x4xeizygv6a7sqzljl.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--1drwakXq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/y1x4xeizygv6a7sqzljl.png" alt="Change wordpress site name" width="596" height="109"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Change permanent links by going into &lt;code&gt;Settings &amp;gt; Permalinks&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--962EXHcB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1m1vndbhmxxpeyoukq1x.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--962EXHcB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1m1vndbhmxxpeyoukq1x.png" alt="Change wordpress permalink" width="577" height="59"&gt;&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;and that's it 🥳&lt;/p&gt;

&lt;p&gt;Your main website is running on a separate instance which could be static site, reactjs, nextjs or anything you want it to be and when you open &lt;code&gt;/blog&lt;/code&gt; your wordpress site will load.&lt;/p&gt;

&lt;p&gt;That will make your marketing team lives much easier regarding posting blogs, updates and sharing them on social media and other sites with easy SEO via wordpress plugins like &lt;strong&gt;yoast seo&lt;/strong&gt;.&lt;/p&gt;

</description>
      <category>aws</category>
      <category>wordpress</category>
      <category>nextjs</category>
      <category>devops</category>
    </item>
    <item>
      <title>Better Sleep with PagerDuty Dynamic Notifications and Support Hours
</title>
      <author>Mandi Walls</author>
      <pubDate>Tue, 18 Jan 2022 21:07:35 +0000</pubDate>
      <link>https://dev.to/pdcommunity/better-sleep-with-pagerduty-dynamic-notifications-and-support-hours-4jkp</link>
      <guid>https://dev.to/pdcommunity/better-sleep-with-pagerduty-dynamic-notifications-and-support-hours-4jkp</guid>
      <description>&lt;p&gt;We get a lot of questions from folks about how to better manage notifications and alerts for their services on PagerDuty. Dynamic Notifications and Support Hours will help you do exactly that, but you might have missed them on your first journey through PagerDuty. Let’s take a look at what they can do for your team.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://support.pagerduty.com/docs/dynamic-notifications"&gt;Dynamic Notifications&lt;/a&gt; can help you better manage what actions are taken when an alert is received on a particular service. They are linked to the service itself, so your team can customize actions for different services to meet the specific needs of that service and prioritize the most important services for immediate response. &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There might be any number of reasons why a service doesn’t require 24x7 high-priority response:&lt;/li&gt;
&lt;li&gt;The service isn’t in production. Your definition of “production” can include internal applications and tools!&lt;/li&gt;
&lt;li&gt;The service has minimal use during off hours in the same timezone as your staff.&lt;/li&gt;
&lt;li&gt;The service is only in limited production use, maybe a beta or a limited-release feature for a subset of users. &lt;/li&gt;
&lt;li&gt;The service isn’t in a critical path for all users.
&lt;/li&gt;
&lt;li&gt;The service has a graceful degradation state that doesn’t adversely affect user experience.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Resolving a fault state the following morning can be acceptable for these and any other reasons your team decides on. Establishing a good practice for incident urgency requires some setup in your alerts, your services, and in your team’s individual user profiles.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#dont-alert-for-lowurgency-issues"&gt;
  &lt;/a&gt;
  Don’t Alert for Low-Urgency Issues
&lt;/h2&gt;

&lt;p&gt;Plenty of teams have monitoring services that are chatty - they produce notifications about potential problems in advance of anything having an impact on user experience. This is great; your team has an opportunity to fix potential issues before an emergency happens. It might not be so great if those warning notifications come in the middle of the night.&lt;/p&gt;

&lt;p&gt;All alerts that come into PagerDuty can have an associated &lt;a href="https://support.pagerduty.com/docs/dynamic-notifications"&gt;severity&lt;/a&gt;. This is a field in the alert that establishes how important the alert is. The severities available in PagerDuty are based on industry-standard levels (note: they are case sensitive!), so hopefully they’re already familiar to you:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--WY6txEwh--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ec9p9dluim09enjzhnhr.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--WY6txEwh--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ec9p9dluim09enjzhnhr.png" alt="A table of alert severities and their behaviors." width="880" height="1043"&gt;&lt;/a&gt;&lt;br&gt;
PagerDuty uses these levels during the processing of &lt;a href="https://support.pagerduty.com/docs/rulesets#section-service-event-rules"&gt;event rules&lt;/a&gt;, and will also assign a default behavior to the alert if there are no applicable rules. Make sure your monitoring systems and other inputs are sending alerts at the appropriate severity level so your team isn’t bombarded with arbitrarily inflated alerts.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#dont-alert-overnight-for-everything"&gt;
  &lt;/a&gt;
  Don't Alert Overnight for Everything
&lt;/h2&gt;

&lt;p&gt;One of the worst parts about owning services in production is that sometimes things happen when you really want to be asleep. Waking up to deal with incidents overnight is hard; it’s hard on your team to lose sleep, it’s hard to get folks mobilized, and it’s hard to resolve issues when folks are trying to wake up enough to concentrate on the issue. So you want to make sure that the problems the team is being alerted for overnight really require an immediate response.&lt;/p&gt;

&lt;p&gt;Dynamic alerts are found in the service configuration under “Settings”. The first section of the page is “Assign and Notify”:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--pIx6J_5L--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/oni725prqld0fdngfgog.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--pIx6J_5L--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/oni725prqld0fdngfgog.png" alt="The default settings for a service in PagerDuty" width="880" height="396"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The default action here is to just assign the service to an escalation policy and move on, but there is so much more you can do. When you click the “Edit” button, you have an option with a dropdown menu: “How should responders be notified?”. Here’s where things get interesting.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--vBk0q9Vp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/rx8zqtxst6g9ttt7bhk1.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--vBk0q9Vp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/rx8zqtxst6g9ttt7bhk1.png" alt="The advanced settings for assigning and notifying responders in PagerDuty" width="880" height="474"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;These settings give you the ability to increase or decrease the urgency of the notifications related to this service. The default configuration is “High-urgency”, which might not be necessary for all of your services. Low urgency can absolutely be appropriate for some services. The third setting, “Dynamic notifications based on alert severity” will allow you to make use of the behaviors outlined above, assigning high urgency or low urgency based on the alert severity.&lt;/p&gt;

&lt;p&gt;The bottom option is “Based on support hours”, and choosing that option presents another set of useful options. &lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--x4TyduM5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2f04ksj8b5rs6x3vpbem.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--x4TyduM5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2f04ksj8b5rs6x3vpbem.png" alt="The Support Hours dialogue box in PagerDuty" width="880" height="482"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now the magic happens. You have the option to configure your “Support Hours”. These aren’t just for Support teams, they’re for any service your team has that doesn’t warrant urgent overnight alerts! The schedule here allows you to be flexible with the days and hours - though the hours will be the same each day. The default is M-F, 9:00am to 5:00pm in your default timezone. &lt;/p&gt;

&lt;p&gt;You’ll also see the checkbox to “Raise urgency of unacknowledged incidents to high” when support hours start. Any alerts received during off hours that would have been high-severity and  haven’t been acknowledged will be raised to your team the next working day, so you won’t miss things. Additionally, if the team did happen to ack the alerts during off hours, they won’t be re-raised in the morning. &lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#make-use-of-nonimmediate-notifications"&gt;
  &lt;/a&gt;
  Make Use of Non-Immediate Notifications
&lt;/h2&gt;

&lt;p&gt;Once your input alerts are setting severities and your service notification rules are set to use them, your team can make judicious use of the low-urgency settings to make alerts more manageable. The behavior for low-urgency alerts is a user setting, which each user will find in their profile under &lt;a href="https://support.pagerduty.com/docs/configuring-a-user-profile#section-notification-rules"&gt;Notification Rules&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--yVCfWPPs--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/smcvyw8vucs5ypgn0m9a.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--yVCfWPPs--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/smcvyw8vucs5ypgn0m9a.png" alt="User notification settings in PagerDuty. Choose the methods that best meet your needs." width="880" height="427"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Depending on your account configuration, your notifications can be a mix of email, SMS, push notifications to the PagerDuty App, or phone calls. Allowing your team to use less-distracting notifications like email for low-urgency alerts will help your team focus on regular work and urgent issues, as well as getting a good night’s rest.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#summary"&gt;
  &lt;/a&gt;
  Summary
&lt;/h2&gt;

&lt;p&gt;Defend your team against burnout! Actively managing alert severity is a key tool for making sure your team is getting the right alerts at the right time. By lowering the severity of alerts that aren’t really high-urgency, you give your team back their time and make on-call duties less of a burden. Alert severity can always be adjusted if the settings aren’t helping you maintain your reliability goals. For more on incident priorities, check out some additional posts on &lt;a href="https://www.pagerduty.com/blog/determining-incident-priority/"&gt;Determining Incident Priority&lt;/a&gt; and &lt;a href="https://www.pagerduty.com/blog/cutting-alert-fatigue-modern-ops/"&gt;Cutting Alert Fatigue in Modern Ops&lt;/a&gt;. Our support knowledge base has more on using &lt;a href="https://support.pagerduty.com/docs/dynamic-notifications"&gt;Dynamic Notifications&lt;/a&gt; and &lt;a href="https://support.pagerduty.com/docs/configurable-service-settings"&gt;service settings&lt;/a&gt;.  &lt;/p&gt;

&lt;p&gt;If you have questions about these features or others in PagerDuty, join our &lt;a href="https://community.pagerduty.com"&gt;community forum&lt;/a&gt;!&lt;/p&gt;

</description>
      <category>devops</category>
      <category>oncall</category>
      <category>alerts</category>
    </item>
    <item>
      <title>How a hacker, a hustler, and a designer made RSS feeds cool</title>
      <author>Conor Bronsdon</author>
      <pubDate>Tue, 18 Jan 2022 21:05:29 +0000</pubDate>
      <link>https://dev.to/linearb/how-a-hacker-a-hustler-and-a-designer-made-rss-feeds-cool-1p13</link>
      <guid>https://dev.to/linearb/how-a-hacker-a-hustler-and-a-designer-made-rss-feeds-cool-1p13</guid>
      <description>&lt;p&gt;Building a platform that 100,000 devs use every day is no accident, but it can happen (almost) overnight. &lt;/p&gt;

&lt;p&gt;&lt;a href="https://daily.dev/"&gt;Daily.Dev&lt;/a&gt; is the fastest growing online community for developers to stay updated on the hottest developer news, and their mission is to build the home page that every developer deserves.&lt;/p&gt;

&lt;p&gt;It pulls together and rewards dev-focused content from 400 sources – letting its users vote on which ones they find the most useful, the most interesting or the most entertaining.&lt;/p&gt;

&lt;p&gt;Co-founders Nimrod Kramer and Ido Shamun sit down with me to discuss their mission, the trick to building something that grows itself and why they chose to create a platform that actually makes RSS feeds cool!&lt;/p&gt;

&lt;p&gt;&lt;iframe src="https://open.spotify.com/embed/episode/2lgAQ3EbDtd3rb86M50v4u" width="100%" height="232px"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#episode-highlights-include"&gt;
  &lt;/a&gt;
  Episode Highlights Include:
&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Building the homepage every dev deserves&lt;/li&gt;
&lt;li&gt;Why RSS feeds are still relevant&lt;/li&gt;
&lt;li&gt;The importance of curating dev-focused content&lt;/li&gt;
&lt;li&gt;How to achieve explosive community growth&lt;/li&gt;
&lt;li&gt;Why Nimrod &amp;amp; Ido are excited about &lt;a href="https://devinterrupted.com/event/interact/"&gt;INTERACT&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;




&lt;p&gt;&lt;strong&gt;&lt;em&gt;Starved for top-level software engineering content? Need some good tips on how to manage your team? This article is inspired by &lt;a href="https://devinterrupted.com/podcasts/"&gt;Dev Interrupted&lt;/a&gt; - the go-to podcast for engineering leaders.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Dev Interrupted features expert guests from around the world to explore strategy and day-to-day topics ranging from dev team metrics to accelerating delivery. With new guests every week from Google to small startups, the Dev Interrupted Podcast is a fresh look at the world of software engineering and engineering management.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://devinterrupted.com/podcasts/"&gt;&lt;strong&gt;&lt;em&gt;Listen and subscribe on your streaming service of choice today.&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s---Asj0_HA--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/n5o5jcxrgw6ecv2xzavu.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s---Asj0_HA--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/n5o5jcxrgw6ecv2xzavu.png" alt="Our Favorite Podcasts" width="880" height="495"&gt;&lt;/a&gt;&lt;/p&gt;

</description>
      <category>podcast</category>
      <category>techtalks</category>
      <category>webdev</category>
      <category>startup</category>
    </item>
    <item>
      <title>Pragmatic Functional Programming in JavaScript</title>
      <author>Caleb Weeks</author>
      <pubDate>Tue, 18 Jan 2022 21:03:17 +0000</pubDate>
      <link>https://dev.to/sethcalebweeks/pragmatic-functional-programming-in-javascript-2lll</link>
      <guid>https://dev.to/sethcalebweeks/pragmatic-functional-programming-in-javascript-2lll</guid>
      <description>&lt;p&gt;If you have been following along with my recent posts, it is no surprise that I am an avid fan of functional programming. I &lt;a href="https://dev.to/sethcalebweeks/advent-of-code-1-in-javascript-haskell-24in"&gt;attempted to solve the Advent of Code 2021&lt;/a&gt; problems using both Haskell and JavaScript to find an idiomatic functional solution. Unfortunately, I &lt;a href="https://dev.to/sethcalebweeks/lessons-learned-from-aoc-2021-2b3b"&gt;learned along the way&lt;/a&gt; that certain approaches and techniques are not practical in JavaScript. This led me to the conclusion that functional programming has different flavors, and it is important to find the right blend for your language of choice.&lt;/p&gt;

&lt;p&gt;JavaScript is the language I use the most (whether by choice or not), and fortunately it supports functional programming fairly well. I think the bare minimum requirement needed for a language to claim to support functional programming is ergonomic support for higher order functions. (First-class functions are a requirement for higher order functions). What I mean by ergonomic support is that it has to feel natural, not gimmicky. Higher order functions work very well in JavaScript, particularly with ES6 arrow functions. &lt;/p&gt;

&lt;p&gt;The lack of certain features such as static types (in particular algebraic data types), pattern matching, or immutable data structures limits the techniques we can use without sacrificing ergonomics, but fortunately, you can get pretty far without these features.&lt;/p&gt;

&lt;p&gt;I came across two resources recently which have helped me think through pragmatic functional programming in JavaScript. The first is &lt;a href="https://youtu.be/3n17wHe5wEw"&gt;this talk&lt;/a&gt; by Richard Feldman that does a great job of explaining the why of functional programming. The second is &lt;a href="https://github.com/getify/Functional-Light-JS"&gt;this book&lt;/a&gt; by Kyle Simpson which proposes a flavor of functional programming that is practical in JavaScript. There are certain areas where my opinions differ from Kyle's, but this book introduces pragmatic functional programming from first principals. Also check out the &lt;a href="https://mostly-adequate.gitbook.io/mostly-adequate-guide/"&gt;Mostly Adequate Guide to Functional Programming&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Learning functional programming and figuring out how to use it practically has been a very long journey, and I think many people have felt the same frustrations that I did while learning. Although the functional programming paradigm is gaining momentum, practical resources get drowned out in the noise of both dissenters and people just riding the hype train. This is the start of a series where we will try to make sense of the plethora of information and distill it into actionable conclusions.&lt;/p&gt;

</description>
    </item>
    <item>
      <title>Todo List App and a Color Box Maker | Day 13 &amp; 14</title>
      <author>Web.Developer.io</author>
      <pubDate>Tue, 18 Jan 2022 19:45:25 +0000</pubDate>
      <link>https://dev.to/developerioweb/todo-list-app-and-a-color-box-maker-day-13-14-551g</link>
      <guid>https://dev.to/developerioweb/todo-list-app-and-a-color-box-maker-day-13-14-551g</guid>
      <description>&lt;h3&gt;
  &lt;a href="#i-have-made-2-react-app"&gt;
  &lt;/a&gt;
  I have made 2 React App
&lt;/h3&gt;

&lt;p&gt;1) &lt;strong&gt;Todo List&lt;/strong&gt;&lt;br&gt;
2) &lt;strong&gt;Color Box Maker&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#to-do-list"&gt;
  &lt;/a&gt;
  To Do List
&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--A7aPbyNG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/5ys7gdyc22psv4l1u5xp.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--A7aPbyNG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/5ys7gdyc22psv4l1u5xp.png" alt="To Do list" width="880" height="525"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#components"&gt;
  &lt;/a&gt;
  Components
&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;App - this component should render the TodoList component&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;TodoList - this component should render the NewTodoForm component and should render the list of Todo components. Place your state that contains all of the todos in this component.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;NewTodoForm - this component should render a form with one text input for the task to be created. When this form is submitted, a new Todo component should be created.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Todo- this component should display a div with the task of the todo.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#for-each-todo-component-there-should-also-be-a-button-with-the-text-x-that-when-clicked-removes-the-todo"&gt;
  &lt;/a&gt;
  For each Todo component, there should also be a button with the text “X” that when clicked, removes the todo.
&lt;/h3&gt;

&lt;h3&gt;
  &lt;a href="#each-todo-component-should-also-display-a-button-with-the-text-edit-that-when-clicked-displays-a-form-with-the-task-of-the-todo-as-an-input-and-a-button-to-submit-the-form-when-the-form-is-submitted-the-task-of-the-text-should-be-updated-and-the-form-should-be-hidden"&gt;
  &lt;/a&gt;
  Each Todo component should also display a button with the text “edit” that when clicked, displays a form with the task of the todo as an input and a button to submit the form. When the form is submitted, the task of the text should be updated and the form should be hidden.
&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://github.com/Developer-io-web/Todo-list"&gt;https://github.com/Developer-io-web/Todo-list&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#colorbox-maker"&gt;
  &lt;/a&gt;
  Color-Box Maker
&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://github.com/Developer-io-web/Color-Box-Maker"&gt;https://github.com/Developer-io-web/Color-Box-Maker&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#components"&gt;
  &lt;/a&gt;
  Components
&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;App - this component should render the BoxList component.&lt;/li&gt;
&lt;li&gt;BoxList - Place your state that contains all of the boxes here. This component should render all of the Box components along with the NewBoxForm component&lt;/li&gt;
&lt;li&gt;Box- this component should display a div with a background color, width and height based on the props passed to it.
NewBoxForm - this component should render a form that when submitted, creates a new Box. You should be able to specify the Box’s width, height, and background color. When the form is submitted, clear the input values.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#when-each-box-component-is-displayed-add-a-button-with-the-text-of-of-x-next-to-each-box-when-this-button-is-clicked-remove-that-specific-box-this-will-require-you-to-pass-a-function-down-as-props-the-button-should-not-be-a-seperate-component-it-should-be-included-in-the-box-component"&gt;
  &lt;/a&gt;
  When each Box component is displayed, add a button with the text of of “X” next to each Box. When this button is clicked, remove that specific box. This will require you to pass a function down as props - the button should not be a seperate component, it should be included in the Box component.
&lt;/h3&gt;

</description>
      <category>javascript</category>
      <category>webdev</category>
      <category>beginners</category>
      <category>programming</category>
    </item>
    <item>
      <title>Using the DevOps second way to improve the product development process</title>
      <author>Francisco Ortiz</author>
      <pubDate>Tue, 18 Jan 2022 19:43:27 +0000</pubDate>
      <link>https://dev.to/fran_ortiz/using-the-devops-second-way-to-improve-the-product-development-process-4k25</link>
      <guid>https://dev.to/fran_ortiz/using-the-devops-second-way-to-improve-the-product-development-process-4k25</guid>
      <description>&lt;p&gt;All the DevOps principles and practices can be derived from the &lt;a href="https://itrevolution.com/the-three-ways-principles-underpinning-devops/"&gt;“Three Ways of DevOps”&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;The first way&lt;/strong&gt;: Flow/Systems Thinking&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;The second way&lt;/strong&gt;: Amplify Feedback Loops&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;The third way&lt;/strong&gt;: Culture of Continual Experimentation and Learning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These practices are well covered in both “&lt;a href="https://itrevolution.com/book/the-devops-handbook"&gt;The DevOps Handbook&lt;/a&gt;” and the “&lt;a href="https://itrevolution.com/book/the-phoenix-project/"&gt;Phoenix Project&lt;/a&gt;” books. In this post, we will look more closely at a concept mentioned in “the second way”: &lt;strong&gt;feedback loops&lt;/strong&gt;. From the &lt;a href="https://itrevolution.com/the-three-ways-principles-underpinning-devops/"&gt;“Three Ways of DevOps”&lt;/a&gt;: &lt;em&gt;“The second way is about creating the right to left feedback loops. The goal of almost any process improvement initiative is to shorten and amplify feedback loops so necessary corrections can be continually made”&lt;/em&gt;.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#what-are-feedback-loops"&gt;
  &lt;/a&gt;
  What are feedback loops?
&lt;/h4&gt;

&lt;p&gt;In simple terms, a feedback loop is a process where the outputs of a system are used as inputs again.&lt;/p&gt;

&lt;p&gt;Feedback loops are always running in the background of our lives. The human body is dominated by a variety of feedback loops: there are processes that ensure a proper balance of everything, from the amount of water in our cells to the number of hormones that we release. They are not only present in human biology, but also in the center of human behavior, where the outputs of many processes influence many of our decisions.&lt;/p&gt;

&lt;p&gt;Of course, feedback loops are also present in product development. Through this post, we will explore how we can shorten and amplify these feedback loops and use them to improve our product development process. First, we will see the two types of feedback loops.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#the-two-types-of-feedback-loops"&gt;
  &lt;/a&gt;
  The two types of feedback loops
&lt;/h4&gt;

&lt;p&gt;As we said, a feedback loop occurs when a change in something ultimately comes back to cause a further change in the same thing. Depending on this further change’ direction, there are two different types of feedback loop.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#reinforcing-feedback-loop"&gt;
  &lt;/a&gt;
  Reinforcing feedback loop
&lt;/h5&gt;

&lt;p&gt;Further change is in the same direction. By increasing the value of a variable in the first entity, the value of the second entity increases, which causes the value of the first entity to increase even more. We can see it as a loop of accelerating change.&lt;/p&gt;

&lt;p&gt;Compound interest is a classical example of a reinforcing feedback loop: imagine that you start with 100€ and get paid 10 percent interest each year. After one year, you’ll have 110€. The next time around, you get paid 10 percent interest on 110€, so you will have 121€. The loop will go on and on.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s---Ah7rlzs--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/32uf0g1eyj22l7rupkhm.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s---Ah7rlzs--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/32uf0g1eyj22l7rupkhm.jpg" alt="Reinforcing Feedback Loop" width="500" height="283"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Reinforcing feedback loops can be great for building good habits or achieving peak performance in something. Of course, they can amplify the impact of bad behaviors as well.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#balancing-feedback-loop"&gt;
  &lt;/a&gt;
  Balancing feedback loop
&lt;/h5&gt;

&lt;p&gt;Further change is in the opposite direction. In this case, an increase in value in the first entity causes a decrease in the second entity, which in turn leads back to a decrease in the first entity. A loop of this type causes the system to stabilize at a point where there can be no more change.&lt;/p&gt;

&lt;p&gt;An example of a balancing feedback loop is a thermostat. Suppose we set a target temperature of 23 degrees. The lower the current temperature the greater the temperature gap. The greater the gap the more heat that flows into the system. That increases the temperature, which leads to a smaller temperature gap. It keeps going down until the gap is zero, where the system has reached the target.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s---HZytRpn--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7bziwpk4iet95tzmwoii.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s---HZytRpn--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7bziwpk4iet95tzmwoii.jpg" alt="Balancing Feedback Loop" width="500" height="262"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Balancing feedback loops can be very effective at moderating bad habits.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#feedback-loops-in-product-development"&gt;
  &lt;/a&gt;
  Feedback loops in product development
&lt;/h4&gt;

&lt;p&gt;During the product development process, we turn ideas into products, measure how customers respond, and adapt our product based on that feedback. Here we have the most obvious feedback loop in product development: the process of collecting customer feedback continuously and improving our product based on these insights.&lt;/p&gt;

&lt;p&gt;But there are many other opportunities to get feedback before we put our software in front of customers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;Testing&lt;/strong&gt;: each time we execute a test, we receive feedback about the test result.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;Merge&lt;/strong&gt;: when we merge our code with the main branch, we receive feedback about possible conflicts.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;Code review&lt;/strong&gt;: when more people see one piece of code, there is feedback about possible improvements.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;Deploy&lt;/strong&gt;: every time we deploy new code to production, we receive feedback about how it performs. Examples: how the system works with that new feature, possible incompatibilities with other features.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;System monitoring&lt;/strong&gt;: we continuously have feedback about the system’s health (dashboards, alerts, etc.).&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;Release&lt;/strong&gt;: every time we release a new feature, we receive feedback about how it is used by customers.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;Product instrumentation&lt;/strong&gt;: we receive continuous feedback about the actions that customers are doing in our product through product instrumentation tools.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--HFje57st--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3x171x446wdesw3kuvoq.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--HFje57st--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3x171x446wdesw3kuvoq.jpg" alt="Feedback Loops in Product Development" width="800" height="554"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As we go through all these steps, from the moment we write the first line of code to the moment we know whether a feature is being used, the results we receive shape our next decisions, &lt;strong&gt;creating a feedback loop&lt;/strong&gt;.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#shortening-our-feedback-loops"&gt;
  &lt;/a&gt;
  Shortening our feedback loops
&lt;/h4&gt;

&lt;p&gt;Each action has a delay between doing it and receiving feedback. The longer this delay, the slower we can react. Additionally, long delays in receiving feedback lead to other problems such as:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A lot of wasted time on bad assumptions.&lt;/li&gt;
&lt;li&gt;We make a lot of wrong decisions because of the impossibility of seeing the effects of our actions. Think about that shower faucet with a long delay: you always end up frozen or burned :)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some examples of this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;Working in a separate branch for a long time&lt;/strong&gt;: we may then discover that the main branch has changed and it is not compatible with our code.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;A single developer works alone for a long time and the code is not compatible with the team practices&lt;/strong&gt;: once the problem is found in a code review, all the code has to be rewritten.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;We don’t talk with customers before implementing a feature&lt;/strong&gt;: we work for a long time on implementing it. Then, the feature is not used by any customer.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To avoid these problems, &lt;strong&gt;we need to adapt our processes in order to have feedback loops as fast as possible&lt;/strong&gt;. Remember, from &lt;a href="https://itrevolution.com/the-three-ways-principles-underpinning-devops/"&gt;“Three Ways of DevOps”&lt;/a&gt;: &lt;em&gt;“The goal of almost any process improvement initiative is to shorten and amplify feedback loops so necessary corrections can be continually made”.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Let’s look at some practices that lead to shorter feedback loops.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#unit-testing"&gt;
  &lt;/a&gt;
  Unit testing
&lt;/h5&gt;

&lt;p&gt;Unit testing is the first feedback loop that should be established on any project. Rather than running the whole application, you’re running smaller parts of code (test suites) designed to be fast. With unit testing, you can have feedback about your work in seconds.&lt;/p&gt;

&lt;p&gt;Next, you can shorten and increase the number of feedback loops even more by practicing &lt;strong&gt;test-driven development (TDD)&lt;/strong&gt;. One of the biggest benefits of TDD is that you run your code often. As you write the test first, you’ll automatically have rapid feedback every time you save a new change. For me, this fast feedback is one of the main reasons to practice TDD.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#pairmob-programming"&gt;
  &lt;/a&gt;
  Pair/Mob Programming
&lt;/h5&gt;

&lt;p&gt;Apart from the advantage of improving your knowledge by continuously explaining problems or solutions to someone else, pair/mob programming is a powerful loop technique that provides peer feedback in seconds. By having people work together, the feedback they give each other is immediate and easily applied.&lt;/p&gt;

&lt;p&gt;As an alternative to pair/mob programming, you can conduct synchronous code reviews. You’ll lose other benefits of group programming, but we will avoid long feedback cycles.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#trunk-based-development"&gt;
  &lt;/a&gt;
  Trunk based development
&lt;/h5&gt;

&lt;p&gt;With &lt;a href="https://trunkbaseddevelopment.com/"&gt;trunk-based development&lt;/a&gt;, we have continuous feedback about the compatibility of the newly developed code with the main branch. We are committing new changes to the main branch continuously so we avoid long feedback loops and painful merges.&lt;/p&gt;

&lt;p&gt;Trunk-based development is a key enabler of the next practice, continuous delivery.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#continuous-delivery"&gt;
  &lt;/a&gt;
  Continuous Delivery
&lt;/h5&gt;

&lt;p&gt;&lt;a href="https://continuousdelivery.com/"&gt;Continuous Delivery&lt;/a&gt; is the ability to get changes of all types—including new features, configuration changes, bug fixes, and experiments—into production, or into the hands of users, &lt;em&gt;safely&lt;/em&gt; and &lt;em&gt;quickly&lt;/em&gt; in a &lt;em&gt;sustainable&lt;/em&gt; way.&lt;/p&gt;

&lt;p&gt;Decoupling our deployments from our releases means that we can deploy more often, so we will have more feedback. &lt;a href="https://martinfowler.com/articles/feature-toggles.html"&gt;Feature toggles&lt;/a&gt; are a great tool to do this.&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#work-in-small-batches"&gt;
  &lt;/a&gt;
  Work in small batches
&lt;/h5&gt;

&lt;p&gt;Work in small increments. Then deploy those small increments to production. Remember, the more time we spend working on an idea without getting feedback, the more probability we have of working on bad assumptions.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#amplifying-our-feedback-loops-look-for-virtuous-cycles"&gt;
  &lt;/a&gt;
  Amplifying our feedback loops: look for virtuous cycles
&lt;/h4&gt;

&lt;p&gt;When we talk about amplifying feedback loops, we are looking for loops where each iteration of the cycle reinforces the previous one: reinforcing feedback loops.&lt;/p&gt;

&lt;p&gt;When we get reinforcing feedback loops in a positive way we get a **virtuous cycle. **We can see an example with the level of automated testing on our product and the team's confidence.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--BeIP3bs_--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/5v0flk28e49xse6awtz4.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--BeIP3bs_--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/5v0flk28e49xse6awtz4.jpg" alt="Virtuous Cycle" width="500" height="262"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As our product is more tested, the team will have a greater level of confidence when doing new features. Each iteration of the loop reinforces the previous one, and the levels of confidence and testing are rising continuously. This is why we want to amplify feedback loops.&lt;/p&gt;

&lt;p&gt;However, we have to be careful, as the same positive feedback loop can also run in reverse order, creating a &lt;strong&gt;vicious cycle.&lt;/strong&gt; Here, a bad situation feeds on itself to make it even worse. We can see an example below, with the technical debt and the code quality:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--5D-6k87w--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/g2phs5p0nf8kyfjadvr7.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--5D-6k87w--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/g2phs5p0nf8kyfjadvr7.jpg" alt="Vicious Cycle" width="500" height="264"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The more technical debt in our project, the more quick and dirty code we will produce. This feedback loop will be continuously running unless we stop it.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#conclusions"&gt;
  &lt;/a&gt;
  Conclusions
&lt;/h4&gt;

&lt;p&gt;Feedback loops can be a powerful tool in our product development process. The more positive feedback loops we have, the greater control of our system and better customer satisfaction, some goals that we all want to achieve.&lt;/p&gt;

&lt;p&gt;However, we have also seen that there are negative feedback loops that can produce some vicious cycles if we don’t identify and stop them.&lt;/p&gt;

&lt;p&gt;The intent of this article was to assist with creating and identifying feedback loops in the product development process so we can:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Amplify our current positive feedback loops, reaching virtuous cycles.&lt;/li&gt;
&lt;li&gt;Stop our current negative feedback loops, removing the vicious cycles.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This way, we can move from letting feedback loops shape our decisions in an invisible way to designing the feedback loops we want and need. &lt;strong&gt;Rather than being victims of feedback loops suffering vicious cycles, we should be architects of them and benefit from virtuous cycles.&lt;/strong&gt;&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#related-content"&gt;
  &lt;/a&gt;
  Related content
&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;The DevOps Handbook (book): &lt;a href="https://itrevolution.com/book/the-devops-handbook/?_ga=2.102924932.520566917.1641551391-1413882804.1637091596"&gt;https://itrevolution.com/book/the-devops-handbook&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Small batches for the win (blog from @eferro): &lt;a href="https://www.eferro.net/2021/01/small-batches-for-win-continuous.html"&gt;https://www.eferro.net/2021/01/small-batches-for-win-continuous.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Many Much More Smaller Steps (post from GeePaw Hill): &lt;a href="https://www.geepawhill.org/series/many-much-more-smaller-steps/"&gt;https://www.geepawhill.org/series/many-much-more-smaller-steps/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Introducing Extreme Programming: &lt;a href="http://www.extremeprogramming.org/introduction.html"&gt;http://www.extremeprogramming.org/introduction.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;The Virtuous Cycle of Velocity: What I learned about going fast at eBay and Google (talk from Randy Shoup): &lt;a href="https://www.youtube.com/watch?v=EwLBoRyXTOI"&gt;https://www.youtube.com/watch?v=EwLBoRyXTOI&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Code reviews, synchronous and asynchronous (post from @eferro): &lt;a href="https://www.eferro.net/2021/09/code-reviews-synchronous-and.html"&gt;https://www.eferro.net/2021/09/code-reviews-synchronous-and.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Equipos de algo rendimiento, qué son y cómo identificarlos: &lt;a href="https://www.youtube.com/watch?v=Eqwy6w2RYUk"&gt;https://www.youtube.com/watch?v=Eqwy6w2RYUk&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;

</description>
      <category>devops</category>
      <category>programming</category>
    </item>
    <item>
      <title>What is the Jamstack in 2022?</title>
      <author>Brian Rinaldi</author>
      <pubDate>Tue, 18 Jan 2022 19:26:14 +0000</pubDate>
      <link>https://dev.to/remotesynth/what-is-the-jamstack-in-2022-134</link>
      <guid>https://dev.to/remotesynth/what-is-the-jamstack-in-2022-134</guid>
      <description>&lt;p&gt;2021 was a year of big changes in the Jamstack. &lt;a href="https://remotesynthesis.com/blog/jamstack-in-2021"&gt;A year ago&lt;/a&gt;, we were struggling a bit with how to define Jamstack in a world that included the ability to use SSR in a Jamstack application. At the time, this was unique to Next.js, but today you'll find this supported in Nuxt.js 3, Gatsby 4 and even Eleventy via the Eleventy Serverless plugin. Not just that, but we've now added in multiple other kinds of rendering such that I wrote an extensive article clarifying the &lt;a href="https://bejamas.io/blog/understanding-rendering-in-the-jamstack/"&gt;various types of Jamstack rendering&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;2021 also included the release of some new tools that gained a great deal of popularity very quickly and introduced a new concept, the &lt;a href="https://jasonformat.com/islands-architecture/"&gt;islands architecture&lt;/a&gt;, to the Jamstack. Both &lt;a href="https://astro.build/"&gt;Astro&lt;/a&gt;, a completely new SSG, and &lt;a href="https://slinkity.dev/"&gt;Slinkity&lt;/a&gt;, which is built on top of Eleventy, offered the ability to use frameworks like React, but limit JavaScript to only where it is needed.&lt;/p&gt;

&lt;p&gt;So, suffice it to say, Jamstack got more popular but it also arguably got more complicated. We probably came no closer to clarity on what the Jamstack is in 2021. And this has led to some thoughts on how I see Jamstack in 2022.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If you're into Jamstack, which I'm guessing you are because you are reading this, you'll definitely want to join me (virtually) at &lt;a href="https://thejam.dev"&gt;TheJam.dev&lt;/a&gt; on January 26-27. It's 2 days of amazing speakers all about Jamstack and it's completely FREE!&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#whered-the-simple-go"&gt;
  &lt;/a&gt;
  Where'd the Simple Go?
&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;For any technology, the hardest part is not establishing simplicity, but protecting it over time.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Matt Biilmann, CEO of Netlify&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;I got into Jamstack development – well really static site development – because it felt like a return to simpler days of developing for the web. Sure, SSGs couldn't handle every kind of site, but that was ok because they handled a lot of types of sites. Plus, they were fun and easy to use for many developers in a way that Wordpress or its alternatives were not.&lt;/p&gt;

&lt;p&gt;Over time, we added more complexity because we liked building with Jamstack and wanted it to be able to build more sites with it – sites that pure static couldn't handle. In one sense, that's been great. Only a few years ago, it was easy to think of types of sites that couldn't be built with Jamstack. That's no longer true.&lt;/p&gt;

&lt;p&gt;But it also has come with some tradeoffs. Getting started with Jamstack was never incredibly easy given that it isn't prescriptive and there are so many options, but once you got past that, the experience used to be much simpler in my opinion. Today, I feel that the learning curve is becoming much steeper. Plus, the result isn't always better than the alternative, with large JavaScript bundles weighing down the apps performance.&lt;/p&gt;

&lt;p&gt;This has led to "competition" (so to speak) appealing to developers on territory that Jamstack used to own. Frameworks like Remix or concepts like &lt;a href="https://cfe.dev/sessions/moar2021-functional-web-apps/"&gt;functional web apps&lt;/a&gt; often specifically target Jamstack for its growing complexity. "Why fight with rendering options and long builds when pure SSR using serverless is easier to build and offers similar performance?" they argue. Plus, we can run on platforms like Netlify and Vercel just the same.&lt;/p&gt;

&lt;p&gt;While it's difficult to admit for someone like me who has been a Jamstack advocate, but I think they have a point.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#2022-is-about-rediscovering-the-simple"&gt;
  &lt;/a&gt;
  2022 is About Rediscovering the Simple
&lt;/h2&gt;


&lt;blockquote&gt;
&lt;p&gt;One of the quirks of growing older as a developer in my experience is that, while I've learned to appreciate complexity in people a lot more, I've also learned to appreciate complexity in code a lot less.&lt;/p&gt;— Brian Rinaldi (&lt;a class="mentioned-user" href="https://dev.to/remotesynth"&gt;@remotesynth&lt;/a&gt;) &lt;a href="https://twitter.com/remotesynth/status/1482032277005742080?ref_src=twsrc%5Etfw"&gt;January 14, 2022&lt;/a&gt;
&lt;/blockquote&gt; 

&lt;p&gt;I feel like, if the concept of Jamstack is to continue to be valuable in 2022 as differentiated from just plain web development, it needs to rediscover what made it appealing – it needs to bring back the simplicity. The good news is that I do not believe that means going back to plain old static sites using traditional SSGs.&lt;/p&gt;

&lt;p&gt;This is my list of requirements that I think a modern SSG needs to have:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;A way to call APIs for data at build time.&lt;/li&gt;
&lt;li&gt;The ability to modularize my code, whether that be components or partials.&lt;/li&gt;
&lt;li&gt;Some tools to make building frontend interactivity easier.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To me, everything else is a bit superfluous and adds complexity. Is the ability to build and deploy an edge function within my sites application code cool? Heck, yes. Is it a necessary feature in a Jamstack site builder? No.&lt;/p&gt;

&lt;p&gt;It's worth remembering what all this added rendering complexity is actually doing for us and that's just handling the compiling and deployment of our application API. SSR in a Jamstack framework is just deploying parts of your code to serverless functions for you. I could actually already accomplish this to a large degree without the framework depending on the platform that I am deploying my application to. For instance, both Netlify and Cloudflare (and I am sure others) will deploy serverless functions for your API for you automatically if they are placed in a specific folder.&lt;/p&gt;

&lt;p&gt;I think we're already seeing some movement in this direction. For example, both Astro and 11ty seem to be geared towards specifically accomplishing the core requirements without the extras (I'm curious if Astro sticks to that given &lt;a href="https://astro.build/blog/the-astro-technology-company/"&gt;recent announcements&lt;/a&gt; or moves more in the direction of Next.js). The growing popularity of both tools seems to indicate to me that this has some value and resonance.&lt;/p&gt;

&lt;p&gt;But both tools also emphasize something that can make Jamstack &lt;em&gt;better&lt;/em&gt; than other methods in the way we always claimed it was better but &lt;a href="https://almanac.httparchive.org/en/2021/jamstack#performance-score"&gt;didn't always live up to&lt;/a&gt;. That's because both aim to deliver less JavaScript, meaning that the site they deliver should perform better than a framework-heavy alternative both because most of the content is prerendered and because they don't inlude all the extra baggage of a JavaScript framework whenever it isn't necessary. I'm hopeful that it is a path other tools pursue as well.&lt;/p&gt;

&lt;p&gt;The original goal of Jamstack was to deliver a better experience to end users (faster and more secure) while offering a better experience to developers (easy to build and maintain). Go &lt;a href="http://web.archive.org/web/20160603092304/http://jamstack.org/"&gt;check out the original manifesto&lt;/a&gt;. Tons of new (and undeniably cool) advances in cloud computing and application development have seemingly led us down a path towards ever increasing complexity.&lt;/p&gt;

&lt;p&gt;All of this complexity added value but complexity also came at a cost. I'm not advocating removing features, and, to be honest, I am still thinking through how this problem can be solved. But I think it can start refocusing on the core tenets of what Jamstack means – it doesn't have to be the solution to every problem but instead a solution that solve a set of particular problems, better. Maybe Jamstack needs to be more opinionated about the experience of building a Jamstack site and about the result. In my view, 2022 could be about rediscovering the simplicity of Jamstack's developer experience and the differentiation of its output or Jamstack could simply blend into web development, not really offering a clear alternative to non-Jamstack options. I personally think the concept still has a ton of value.&lt;/p&gt;

</description>
      <category>javascript</category>
      <category>webdev</category>
      <category>jamstack</category>
    </item>
    <item>
      <title>ES6: JavaScript for...of statement</title>
      <author>Naftali Murgor</author>
      <pubDate>Tue, 18 Jan 2022 19:24:39 +0000</pubDate>
      <link>https://dev.to/naftalimurgor/es6-javascript-forof-statement-2caa</link>
      <guid>https://dev.to/naftalimurgor/es6-javascript-forof-statement-2caa</guid>
      <description>&lt;h2&gt;
  &lt;a href="#introduction"&gt;
  &lt;/a&gt;
  Introduction
&lt;/h2&gt;

&lt;p&gt;This tutorial will learn about &lt;code&gt;for-of&lt;/code&gt; introduced in  &lt;code&gt;ES6&lt;/code&gt; version of JavaScript.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;for...of&lt;/code&gt; statement is used for iterating over arrays, maps or sets.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#looping-over-an-array"&gt;
  &lt;/a&gt;
  Looping over an array
&lt;/h2&gt;

&lt;p&gt;Example in code:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight typescript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;fruits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;Orange&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;Apple&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;banana&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;Lemon&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;// looping through&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;fruit&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="nx"&gt;fruits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="c1"&gt;// do something with fruit&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h2&gt;
  &lt;a href="#looping-over-a-string"&gt;
  &lt;/a&gt;
  Looping over a string
&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;for...of&lt;/code&gt; can also be used to loop over contents of a string.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight typescript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;Happy new year!&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;char&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="nx"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;char&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;// H a p p y n e w y e a r !&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h2&gt;
  &lt;a href="#looping-over-a-set"&gt;
  &lt;/a&gt;
  Looping over a Set
&lt;/h2&gt;

&lt;p&gt;A set is a collection of unique values.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight typescript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;letters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Set&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;a&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;b&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;c&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;letter&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="nx"&gt;letters&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;letters&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;// a, b, c&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h2&gt;
  &lt;a href="#looping-over-a-map"&gt;
  &lt;/a&gt;
  Looping over a map
&lt;/h2&gt;

&lt;p&gt;A map is key-value pair, where key can be of any type. In JavaScript it's common to use object literals as maps&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight typescript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;details&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;name&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;Michael Myers&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;age&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;// made up&lt;/span&gt;
&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="c1"&gt;// or a cleaner way:&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;details&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Map&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;details&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="kd"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;name&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;Michael Myers&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;detail&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="nx"&gt;details&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;detail&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h2&gt;
  &lt;a href="#summary"&gt;
  &lt;/a&gt;
  Summary
&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;for...of&lt;/code&gt; introduces a cleaner way of looping over arrays, sets, strings and maps.&lt;/p&gt;




&lt;p&gt;Read more about 👉 &lt;a href="https://dev.toe"&gt;Map objects&lt;/a&gt;&lt;/p&gt;

</description>
      <category>javascript</category>
      <category>webdev</category>
      <category>tutorial</category>
      <category>node</category>
    </item>
    <item>
      <title>Unofficial guide to Slack literacy: communication in a remote-first world</title>
      <author>Alyss 💜</author>
      <pubDate>Tue, 18 Jan 2022 19:19:40 +0000</pubDate>
      <link>https://dev.to/preciselyalyss/unofficial-guide-to-slack-literacy-navigating-communication-in-a-remote-first-world-dbd</link>
      <guid>https://dev.to/preciselyalyss/unofficial-guide-to-slack-literacy-navigating-communication-in-a-remote-first-world-dbd</guid>
      <description>&lt;p&gt;Before landing my first job in tech, I’d already been well acquainted with IRC, ventrilo, and message boards. With a career came Campfire (Basecamp) and then Slack launched in August 2013. Slack, for the purposes of this post, is used as a proxy for asynchronous chat platforms/tooling. Such software has become ubiquitous to the daily toil for knowledge workers and expands into professional, personal, and hobby communities. &lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#basic-rules-of-etiquette"&gt;
  &lt;/a&gt;
  Basic rules of etiquette
&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Unless you’ve formally discussed the use of &lt;code&gt;@channel&lt;/code&gt; or &lt;code&gt;@here&lt;/code&gt; on your team and there’s a shared understanding of when to use it, err on the side of never using it. I’ve personally found this notification used more frequently among sales teams or within groups where most users do not have a desktop app installed and access through a browser instead.&lt;/li&gt;
&lt;li&gt;When sending a direct or private message, send a single message with your request. (e.g. Hello! Can you share any updates on the Apollo project?) There are individuals who may prefer an opening salutation or some kind of friendly watercooler banter but the point of async communication is you don’t have to sit around waiting to have a conversation to get a question answered. If you’re working across time zones, you can also consider &lt;a href="https://slack.com/help/articles/1500012915082-Schedule-messages-to-send-later"&gt;scheduling a message&lt;/a&gt; to send.&lt;/li&gt;
&lt;li&gt;Set your own boundaries. Slack has a &lt;a href="https://slack.com/help/articles/214908388-Pause-notifications-with-Do-Not-Disturb"&gt;notification schedule feature&lt;/a&gt; and Do Not Disturb (when you may want to focus or go on vacation).
&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--VjPz98HT--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/is92ct9u3h2zjg7kvvqr.png" alt="notification schedule in slack profile settings" width="556" height="266"&gt;
&lt;/li&gt;
&lt;li&gt;Finally: Set a profile photo, pronouns, and name pronunciation*.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;*Enterprise slack plans have more configurable profile fields, like name pronunciation. This may not be available in your slack experience.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#intermediate-skills"&gt;
  &lt;/a&gt;
  Intermediate skills
&lt;/h2&gt;

&lt;h3&gt;
  &lt;a href="#mentions"&gt;
  &lt;/a&gt;
  Mentions
&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;If an individual isn’t in the channel or private message, using their tag or handle will not notify them. For a channel in slack, a message will appear asking if you’d like to invite or notify them (or do nothing).&lt;/li&gt;
&lt;li&gt;@ mentions can be disruptive. If you’d like to mention a person without notifying them, placing their name or handle in backtick/code blocks (e.g. &lt;code&gt;@preciselyalyss&lt;/code&gt;). You can do this when you aren’t sure if they are in a channel but still want to reduce noise/distractions.&lt;/li&gt;
&lt;li&gt;If you are interacting via a private message, you don’t need to tag/@ mention participants. They will be notified by default. In a private group DM, you can further configure your notification settings.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#channels"&gt;
  &lt;/a&gt;
  Channels
&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Read descriptions and pinned messages for a channel if you aren’t sure how to interact. Rules of engagement may be documented or the best way to engage with a particular team. &lt;/li&gt;
&lt;li&gt;Organize slack channels with the sections feature&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#reactji-emoji"&gt;
  &lt;/a&gt;
  Reactji + Emoji
&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Reactji are highly cultural. We have over 10k custom slack emoji at GitHub. Sometimes these gain more traction, like Atlassian popularized chompy when HipChat shipped with the character in the default emoji set. Chompy was used when posting that lunch was available.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--bC1lhmOy--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/eg2tgu7p1ab9wdwr4rx3.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--bC1lhmOy--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/eg2tgu7p1ab9wdwr4rx3.gif" alt="cartoon character chewing" width="480" height="307"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Most platforms allow you to configure a default skin tone of the core emoji set. Please think about this. Even leaving the default to yellow should be a deliberate choice, in my opinion. More reading &lt;a href="https://firstmonday.org/ojs/index.php/fm/article/view/10060/8048"&gt;here&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/2105.05887.pdf"&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#threads"&gt;
  &lt;/a&gt;
  Threads
&lt;/h3&gt;

&lt;p&gt;There are no universally agreed rules that I’ve observed on Threads yet. They are still fairly new feature to several platforms. It can help with multi-threaded conversations but does change the notification location or reduce visibility in some cases.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#advanced"&gt;
  &lt;/a&gt;
  Advanced
&lt;/h2&gt;

&lt;h3&gt;
  &lt;a href="#writing-styles"&gt;
  &lt;/a&gt;
  Writing styles
&lt;/h3&gt;

&lt;p&gt;Chat is a highly informal medium and written communication can be fraught with opportunities to miscommunicate and misunderstand. It is possible to reduce the risks but never fully mitigate them. If you're unsure of the tone something was written in, ask.&lt;/p&gt;

&lt;p&gt;Some rules I follow:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If there’s a context-loaded word, like DevOps, I try to define what usage I’m intending when discussing in chat.&lt;/li&gt;
&lt;li&gt;Incorporating &lt;a href="https://fourminutebooks.com/nonviolent-communication-summary/"&gt;non-violent communication&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Explicit requests vs implied. “Can you do x?” instead of “X needs to get done”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Consider cultural-specific communication&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Do I have teammates that wouldn’t understand this reference?&lt;/li&gt;
&lt;li&gt;Is this a necessary reference if it does exclude people who don’t understand and should I explain it?&lt;/li&gt;
&lt;li&gt;Is there potentially ambiguous or inflammatory meaning? (e.g. Gifs or images referencing Winnie the Pooh when speaking with China-based colleagues could have an unintended impact)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you’re interested in further improving your remote-first skills, &lt;a href="https://yougotthis.io/talks/"&gt;You Got This&lt;/a&gt; is a community event series with even more educational content to dive into.&lt;/p&gt;

</description>
      <category>career</category>
      <category>productivity</category>
    </item>
  </channel>
</rss>
