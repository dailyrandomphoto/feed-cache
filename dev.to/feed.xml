<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>DEV Community</title>
    <author>DEV Community</author>
    <description>A constructive and inclusive social network for software developers. With you every step of your journey.</description>
    <link>https://dev.to</link>
    <language>en</language>
    <item>
      <title>How to Game Dev Metrics w/ Ray Elenteny</title>
      <author>Conor Bronsdon</author>
      <pubDate>Fri, 09 Jul 2021 14:52:28 +0000</pubDate>
      <link>https://dev.to/conorbronsdon/how-to-game-dev-metrics-w-ray-elenteny-5h3l</link>
      <guid>https://dev.to/conorbronsdon/how-to-game-dev-metrics-w-ray-elenteny-5h3l</guid>
      <description>&lt;p&gt;What leads teams to game metrics within their organization?&lt;/p&gt;

&lt;p&gt;On this week‚Äôs episode of &lt;a href="https://devinterrupted.com/podcast/how-to-game-dev-metrics/"&gt;Dev Interrupted&lt;/a&gt;, we speak with agile expert Ray Elenteny, Principal Owner at Solutech Consulting, about how people game dev metrics and the underlying issues in culture &amp;amp; leadership that lead to it.&lt;/p&gt;

&lt;p&gt;So whether you're trying to game your own metrics (don't do it!) or solve culture issues that have led to this issue at your organization, give this episode a listen.&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#listen-to-the-full-episode"&gt;
  &lt;/a&gt;
  &lt;strong&gt;Listen to the full episode&lt;/strong&gt;
&lt;/h1&gt;

&lt;p&gt;&lt;iframe width="100%" height="232px" src="https://open.spotify.com/embed/episode/2AJVkiMHT3Zd4vb3pzLEbs"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#episode-highlights-include"&gt;
  &lt;/a&gt;
  &lt;strong&gt;Episode Highlights include:&lt;/strong&gt;
&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Which metrics are easiest to game&lt;/li&gt;
&lt;li&gt;The long-term implications of gaming metrics&lt;/li&gt;
&lt;li&gt;How poor culture and leadership lead engineering teams to game dev metrics&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;
  &lt;a href="#join-the-dev-interrupted-discord-server"&gt;
  &lt;/a&gt;
  &lt;strong&gt;Join the Dev Interrupted Discord Server&lt;/strong&gt;
&lt;/h1&gt;

&lt;p&gt;With over 1200 members, the Dev Interrupted Discord Community is the best place for Engineering Leaders to engage in daily conversation. No sales people allowed. &lt;a href="https://discord.gg/tpkmwM6c3g"&gt;Join the community &amp;gt;&amp;gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--wzIBzHH0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/19j3dzgz4r4kzav3w6z8.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--wzIBzHH0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/19j3dzgz4r4kzav3w6z8.png" alt="Join the Dev Interrupted Discord Community!"&gt;&lt;/a&gt;&lt;/p&gt;

</description>
      <category>devops</category>
      <category>agile</category>
      <category>leadership</category>
      <category>culture</category>
    </item>
    <item>
      <title>A Gentle Introduction to Reinforcement Learning </title>
      <author>Satwik Kansal</author>
      <pubDate>Fri, 09 Jul 2021 14:36:20 +0000</pubDate>
      <link>https://dev.to/satwikkansal/a-gentle-introduction-to-reinforcement-learning-75h</link>
      <guid>https://dev.to/satwikkansal/a-gentle-introduction-to-reinforcement-learning-75h</guid>
      <description>&lt;h1&gt;
  &lt;a href="#a-gentle-introduction-to-reinforcement-learning"&gt;
  &lt;/a&gt;
  A gentle introduction to Reinforcement Learning
&lt;/h1&gt;

&lt;p&gt;In 2016, AplhaGo, a program developed for playing the game of &lt;a href="https://en.wikipedia.org/wiki/Go_(game)"&gt;Go&lt;/a&gt;, made headlines when it beat the world champion Go player in a five-game match. It was a remarkable feat because the number of possible legal moves in Go are of the order of 2.1 √ó 10&lt;sup&gt;170&lt;/sup&gt;.  To put this in context, this number is far, far greater than the number of atoms in the observable universe, which are of the order of 10&lt;sup&gt;80&lt;/sup&gt;. Such a high number of possibilities make it almost impossible to create a program that can play effectively using brute-force or somewhat optimized search algorithms. &lt;/p&gt;

&lt;p&gt;A part of the secret sauce of AlphaGO was the usage of Reinforcement Learning to improve its understanding of the game by playing against itself. Since then, the field of Reinforcement Learning has seen increased interest, and much more efficient programs have been developed to play various games at a pro-human efficiency. Although you would find Reinforcement Learning discussed in the context of Games and Puzzles in most places (including this post), the applications of Reinforcement Learning are much more expansive. The objective of this tutorial is to give you a gentle introduction to the world of Reinforcement Learning. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;‚ÑπÔ∏è First things first! This post was written in collaboration with &lt;a href="https://scholar.google.com/citations?user=H4WCOr8AAAAJ"&gt;Alexey Vinel&lt;/a&gt; (Professor, Halmstead University). Some ideas and visuals are borrowed from my previous post on Q-learning written for &lt;a href="https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/"&gt;Learndatasci&lt;/a&gt;. Unlike most posts you'll find on Reinforcement learning, we try to explore Reinforcement Learning here with an angle of multiple agents. So this makes it slightly more complicated and interesting at the same time. While this will be a good resource to develop intuitive understanding of Reinforcement Learning (Reinforcement Q-learning to be specific), it is highly recommended to visit the theoretical parts (some links shared in the appendix), if you're willing to explore Reinforcement Learning beyond this post.&lt;/p&gt;

&lt;p&gt;I had to fork openAIs gym library to implement a custom environment. The code can be found on &lt;a href="https://github.com/satwikkansal/gym-dual-taxi"&gt;this github repository&lt;/a&gt;.  If you'd like to explore an interactive version, you can check &lt;a href="https://colab.research.google.com/github/satwikkansal/gym-dual-taxi/blob/master/draft.ipynb"&gt;out this google colab notebook&lt;/a&gt;. We use Python to implement the algorithms, if you're not familiar with Python you can simply pretend that those snippets don't exist and read through the textual part (including code comments). Alright, time to get started üöÄ&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;
  &lt;a href="#what-is-reinforcement-learning"&gt;
  &lt;/a&gt;
  What is Reinforcement Learning?
&lt;/h2&gt;

&lt;p&gt;Reinforcement learning is a paradigm of Machine Learning where learning happens through the feedback gained by an agent's interaction with its environment. This is also one of the key differentiators of Reinforcement Learning with the other two paradigms of Machine learning (&lt;a href="https://en.wikipedia.org/wiki/Supervised_learning"&gt;Supervised learning&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Unsupervised_learning"&gt;Unsupervised learning&lt;/a&gt;). Supervised learning algorithms require fully labelled-training-data, and Unsupervised learning algorithms need no labels. On the other hand, Reinforcement learning algorithms utilize feedback from the environment they're operating in to get better at the tasks they're being trained to perform. So we can say that Reinforcement Learning lies somewhere in the middle of the spectrum.&lt;/p&gt;

&lt;p&gt;It is inevitable to talk about Reinforcement Learning with clarity without using some technical terms like "agent", "action", "state", "reward", and "environment". So let's try to gain a high-level understanding of Reinforcement Learning and these terms through an analogy,&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#understanding-reinforcement-learning-through-birbing"&gt;
  &lt;/a&gt;
  Understanding Reinforcement learning through Birbing
&lt;/h3&gt;

&lt;p&gt;Let's watch the first few seconds of this video first,&lt;/p&gt;

&lt;p&gt;&lt;iframe width="710" height="399" src="https://www.youtube.com/embed/u7TiRqh7x8s"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;p&gt;Pretty cool, isn't it?&lt;/p&gt;

&lt;p&gt;And now think about how did someone manage to teach this parrot to reply with certain sounds on certain prompts. And if you carefully observed, part of the answer lies in the food the parrot is given after every cool response. The human asks a question, and the parrot tries to respond in many different ways, and if the parrot's response is the desired one, it is rewarded with food. Now guess what? The next time the parrot is exposed to the same cue, it is likely to answer similarly, expecting more food. This is how we "reinforce" certain behaviours through positive experiences. If I had to explain the above process in terms of Reinforcement learning concepts, it'd be something like,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;"The agent learns to take desired for a given state in the environment", &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;where,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The "agent" is the parrot&lt;/li&gt;
&lt;li&gt;The "state" is questions or cues the parrot is exposed to&lt;/li&gt;
&lt;li&gt;The "actions" are the sounds it is uttering &lt;/li&gt;
&lt;li&gt;The "reward" is the food he gets when he takes the desired action&lt;/li&gt;
&lt;li&gt;And the "environment" is the place where the parrot is living (or, in other words, everything else than the parrot)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The reinforcement can happen through negative experiences too. For example, if a child touches a burning candle out of curiosity, (s)he is unlikely to repeat the same action. So, in this case, instead of a reward, the agent got a penalty, which would disincentivize the agent to repeat the same action in future again.&lt;/p&gt;

&lt;p&gt;&lt;iframe width="710" height="399" src="https://www.youtube.com/embed/hsVEiat444Q"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;p&gt;If you try to think about it, there are countless similar real-world analogies. This suggests why Reinforcement Learning can be helpful for a wide variety of real-world applications and why it might be a path to create General AI Agents (think of a program that can not just beat a human in the game of Go, but multiple games like Chess, GTA, etc.). It might still take a lot of time to develop agents with general intelligence, but reading about programs like &lt;a href="https://en.wikipedia.org/wiki/MuZero"&gt;MuZero&lt;/a&gt; (one of the many successors of Alpha Go) hints that Reinforcement learning might have a decent role to play in achieving that.&lt;/p&gt;

&lt;p&gt;After reading the analogies, a few questions like below might have come into your mind,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Real-world example is fine, but how do I do this "reinforcement" in the world of programs?&lt;/li&gt;
&lt;li&gt;What are these algorithms, and how do they work?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let's start answering such questions as switch gears and dive into certain technicalities of Reinforcement learning.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#example-problem-statement-selfdriving-taxi"&gt;
  &lt;/a&gt;
  Example problem statement: Self-driving taxi
&lt;/h2&gt;

&lt;p&gt;Wouldn't it be fantastic to train an agent (i.e. create a computer program) to pick up from a location and drop them at their desired location? In the rest of the tutorial, we'll try to solve a simplified version of this problem through reinforcement learning.&lt;/p&gt;

&lt;p&gt;Let's start by specifying typical steps in a Reinforcement learning process,&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Agent observes the environment. The observation is represented in digital form and also called "state".&lt;/li&gt;
&lt;li&gt;The agent utilizes the observation to decide how to act. The strategy agent uses to figure out the action to perform is also referred to as "policy".&lt;/li&gt;
&lt;li&gt;The agent performs the action in the environment.&lt;/li&gt;
&lt;li&gt;The environment, as a result of the action, may move to a new state (i.e. generate different observations) and may return feedback to the agent in the form of rewards/penalties. &lt;/li&gt;
&lt;li&gt;The agent uses the rewards and penalties to refine its policy.&lt;/li&gt;
&lt;li&gt;The process can be repeated until the agent finds an optimal policy.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--1ynz3QjF--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://storage.googleapis.com/lds-media/documents/Reinforcement-Learning-Animation.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--1ynz3QjF--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://storage.googleapis.com/lds-media/documents/Reinforcement-Learning-Animation.gif" alt=""&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now that we're clear about the process, we need to set up the environment. In most cases, what this means is we need to figure out the following details,&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#1-the-statespace"&gt;
  &lt;/a&gt;
  1. The state-space
&lt;/h3&gt;

&lt;p&gt;Typically, a "state" will encode the observable information that the agent can use to learn to act efficiently. For example, in the case of self-driving-taxi, the state information could contain the following information,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The current location of the taxi&lt;/li&gt;
&lt;li&gt;The current location of the passenger&lt;/li&gt;
&lt;li&gt;The destination&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There can be multiple ways to represent such information, and how one ends up doing it depends on the level of sophistication intended. &lt;/p&gt;

&lt;p&gt;The state space is the set of all possible states an environment can be in. For example, if we consider our environment for the self-driving taxi to be a two-dimensional 4x4 grid, there are &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;16 possible locations for the taxi&lt;/li&gt;
&lt;li&gt;16 possible locations for the passenger&lt;/li&gt;
&lt;li&gt;and 16 possible destination&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This means our state-space size becomes 16 x 16 x 16 = 4096, i.e. at any point in time the environment must be in either of these 4096 states. &lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--1UeQ7JwC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/N.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--1UeQ7JwC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/N.gif" alt="https://github.com/satwikkansal/gym-dual-taxi/raw/master/N.gif"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#2-the-action-space"&gt;
  &lt;/a&gt;
  2. The action space
&lt;/h3&gt;

&lt;p&gt;Action space is the set of all possible actions an agent can take in the environment. Taking the same 2D grid-world example, the taxi agent may be allowed to take the following actions,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Move North&lt;/li&gt;
&lt;li&gt;Move South&lt;/li&gt;
&lt;li&gt;Move East&lt;/li&gt;
&lt;li&gt;Move West&lt;/li&gt;
&lt;li&gt;Pickup&lt;/li&gt;
&lt;li&gt;Drop-off&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Again, there can be multiple ways to define the action space, and this is just one of them. The choice also depends on the level of complexity and algorithms you'd want to use later.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#3-the-rewards"&gt;
  &lt;/a&gt;
  3. The rewards
&lt;/h3&gt;

&lt;p&gt;The rewards and penalties are critical for an agent's learning. While deciding the reward structure, we must carefully think about the magnitude, direction (positive or negative), and the reward frequency (every time step / based on specific milestone / etc.). Taking the same grid environment example, some ideas for reward structure can be,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The agent should receive a positive reward when it performs a successful passenger drop-off. The reward should be high in magnitude because this behaviour is highly desired.&lt;/li&gt;
&lt;li&gt;The agent should be penalized if it tries to drop off a passenger in the wrong locations.&lt;/li&gt;
&lt;li&gt;The agent should get a small negative reward for not making it to the destination after every time step. This would incentivize the agent to take faster routes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There can be more ideas for rewards like giving a reward for successful pickup and so on. &lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#4-the-transition-rules"&gt;
  &lt;/a&gt;
  4. The transition rules
&lt;/h3&gt;

&lt;p&gt;The transition rules are kind of the brain of the environment. They specify the dynamics of the above discussed components (state, action, and reward). They are often represented in terms of tables (a.k.a state transition tables) which specify that,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For a given state S, if you take an action A, the new state of the environment becomes S', and the reward received is R. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="table-wrapper-paragraph"&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;State&lt;/th&gt;
&lt;th&gt;Action&lt;/th&gt;
&lt;th&gt;Reward&lt;/th&gt;
&lt;th&gt;Probability&lt;/th&gt;
&lt;th&gt;Next State&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;S&lt;code&gt;p&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;A&lt;code&gt;q&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;R&lt;code&gt;pq&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;td&gt;S&lt;code&gt;p'&lt;/code&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/div&gt;

&lt;p&gt;An example row could be when the taxi's location is in the middle of grid, the passenger's location in in the bottom-right corner. The agent takes the "Move North" action, it gets a negative reward, and the next state becomes the state that represents the taxi in its new position.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; In the real-world, the state transitions may not be deterministic, i.e. they can be either.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Stochastic; which means the rules operate by probability, i.e. if you take an action, there's an X1% chance you'll end up in state S1, and Xn% chance you'd end up in a state Sn.&lt;/li&gt;
&lt;li&gt;Unknown; which means it is not known in advance what all possible states the agent can get into if it takes action A in a given state S. This might be the case when the agent is operating in the real world.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;
  &lt;a href="#implementing-the-environment"&gt;
  &lt;/a&gt;
  Implementing the environment
&lt;/h2&gt;

&lt;p&gt;Implementing a computer program that represents the environment can be a bit of a programming effort. Apart from deciding the specifics like the state space, transition table, reward structure, etc., we need to implement other features like creating a way to input actions into the environment and getting feedback in return. More often than not, there's also a requirement to visualize what's happening under the hood. Since the objective of this tutorial is "Introduction to Reinforcement Learning", we will skip the "how to program a Reinforcement learning environment" part and jump straight to using it. However, if you're interested, you can check the &lt;a href="https://github.com/satwikkansal/gym-dual-taxi"&gt;source code&lt;/a&gt; and follow the comments there.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#specifics-of-the-environment"&gt;
  &lt;/a&gt;
  Specifics of the environment
&lt;/h3&gt;

&lt;p&gt;We'll use a custom environment inspired by OpenAI gym's &lt;a href="https://gym.openai.com/envs/Taxi-v3/"&gt;Taxi-v3 environment&lt;/a&gt;. We have added a twist to the environment. Instead of having a single taxi and a single passenger, we'll be having two taxis and a passenger! The intention behind the mod is to observe interesting dynamics that might arise because of the presence of another taxi. This also means the state space would comprise an additional taxi location, and the action space would comprise of actions of both the taxis now.&lt;/p&gt;

&lt;p&gt;Our environment is built on OpenAI's gym library, making it a bit convenient to implement environments to evaluate Reinforcement learning algorithms. They also include some pre-packaged environment (Taxi-v3 is one of them), and their environments are a popular way to practice Reinforcement Learning and evaluate Reinforcement Learning algorithms. Feel free to check out their docs to know more about them! &lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#exploring-the-environment"&gt;
  &lt;/a&gt;
  Exploring the environment
&lt;/h3&gt;

&lt;p&gt;It's time we start diving into some code and explore the specifics of the environment we'll be using for Reinforcement learning in this tutorial.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="c1"&gt;# Let's first install the custom gym module which contains the environment 
&lt;/span&gt;&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;uninstall&lt;/span&gt; &lt;span class="n"&gt;gym&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;git&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;git&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;github&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;satwikkansal&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;gym&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;dual&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;taxi&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;git&lt;/span&gt;&lt;span class="c1"&gt;#"egg=gym&amp;amp;subdirectory=gym/"
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;





&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;gym&lt;/span&gt;
&lt;span class="n"&gt;env&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gym&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'DualTaxi-v1'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;render&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# PS: If you're using jupyter notebook and get env not registered error; you have to restart your kernel after install the custom gym package in the last step.
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a href="/Users/satwik/Library/Application%20Support/typora-user-images/image-20210709135319304.png" class="article-body-image-wrapper"&gt;&lt;img src="/Users/satwik/Library/Application%20Support/typora-user-images/image-20210709135319304.png" alt="image-20210709135319304"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the snippet above, we initialize our custom &lt;code&gt;DualTaxi-v1&lt;/code&gt; environment, and rendered its current state. In the rendered output,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The yellow and red rectangles represents both taxis on the 4x4 grid&lt;/li&gt;
&lt;li&gt;R, G, B, and Y are the 4 possible pick up or drop-off locations for the passenger&lt;/li&gt;
&lt;li&gt;The character ‚Äú|‚Äù represents a wall which the taxis can't cross&lt;/li&gt;
&lt;li&gt;The blue colored letter represents the pick-up location of the passenger&lt;/li&gt;
&lt;li&gt;The purple letter represents the drop-off location.&lt;/li&gt;
&lt;li&gt;Any taxi that gets the passenger aboard, would turn green in color
&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;observation_space&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;action_space&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;(Discrete(6144), Discrete(36))
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;You might have noticed that the only information that's printed is their discrete nature and the size of the space. The rest of the details are abstracted. This is an important point, and as you'll realize by the end of the post, our RL algorithm won't need any more information. &lt;/p&gt;

&lt;p&gt;However if you're still curious to know how the environment functions, feel free to check out the &lt;a href="https://github.com/satwikkansal/gym-dual-taxi"&gt;enviroment's code&lt;/a&gt; and follow the comments there. Another thing that you can do is peek into the state-transition table (check the code in the appendix if you're curious how to do it)&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#the-objective"&gt;
  &lt;/a&gt;
  The objective
&lt;/h3&gt;

&lt;p&gt;The objective of the environment is pick up the passenger from the blue location and drop to the violet location as fast as possible. An intelligent agent should be able to do this with consistency. Now let's see what information to we have for the environment's state space (a.k.a observation space) and action space. But before we dive into implementing that intelligent agent, let's see how a random agent would perform in this kind of enviromnet,&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;play_random&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="s"&gt;"""
    Function to play the episodes.
    """&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;done&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;next_action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;action_space&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_action&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;





&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="c1"&gt;# Trying the dumb agent
&lt;/span&gt;&lt;span class="n"&gt;print_frames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;play_random&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# check github for the code for print_frames
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--UZ9DSH9f--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/rl-1.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--UZ9DSH9f--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/rl-1.gif" alt=""&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can see the episode number at the top. In our case, an episode is the timeframe between the steps where the taxis make the first move and the step where they drop a passenger at the desired after picking up. When this happens, the episode is over, and we have to reset the environment to start all over again. &lt;/p&gt;

&lt;p&gt;You can see different actions at the bottom, and how the state keeps changing and the reward the agent gets after every action.&lt;/p&gt;

&lt;p&gt;As you can might have realized, these taxis are taking a while to finish even a single episode. So our random approach is very dumb for sure. Our intelligent agent definitely will have to perform this task better.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#introducing-qlearning"&gt;
  &lt;/a&gt;
  Introducing Q-learning
&lt;/h2&gt;

&lt;p&gt;Q-learning is one among several Reinforcement Learning algorithms. The reason we are picking Q-learning is because it is simple and straightforward to understand. We'll use Q-learning to make our agent somewhat intelligent. &lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#intuition-behind-qlearning"&gt;
  &lt;/a&gt;
  Intuition behind Q-learning
&lt;/h3&gt;

&lt;p&gt;The way Q-learning works, is by storing what we call Q-values for every state-action combination. The Q-value represents the "quality" of an action taken from that state. Of course, the initial q-values are just random numbers, but the goal is to iteratively update them in the right direction. After enough iterations, these Q-values can start to converge (i.e. the size of update in upcoming iterations gets so small that it has a negligible impact). Once that is the case, we can safely say that, &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For a given state, the higher the Q-value for the state-action pair, the higher would be the expected long term reward of taking that particular action. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So long story short, the "developing intelligence" part of Q-learning lies in how the Q-values after agent's ineteraction with the environment, which requires discussion of two key concepts,&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#1-the-bellman-equation"&gt;
  &lt;/a&gt;
  1. The bellman equation
&lt;/h3&gt;

&lt;p&gt;Attached below is the bellman equation in the context of updating Q-values, this is the equation we use to update Q-values after agent's interaction with the environment.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://postimg.cc/image/4ghnvcjgn/"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--IFO521r_--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://s31.postimg.cc/jp7l94d57/q_learning_equation.png" alt="q_learning_equation.png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The Q-value of a state-action pair is the sum of the instant reward and the discounted future reward (of the resulting state). Where,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;st represents the state at time &lt;code&gt;t&lt;/code&gt;
&lt;/li&gt;
&lt;li&gt;at represents action taken at time &lt;code&gt;t&lt;/code&gt; (the agent was in state st at this point in time)&lt;/li&gt;
&lt;li&gt;rt is the reward received by performing the action at in the state st.&lt;/li&gt;
&lt;li&gt;st+1 is the next state that our agent will transition to after performing the action at in the state st.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The discount factor Œ≥(gamma) determines how much importance we want to give to future rewards. A high value for the discount factor (close to &lt;strong&gt;1&lt;/strong&gt;) captures the long-term effective award, whereas, a discount factor of &lt;strong&gt;0&lt;/strong&gt; makes our agent consider only immediate reward, hence making it greedy. &lt;/p&gt;

&lt;p&gt;The $\alpha$ (alpha) is our learning rate. Just like in supervised learning settings, alpha here is representative of the extent to which our Q-values are being updated in every iteration.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#2-epsilon-greedy-method"&gt;
  &lt;/a&gt;
  2. Epsilon greedy method
&lt;/h3&gt;

&lt;p&gt;While we keep updating Q-values every iteration, there's an important choice the agent has to make while taking an action. The choice it faces is whether to "explore" or "exploit"?&lt;/p&gt;

&lt;p&gt;So with time, the Q-values get better at representing the quality of a state-action pair. But to reach that goal, the agent has to try different actions (how can it know if a state-action pair is good if it hasn't tried it?). So it becomes critical for agent to "explore" i.e. take random actions to gather more knowledge about the environment. &lt;/p&gt;

&lt;p&gt;But there's a problem if the agent only explores. Exploration can only get the agent so far. Imagine that the environment agent is in is like a maze. Exploration can put agent on unknown path and give feedback to make q-values more valuable. But if the agent is only taking random actions at every step, it is going to have a hard time reaching the end state of the maze. That's why it is also important to "exploit". The agent should also consider using what it has already learned (i.e. the Q-values) to decided what action to take next.&lt;/p&gt;

&lt;p&gt;That's all to say, the agent needs to balance exploitation and exploration. There are many ways to do this. Once common way to do it with Q-learning is to have a value called "epsilon", which denotes the probability by which the agent will explore. A higher epsilon value results in interactions with more penalties (on average) which is obvious because we are exploring and making random decisions. We can add more sophistication to this method, and its a common practice that people start with a high epsilon value, and keep reducing it as time progresses. This is called epsilon decay. The intution is that as we keep adding more knowledge to Q-values through exploration, the exploitation becomes more trustworthy which in turn means we can explore at a lower rate. &lt;/p&gt;

&lt;p&gt;Note: There's usually some confusion around if epsilon represents probability of "exploration" or "exploitation". You'll find it used both ways on the internet and other resources. I find the first way more comfortable as it fits the terminology "epsilon decay". If you see it other way around, don't get confused, the concept is still the same. &lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#using-qlearning-for-our-environment"&gt;
  &lt;/a&gt;
  Using Q-learning for our environment
&lt;/h2&gt;

&lt;p&gt;Okay, enough background about Q-learning. Now how do we apply it to our &lt;code&gt;DualTaxi-v1&lt;/code&gt; environment? Because of the fact that we have two taxis in our environment, we can do it in a couple of ways,&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#1-cooperative-approach"&gt;
  &lt;/a&gt;
  1. Cooperative approach
&lt;/h3&gt;

&lt;p&gt;In this approach we can assume that there's a single agent with a single Q-table that controls both the taxis (think of it like a taxi agency). The overall goal of this agent would be to maximize the reward these taxis receive combined.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#2-competitive-approach"&gt;
  &lt;/a&gt;
  2. Competitive approach
&lt;/h3&gt;

&lt;p&gt;In this approach we can train two agents (one for each taxi). Every agent has its own Q-table and gets its own reward. Of course, the next state of the environment still depends on the actions of both the agents. This creates an interesting dynamic where each taxi would be trained to maximize its own individual rewards.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#cooperative-approach-in-action"&gt;
  &lt;/a&gt;
  Cooperative approach in action
&lt;/h2&gt;

&lt;p&gt;Before we see the code, let us specify the steps we'd have to take,&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Initialize the Q-table (size of the Q-table is state_space_size x action_space_size) by all zeros.&lt;/li&gt;
&lt;li&gt;Decide between exploration and exploitation based on the epsilon value.&lt;/li&gt;
&lt;li&gt;Exploration: For each state, select any one among all possible actions for the current state (S).&lt;/li&gt;
&lt;li&gt;Exploitation: For all possible actions from the state (S') select the one with the highest Q-value.&lt;/li&gt;
&lt;li&gt;Travel to the next state (S') as a result of that action (a).&lt;/li&gt;
&lt;li&gt;Update Q-table values using the update equation.&lt;/li&gt;
&lt;li&gt;If the episode is over (i.e. goal state is reached), reset the environment for next iteration.&lt;/li&gt;
&lt;li&gt;Keep repeating steps 2 to 7 until we start seeing decent results in agent's performance.
&lt;/li&gt;
&lt;/ol&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;deque&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt; 


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bellman_update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="s"&gt;"""
    Function to perform q-value update as per bellman equation.
    """&lt;/span&gt;
    &lt;span class="c1"&gt;# Get the old q_value
&lt;/span&gt;    &lt;span class="n"&gt;old_q_value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="c1"&gt;# Find the maximum q_value for the actions in next state
&lt;/span&gt;    &lt;span class="n"&gt;next_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;next_state&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;# Calculate the new q_value as per the equation
&lt;/span&gt;    &lt;span class="n"&gt;new_q_value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;old_q_value&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;gamma&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;next_max&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# Finally, update the q_value
&lt;/span&gt;    &lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_q_value&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="s"&gt;"""
    Selects an action according to epsilon greedy method, performs it, and the calls bellman update
    to update the Q-values.
    """&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;action_space&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="n"&gt;next_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;bellman_update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;next_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;info&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_agent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;log_every&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;running_metrics_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;evaluate_every&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;evaluate_trials&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="s"&gt;"""
    This is the training logic. It takes input as a q-table, the environment.
    The training is done for num_episodes episodes. The results are logged preiodcially.

    We also record some useful metrics like average reward in last 50k timesteps, the average
    length of last 50 episodes and so on. These are helpful to gauge how the algorithm is performing
    over time.

    After every few episodes of training. We run evaluation routine, where we just "exploit" i.e. rely on 
    the q-table so far and see how well the agent has learned so far. Over the time, the results should get
    better until the q-table starts converging, after which, there's negligible change in the results.
    """&lt;/span&gt;
    &lt;span class="n"&gt;rewards&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;deque&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;running_metrics_len&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;episode_lengths&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;deque&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;total_timesteps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="n"&gt;metrics&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;num_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;done&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;

        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;rewards&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="n"&gt;total_timesteps&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;total_timesteps&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;log_every&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;rd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rewards&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;avg_ep_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;episode_lengths&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;zeroes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fill_percent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;calculate_q_table_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'Current Episode: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'Reward distribution: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;rd&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'Last 10 episode lengths (avg: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;avg_ep_len&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt;)'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;zeroes&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt; Q table zeroes, &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;fill_percent&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt; percent filled'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


        &lt;span class="n"&gt;episode_lengths&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;evaluate_every&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'==='&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;"Running evaluation after &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt; episodes"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;finish_percent&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;avg_time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;penalties&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;evaluate_agent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;evaluate_trials&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'==='&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;rd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rewards&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;avg_ep_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;episode_lengths&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;zeroes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fill_percent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;calculate_q_table_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
                    &lt;span class="s"&gt;'train_reward_distribution'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;rd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s"&gt;'train_ep_len'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;avg_ep_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s"&gt;'fill_percent'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;fill_percent&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s"&gt;'test_finish_percent'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;finish_percent&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s"&gt;'test_ep_len'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;avg_time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s"&gt;'test_penalties'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;penalties&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Training finished."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;calculate_q_table_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="s"&gt;"""
    This function counts what perecentage of cells in the q-table are non-zero.
    Note: There are certain state-action combinations that are illegal, so the table might never 
    be full.
    """&lt;/span&gt;
    &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
    &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;
    &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;cell&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;cell&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;fill_percent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;100.0&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fill_percent&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;evaluate_agent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="s"&gt;"""
    The routine to evaluate an agent. It simply exploits the q-table and records the performance metrics.
    """&lt;/span&gt;
    &lt;span class="n"&gt;total_epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total_wins&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;wins&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;done&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;next_action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_action&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;num_penalties&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;wins&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;total_epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;
        &lt;span class="n"&gt;total_penalties&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;num_penalties&lt;/span&gt;
        &lt;span class="n"&gt;total_wins&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;wins&lt;/span&gt;

    &lt;span class="n"&gt;average_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average_time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;complete_percent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;compute_evaluation_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;total_epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;total_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;total_wins&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;print_evaluation_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;average_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;average_time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;total_wins&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;complete_percent&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average_time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average_penalties&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;print_evaluation_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;average_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average_time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total_wins&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Evaluation results after {} trials"&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Average time steps taken: {}"&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;average_time&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Average number of penalties incurred: {}"&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;average_penalties&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;"Had &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;total_wins&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt; wins in &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt; episodes"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;compute_evaluation_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total_epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total_wins&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;average_time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;total_epochs&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;average_penalties&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;total_penalties&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;complete_percent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;total_wins&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;num_trials&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;100.0&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;average_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average_time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;complete_percent&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;





&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# The hyper-parameters of Q-learning
&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt; &lt;span class="c1"&gt;# learning rate
&lt;/span&gt;&lt;span class="n"&gt;gamma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.7&lt;/span&gt; &lt;span class="c1"&gt;# discout factor
&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;
&lt;span class="n"&gt;env&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gym&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'DualTaxi-v1'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;num_episodes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50000&lt;/span&gt;

&lt;span class="c1"&gt;# Initialize a q-table full of zeroes
&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;observation_space&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;action_space&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_agent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Get back trained q-table and metrics
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;Total encoded states are 6144
==============================
Running evaluation after 0 episodes
Evaluation results after 200 trials
Average time steps taken: 1500.0
Average number of penalties incurred: 1500.0
Had 0 wins in 200 episodes
==============================

----------------------------
Skipping intermediate output
----------------------------


==============================
Running evaluation after 49000 episodes
Evaluation results after 200 trials
Average time steps taken: 210.315
Average number of penalties incurred: 208.585
Had 173 wins in 200 episodes
==============================
Current Episode: 49404
Reward distribution: Counter({-3: 15343, -12: 12055, -4: 11018, -11: 4143, -20: 3906, -30: 1266, -2: 1260, 99: 699, -10: 185, 90: 125})
Last 10 episode lengths (avg: 63.0)
48388 Q table zeroes, 78.12319155092592 percent filled
Training finished.
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;I have skipped the intermediate output on purpose, you can check &lt;a href="https://pastebin.com/XHJLatiX"&gt;this pastebin&lt;/a&gt; if you're interested in full output. &lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#competitive-approach"&gt;
  &lt;/a&gt;
  Competitive Approach
&lt;/h3&gt;

&lt;p&gt;The steps for this are similar to the cooperative approach, with the differnce that now we have multiple Q-tables to update.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Initialize the Q-table 1 and 2 for both the agents by all zeros. The size of each Q-table is &lt;code&gt;state_space_size x sqrt(action_space_size)&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Decide between exploration and exploitation based on the epsilon value.&lt;/li&gt;
&lt;li&gt;Exploration: For each state, select any one among all possible actions for the current state (S).&lt;/li&gt;
&lt;li&gt;Exploitation: For all possible actions from the state (S') select the one with the highest Q-value in the Q-tables of respective agents.&lt;/li&gt;
&lt;li&gt;Transition to the next state (S') as a result of that combined action (a1, a2).&lt;/li&gt;
&lt;li&gt;Update Q-table values for both the agents using the update equation and respective rewards &amp;amp; actions.&lt;/li&gt;
&lt;li&gt;If the episode is over (i.e. goal state is reached), reset the environment for next iteration.&lt;/li&gt;
&lt;li&gt;Keep repeating steps 2 to 7 until we start seeing decent results in the performance.
&lt;/li&gt;
&lt;/ol&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;update_multi_agent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="s"&gt;"""
    Same as update method discussed in the last section, just modified for two independent q-tables.
    """&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;action_space&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;action1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode_action&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;action1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;action2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode_action&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;action1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;next_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;reward1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;
    &lt;span class="n"&gt;bellman_update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;bellman_update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;next_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;info&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_multi_agent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;log_every&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;running_metrics_len&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;evaluate_every&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;evaluate_trials&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="s"&gt;"""
    Same as train method discussed in the last section, just modified for two independent q-tables.
    """&lt;/span&gt;
    &lt;span class="n"&gt;rewards&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;deque&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;running_metrics_len&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;episode_lengths&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;deque&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;total_timesteps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="n"&gt;metrics&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;done&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;

        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c1"&gt;# Modification here
&lt;/span&gt;            &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;update_multi_agent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;rewards&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="n"&gt;total_timesteps&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;total_timesteps&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;log_every&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;rd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rewards&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;avg_ep_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;episode_lengths&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;zeroes1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fill_percent1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;calculate_q_table_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;zeroes2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fill_percent2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;calculate_q_table_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'Current Episode: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'Reward distribution: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;rd&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'Last 10 episode lengths (avg: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;avg_ep_len&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt;)'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;zeroes1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt; Q table 1 zeroes, &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;fill_percent1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt; percent filled'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;zeroes2&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt; Q table 2 zeroes, &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;fill_percent2&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt; percent filled'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


        &lt;span class="n"&gt;episode_lengths&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;evaluate_every&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'==='&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;"Running evaluation after &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt; episodes"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;finish_percent&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;avg_time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;penalties&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;evaluate_multi_agent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;evaluate_trials&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'==='&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;rd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rewards&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;avg_ep_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;episode_lengths&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;zeroes1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fill_percent1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;calculate_q_table_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;zeroes2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fill_percent2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;calculate_q_table_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
                    &lt;span class="s"&gt;'train_reward_distribution'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;rd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s"&gt;'train_ep_len'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;avg_ep_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s"&gt;'fill_percent1'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;fill_percent1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s"&gt;'fill_percent2'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;fill_percent2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s"&gt;'test_finish_percent'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;finish_percent&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s"&gt;'test_ep_len'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;avg_time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s"&gt;'test_penalties'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;penalties&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Training finished.&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;evaluate_multi_agent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="s"&gt;"""
    Same as evaluate method discussed in last section, just modified for two independent q-tables.
    """&lt;/span&gt;
    &lt;span class="n"&gt;total_epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total_wins&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;wins&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;done&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c1"&gt;# Modification here
&lt;/span&gt;            &lt;span class="n"&gt;next_action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode_action&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
                &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

            &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_action&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;num_penalties&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;wins&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

            &lt;span class="n"&gt;epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;total_epochs&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;epochs&lt;/span&gt;
        &lt;span class="n"&gt;total_penalties&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;num_penalties&lt;/span&gt;
        &lt;span class="n"&gt;total_wins&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;wins&lt;/span&gt;

    &lt;span class="n"&gt;average_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average_time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;complete_percent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;compute_evaluation_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;total_epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;total_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;total_wins&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;print_evaluation_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;average_penalties&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;average_time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;num_trials&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;total_wins&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;complete_percent&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average_time&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average_penalties&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;





&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="c1"&gt;# The hyperparameter of Q-learning
&lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;
&lt;span class="n"&gt;gamma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt;
&lt;span class="n"&gt;epsilon&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;

&lt;span class="n"&gt;env_c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gym&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'DualTaxi-v1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;competitive&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;num_episodes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50000&lt;/span&gt;
&lt;span class="n"&gt;q_table1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;env_c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;observation_space&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;env_c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;action_space&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))])&lt;/span&gt;
&lt;span class="n"&gt;q_table2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;env_c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;observation_space&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;env_c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;action_space&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))])&lt;/span&gt;
&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metrics_c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_multi_agent&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env_c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;Total encoded states are 6144
==============================
Running evaluation after 0 episodes
Evaluation results after 200 trials
Average time steps taken: 1500.0
Average number of penalties incurred: 1500.0
Had 0 wins in 200 episodes
==============================

----------------------------
Skipping intermediate output
----------------------------


==============================
Running evaluation after 48000 episodes
Evaluation results after 200 trials
Average time steps taken: 323.39
Average number of penalties incurred: 322.44
Had 158 wins in 200 episodes
==============================
Current Episode: 48445
Reward distribution: Counter({-12: 13993, -3: 12754, -4: 11561, -20: 3995, -11: 3972, -30: 1907, -10: 649, -2: 524, 90: 476, 99: 169})
Last 10 episode lengths (avg: 78.08)
8064 Q table 1 zeroes, 78.125 percent filled
8064 Q table 2 zeroes, 78.125 percent filled
==============================
Running evaluation after 49000 episodes
Evaluation results after 200 trials
Average time steps taken: 434.975
Average number of penalties incurred: 434.115
Had 143 wins in 200 episodes
==============================
Current Episode: 49063
Reward distribution: Counter({-3: 13928, -12: 13605, -4: 10286, -11: 4542, -20: 3917, -30: 1874, -10: 665, -2: 575, 90: 433, 99: 175})
Last 10 episode lengths (avg: 75.1)
8064 Q table 1 zeroes, 78.125 percent filled
8064 Q table 2 zeroes, 78.125 percent filled
Current Episode: 49706
Reward distribution: Counter({-12: 13870, -3: 13169, -4: 11054, -11: 4251, -20: 3985, -30: 1810, -10: 704, -2: 529, 90: 436, 99: 192})
Last 10 episode lengths (avg: 76.12)
8064 Q table 1 zeroes, 78.125 percent filled
8064 Q table 2 zeroes, 78.125 percent filled
Training finished.
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;I have skipped the intermediate output on purpose, you can check &lt;a href="https://pastebin.com/ZPKZtjK1"&gt;this pastebin&lt;/a&gt; if you're interested in full output. &lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#evaluating-the-performance"&gt;
  &lt;/a&gt;
  Evaluating the performance
&lt;/h2&gt;

&lt;p&gt;If you observed the code carefully, the train functions returned q-tables as well as some metrics. We can use the q-table now for taking agent's actions, and see how intelligent it has become. Also, we'll try to plot these metrics to visualize how the training progressed.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;defaultdict&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;  
&lt;span class="c1"&gt;# import seaborn as plt
&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="s"&gt;"""
    Plotting various metrics over the number of episodes.
    """&lt;/span&gt;
    &lt;span class="n"&gt;ep_nums&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;series&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;defaultdict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ep_num&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;metric_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metric_val&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
            &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;metric_val&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float64&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                &lt;span class="n"&gt;series&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;metric_name&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;metric_val&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;m_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;series&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ep_nums&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'Number of episodes'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;done&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;next_action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_action&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;play_multi&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="s"&gt;"""
    Capture frames by playing using the two q-tables.
    """&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_episodes&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;done&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;next_action&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode_action&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
                &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
            &lt;span class="n"&gt;state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_action&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;





&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;plot_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--_d7PFUvq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/coop_train_ep_len.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--_d7PFUvq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/coop_train_ep_len.png" alt="png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--4vUu2Fql--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/coop_test_ep_len.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--4vUu2Fql--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/coop_test_ep_len.png" alt="png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--L2zrops0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/coop_fill_percent.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--L2zrops0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/coop_fill_percent.png" alt="png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--FTIadJ3I--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/coop_test_finish_percent.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--FTIadJ3I--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/coop_test_finish_percent.png" alt="png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--imYco__r--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/coop_test_penalties.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--imYco__r--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/coop_test_penalties.png" alt="png"&gt;&lt;/a&gt;&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;frames&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;print_frames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frames&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--ismCs_9W--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/rl-2-cooperative.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ismCs_9W--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/rl-2-cooperative.gif" alt=""&gt;&lt;/a&gt;&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;plot_metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;metrics_c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Vgf_MIS0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/comp_train_ep_len.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Vgf_MIS0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/comp_train_ep_len.png" alt="png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--lWTBWcnl--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/comp_test_ep_len.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--lWTBWcnl--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/comp_test_ep_len.png" alt="png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--ZK6Cqvu5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/comp_fill_percent1.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ZK6Cqvu5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/comp_fill_percent1.png" alt="png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--X64ubyvv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/comp_fill_percent2.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--X64ubyvv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/comp_fill_percent2.png" alt="png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--bAFiAqmn--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/comp_test_finish_percent.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--bAFiAqmn--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/comp_test_finish_percent.png" alt="png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--85gFAzYI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/comp_test_penalties.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--85gFAzYI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/comp_test_penalties.png" alt="png"&gt;&lt;/a&gt;&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;print_frames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;play_multi&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q_table1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q_table2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;env_c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--PchCKrpF--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/rl-4-competitive.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--PchCKrpF--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/rl-4-competitive.gif" alt=""&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#some-observations"&gt;
  &lt;/a&gt;
  Some observations
&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;While Q-learning agent commits errors initially during exploration but once it has explored enough (seen most of the states), it starts to act wisely.&lt;/li&gt;
&lt;li&gt;Both the approaches did fairly well. However, in relative comparison, the cooperative approach seem to perform better. The plots of competitive approach are more volatile. &lt;/li&gt;
&lt;li&gt;It took around 2000 episodes for agents to explore most of the possible state-action pairs. Note that not state-action pairs are feasible because some states aren't legal (for example, states where both the taxis are at same location aren't possible).&lt;/li&gt;
&lt;li&gt;As the training progressed the number of penalties reduced. They didn't reduce completely because of the epsilon (we're still exploring based on the epsilon value during training). &lt;/li&gt;
&lt;li&gt;The episode length kept decreasing, which means the taxis were able to pickup and drop the passenger faster because of the new learned knowledge in q-tables.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So to summarize, the agent is able to get around the walls, pick the passengers, take less penalties, and reach the destination timely. And the fact that the code where q-learning update happens is merely around 20-30 lines of Python code makes it even more impressive.&lt;/p&gt;

&lt;p&gt;From what we've discussed so far in the post, it's likely that you have a fair bit of intution about how Reinforcement Learning works. Now in the last few sections we will dip our toes in some broader level ideas and concepts that might be relevant to you when exploring Reinforcement Learning further. Let's start with the common challenges of Reinforcement Learning first,&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#common-challenges-while-applying-reinforcement-learning"&gt;
  &lt;/a&gt;
  Common challenges while applying Reinforcement learning
&lt;/h2&gt;

&lt;h3&gt;
  &lt;a href="#finiding-the-right-hyperparameters"&gt;
  &lt;/a&gt;
  Finiding the right Hyperparameters
&lt;/h3&gt;

&lt;p&gt;You might be wondering how did I decide values of alpha, gamma, and epsilon. In the above program, it was mostly based on intuition from my past experience and some "hit and trial". This goes a long way, but there are also some techniques to come up with good values. The process in itself is sometimes referred to as Hyperparamter tuning or Hyperparameter optimization.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#tuning-the-hyperparameters"&gt;
  &lt;/a&gt;
  Tuning the hyperparameters
&lt;/h4&gt;

&lt;p&gt;A simple way to programmatically come up with the best set of values of the hyperparameter is to create a comprehensive search function that selects the parameters that would result in best agent performance. A more sophisticated way to get the right combination of hyperparameter values would be to use Genetic Algorithms. Also, it is a common practice to make these parameters dynamic instead of fixed values. For example, in our case, all of the three hyperparmeters can be configured to decrease over time because as the agent continues to learn, it builds up more resilient priors.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#choosing-the-right-algorithms"&gt;
  &lt;/a&gt;
  Choosing the right algorithms
&lt;/h3&gt;

&lt;p&gt;Q-learning is just one of the many Reinformcement Learning algorithms out there. There are multiple ways to classify Reinforcement Learning algorithms. The selection depends on various factors including the nature of the environment. For example, if the state space of action space is continuous instead of discrete (imagine that the environment now expects continuous degree values instead of discrete north / east / etc directions as actions, and the state space consists of more precise lat/lng location of taxis instead of grid coordinates), tabular Q-learning can't work. There are hacks to get around continuous spaces (like bucketing their range and making it discrete as a result), but these hacks fail too if the state space and action space gets too large. In those cases, it is preferred to use more generic algorithms, usually the ones that involve approximators like Neural Networks.&lt;/p&gt;

&lt;p&gt;More often than not, in practice, the agent is trained with multiple algorithms initially to decide which algorithm would fit the best.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#reward-structure"&gt;
  &lt;/a&gt;
  Reward Structure
&lt;/h3&gt;

&lt;p&gt;It is important to think strategically about the rewards to be given to the agent. If the rewards are too sparse, the agent might have difficulty in learning. Poorly structured rewards can also lead to cases of non-convergence and situations in which agent gets stuck in local minima. For example, let's say the environment gave +1 reward for successfully picking up passenger, and no penalty for dropping the passenger. So it might happen, that the agent might end up repeatedly picking up and dropping a passenger to maximise it rewards. Similary, if we there was very high negative reward for picking up passenger, agent would eventually learn to not pick a passenger at all, and hence would never finish successfully.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#the-challenges-of-real-world-environments"&gt;
  &lt;/a&gt;
  The challenges of real world environments
&lt;/h3&gt;

&lt;p&gt;Training an agent on an openAI gym environment is realtively easy because you get a lot of things out of the box. The real world, however, is a bit more unorganised. We sensors to ingest environment information and mechanism to translate it into something that can be fed to a Machine Learning algorithm. So such systems involve a lots of techniques overall aside from the learning algorithm. As a simple example, consider a general Reinforcement Learning agent that is being trained to play ATARI games. The information this agent needs to be passed is pixels on the screen. So we might have to use deep learning techniques (like Convolutional Neural Networks) to interpret the pixels on the screen and extract information out of the game (like scores) to enable the agent to interpret the game.&lt;/p&gt;

&lt;p&gt;There's also a challenge of sample efficiency. Since the state spaces and action spaces might be continuous and have big ranges, it becomes critical to achieve a decent sample efficiency that makes Reinforcement Learning feasible. If the algorithm needs high number of episodes (high enough that we cannot make it to produce results in reasonable amount of time), then Reinforcement Learning becomes impractical. &lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#respecting-the-theoretical-boundaries"&gt;
  &lt;/a&gt;
  Respecting the theoretical boundaries
&lt;/h3&gt;

&lt;p&gt;It is easy to sometimes get carried away and see Reinforcement Learning to be the solution of most problems. It helps to have a theoretical understanding of how these algorithm works and fundamental concepts like &lt;a href="https://en.wikipedia.org/wiki/Markov_decision_process"&gt;Markov Decision Processes&lt;/a&gt; and awareness of the state of the art algorithms to have a better intution about what can and what can't be solved using present-day Reinforcement Learning algorithms.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#wrapping-up"&gt;
  &lt;/a&gt;
  Wrapping up
&lt;/h2&gt;

&lt;p&gt;In this tutorial, we began with understanding Reinforcement Learning with the help of real-world analogies. Then  we learned about some fundamental conepts like state, action, and rewards. Next, we went over the process of framing a problem such that we can traing an agent through Reinforcement Learning algorithms to solve it.&lt;/p&gt;

&lt;p&gt;We took Self-driving taxi as our reference problem for the rest of the tutorial. We then used OpenAL's gym module in python to provide us with a related environment, where we can develop our agent and evaluate it. Then we observed how terrible our agent was without using any algorithm to play the game, so we went ahead to implement the Q-learning algorithm from scratch. &lt;/p&gt;

&lt;p&gt;We then introduced Q-learning, and went over the steps to use it for our environment. We came up with two approaches (cooperative and competitive). We then evaluated the Q-learning results, and saw how the agent's performance improved significantly after Q-learning.&lt;/p&gt;

&lt;p&gt;As mentioned in beginning, Reinforcement learning is not just limited to openAI gym environments and games. It is also used for managing portfolio and finances, for making humanoid robots, for manufacturing and inventory management, to develop general AI agents (agents that can perform multiple things with a single algorithm, like same agent playing multiple Atari games).&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#appendix"&gt;
  &lt;/a&gt;
  Appendix
&lt;/h2&gt;

&lt;h3&gt;
  &lt;a href="#further-reading"&gt;
  &lt;/a&gt;
  Further reading
&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;"Reinforcement Learning: An Introduction" Book by Andrew Barto and Richard S. Sutton. Most popular book about Reinforcement Learning out there. Highly recommended if you're planning to dive deep into the field. &lt;/li&gt;
&lt;li&gt;Lectures by David Silver (also available on &lt;a href="https://www.youtube.com/watch?v=2pWv7GOvuf0&amp;amp;list=PLqYmG7hTraZBiG_XpjnPrSNw-1XQaM_gB&amp;amp;index=3"&gt;YouTube&lt;/a&gt;). Another great resource if you're more into learning from videos than books.&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0"&gt;Tutorial series on medium&lt;/a&gt; on Reinforcement learning using Tensorflow by Arthur Juliani.&lt;/li&gt;
&lt;li&gt;Some interesting topics related to Multi Agent environments,

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.researchgate.net/publication/2933305_Friend-or-Foe_Q-learning_in_General-Sum_Games"&gt;Friend and foe Q-learning in general-sum games&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Game theory concepts like&lt;/li&gt;
&lt;li&gt;Strictly dominant strategies&lt;/li&gt;
&lt;li&gt;Nash equilibrium&lt;/li&gt;
&lt;li&gt;Shapely values for reward distribution&lt;/li&gt;
&lt;/ul&gt;


&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#visualising-the-transition-table-of-our-dual-taxi-enviroment"&gt;
  &lt;/a&gt;
  Visualising the transition table of our dual taxi enviroment
&lt;/h3&gt;

&lt;p&gt;The following is an attempt to visualize the internal tranistion table of our environment in a human readable way. The source of this information is the &lt;code&gt;env.P&lt;/code&gt; object which contains a mapping of the form&lt;/p&gt;

&lt;p&gt;&lt;code&gt;current_state : action_taken: [(transition_prob, next_state, reward, done)]&lt;/code&gt;, this is all the info we need to simulate the environment and this is what we can use to create the transition table.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt; &lt;span class="c1"&gt;# First let's take a peek at this object
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;





&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;{0: {
    0: [(1.0, 0, -30, False)],
  1: [(1.0, 1536, -0.5, True)],
  2: [(1.0, 1560, -0.5, True)],
  3: [(1.0, 1536, -0.5, True)],
  4: [(1.0, 1536, -0.5, True)],
  5: [(1.0, 1536, -0.5, True)],
  6: [(1.0, 96, -0.5, True)],
  7: [(1.0, 0, -30, False)],
  8: [(1.0, 24, -0.5, True)],
  9: [(1.0, 0, -30, False)],
  10: [(1.0, 0, -30, False)],
  11: [(1.0, 0, -30, False)],
  12: [(1.0, 480, -0.5, True)],
  13: [(1.0, 384, -0.5, True)],
  14: [(1.0, 0, -30, False)],
  15: [(1.0, 384, -0.5, True)],
  16: [(1.0, 384, -0.5, True)],
  17: [(1.0, 384, -0.5, True)],
  18: [(1.0, 96, -0.5, True)],
  19: [(1.0, 0, -30, False)],
  20: [(1.0, 24, -0.5, True)],
  21: [(1.0, 0, -30, False)],
  22: [(1.0, 0, -30, False)],
  23: [(1.0, 0, -30, False)],
  24: [(1.0, 96, -0.5, True)],
  25: [(1.0, 0, -30, False)],
  26: [(1.0, 24, -0.5, True)],
  27: [(1.0, 0, -30, False)],
  28: [(1.0, 0, -30, False)],
  29: [(1.0, 0, -30, False)],
  30: [(1.0, 96, -0.5, True)],
  31: [(1.0, 0, -30, False)],
  32: [(1.0, 24, -0.5, True)],
  33: [(1.0, 0, -30, False)],
  34: [(1.0, 0, -30, False)],
  35: [(1.0, 0, -30, False)]},
 1: {0: [(1.0, 1, -30, False)],
  1: [(1.0, 1537, -0.5, True)],
  2: [(1.0, 1561, -0.5, True)],
  3: [(1.0, 1537, -0.5, True)],
  4: [(1.0, 1537, -0.5, True)],
  5: [(1.0, 1537, -0.5, True)],
  6: [(1.0, 97, -0.5, True)],
  7: [(1.0, 1, -30, False)],
  8: [(1.0, 25, -0.5, True)],
  9: [(1.0, 1, -30, False)],
  10: [(1.0, 1, -30, False)],
  11: [(1.0, 1, -30, False)],
  12: [(1.0, 481, -0.5, True)],
  13: [(1.0, 385, -0.5, True)],
  14: [(1.0, 1, -30, False)],
  15: [(1.0, 385, -0.5, True)],
  16: [(1.0, 385, -0.5, True)],
  17: [(1.0, 385, -0.5, True)],
  18: [(1.0, 97, -0.5, True)],
  19: [(1.0, 1, -30, False)],
  20: [(1.0, 25, -0.5, True)],
  21: [(1.0, 1, -30, False)],
  22: [(1.0, 1, -30, False)],
  23: [(1.0, 1, -30, False)],
  24: [(1.0, 97, -0.5, True)],
  25: [(1.0, 1, -30, False)],
  26: [(1.0, 25, -0.5, True)],
  27: [(1.0, 1, -30, False)],
  28: [(1.0, 1, -30, False)],
  29: [(1.0, 1, -30, False)],
  30: [(1.0, 97, -0.5, True)],
  31: [(1.0, 1, -30, False)],
  32: [(1.0, 25, -0.5, True)],
  33: [(1.0, 1, -30, False)],
  34: [(1.0, 1, -30, False)],
  35: [(1.0, 1, -30, False)]},
# omitting the whole output because it's very long! 
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now, let's put some code together to convert this information in more readable tabular form.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="err"&gt;!&lt;/span&gt; &lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;





&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;
&lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

&lt;span class="n"&gt;env_c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gym&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'DualTaxi-v1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;competitive&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;state_to_human_readable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;passenger_loc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'R'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'G'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'B'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'Y'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'T1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'T2'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
    &lt;span class="n"&gt;destination&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'R'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'G'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'B'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'Y'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'Taxi 1: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt;, Taxi 2: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt;, Pass: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;passenger_loc&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt;, Dest: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;destination&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;action_to_human_readable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;actions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;'NSEWPD'&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;actions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;actions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;state_num&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transition_info&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;env_c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;possible_transitions&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;transition_info&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;transition_prob&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;possible_transitions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
            &lt;span class="s"&gt;'State'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;state_to_human_readable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;state_num&lt;/span&gt;&lt;span class="p"&gt;))),&lt;/span&gt;
            &lt;span class="s"&gt;'Action'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;action_to_human_readable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode_action&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
            &lt;span class="s"&gt;'Probablity'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;transition_prob&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s"&gt;'Next State'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;state_to_human_readable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_state&lt;/span&gt;&lt;span class="p"&gt;))),&lt;/span&gt;
            &lt;span class="s"&gt;'Reward'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;reward&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s"&gt;'Is over'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;div class="table-wrapper-paragraph"&gt;&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;State&lt;/th&gt;
      &lt;th&gt;Action&lt;/th&gt;
      &lt;th&gt;Probablity&lt;/th&gt;
      &lt;th&gt;Next State&lt;/th&gt;
      &lt;th&gt;Reward&lt;/th&gt;
      &lt;th&gt;Is over&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Taxi 1: (0, 0), Taxi 2: (0, 0), Pass: R, Dest: R&lt;/td&gt;
      &lt;td&gt;(N, N)&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;Taxi 1: (0, 0), Taxi 2: (0, 0), Pass: R, Dest: R&lt;/td&gt;
      &lt;td&gt;(-15, -15)&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Taxi 1: (0, 0), Taxi 2: (0, 0), Pass: R, Dest: R&lt;/td&gt;
      &lt;td&gt;(N, S)&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;Taxi 1: (1, 0), Taxi 2: (0, 0), Pass: R, Dest: R&lt;/td&gt;
      &lt;td&gt;(-0.5, 0)&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Taxi 1: (0, 0), Taxi 2: (0, 0), Pass: R, Dest: R&lt;/td&gt;
      &lt;td&gt;(N, E)&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;Taxi 1: (1, 0), Taxi 2: (0, 1), Pass: R, Dest: R&lt;/td&gt;
      &lt;td&gt;(-0.5, 0)&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Taxi 1: (0, 0), Taxi 2: (0, 0), Pass: R, Dest: R&lt;/td&gt;
      &lt;td&gt;(N, W)&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;Taxi 1: (1, 0), Taxi 2: (0, 0), Pass: R, Dest: R&lt;/td&gt;
      &lt;td&gt;(-0.5, 0)&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Taxi 1: (0, 0), Taxi 2: (0, 0), Pass: R, Dest: R&lt;/td&gt;
      &lt;td&gt;(N, P)&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;Taxi 1: (1, 0), Taxi 2: (0, 0), Pass: R, Dest: R&lt;/td&gt;
      &lt;td&gt;(-0.5, 0)&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;...&lt;/th&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
      &lt;td&gt;...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;221179&lt;/th&gt;
      &lt;td&gt;Taxi 1: (3, 3), Taxi 2: (3, 3), Pass: T2, Dest: Y&lt;/td&gt;
      &lt;td&gt;(D, S)&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;Taxi 1: (3, 3), Taxi 2: (2, 3), Pass: T2, Dest: Y&lt;/td&gt;
      &lt;td&gt;(-0.5, 0)&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;221180&lt;/th&gt;
      &lt;td&gt;Taxi 1: (3, 3), Taxi 2: (3, 3), Pass: T2, Dest: Y&lt;/td&gt;
      &lt;td&gt;(D, E)&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;Taxi 1: (3, 3), Taxi 2: (3, 3), Pass: T2, Dest: Y&lt;/td&gt;
      &lt;td&gt;(-15, -15)&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;221181&lt;/th&gt;
      &lt;td&gt;Taxi 1: (3, 3), Taxi 2: (3, 3), Pass: T2, Dest: Y&lt;/td&gt;
      &lt;td&gt;(D, W)&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;Taxi 1: (3, 3), Taxi 2: (3, 2), Pass: T2, Dest: Y&lt;/td&gt;
      &lt;td&gt;(-0.5, 0)&lt;/td&gt;
      &lt;td&gt;True&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;221182&lt;/th&gt;
      &lt;td&gt;Taxi 1: (3, 3), Taxi 2: (3, 3), Pass: T2, Dest: Y&lt;/td&gt;
      &lt;td&gt;(D, P)&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;Taxi 1: (3, 3), Taxi 2: (3, 3), Pass: T2, Dest: Y&lt;/td&gt;
      &lt;td&gt;(-15, -15)&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;221183&lt;/th&gt;
      &lt;td&gt;Taxi 1: (3, 3), Taxi 2: (3, 3), Pass: T2, Dest: Y&lt;/td&gt;
      &lt;td&gt;(D, D)&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;Taxi 1: (3, 3), Taxi 2: (3, 3), Pass: T2, Dest: Y&lt;/td&gt;
      &lt;td&gt;(-15, -15)&lt;/td&gt;
      &lt;td&gt;False&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;&lt;/div&gt;

&lt;p&gt;221184 rows √ó 6 columns&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#bloopers"&gt;
  &lt;/a&gt;
  Bloopers
&lt;/h3&gt;

&lt;p&gt;In retrospect, the hardest part of writing this post was to get the dual-taxi-environment working. There were so many moments like below,&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--9hQk2Ugx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/rl-3-blooper.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--9hQk2Ugx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://github.com/satwikkansal/gym-dual-taxi/raw/master/static/rl-3-blooper.gif" alt=""&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It took a lot of trial and errors (tweaking rewards, updating rules for situations like collision, reducing state space) to get to a stage where the solutions for competitive set up were converging. The feeling when the solution converges for the first time is very cool. So if you have some free time, I'd recommend you to hack up an environment yourself (the first time I tried q-learning was with a snake-apple game I developed using pygame), and try to solve it with Reinforcement Learning. Trust me, you'll be humbled and learn lots of interesting things along the way! &lt;/p&gt;

</description>
      <category>python</category>
      <category>machinelearning</category>
      <category>reinforcementlearning</category>
      <category>openai</category>
    </item>
    <item>
      <title>How to Build a Stock Trading Bot with Python</title>
      <author>Saji Wang</author>
      <pubDate>Fri, 09 Jul 2021 14:21:16 +0000</pubDate>
      <link>https://dev.to/codesphere/how-to-build-a-stock-trading-bot-with-python-b1</link>
      <guid>https://dev.to/codesphere/how-to-build-a-stock-trading-bot-with-python-b1</guid>
      <description>&lt;p&gt;Earlier this week, we explored how code has drastically changed financial markets through the use of autonomous trading algorithms. Surprisingly, building your own trading bot is actually not that difficult!¬†&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In this tutorial, we're going to be using Python to build our own trading bot.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Keep in mind that this tutorial is not about how to make billions off of your trading bot. If I had an algorithm that sophisticated I probably wouldn't be giving it away. Rather, I'm going to show you how you can read market data, buy and sell stocks, and program the logic of your trading algorithm, all with some relatively simple Python code.&lt;/p&gt;

&lt;p&gt;And of course:&lt;br&gt;
&lt;em&gt;This article is for information purposes only. It is not intended to be investment advice. Seek a duly licensed professional for investment advice.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;You can open up a quick demo of the project on Codesphere here:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://link.codesphere.com/AX"&gt;https://codesphere.com/#https://github.com/LiorB-D/TradingBot&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, you will need an API key before you can actually start trading with our bot‚Ää-‚ÄäMore on that later.&lt;/p&gt;


&lt;h3&gt;
  &lt;a href="#some-helpful%C2%A0terms"&gt;
  &lt;/a&gt;
  Some Helpful¬†Terms
&lt;/h3&gt;

&lt;p&gt;Before we get started, it'll be helpful to define a couple of terms:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Paper Trading: The trading of securities with fake money for educational or testing purposes.&lt;/li&gt;
&lt;li&gt;Backtesting: Testing a trading algorithm against past market data in order to evaluate its effectiveness.&lt;/li&gt;
&lt;li&gt;Moving Average: The average of a certain amount of recent entries in a set of data.&lt;/li&gt;
&lt;li&gt;S&amp;amp;P 500: A stock market index composed of the 500 largest companies listed on US stock exchanges&lt;/li&gt;
&lt;li&gt;Closing Price: The final price of a security during a unit of time&lt;/li&gt;
&lt;li&gt;Good 'Til Cancel (GTC): When you place a trade, it may not be met right away. A broker will continue to try and execute a GTC trade until you cancel it.&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;
  &lt;a href="#setup"&gt;
  &lt;/a&gt;
  Setup
&lt;/h3&gt;

&lt;p&gt;The trading API we're going to be using is called Alpaca and is by far one of the most intuitive trading APIs I've found.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://alpaca.markets/"&gt;https://alpaca.markets/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In its free tier, Alpaca includes both Paper and Real Trading and both Historical and Live market data. It also has an incredibly clean user interface and Python library.&lt;/p&gt;

&lt;p&gt;In addition, unless you're willing to leave your python script running on your computer, you're going to need to deploy your trading bot in the cloud. For this, we're going to use Codesphere:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://link.codesphere.com/BA"&gt;https://codesphere.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Since Codesphere's front-end is an IDE, we can develop our bot directly on the platform. If you wish to do the coding on your local machine, however, you can connect your GitHub repo to Codesphere and deploy afterward.&lt;/p&gt;

&lt;p&gt;The only environment setup we really need before we can start coding is to create our pip environment:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;pipenv shell&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;And then install the Alpaca API&lt;/p&gt;

&lt;p&gt;&lt;code&gt;pipenv install alpaca_trade_api&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;We are also going to need to make a free Alpaca account and then navigate to our Paper Trading Account.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--GeGaprxi--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/84vieolvwgujbvn7gewz.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--GeGaprxi--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/84vieolvwgujbvn7gewz.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Notice your API Key on the right-hand side. When you first open your account, you will be prompted to generate a key and both public and private key will be shown to you. We're going to need those for later.&lt;/p&gt;
&lt;h3&gt;
  &lt;a href="#buying-and-selling%C2%A0stocks"&gt;
  &lt;/a&gt;
  Buying and Selling¬†Stocks
&lt;/h3&gt;

&lt;p&gt;We can then set up our Alpaca Trading library and buy and sell stocks in Python like so:&lt;/p&gt;


&lt;div class="ltag_gist-liquid-tag"&gt;
  
&lt;/div&gt;


&lt;h3&gt;
  &lt;a href="#our-strategy"&gt;
  &lt;/a&gt;
  Our Strategy
&lt;/h3&gt;

&lt;p&gt;The strategy we're going to use is to buy and sell whenever the 5 minute moving average crosses our price. Now, this is FAR from a good trading strategy, but the logic is relatively simple and will allow us to focus on the general structure of a trading bot.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--vZUzumsu--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uex5g9bbczw0jl1l6vzy.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--vZUzumsu--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uex5g9bbczw0jl1l6vzy.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the above example, the red line is the stock price and the blue line is the moving average. When the moving average crosses under our price, we are going to buy a share of our stock. We are then going to hold the stock until the moving average crosses again and goes above the price. When that happens we are going to sell our share, and then wait for the next buying signal.&lt;/p&gt;

&lt;p&gt;In this article, we'll be trading SPY, which is an index that tracks the S&amp;amp;P 500, and we will only be trading one stock at a time.&lt;/p&gt;

&lt;p&gt;Keep in mind that if you were to make these trades with real money, you would have to comply with day trading regulations and brokerage fees, which would likely offset your gains.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#reading-market%C2%A0data"&gt;
  &lt;/a&gt;
  Reading Market¬†Data
&lt;/h3&gt;

&lt;p&gt;Now let's go over how to read market data using the Alpaca API in Python:&lt;/p&gt;


&lt;div class="ltag_gist-liquid-tag"&gt;
  
&lt;/div&gt;


&lt;p&gt;If you're looking for more in-depth information for when you build your strategy, check out Alpaca's documentation:&lt;br&gt;
&lt;a href="https://alpaca.markets/docs/api-documentation/api-v2/market-data/alpaca-data-api-v2/"&gt;https://alpaca.markets/docs/api-documentation/api-v2/market-data/alpaca-data-api-v2/&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;
  &lt;a href="#executing-our%C2%A0strategy"&gt;
  &lt;/a&gt;
  Executing Our¬†Strategy
&lt;/h3&gt;

&lt;p&gt;Now let's finally put all of this together for our complete trading algorithm:&lt;/p&gt;


&lt;div class="ltag_gist-liquid-tag"&gt;
  
&lt;/div&gt;


&lt;p&gt;And there we have it! We just built a trading bot in 54 lines of code! Now if we leave this running on Codesphere throughout the day, we should see our Alpaca dashboard update throughout the day:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--vZUzumsu--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uex5g9bbczw0jl1l6vzy.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--vZUzumsu--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uex5g9bbczw0jl1l6vzy.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#backtesting-a%C2%A0strategy"&gt;
  &lt;/a&gt;
  Backtesting a¬†Strategy
&lt;/h3&gt;

&lt;p&gt;Now if you don't want to wait around to see if your algorithm is any good, we can use Alpaca's market data API to backtest our Python algorithm against historical data:&lt;/p&gt;


&lt;div class="ltag_gist-liquid-tag"&gt;
  
&lt;/div&gt;


&lt;h3&gt;
  &lt;a href="#next-steps"&gt;
  &lt;/a&gt;
  Next Steps
&lt;/h3&gt;

&lt;p&gt;So there you have it, we just created a rudimentary trading bot with some fairly simple Python!&lt;/p&gt;

&lt;p&gt;Here is the full repo:&lt;br&gt;
&lt;a href="https://github.com/LiorB-D/TradingBot"&gt;https://github.com/LiorB-D/TradingBot&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;While I highly encourage you guys to play around with the Alpaca API for educational purposes, be extremely careful if you are going to trade real securities. One bug in your code could have disastrous effects on your bank account.&lt;br&gt;
On a lighter note, this is a great opportunity to put those statistics classes you took to work.&lt;/p&gt;




&lt;p&gt;Comment down below if you're going to build your own trading algorithm!&lt;/p&gt;

&lt;p&gt;Happy Coding from your folks at Codesphere, the next generation cloud provider&lt;/p&gt;

</description>
      <category>python</category>
      <category>tutorial</category>
      <category>webdev</category>
      <category>programming</category>
    </item>
    <item>
      <title>New to node.js and struggling with socket.io</title>
      <author>Fletcher Moore</author>
      <pubDate>Fri, 09 Jul 2021 14:02:10 +0000</pubDate>
      <link>https://dev.to/fletch0132/new-to-node-js-and-struggling-with-socket-io-o75</link>
      <guid>https://dev.to/fletch0132/new-to-node-js-and-struggling-with-socket-io-o75</guid>
      <description>&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;Nervous first post but really need some help. I'm working on a Web application for p2p communication (both video and text). &lt;/p&gt;

&lt;p&gt;The video communication works (some teething issues), but my main issue is getting user socket.id. specifically the user just having connected.&lt;/p&gt;

&lt;p&gt;I have tried many things including:&lt;br&gt;
Socket.on("connected", () {&lt;br&gt;
console.log(socket.id);&lt;br&gt;
});&lt;/p&gt;

&lt;p&gt;All I get is "undefined". Yet if I run te same console.log code after the page loads I can get it displayed.&lt;/p&gt;

&lt;p&gt;Not sure how to work with that.&lt;/p&gt;

&lt;p&gt;I want to store the socket.id and username in an object/array &lt;/p&gt;

&lt;p&gt;Thank you &lt;/p&gt;

</description>
      <category>node</category>
      <category>javascript</category>
      <category>webdev</category>
      <category>webrtc</category>
    </item>
    <item>
      <title>üöÄ10 Trending projects on GitHub for web developers - 9th July 2021</title>
      <author>Iain Freestone</author>
      <pubDate>Fri, 09 Jul 2021 13:49:33 +0000</pubDate>
      <link>https://dev.to/iainfreestone/10-trending-projects-on-github-for-web-developers-9th-july-2021-5gl6</link>
      <guid>https://dev.to/iainfreestone/10-trending-projects-on-github-for-web-developers-9th-july-2021-5gl6</guid>
      <description>&lt;p&gt;Trending Projects is available as a weekly newsletter please sign up at &lt;a href="https://www.iainfreestone.com"&gt;www.iainfreestone.com&lt;/a&gt; to ensure you never miss an issue.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#1-machine-learning-for-beginners"&gt;
  &lt;/a&gt;
  1. Machine Learning for Beginners
&lt;/h3&gt;

&lt;p&gt;12 weeks, 24 lessons, classic Machine Learning for all.&lt;/p&gt;


&lt;div class="ltag-github-readme-tag"&gt;
  &lt;div class="readme-overview"&gt;
    &lt;h2&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i3JOwpme--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/github-logo-ba8488d21cd8ee1fee097b8410db9deaa41d0ca30b004c0c63de0a479114156f.svg" alt="GitHub logo"&gt;
      &lt;a href="https://github.com/microsoft"&gt;
        microsoft
      &lt;/a&gt; / &lt;a href="https://github.com/microsoft/ML-For-Beginners"&gt;
        ML-For-Beginners
      &lt;/a&gt;
    &lt;/h2&gt;
    &lt;h3&gt;
      12 weeks, 24 lessons, classic Machine Learning for all
    &lt;/h3&gt;
  &lt;/div&gt;
  &lt;div class="ltag-github-body"&gt;
    
&lt;div id="readme" class="md"&gt;
&lt;p&gt;&lt;a href="https://github.com/microsoft/ML-For-Beginners/blob/master/LICENSE"&gt;&lt;img src="https://camo.githubusercontent.com/5de80cbb57075704e04fe747ad3ad191aa6f34c131df08e56c0d64fd87abcfe8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6963726f736f66742f4d4c2d466f722d426567696e6e6572732e737667" alt="GitHub license"&gt;&lt;/a&gt;
&lt;a href="https://GitHub.com/microsoft/ML-For-Beginners/graphs/contributors/"&gt;&lt;img src="https://camo.githubusercontent.com/5928183d1e2b214910584f0a1a33cef45a70531548904b2257343e04d0b94249/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6e7472696275746f72732f6d6963726f736f66742f4d4c2d466f722d426567696e6e6572732e737667" alt="GitHub contributors"&gt;&lt;/a&gt;
&lt;a href="https://GitHub.com/microsoft/ML-For-Beginners/issues/"&gt;&lt;img src="https://camo.githubusercontent.com/aab9f79d64b8b1bf143c160c806b5c79f6cee50240592502c57f312113f7383f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f6d6963726f736f66742f4d4c2d466f722d426567696e6e6572732e737667" alt="GitHub issues"&gt;&lt;/a&gt;
&lt;a href="https://GitHub.com/microsoft/ML-For-Beginners/pulls/"&gt;&lt;img src="https://camo.githubusercontent.com/0a604cca2c6363c6af0501543ef3a6565b7b82fd2ff894be8e417cf8db7d27c3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f6d6963726f736f66742f4d4c2d466f722d426567696e6e6572732e737667" alt="GitHub pull-requests"&gt;&lt;/a&gt;
&lt;a href="http://makeapullrequest.com" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/0ff11ed110cfa69f703ef0dcca3cee6141c0a8ef465e8237221ae245de3deb3d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e7376673f7374796c653d666c61742d737175617265" alt="PRs Welcome"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/ML-For-Beginners/watchers/"&gt;&lt;img src="https://camo.githubusercontent.com/de9e0a6feb4334207b106185b7867b42c3d9fc189bc4adaf0b5733c93535353d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f77617463686572732f6d6963726f736f66742f4d4c2d466f722d426567696e6e6572732e7376673f7374796c653d736f6369616c266c6162656c3d5761746368" alt="GitHub watchers"&gt;&lt;/a&gt;
&lt;a href="https://GitHub.com/microsoft/ML-For-Beginners/network/"&gt;&lt;img src="https://camo.githubusercontent.com/fd710b83bb546a380eb15d0d154fcf63736a675d1736a3cd8825e638eb882502/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f6d6963726f736f66742f4d4c2d466f722d426567696e6e6572732e7376673f7374796c653d736f6369616c266c6162656c3d466f726b" alt="GitHub forks"&gt;&lt;/a&gt;
&lt;a href="https://GitHub.com/microsoft/ML-For-Beginners/stargazers/"&gt;&lt;img src="https://camo.githubusercontent.com/cfd66469d198134664186871e4dbf0d45d4c3904e9ad51f553d55080d55b5af2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6d6963726f736f66742f4d4c2d466f722d426567696e6e6572732e7376673f7374796c653d736f6369616c266c6162656c3d53746172" alt="GitHub stars"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;
Machine Learning for Beginners - A Curriculum&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;üåç Travel around the world as we explore Machine Learning by means of world cultures üåç&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Azure Cloud Advocates at Microsoft are pleased to offer a 12-week, 24-lesson curriculum all about &lt;strong&gt;Machine Learning&lt;/strong&gt;. In this curriculum, you will learn about what is sometimes called &lt;strong&gt;classic machine learning&lt;/strong&gt;, using primarily Scikit-learn as a library and avoiding deep learning, which is covered in our forthcoming 'AI for Beginners' curriculum. Pair these lessons with our forthcoming 'Data Science for Beginners' curriculum, as well!&lt;/p&gt;
&lt;p&gt;Travel with us around the world as we apply these classic techniques to data from many areas of the world. Each lesson includes pre- and post-lesson quizzes, written instructions to complete the lesson, a solution, an assignment and more. Our project-based pedagogy allows you to learn while building, a proven way for new skills to 'stick'.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;‚úçÔ∏è Hearty thanks to our&lt;/strong&gt;‚Ä¶&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="gh-btn-container"&gt;&lt;a class="gh-btn" href="https://github.com/microsoft/ML-For-Beginners"&gt;View on GitHub&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;





&lt;h3&gt;
  &lt;a href="#2-petitevue"&gt;
  &lt;/a&gt;
  2. petite-vue
&lt;/h3&gt;

&lt;p&gt;petite-vue is an 5kb subset alternative distribution of Vue optimized for progressive enhancement. It provides the same template syntax and reactivity mental model with standard Vue. However, it is specifically optimized for "sprinkling" small amount of interactions on an existing HTML page rendered by a server framework&lt;/p&gt;


&lt;div class="ltag-github-readme-tag"&gt;
  &lt;div class="readme-overview"&gt;
    &lt;h2&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i3JOwpme--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/github-logo-ba8488d21cd8ee1fee097b8410db9deaa41d0ca30b004c0c63de0a479114156f.svg" alt="GitHub logo"&gt;
      &lt;a href="https://github.com/vuejs"&gt;
        vuejs
      &lt;/a&gt; / &lt;a href="https://github.com/vuejs/petite-vue"&gt;
        petite-vue
      &lt;/a&gt;
    &lt;/h2&gt;
    &lt;h3&gt;
      5kb subset of Vue optimized for progressive enhancement
    &lt;/h3&gt;
  &lt;/div&gt;
  &lt;div class="ltag-github-body"&gt;
    
&lt;div id="readme" class="md"&gt;
&lt;h1&gt;
petite-vue&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;petite-vue&lt;/code&gt; is an alternative distribution of Vue optimized for progressive enhancement. It provides the same template syntax and reactivity mental model with standard Vue. However, it is specifically optimized for "sprinkling" small amount of interactions on an existing HTML page rendered by a server framework. See more details in &lt;a href="https://raw.githubusercontent.com/vuejs/petite-vue/main/#comparison-with-standard-vue"&gt;how it differs from standard Vue&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Only ~5.8kb&lt;/li&gt;
&lt;li&gt;Vue-compatible template syntax&lt;/li&gt;
&lt;li&gt;DOM-based, mutates in place&lt;/li&gt;
&lt;li&gt;Driven by &lt;code&gt;@vue/reactivity&lt;/code&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;
Status&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;This is pretty new. There are probably bugs and there might still be API changes, so &lt;strong&gt;use at your own risk.&lt;/strong&gt; Is it usable though? Very much. Check out the &lt;a href="https://github.com/vuejs/petite-vue/tree/main/examples"&gt;examples&lt;/a&gt; to see what it's capable of.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The issue list is intentionally disabled because I have higher priority things to focus on for now and don't want to be distracted. If you found a bug, you'll have to either workaround it or submit a PR to fix it yourself. That‚Ä¶&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="gh-btn-container"&gt;&lt;a class="gh-btn" href="https://github.com/vuejs/petite-vue"&gt;View on GitHub&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;





&lt;h3&gt;
  &lt;a href="#3-milkdown"&gt;
  &lt;/a&gt;
  3. Milkdown
&lt;/h3&gt;

&lt;p&gt;Plugin driven WYSIWYG markdown editor.&lt;/p&gt;


&lt;div class="ltag-github-readme-tag"&gt;
  &lt;div class="readme-overview"&gt;
    &lt;h2&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i3JOwpme--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/github-logo-ba8488d21cd8ee1fee097b8410db9deaa41d0ca30b004c0c63de0a479114156f.svg" alt="GitHub logo"&gt;
      &lt;a href="https://github.com/Saul-Mirone"&gt;
        Saul-Mirone
      &lt;/a&gt; / &lt;a href="https://github.com/Saul-Mirone/milkdown"&gt;
        milkdown
      &lt;/a&gt;
    &lt;/h2&gt;
    &lt;h3&gt;
      üçº Plugin driven WYSIWYG  markdown editor.
    &lt;/h3&gt;
  &lt;/div&gt;
  &lt;div class="ltag-github-body"&gt;
    
&lt;div id="readme" class="md"&gt;
&lt;h1&gt;
&lt;a rel="noopener noreferrer" href="https://raw.githubusercontent.com/Saul-Mirone/milkdown/main//gh-pages/public/milkdown-mini.svg"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--y7TdPbuw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/Saul-Mirone/milkdown/main/gh-pages/public/milkdown-mini.svg" height="30px"&gt;&lt;/a&gt; Milkdown&lt;/h1&gt;
&lt;div&gt;
    &lt;a rel="noopener noreferrer" href="https://raw.githubusercontent.com/Saul-Mirone/milkdown/main//gh-pages/public/milkdown-homepage.svg"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--AJlT59_Z--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/Saul-Mirone/milkdown/main/gh-pages/public/milkdown-homepage.svg"&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;A plugin-driven WYSIWYG markdown Editor, inspired by &lt;a href="https://typora.io/" rel="nofollow"&gt;Typora&lt;/a&gt;, built on top of &lt;a href="https://prosemirror.net/" rel="nofollow"&gt;prosemirror&lt;/a&gt; and &lt;a href="https://github.com/remarkjs/remark"&gt;remark&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Designed by Meo.&lt;/p&gt;
&lt;h1&gt;
Documentation&lt;/h1&gt;
&lt;p&gt;For more information, please check our &lt;a href="https://saul-mirone.github.io/milkdown/" rel="nofollow"&gt;official documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;
What's Next&lt;/h1&gt;
&lt;p&gt;You can check our &lt;a href="https://github.com/Saul-Mirone/milkdown/projects/1"&gt;Milkdown TODO&lt;/a&gt; project page to know what's on the plan.&lt;/p&gt;
&lt;h1&gt;
Contributor&lt;/h1&gt;
&lt;p&gt;&lt;a title="Saul-Mirone" href="https://github.com/Saul-Mirone"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--6040WrNP--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://avatars.githubusercontent.com/u/10047788%3Fv%3D4" width="100" alt="profile picture of Saul Mirone"&gt;&lt;/a&gt;
&lt;a title="xia" href="https://github.com/xiadd"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--aw8-Kbnw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://avatars.githubusercontent.com/u/8351437%3Fv%3D4" width="100" alt="profile picture of xiadd"&gt;&lt;/a&gt;
&lt;a title="kitty" href="https://github.com/Kitty0730"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--arMHWykr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://avatars.githubusercontent.com/u/14139395%3Fv%3D4" width="100" alt="profile picture of kitty"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;
Sponsors&lt;/h1&gt;
&lt;p&gt;If you like this project, please consider fund me to help the maintenance.&lt;/p&gt;
&lt;p&gt;&lt;a title="Johno Scott" href="https://github.com/johnoscott"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--WsqwT1u1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://avatars.githubusercontent.com/u/291958%3Fv%3D4" width="100" alt="profile picture of Johno Scott"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;
License&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Saul-Mirone/milkdown/main//LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;



&lt;/div&gt;
&lt;br&gt;
  &lt;div class="gh-btn-container"&gt;&lt;a class="gh-btn" href="https://github.com/Saul-Mirone/milkdown"&gt;View on GitHub&lt;/a&gt;&lt;/div&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;





&lt;h3&gt;
  &lt;a href="#4-fronts"&gt;
  &lt;/a&gt;
  4. Fronts
&lt;/h3&gt;

&lt;p&gt;Fronts is a progressive micro frontends framework for building Web applications, and it's based on the module federation of Webpack.&lt;/p&gt;


&lt;div class="ltag-github-readme-tag"&gt;
  &lt;div class="readme-overview"&gt;
    &lt;h2&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i3JOwpme--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/github-logo-ba8488d21cd8ee1fee097b8410db9deaa41d0ca30b004c0c63de0a479114156f.svg" alt="GitHub logo"&gt;
      &lt;a href="https://github.com/unadlib"&gt;
        unadlib
      &lt;/a&gt; / &lt;a href="https://github.com/unadlib/fronts"&gt;
        fronts
      &lt;/a&gt;
    &lt;/h2&gt;
    &lt;h3&gt;
      A progressive  micro frontends framework for building Web applications
    &lt;/h3&gt;
  &lt;/div&gt;
  &lt;div class="ltag-github-body"&gt;
    
&lt;div id="readme" class="md"&gt;
&lt;p&gt;&lt;a href="https://fronts.js.org/" rel="nofollow"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ohJ9MZKX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/unadlib/fronts/master/website/static/img/logo.svg" height="96" alt="Fronts Logo"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a rel="noopener noreferrer" href="https://github.com/unadlib/fronts/workflows/Node%20CI/badge.svg"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ahL3qJG8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/unadlib/fronts/workflows/Node%2520CI/badge.svg" alt="Node CI"&gt;&lt;/a&gt;
&lt;a href="http://badge.fury.io/js/fronts" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/12fac87a971be32fb31ebcbeb51849a611ba78e1ee539727bf25fbb09af69739/68747470733a2f2f62616467652e667572792e696f2f6a732f66726f6e74732e737667" alt="npm version"&gt;&lt;/a&gt;
&lt;a rel="noopener noreferrer" href="https://camo.githubusercontent.com/f20185893bd782736cd6c8449278ebb92616ad7d6f263c6daca900f7368309d3/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f6c2f66726f6e7473"&gt;&lt;img src="https://camo.githubusercontent.com/f20185893bd782736cd6c8449278ebb92616ad7d6f263c6daca900f7368309d3/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f6c2f66726f6e7473" alt="license"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Fronts is a progressive micro frontends framework for building Web applications, and it's based on the &lt;a href="https://webpack.js.org/concepts/module-federation/" rel="nofollow"&gt;module federation&lt;/a&gt; of Webpack.&lt;/p&gt;
&lt;h2&gt;
Motivation&lt;/h2&gt;
&lt;p&gt;Among the many micro frontends solutions, &lt;a href="https://github.com/single-spa/single-spa"&gt;single-spa&lt;/a&gt; and &lt;a href="https://webpack.js.org/concepts/module-federation/" rel="nofollow"&gt;Module Federation&lt;/a&gt; are the best of them.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/single-spa/single-spa"&gt;single-spa&lt;/a&gt; is a micro frontends framework based on router configuration. The centralization of configuration brings some limitations, such as it is difficult to granulate nestable micro frontends, module granularity control, module sharing, and so on.&lt;/p&gt;
&lt;p&gt;In 2019, Zack Jackson proposed and implemented Module Federation. Module Federation is a completely different concept from single-spa, and allows a JavaScript application to dynamically load code from another application. It completely solves the problem of code dependency sharing and runtime modularity. The idea is true - &lt;a href="https://medium.com/swlh/webpack-5-module-federation-a-game-changer-to-javascript-architecture-bcdd30e02669" rel="nofollow"&gt;A game-changer in JavaScript architecture&lt;/a&gt; as mentioned in Zack Jackson's article. And it's currently supported by Webpack, Next.js, and Rollup.&lt;/p&gt;
&lt;p&gt;Although the Module Federation concept is so amazing, it has not yet‚Ä¶&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="gh-btn-container"&gt;&lt;a class="gh-btn" href="https://github.com/unadlib/fronts"&gt;View on GitHub&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;





&lt;h3&gt;
  &lt;a href="#5-vscodethemegenerator"&gt;
  &lt;/a&gt;
  5. vscode-theme-generator
&lt;/h3&gt;

&lt;p&gt;Easily generate themes for VS Code with only a few colors.&lt;/p&gt;


&lt;div class="ltag-github-readme-tag"&gt;
  &lt;div class="readme-overview"&gt;
    &lt;h2&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i3JOwpme--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/github-logo-ba8488d21cd8ee1fee097b8410db9deaa41d0ca30b004c0c63de0a479114156f.svg" alt="GitHub logo"&gt;
      &lt;a href="https://github.com/Tyriar"&gt;
        Tyriar
      &lt;/a&gt; / &lt;a href="https://github.com/Tyriar/vscode-theme-generator"&gt;
        vscode-theme-generator
      &lt;/a&gt;
    &lt;/h2&gt;
    &lt;h3&gt;
      Easily generate themes for VS Code with only a few colors
    &lt;/h3&gt;
  &lt;/div&gt;
  &lt;div class="ltag-github-body"&gt;
    
&lt;div id="readme" class="md"&gt;
&lt;h1&gt;
vscode-theme-generator&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/Tyriar/vscode-theme-generator" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/5ce59df1a4ef346bc5ba5293484f79e802d9a2fbd4998822a4381e08f58ceb64/68747470733a2f2f7472617669732d63692e6f72672f5479726961722f7673636f64652d7468656d652d67656e657261746f722e7376673f6272616e63683d6d6173746572" alt="Build Status"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a preview that leverages the new VS Code theming options in v1.12.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Problem&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;New themes are typically forked from other themes, carrying the bugs with them&lt;/li&gt;
&lt;li&gt;.tmThemes are overly verbose and difficult to maintain&lt;/li&gt;
&lt;li&gt;Themes are difficult to write from scratch&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;The Solution&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;What if all you needed to do to generate a theme was specify a few colors and everything else was handled for you? Well that's what this module aims to accomplish. All you need to do is specify a set of "base colors" (background, foreground and 4 accent colors) and you have a reasonably good looking theme.&lt;/p&gt;
&lt;p&gt;All other VS Code theme colors are then derived from those base colors, with the option to tweak each underlying color as well.&lt;/p&gt;
&lt;h2&gt;
Example&lt;/h2&gt;
&lt;p&gt;This is all that's needed to generate a great looking theme:&lt;/p&gt;
&lt;div class="highlight highlight-source-ts position-relative js-code-highlight"&gt;
&lt;pre&gt;&lt;span class="pl-k"&gt;import&lt;/span&gt; &lt;span class="pl-kos"&gt;{&lt;/span&gt; &lt;span class="pl-s1"&gt;generateTheme&lt;/span&gt;&lt;span class="pl-kos"&gt;,&lt;/span&gt; &lt;span class="pl-smi"&gt;IColorSet&lt;/span&gt; &lt;span class="pl-kos"&gt;}&lt;/span&gt; &lt;span class="pl-k"&gt;from&lt;/span&gt; &lt;span class="pl-s"&gt;'vscode-theme-generator'&lt;/span&gt;&lt;span class="pl-kos"&gt;;&lt;/span&gt;
&lt;span class="pl-k"&gt;const&lt;/span&gt; &lt;span class="pl-s1"&gt;colorSet&lt;/span&gt;&lt;/pre&gt;‚Ä¶
&lt;/div&gt;
&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="gh-btn-container"&gt;&lt;a class="gh-btn" href="https://github.com/Tyriar/vscode-theme-generator"&gt;View on GitHub&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;





&lt;h3&gt;
  &lt;a href="#6-qwik"&gt;
  &lt;/a&gt;
  6. Qwik
&lt;/h3&gt;

&lt;p&gt;An Open-Source framework designed for best possible time to interactive, by focusing on resumability of server-side-rendering of HTML, and fine-grained lazy-loading of code.&lt;/p&gt;


&lt;div class="ltag-github-readme-tag"&gt;
  &lt;div class="readme-overview"&gt;
    &lt;h2&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i3JOwpme--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/github-logo-ba8488d21cd8ee1fee097b8410db9deaa41d0ca30b004c0c63de0a479114156f.svg" alt="GitHub logo"&gt;
      &lt;a href="https://github.com/BuilderIO"&gt;
        BuilderIO
      &lt;/a&gt; / &lt;a href="https://github.com/BuilderIO/qwik"&gt;
        qwik
      &lt;/a&gt;
    &lt;/h2&gt;
    &lt;h3&gt;
      An Open-Source framework designed for best possible time to interactive, by focusing on resumability of server-side-rendering of HTML, and fine-grained lazy-loading of code.
    &lt;/h3&gt;
  &lt;/div&gt;
  &lt;div class="ltag-github-body"&gt;
    
&lt;div id="readme" class="md"&gt;
&lt;br&gt;
&lt;p&gt;
  &lt;a rel="noopener noreferrer" href="https://camo.githubusercontent.com/3518364b161ab1351455c0f3774d01973e25602a4b63a3e9129c21deddb2f223/68747470733a2f2f63646e2e6275696c6465722e696f2f6170692f76312f696d6167652f617373657473253246594a494762346930316a7677305352644c3542742532463636376162366332323833643463346438373866623930383361616363313066"&gt;&lt;img alt="Qwik Logo" width="400" src="https://camo.githubusercontent.com/3518364b161ab1351455c0f3774d01973e25602a4b63a3e9129c21deddb2f223/68747470733a2f2f63646e2e6275696c6465722e696f2f6170692f76312f696d6167652f617373657473253246594a494762346930316a7677305352644c3542742532463636376162366332323833643463346438373866623930383361616363313066"&gt;&lt;/a&gt;
&lt;/p&gt;



&lt;h1&gt;
&lt;code&gt;Qwik&lt;/code&gt; DOM-Centric, Resumable Web-App Framework&lt;/h1&gt;

&lt;p&gt;An Open-Source framework designed for best possible &lt;a href="https://web.dev/interactive/" rel="nofollow"&gt;time to interactive&lt;/a&gt;, by focusing on &lt;a href="https://github.com/BuilderIO/qwik/blob/main/docs/RESUMABLE.md"&gt;resumability&lt;/a&gt; of server-side-rendering of HTML, and &lt;a href="https://github.com/BuilderIO/qwik/blob/main/docs/LAZY_LOADING.md"&gt;fine-grained lazy-loading&lt;/a&gt; of code.&lt;/p&gt;

&lt;h2&gt;
Getting Started&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Visit &lt;a href="https://stackblitz.com/edit/qwik-todo-demo" rel="nofollow"&gt;StackBlitz&lt;/a&gt; for a simple demo you can play with.&lt;/li&gt;
&lt;li&gt;Visit &lt;a href="https://raw.githubusercontent.com/BuilderIO/qwik/main/./integration"&gt;integration&lt;/a&gt; folder for guided tours of Qwik to learn how it works.&lt;/li&gt;
&lt;li&gt;Understand the difference between &lt;a href="https://github.com/BuilderIO/qwik/blob/main/docs/RESUMABLE.md"&gt;resumable and replayable&lt;/a&gt; applications.&lt;/li&gt;
&lt;li&gt;Learn about Qwik's high level &lt;a href="https://github.com/BuilderIO/qwik/blob/main/docs/LAZY_LOADING.md"&gt;mental model&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;
Blog Posts&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://dev.to/mhevery/a-first-look-at-qwik-the-html-first-framework-af" rel="nofollow"&gt;A first look at Qwik - the HTML first framework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dev.to/mhevery/death-by-closure-and-how-qwik-solves-it-44jj" rel="nofollow"&gt;Death by Closure (and how Qwik solves it)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;
Community&lt;/h2&gt;

&lt;p&gt;Join our &lt;a href="https://discord.gg/JHVpZmqSs4" rel="nofollow"&gt;discord&lt;/a&gt; community.&lt;/p&gt;




&lt;p&gt;
  Made with ‚ù§Ô∏è by &lt;a href="https://www.builder.io/" rel="nofollow"&gt;Builder.io&lt;/a&gt;
&lt;/p&gt;

&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
  &lt;/div&gt;
&lt;br&gt;
  &lt;div class="gh-btn-container"&gt;&lt;a class="gh-btn" href="https://github.com/BuilderIO/qwik"&gt;View on GitHub&lt;/a&gt;&lt;/div&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;





&lt;h3&gt;
  &lt;a href="#7-captain-stack"&gt;
  &lt;/a&gt;
  7. Captain Stack
&lt;/h3&gt;

&lt;p&gt;This feature is somewhat similar to Github Copilot's code suggestion. But instead of using AI, it sends your search query to Google, then retrieves StackOverflow answers and autocompletes them for you.&lt;/p&gt;


&lt;div class="ltag-github-readme-tag"&gt;
  &lt;div class="readme-overview"&gt;
    &lt;h2&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i3JOwpme--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/github-logo-ba8488d21cd8ee1fee097b8410db9deaa41d0ca30b004c0c63de0a479114156f.svg" alt="GitHub logo"&gt;
      &lt;a href="https://github.com/hieunc229"&gt;
        hieunc229
      &lt;/a&gt; / &lt;a href="https://github.com/hieunc229/copilot-clone"&gt;
        copilot-clone
      &lt;/a&gt;
    &lt;/h2&gt;
    &lt;h3&gt;
      VSCode extension for code suggestion
    &lt;/h3&gt;
  &lt;/div&gt;
  &lt;div class="ltag-github-body"&gt;
    
&lt;div id="readme" class="md"&gt;
&lt;p&gt;&lt;a rel="noopener noreferrer" href="https://raw.githubusercontent.com/hieunc229/copilot-clone/master/./logo.svg"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--HUvSv-NM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/hieunc229/copilot-clone/master/./logo.svg" alt="Captain Stack"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;
Captain Stack ‚Äî Code suggestion for VSCode&lt;/h1&gt;
&lt;p&gt;This feature is somewhat similar to &lt;a href="https://copilot.github.com/"&gt;Github Copilot&lt;/a&gt;'s code suggestion. But instead of using AI, it sends your search query to Google, then retrieves StackOverflow answers and autocompletes them for you.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Captain Stack is launched on Product Hunt and would appricate your support&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.producthunt.com/posts/captain-stack?utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-captain-stack" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/19a33bf154dd0ecfd1b2890acd3bc7e7c3735df20f53cc94673344c6b7c510bd/68747470733a2f2f6170692e70726f6475637468756e742e636f6d2f776964676574732f656d6265642d696d6167652f76312f66656174757265642e7376673f706f73745f69643d333032343337267468656d653d6c69676874" alt="Captain Stack - An open source alternative to GitHub Copilot | Product Hunt" width="250" height="54"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a rel="noopener noreferrer" href="https://raw.githubusercontent.com/hieunc229/copilot-clone/master/./demo.gif"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Kwl3AtOf--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://raw.githubusercontent.com/hieunc229/copilot-clone/master/./demo.gif" alt="Demo Video"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;
Table of contents:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hieunc229/copilot-clone/master/#1-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hieunc229/copilot-clone/master/#2-play-with-captain-stack"&gt;Play with Captain Stack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hieunc229/copilot-clone/master/#3-notes"&gt;Notes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hieunc229/copilot-clone/master/#4-changelog"&gt;Changelog&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Note: ‚ö†Ô∏è This extension uses a proposed API (inline-completion) and can only be used for extension development in &lt;a href="https://code.visualstudio.com/insiders/" rel="nofollow"&gt;VSCode Insider release&lt;/a&gt;. It's not yet available on VSCode&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;
1. Installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Check out the installation video: &lt;a href="https://youtu.be/MD-kzsF0Scg" rel="nofollow"&gt;https://youtu.be/MD-kzsF0Scg&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Before installation, make sure you have &lt;a href="https://code.visualstudio.com/insiders/" rel="nofollow"&gt;VSCode Insider&lt;/a&gt;. You'll be using this version. To install and starting Captain Stack:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Download this repository to your local machine. Unzip and open it on VSCode Insider (make sure the root directory is the same as &lt;code&gt;package.json&lt;/code&gt; file)&lt;/li&gt;
&lt;li&gt;(optional) Run &lt;code&gt;npm install&lt;/code&gt; in the terminal to‚Ä¶&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="gh-btn-container"&gt;&lt;a class="gh-btn" href="https://github.com/hieunc229/copilot-clone"&gt;View on GitHub&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;





&lt;h3&gt;
  &lt;a href="#8-vscodevim"&gt;
  &lt;/a&gt;
  8. VSCodeVim
&lt;/h3&gt;

&lt;p&gt;VSCodeVim is a Vim emulator for Visual Studio Code. &lt;/p&gt;


&lt;div class="ltag-github-readme-tag"&gt;
  &lt;div class="readme-overview"&gt;
    &lt;h2&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i3JOwpme--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/github-logo-ba8488d21cd8ee1fee097b8410db9deaa41d0ca30b004c0c63de0a479114156f.svg" alt="GitHub logo"&gt;
      &lt;a href="https://github.com/VSCodeVim"&gt;
        VSCodeVim
      &lt;/a&gt; / &lt;a href="https://github.com/VSCodeVim/Vim"&gt;
        Vim
      &lt;/a&gt;
    &lt;/h2&gt;
    &lt;h3&gt;
      ‚≠ê Vim for Visual Studio Code
    &lt;/h3&gt;
  &lt;/div&gt;
  &lt;div class="ltag-github-body"&gt;
    
&lt;div id="readme" class="md"&gt;
&lt;h2&gt;
&lt;a rel="noopener noreferrer" href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/images/icon.png"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--PaE0MnD7--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/VSCodeVim/Vim/master/images/icon.png" height="128"&gt;&lt;/a&gt;&lt;br&gt;VSCodeVim&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Vim emulation for Visual Studio Code&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://aka.ms/vscodevim" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/c6562f5c7aa19673be9e5809040f90557bd451e1796d517b3c57cf754e695eff/68747470733a2f2f76736d61726b6574706c61636562616467652e61707068622e636f6d2f76657273696f6e2f7673636f646576696d2e76696d2e737667" alt=""&gt;&lt;/a&gt;
&lt;a href="https://marketplace.visualstudio.com/items?itemName=vscodevim.vim" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/2e60af83f0bde09498f3852bedd56bcb33cdac123235d8b608e3149c1500e5f0/68747470733a2f2f76736d61726b6574706c61636562616467652e61707068622e636f6d2f696e7374616c6c732d73686f72742f7673636f646576696d2e76696d2e737667" alt=""&gt;&lt;/a&gt;
&lt;a href="https://github.com/VSCodeVim/Vim/actions?query=workflow%3Abuild+branch%3Amaster"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--e1XiA1c6--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/VSCodeVim/Vim/workflows/build/badge.svg%3Fbranch%3Dmaster" alt=""&gt;&lt;/a&gt;
&lt;a href="https://vscodevim.herokuapp.com/" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/7666ac5c7d5b95e1f9672be8dce0621b1bbad16cfc00639bff69df625c9d8fa6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7673636f646576696d2d736c61636b2d626c75652e7376673f6c6f676f3d736c61636b" alt=""&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;VSCodeVim is a Vim emulator for &lt;a href="https://code.visualstudio.com/" rel="nofollow"&gt;Visual Studio Code&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
üöö For a full list of supported Vim features, please refer to our &lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/ROADMAP.md"&gt;roadmap&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;
üìÉ Our &lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/CHANGELOG.md"&gt;change log&lt;/a&gt; outlines the breaking/major/minor updates between releases.&lt;/li&gt;
&lt;li&gt;
‚ùì If you need to ask any questions, join us on &lt;a href="https://vscodevim.herokuapp.com/" rel="nofollow"&gt;Slack&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Report missing features/bugs on &lt;a href="https://github.com/VSCodeVim/Vim/issues"&gt;GitHub&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

 &lt;strong&gt;Table of Contents&lt;/strong&gt; (click to expand)
&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#-installation"&gt;Installation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#mac"&gt;Mac setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#windows"&gt;Windows setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#linux-setup"&gt;Linux setup&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#%EF%B8%8F-settings"&gt;Settings&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#vscodevim-settings"&gt;VSCodeVim settings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#neovim-integration"&gt;Neovim Integration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#key-remapping"&gt;Key remapping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#vim-settings"&gt;Vim settings&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#%EF%B8%8F-multi-cursor-mode"&gt;Multi-Cursor mode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#-emulated-plugins"&gt;Emulated plugins&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#vim-airline"&gt;vim-airline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#vim-easymotion"&gt;vim-easymotion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#vim-surround"&gt;vim-surround&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#vim-commentary"&gt;vim-commentary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#vim-indent-object"&gt;vim-indent-object&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#vim-sneak"&gt;vim-sneak&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#camelcasemotion"&gt;CamelCaseMotion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#input-method"&gt;Input Method&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#replacewithregister"&gt;ReplaceWithRegister&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#vim-textobj-entire"&gt;vim-textobj-entire&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#-vscodevim-tricks"&gt;VSCodeVim tricks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#-faq"&gt;F.A.Q / Troubleshooting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://raw.githubusercontent.com/VSCodeVim/Vim/master/#%EF%B8%8F-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;
üíæ Installation&lt;/h2&gt;
&lt;p&gt;VSCodeVim is automatically enabled following &lt;a href="https://marketplace.visualstudio.com/items?itemName=vscodevim.vim" rel="nofollow"&gt;installation&lt;/a&gt; and reloading of VS Code.&lt;/p&gt;
&lt;h3&gt;
Mac&lt;/h3&gt;
&lt;p&gt;To enable key-repeating execute the following in your Terminal and restart VS Code:&lt;/p&gt;
&lt;div class="highlight highlight-source-shell position-relative js-code-highlight"&gt;
&lt;pre&gt;$ defaults write com.microsoft.VSCode ApplePressAndHoldEnabled -bool &lt;span class="pl-c1"&gt;false&lt;/span&gt;         &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; For VS Code&lt;/span&gt;
$ defaults write com.microsoft.VSCodeInsiders ApplePressAndHoldEnabled -bool &lt;span class="pl-c1"&gt;false&lt;/span&gt; &lt;span class="pl-c"&gt;&lt;span class="pl-c"&gt;#&lt;/span&gt; For&lt;/span&gt;&lt;/pre&gt;‚Ä¶
&lt;/div&gt;
&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="gh-btn-container"&gt;&lt;a class="gh-btn" href="https://github.com/VSCodeVim/Vim"&gt;View on GitHub&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;





&lt;h3&gt;
  &lt;a href="#9-didact"&gt;
  &lt;/a&gt;
  9. Didact
&lt;/h3&gt;

&lt;p&gt;A DIY guide to build your own React&lt;/p&gt;


&lt;div class="ltag-github-readme-tag"&gt;
  &lt;div class="readme-overview"&gt;
    &lt;h2&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i3JOwpme--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/github-logo-ba8488d21cd8ee1fee097b8410db9deaa41d0ca30b004c0c63de0a479114156f.svg" alt="GitHub logo"&gt;
      &lt;a href="https://github.com/pomber"&gt;
        pomber
      &lt;/a&gt; / &lt;a href="https://github.com/pomber/didact"&gt;
        didact
      &lt;/a&gt;
    &lt;/h2&gt;
    &lt;h3&gt;
      A DIY guide to build your own React
    &lt;/h3&gt;
  &lt;/div&gt;
  &lt;div class="ltag-github-body"&gt;
    
&lt;div id="readme" class="md"&gt;
&lt;p&gt;&lt;a rel="noopener noreferrer" href="https://cloud.githubusercontent.com/assets/1911623/26426031/5176c348-40ad-11e7-9f1a-1e2f8840b562.jpeg"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--4D4Ma4q---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cloud.githubusercontent.com/assets/1911623/26426031/5176c348-40ad-11e7-9f1a-1e2f8840b562.jpeg"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;
Didact&lt;/h1&gt;
&lt;h4&gt;
A DIY guide to build your own React&lt;/h4&gt;
&lt;p&gt;This repository goes together with a &lt;a href="https://engineering.hexacta.com/didact-learning-how-react-works-by-building-it-from-scratch-51007984e5c5" rel="nofollow"&gt;series of posts&lt;/a&gt; that explains how to build React from scratch step by step. &lt;strong&gt;You can jump straight to &lt;a href="https://pomb.us/build-your-own-react" rel="nofollow"&gt;the last post&lt;/a&gt; which is self-contained and includes everything.&lt;/strong&gt;&lt;/p&gt;
&lt;div class="table-wrapper-paragraph"&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Blog Post&lt;/th&gt;
&lt;th&gt;Code sample&lt;/th&gt;
&lt;th&gt;Commits&lt;/th&gt;
&lt;th&gt;Other languages&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://engineering.hexacta.com/didact-learning-how-react-works-by-building-it-from-scratch-51007984e5c5" rel="nofollow"&gt;Introduction&lt;/a&gt;&lt;/td&gt;



&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://engineering.hexacta.com/didact-rendering-dom-elements-91c9aa08323b" rel="nofollow"&gt;Rendering DOM elements&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://codepen.io/pomber/pen/eWbwBq?editors=0010" rel="nofollow"&gt;codepen&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/hexacta/didact/commit/fc4d360d91a1e68f0442d39dbce5b9cca5a08f24"&gt;diff&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/chinanf-boy/didact-explain#1-%E6%B8%B2%E6%9F%93dom%E5%85%83%E7%B4%A0"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://engineering.hexacta.com/didact-element-creation-and-jsx-d05171c55c56" rel="nofollow"&gt;Element creation and JSX&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://codepen.io/pomber/pen/xdmoWE?editors=0010" rel="nofollow"&gt;codepen&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/hexacta/didact/commit/15010f8e7b8b54841d1e2dd9eacf7b3c06b1a24b"&gt;diff&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/chinanf-boy/didact-explain#2-%E5%85%83%E7%B4%A0%E5%88%9B%E5%BB%BA%E5%92%8Cjsx"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://engineering.hexacta.com/didact-instances-reconciliation-and-virtual-dom-9316d650f1d0" rel="nofollow"&gt;Virtual DOM and reconciliation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://codepen.io/pomber/pen/WjLqYW?editors=0010" rel="nofollow"&gt;codepen&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;
&lt;a href="https://github.com/hexacta/didact/commit/8eb7ffd6f5e210526fb4c274c4f60d609fe2f810"&gt;diff&lt;/a&gt; &lt;a href="https://github.com/hexacta/didact/commit/6f5fdb7331ed77ba497fa5917d920eafe1f4c8dc"&gt;diff&lt;/a&gt; &lt;a href="https://github.com/hexacta/didact/commit/35619a039d48171a6e6c53bd433ed049f2d718cb"&gt;diff&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/chinanf-boy/didact-explain#3-%E5%AE%9E%E4%BE%8B-%E5%AF%B9%E6%AF%94%E5%92%8C%E8%99%9A%E6%8B%9Fdom"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://engineering.hexacta.com/didact-components-and-state-53ab4c900e37" rel="nofollow"&gt;Components and State&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://codepen.io/pomber/pen/RVqBrx" rel="nofollow"&gt;codepen&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/hexacta/didact/commit/2e290ff5c486b8a3f361abcbc6e36e2c21db30b8"&gt;diff&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/chinanf-boy/didact-explain#4-%E7%BB%84%E4%BB%B6%E5%92%8C%E7%8A%B6%E6%80%81"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;a href="https://engineering.hexacta.com/didact-fiber-incremental-reconciliation-b2fe028dcaec" rel="nofollow"&gt;Fiber: Incremental reconciliation&lt;/a&gt; (self-contained post)&lt;/td&gt;
&lt;td&gt;&lt;a href="https://codepen.io/pomber/pen/veVOdd" rel="nofollow"&gt;codepen&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;
&lt;a href="https://github.com/hexacta/didact/commit/6174a2289e69895acd8fc85abdc3aaff1ded9011"&gt;diff&lt;/a&gt; &lt;a href="https://github.com/hexacta/didact/commit/accafb81e116a0569f8b7d70e5b233e14af999ad"&gt;diff&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href="https://github.com/chinanf-boy/didact-explain#5-fibre-%E9%80%92%E5%A2%9E%E5%AF%B9%E6%AF%94"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;a href="https://pomb.us/build-your-own-react" rel="nofollow"&gt;The one with Hooks&lt;/a&gt; (self-contained post)&lt;/td&gt;
&lt;td&gt;&lt;a href="https://codesandbox.io/s/didact-8-21ost" rel="nofollow"&gt;codesandbox&lt;/a&gt;&lt;/td&gt;

&lt;td&gt;&lt;a href="https://www.tangdingblog.cn/blog/react/buildyourownreact-2020-09-22/" rel="nofollow"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;Follow &lt;a href="https://twitter.com/pomber" rel="nofollow"&gt;@pomber&lt;/a&gt; on twitter for updates.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;
License&lt;/h2&gt;
&lt;p&gt;The MIT License (MIT)&lt;/p&gt;
&lt;/div&gt;



&lt;/div&gt;
&lt;br&gt;
  &lt;div class="gh-btn-container"&gt;&lt;a class="gh-btn" href="https://github.com/pomber/didact"&gt;View on GitHub&lt;/a&gt;&lt;/div&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;





&lt;h3&gt;
  &lt;a href="#10-uikit"&gt;
  &lt;/a&gt;
  10. UIkit
&lt;/h3&gt;

&lt;p&gt;A lightweight and modular front-end framework for developing fast and powerful web interfaces&lt;/p&gt;


&lt;div class="ltag-github-readme-tag"&gt;
  &lt;div class="readme-overview"&gt;
    &lt;h2&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i3JOwpme--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/github-logo-ba8488d21cd8ee1fee097b8410db9deaa41d0ca30b004c0c63de0a479114156f.svg" alt="GitHub logo"&gt;
      &lt;a href="https://github.com/uikit"&gt;
        uikit
      &lt;/a&gt; / &lt;a href="https://github.com/uikit/uikit"&gt;
        uikit
      &lt;/a&gt;
    &lt;/h2&gt;
    &lt;h3&gt;
      A lightweight and modular front-end framework for developing fast and powerful web interfaces
    &lt;/h3&gt;
  &lt;/div&gt;
  &lt;div class="ltag-github-body"&gt;
    
&lt;div id="readme" class="md"&gt;
&lt;p&gt;&lt;a href="https://getuikit.com/" rel="nofollow"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--5GBWXrv1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cloud.githubusercontent.com/assets/321047/21769911/474d7d9e-d681-11e6-9fe0-d95f8ccfd3a9.jpg" alt="uikit banner"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;
UIkit&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://discord.gg/NEt4Pv7" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/a1da00c3cbdb499d574eb6658ac513245d5ad10d87f37ed1ac112ad026d5a5f3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230646973636f72642d3732383964612e737667" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;UIkit is a lightweight and modular front-end framework for developing fast and powerful web interfaces.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://getuikit.com" rel="nofollow"&gt;Homepage&lt;/a&gt; - Learn more about UIkit&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://twitter.com/getuikit" rel="nofollow"&gt;@getuikit&lt;/a&gt; - Get the latest buzz on Twitter&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://discord.gg/NEt4Pv7" rel="nofollow"&gt;Discord Chat&lt;/a&gt; - Join our developer chat on Discord.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
  &lt;b&gt;UIkit is an Open Source project developed by YOOtheme.&lt;/b&gt;
  &lt;br&gt;&lt;br&gt;
  &lt;a href="https://yootheme.com" rel="nofollow"&gt;
      &lt;img width="134" height="30" src="https://camo.githubusercontent.com/91105a50618c98176a6a52fee730351255ac9cc059b4a64072aa34a02e9e334a/687474703a2f2f796f6f7468656d652e636f6d2f736974652f696d616765732f796f6f7468656d652d6c6f676f2e737667"&gt;
  &lt;/a&gt;
&lt;/p&gt;




&lt;h2&gt;
Getting started&lt;/h2&gt;

&lt;p&gt;You have the following options to get UIkit:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Download the &lt;a href="https://github.com/uikit/uikit/releases/latest"&gt;latest release&lt;/a&gt; with pre-built CSS and JS.&lt;/li&gt;
&lt;li&gt;Install with &lt;a href="https://npmjs.com" rel="nofollow"&gt;npm&lt;/a&gt; to get all source files as they are available on Github: &lt;code&gt;npm install uikit&lt;/code&gt;
&lt;/li&gt;
&lt;li&gt;Install with &lt;a href="https://yarnpkg.com/" rel="nofollow"&gt;yarn&lt;/a&gt; to get all source files as they are available on Github: &lt;code&gt;yarn add uikit&lt;/code&gt;
&lt;/li&gt;
&lt;li&gt;Directly load UIkit from &lt;a href="https://www.jsdelivr.com" rel="nofollow"&gt;jsDelivr&lt;/a&gt;: &lt;a href="https://www.jsdelivr.com/package/npm/uikit" rel="nofollow"&gt;https://www.jsdelivr.com/package/npm/uikit&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Clone the repo to get all source files including build scripts: &lt;code&gt;git clone git://github.com/uikit/uikit.git&lt;/code&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;
Developers&lt;/h2&gt;

&lt;p&gt;To always have the latest development version of UIkit, even before a release, you may want to use npm or yarn with the &lt;code&gt;dev&lt;/code&gt; tag.&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Using npm‚Ä¶&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;br&gt;
  &lt;/div&gt;
&lt;br&gt;
  &lt;div class="gh-btn-container"&gt;&lt;a class="gh-btn" href="https://github.com/uikit/uikit"&gt;View on GitHub&lt;/a&gt;&lt;/div&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;





&lt;h3&gt;
  &lt;a href="#stargazing"&gt;
  &lt;/a&gt;
  Stargazing üìà
&lt;/h3&gt;

&lt;h4&gt;
  &lt;a href="#top-risers-over-last-7-days"&gt;
  &lt;/a&gt;
  Top risers over last 7 days
&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;a href="https://github.com/public-apis/public-apis"&gt;Public APIs&lt;/a&gt; +3,575 stars&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/solidjs/solid"&gt;Solid&lt;/a&gt; +1,631 stars&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/bradtraversy/50projects50days"&gt;50 Projects in 50 Days&lt;/a&gt; +1,602 stars&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/ossf/scorecard"&gt;Security Scorecards&lt;/a&gt; +727 stars&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/kamranahmedse/developer-roadmap"&gt;Web Developer Roadmap&lt;/a&gt; +642 stars&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;
  &lt;a href="#top-growth-over-last-7-days"&gt;
  &lt;/a&gt;
  Top growth(%) over last 7 days
&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;a href="https://github.com/ossf/scorecard"&gt;Security Scorecards&lt;/a&gt; +97%&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/netlify/framework-info"&gt;Framework Info&lt;/a&gt; +75%&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/bradtraversy/50projects50days"&gt;50 Projects in 50 Days&lt;/a&gt; +38%&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/aidenybai/million"&gt;million&lt;/a&gt; +26%&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/solidjs/solid"&gt;Solid&lt;/a&gt; +23%&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;
  &lt;a href="#top-risers-over-last-30-days"&gt;
  &lt;/a&gt;
  Top risers over last 30 days
&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;a href="https://github.com/jwasham/coding-interview-university"&gt;Coding Interview University&lt;/a&gt; +7,706 stars&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/public-apis/public-apis"&gt;Public APIs&lt;/a&gt; +6,905 stars&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/trimstray/the-book-of-secret-knowledge"&gt;The Book Of Secret Knowledge&lt;/a&gt; +5,288 stars&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/microsoft/Web-Dev-For-Beginners"&gt;Web Development for Beginners&lt;/a&gt; +3,554 stars&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/maaslalani/slides"&gt;Slides&lt;/a&gt; +3,268 stars&lt;/li&gt;
&lt;/ol&gt;

&lt;h4&gt;
  &lt;a href="#top-growth-over-last-30-days"&gt;
  &lt;/a&gt;
  Top growth(%) over last 30 days
&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;a href="https://github.com/wellyshen/react-cool-virtual"&gt;React Virtual Cool&lt;/a&gt; +638%&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/maaslalani/slides"&gt;Slides&lt;/a&gt; +305%&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/aidenybai/million"&gt;million&lt;/a&gt; +160%&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/ossf/scorecard"&gt;Security Scorecards&lt;/a&gt; +146%&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/SigNoz/signoz"&gt;SigNoz&lt;/a&gt; +37%&lt;/li&gt;
&lt;/ol&gt;




&lt;p&gt;Trending Projects is available as a weekly newsletter please sign up at &lt;a href="https://www.iainfreestone.com"&gt;www.iainfreestone.com&lt;/a&gt; to ensure you never miss an issue.&lt;/p&gt;

&lt;p&gt;If you enjoyed this article you can &lt;a href="https://twitter.com/iain_freestone"&gt;follow me&lt;/a&gt; on Twitter where I regularly post bite size tips relating to HTML, CSS and JavaScript.&lt;/p&gt;

</description>
      <category>react</category>
      <category>javascript</category>
      <category>webdev</category>
      <category>productivity</category>
    </item>
    <item>
      <title>Building multiple themes with CSS..</title>
      <author>sakethk</author>
      <pubDate>Fri, 09 Jul 2021 13:33:26 +0000</pubDate>
      <link>https://dev.to/sakethkowtha/building-multiple-themes-with-css-mf3</link>
      <guid>https://dev.to/sakethkowtha/building-multiple-themes-with-css-mf3</guid>
      <description>&lt;p&gt;This article is about building a site with multiple color schemes. It will change the theme without reloading the document, without adding theme class names dynamically and without duplicating the code.&lt;/p&gt;

&lt;p&gt;I am using CSS variables in this example. You can try this even if you are using SASS or LESS.&lt;/p&gt;

&lt;p&gt;In this example we will create a document that has background color, Dropdown (to pick scheme) , card, heading and paragraph. Here I am creating six color schemes and have given random names to them. Below are the names&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Light&lt;/li&gt;
&lt;li&gt;Dark&lt;/li&gt;
&lt;li&gt;Sunset&lt;/li&gt;
&lt;li&gt;Moon light&lt;/li&gt;
&lt;li&gt;Cartoon&lt;/li&gt;
&lt;li&gt;bluecrystal&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In dropdown you will find the system option i.e., your OS theme. If your are using Dark mode in your OS, it will be Dark. Else, it will be &lt;code&gt;Light&lt;/code&gt;. &lt;/p&gt;

&lt;p&gt;For each scheme i defined four colors &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;--main-bg-color (Body backgound color)&lt;/li&gt;
&lt;li&gt;--card-shadow-color (Card shadow)&lt;/li&gt;
&lt;li&gt;--primary-text-color (Heading text color)&lt;/li&gt;
&lt;li&gt;--secondry-text-color (Paragraph text color)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;
  &lt;a href="#important"&gt;
  &lt;/a&gt;
  Important
&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;We are getting system theme with the help of &lt;code&gt;prefers-color-scheme&lt;/code&gt; media query.&lt;/li&gt;
&lt;li&gt;I am using &lt;code&gt;data-theme&lt;/code&gt; attribute to set color scheme. Whenever scheme changes just we need to update &lt;code&gt;data-theme&lt;/code&gt; attribute value.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here is the Codepen. You can find color schemes and some other styles for Card, Heading and Paragraph in CSS section.&lt;/p&gt;

&lt;p&gt;&lt;iframe height="600" src="https://codepen.io/saketh-kowtha/embed/OJmXGXN?height=600&amp;amp;default-tab=result&amp;amp;embed-version=2"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

</description>
      <category>html</category>
      <category>css</category>
      <category>beginners</category>
      <category>webdev</category>
    </item>
    <item>
      <title>Scrape Google News with Python</title>
      <author>Dimitry Zub</author>
      <pubDate>Fri, 09 Jul 2021 13:15:26 +0000</pubDate>
      <link>https://dev.to/dimitryzub/scrape-google-news-with-python-4o14</link>
      <guid>https://dev.to/dimitryzub/scrape-google-news-with-python-4o14</guid>
      <description>&lt;p&gt;Contents: intro, imports, what will be scraped, process, code, code with pagination, links, outro.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#intro"&gt;
  &lt;/a&gt;
  Intro
&lt;/h3&gt;

&lt;p&gt;This blog post is a continuation of Google's web scraping series. Here you'll see how to scrape Google News Results using Python with &lt;code&gt;beautifulsoup&lt;/code&gt;, &lt;code&gt;requests&lt;/code&gt;, &lt;code&gt;lxml&lt;/code&gt; libraries. An alternative API solution will be shown.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#imports"&gt;
  &lt;/a&gt;
  Imports
&lt;/h3&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lxml&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;serpapi&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;GoogleSearch&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h3&gt;
  &lt;a href="#what-will-be-scraped"&gt;
  &lt;/a&gt;
  What will be scraped
&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--FdD8n_rG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vr0a02qjk31qv6pdfmgb.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--FdD8n_rG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vr0a02qjk31qv6pdfmgb.png" alt="image"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#process"&gt;
  &lt;/a&gt;
  Process
&lt;/h3&gt;

&lt;p&gt;Selecting &lt;strong&gt;container, title, link, source, snippet, published time&lt;/strong&gt;.&lt;br&gt;
&lt;a href="https://i.giphy.com/media/WwAOMVPxAvFhvG3MWB/giphy.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://i.giphy.com/media/WwAOMVPxAvFhvG3MWB/giphy.gif"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;
  &lt;a href="#code"&gt;
  &lt;/a&gt;
  Code
&lt;/h3&gt;


&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lxml&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;

&lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s"&gt;"User-Agent"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582"&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s"&gt;"q"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"gta san andreas"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s"&gt;"hl"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"en"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s"&gt;"tbm"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"nws"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"https://www.google.com/search"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'lxml'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'.dbsr'&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'.nDgy9d'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
    &lt;span class="n"&gt;link&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'href'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'.WF4CUc'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
    &lt;span class="n"&gt;snippet&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'.Y3v8qd'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
    &lt;span class="n"&gt;date_published&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'.WG9SHc span'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;snippet&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;date_published&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;-------------&lt;/span&gt;
&lt;span class="s"&gt;'''
San Andreas: Cesar &amp;amp; Kendl Is Grand Theft Auto's Best Relationship
https://screenrant.com/gta-san-andreas-cesar-kendl-best-relationship-why/
Many Grand Theft Auto relationships are negative or purely transactional. 
That makes Cesar and Kendl's genuine love for each other stand out.
4 hours ago
Screen Rant
'''&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;h3&gt;
  &lt;a href="#code-with-pagination"&gt;
  &lt;/a&gt;
  Code with pagination
&lt;/h3&gt;


&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lxml&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;paginate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;previous_url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Break from infinite recursion
&lt;/span&gt;    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;previous_url&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="n"&gt;headers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s"&gt;"User-Agent"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)"&lt;/span&gt;
                      &lt;span class="s"&gt;"Chrome/72.0.3538.102 Safari/537.36 Edge/18.19582"&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
    &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'lxml'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# First page
&lt;/span&gt;    &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;

    &lt;span class="n"&gt;next_page_node&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'a#pnnext'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Stop when there is no next page
&lt;/span&gt;    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;next_page_node&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="n"&gt;next_page_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urljoin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'https://www.google.com/'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;next_page_node&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'href'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="c1"&gt;# Pages after the first one
&lt;/span&gt;    &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;paginate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_page_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;scrape&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;pages&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;paginate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"https://www.google.com/search?hl=en-US&amp;amp;q=gta san andreas&amp;amp;tbm=nws"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;pages&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'Current page: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;".YyVfkd"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'.dbsr'&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'.nDgy9d'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
            &lt;span class="n"&gt;link&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'href'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'.WF4CUc'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
            &lt;span class="n"&gt;snippet&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'.Y3v8qd'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
            &lt;span class="n"&gt;date_published&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;select_one&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'.WG9SHc span'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;snippet&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;date_published&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;scrape&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="o"&gt;-------------------&lt;/span&gt;
&lt;span class="s"&gt;'''
Current page: 1

San Andreas: Cesar &amp;amp; Kendl Is Grand Theft Auto's Best Relationship
https://screenrant.com/gta-san-andreas-cesar-kendl-best-relationship-why/
Many Grand Theft Auto relationships are negative or purely transactional. 
That makes Cesar and Kendl's genuine love for each other stand out.
4 hours ago
Screen Rant

...

Current page: 8

Il recr√©√© des covers d'album sur "GTA : San Andreas" et c'est ...
https://intrld.com/gtpmagazine-le-magazine-parodique-du-jeu-gta/
On a trouv√© LE compte parodique √† suivre : Grand Theft Parody, le magazine 
qui revisite des pochettes mythiques sur GTA : San Andreas.
2 weeks ago
Interlude
'''&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;h3&gt;
  &lt;a href="#using-google-news-result-api"&gt;
  &lt;/a&gt;
  Using &lt;a href="https://serpapi.com/news-results"&gt;Google News Result API&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;SerpApi is a paid API with a free trial that soon will be replaced with a free plan.&lt;/p&gt;

&lt;p&gt;The main differences as I usually write in this blog post is that it's much faster and straightforward process rather than tinkering &lt;code&gt;CSS&lt;/code&gt;, &lt;code&gt;XPath&lt;/code&gt; selectors or dealing with Javascript-driven websites e.g. Google Maps which SerpApi scrapes like a charm. &lt;/p&gt;

&lt;p&gt;If you want to get things quickly and write code faster, and don't want to maintain the parser then, I believe that API solution is a way to go.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;serpapi&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;GoogleSearch&lt;/span&gt;

&lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="s"&gt;"api_key"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"YOUR_API_KEY"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;"engine"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"google"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;"q"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"gta san andreas"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;"gl"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"us"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="s"&gt;"tbm"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"nws"&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;search&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GoogleSearch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_dict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'news_results'&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;-----------------------&lt;/span&gt;
&lt;span class="s"&gt;'''
{'position': 1, 'link': 'https://www.sportskeeda.com/gta/5-strange-gta-san-andreas-glitches', 'title': '5 strange GTA San Andreas glitches', 'source': 'Sportskeeda', 'date': '9 hours ago', 'snippet': 'GTA San Andreas has a wide assortment of interesting and strange glitches.', 'thumbnail': 'https://serpapi.com/searches/60e71e1f8b7ed2dfbde7629b/images/1394ee64917c752bdbe711e1e56e90b20906b4761045c01a2cefb327f91d40bb.jpeg'}
'''&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h3&gt;
  &lt;a href="#google-news-results-api-with-pagination"&gt;
  &lt;/a&gt;
  Google News Results API with Pagination
&lt;/h3&gt;



&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight python"&gt;&lt;code&gt;&lt;span class="c1"&gt;# https://github.com/serpapi/google-search-results-python
&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;serpapi&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;GoogleSearch&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;scrape&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s"&gt;"engine"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"google"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;"q"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"coca cola"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;"tbm"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"nws"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;"api_key"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;"YOUR_API_KEY"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="n"&gt;search&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GoogleSearch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pages&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pagination&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;pages&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;"Current page: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'serpapi_pagination'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;'current'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;news_result&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;"news_results"&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s"&gt;"Title: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;news_result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'title'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;Link: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;news_result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'link'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="n"&gt;scrape&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="o"&gt;------------------------&lt;/span&gt;
&lt;span class="s"&gt;'''
Current page: 1
Title: 5 strange GTA San Andreas glitches
Link: https://www.sportskeeda.com/gta/5-strange-gta-san-andreas-glitches

...

Current page: 14
Title: Ambitious Grand Theft Auto: San Andreas Mod Turns It Into A Spider-Man Game
Link: https://gamerant.com/grand-theft-auto-san-andreas-spider-man-game-mod/
...
'''&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h3&gt;
  &lt;a href="#links"&gt;
  &lt;/a&gt;
  Links
&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://replit.com/@DimitryZub1/Scrape-Google-News-with-Pagination-python-serpapi#main.py"&gt;Code in the online IDE&lt;/a&gt; ‚Ä¢ &lt;a href="https://serpapi.com/news-results"&gt;Google News Result API&lt;/a&gt; &lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#outro"&gt;
  &lt;/a&gt;
  Outro
&lt;/h3&gt;

&lt;p&gt;If you want to see how to scrape something using Python/Ruby that I didn't write about yet or you want to see some project made with SerpApi, please write me a message.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Yours, D&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://i.giphy.com/media/8vIFoKU8s4m4CBqCao/giphy.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://i.giphy.com/media/8vIFoKU8s4m4CBqCao/giphy.gif"&gt;&lt;/a&gt;&lt;/p&gt;

</description>
      <category>python</category>
      <category>tutorial</category>
      <category>datascience</category>
      <category>webscraping</category>
    </item>
    <item>
      <title>Learn DevOps? I give you 10 reasons¬†‚úÖ</title>
      <author>Dotnetsafer</author>
      <pubDate>Fri, 09 Jul 2021 12:48:09 +0000</pubDate>
      <link>https://dev.to/dotnetsafer/learn-devops-i-give-you-10-reasons-1482</link>
      <guid>https://dev.to/dotnetsafer/learn-devops-i-give-you-10-reasons-1482</guid>
      <description>&lt;p&gt;Let's start by defining what DevOps means:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;Dev&lt;/strong&gt; (Development)&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;Ops&lt;/strong&gt; (Operations)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Designates the &lt;strong&gt;union of people and technology&lt;/strong&gt; to deliver value to customers on a constant basis.&lt;/p&gt;

&lt;p&gt;What DevOps allows is that the roles (development, security, IT operations‚Ä¶) can be coordinated in a simple way &lt;strong&gt;to create better products&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This is how benefits are obtained such as:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create better products&lt;/li&gt;
&lt;li&gt;Better meet customer needs&lt;/li&gt;
&lt;li&gt;Reach goals in less time&lt;/li&gt;
&lt;/ul&gt;




&lt;p&gt;That is why you are going to know the &lt;strong&gt;top 10&lt;/strong&gt; reasons to learn DevOps&lt;/p&gt;




&lt;h2&gt;
  &lt;a href="#1-you-will-have-a-complete-view-of-the-sdlc%C2%A0"&gt;
  &lt;/a&gt;
  1. You will have a complete view of the SDLC¬†üòé
&lt;/h2&gt;

&lt;p&gt;By getting a little familiar with &lt;em&gt;DevOps&lt;/em&gt;, you will get the concept of the &lt;strong&gt;Software Delivery Lifecycle&lt;/strong&gt; (SDLC). As a developer, you will know what is happening at all times in testing and in production.&lt;/p&gt;




&lt;h2&gt;
  &lt;a href="#2-you-will-separate-yourself-from-the-crowd%C2%A0"&gt;
  &lt;/a&gt;
  2. You will separate yourself from the crowd¬†üîù
&lt;/h2&gt;

&lt;p&gt;DevOps will give you a huge &lt;strong&gt;advantage&lt;/strong&gt; over competitors in an interview. You can always offer something &lt;strong&gt;good&lt;/strong&gt; and &lt;strong&gt;unique&lt;/strong&gt; for any organization.&lt;/p&gt;




&lt;h2&gt;
  &lt;a href="#3-you-will-add-a-lot-of-value-to-a-company%C2%A0"&gt;
  &lt;/a&gt;
  3. You will add a lot of value to a company¬†üë®‚Äçüíª
&lt;/h2&gt;

&lt;p&gt;All good companies look for &lt;strong&gt;quality people&lt;/strong&gt;. Even to cut costs, they look for people &lt;strong&gt;with as many skills as possible&lt;/strong&gt;. If you learn &lt;em&gt;DevOps&lt;/em&gt;, you will stand out and be a person who will add a lot of value to the company since you will know all the tools, technologies and possibilities that can be used for any purpose.&lt;/p&gt;




&lt;h2&gt;
  &lt;a href="#4-you-will-know-the-different-existing-tools%C2%A0"&gt;
  &lt;/a&gt;
  4. You will know the different existing tools¬†üîß
&lt;/h2&gt;

&lt;p&gt;The best thing about DevOps is that you can &lt;strong&gt;work in different phases&lt;/strong&gt; and for each one there are different tools (&lt;em&gt;Jenkins, Chef, Nagios, Docker, Kubernetes, Git&lt;/em&gt;‚Ä¶) which you will learn over time and will be very useful.&lt;/p&gt;




&lt;h2&gt;
  &lt;a href="#5-you-will-avoid-more-errors-in-the-software%C2%A0"&gt;
  &lt;/a&gt;
  5. You will avoid more errors in the software¬†üíª
&lt;/h2&gt;

&lt;p&gt;We all know that, when programming, any error can cause &lt;strong&gt;serious problems&lt;/strong&gt; even for the &lt;strong&gt;entire company&lt;/strong&gt;, indeed, for the &lt;strong&gt;entire country&lt;/strong&gt;. If we go to some extreme example (which can happen) let's imagine that in the software of an electric vehicle there is an error that makes the vehicle not accelerate correctly, that can cause very serious problems.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;DevOps&lt;/em&gt; makes it &lt;strong&gt;easy&lt;/strong&gt; for the entire development team to be aware of all the other &lt;em&gt;DevOps&lt;/em&gt; teams, feedback, and possibilities to improve the &lt;em&gt;Software&lt;/em&gt;.&lt;/p&gt;




&lt;h2&gt;
  &lt;a href="#6-you-will-increase-the-speed%C2%A0"&gt;
  &lt;/a&gt;
  6. You will increase the speed¬†üèÉ‚Äç‚ôÇÔ∏è
&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;SDLC&lt;/strong&gt; process will be much faster with the help of &lt;em&gt;DevOps&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;It would make it easier for companies to better understand user behavior and later incorporate those changes in future versions.&lt;br&gt;
¬†&lt;br&gt;
This can be an &lt;strong&gt;advantage over the competition&lt;/strong&gt; at the same time that the user will have a better product. This is not just about continuous delivery, but also about continuous deployment. The clearest example is &lt;strong&gt;Amazon&lt;/strong&gt;, its engineers implement code &lt;strong&gt;every 12 seconds&lt;/strong&gt; on average.&lt;/p&gt;




&lt;h2&gt;
  &lt;a href="#7-you-will-have-faster-professional-growth%C2%A0"&gt;
  &lt;/a&gt;
  7. You will have faster professional growth¬†‚ö°
&lt;/h2&gt;

&lt;p&gt;It is very important to improve every day and especially when you are a developer, since nowadays technology advances &lt;strong&gt;very fast&lt;/strong&gt;. You need to bring great value to the company and that's where &lt;em&gt;DevOps&lt;/em&gt; comes in. This is the best way to increase your career growth in different companies.&lt;/p&gt;




&lt;h2&gt;
  &lt;a href="#8-you-will-get-a-wellpaid-job%C2%A0"&gt;
  &lt;/a&gt;
  8. You will get a well-paid job¬†ü§ë
&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;DevOps&lt;/em&gt; professionals typically have &lt;strong&gt;high-paying&lt;/strong&gt; jobs anywhere in the world, whatever country it is.&lt;/p&gt;




&lt;h2&gt;
  &lt;a href="#9-you-will-increase-the-ease-of-finding-a-job%C2%A0"&gt;
  &lt;/a&gt;
  9. You will increase the ease of finding a job¬†üî•
&lt;/h2&gt;

&lt;p&gt;The demand for &lt;em&gt;DevOps&lt;/em&gt; professionals &lt;strong&gt;is very high&lt;/strong&gt; around the world, but currently there are not enough people who meet the requirements set by companies. If you are in the development field, &lt;em&gt;DevOps&lt;/em&gt; is a &lt;strong&gt;great&lt;/strong&gt; opportunity for you.&lt;/p&gt;

&lt;p&gt;DevOps will allow you to obtain the ease you need for development since, according to the &lt;strong&gt;CIO's&lt;/strong&gt; knowledge, companies manage to increase their deployment frequency by &lt;strong&gt;50%&lt;/strong&gt; while reducing costs by up to &lt;strong&gt;45%&lt;/strong&gt;. In some cases, there has even been a &lt;strong&gt;22%&lt;/strong&gt; increase in clients, apart from increasing the chances of being hired.&lt;/p&gt;




&lt;h2&gt;
  &lt;a href="#10-learning-devops-is-easy%C2%A0"&gt;
  &lt;/a&gt;
  10. Learning DevOps is easy¬†ü§ó
&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;DevOps&lt;/em&gt; is &lt;strong&gt;easy to learn&lt;/strong&gt;, really any developer with a minimum of experience can learn &lt;em&gt;DevOps&lt;/em&gt; in a simple way, even with &lt;strong&gt;basic knowledge&lt;/strong&gt; of &lt;em&gt;Linux&lt;/em&gt; and any other programming language.&lt;/p&gt;

&lt;p&gt;By becoming a &lt;em&gt;DevOps&lt;/em&gt; engineer, you can easily understand the software development lifecycle and fully understand the different automation tools that exist for developing digital pipelines.&lt;/p&gt;

</description>
      <category>dotnet</category>
      <category>csharp</category>
      <category>programming</category>
      <category>devops</category>
    </item>
    <item>
      <title>Render images with the official Notion API</title>
      <author>Twan kruiswijk</author>
      <pubDate>Fri, 09 Jul 2021 12:47:30 +0000</pubDate>
      <link>https://dev.to/twankrui/render-images-with-the-official-notion-api-3gnh</link>
      <guid>https://dev.to/twankrui/render-images-with-the-official-notion-api-3gnh</guid>
      <description>&lt;p&gt;At the time of writing this post, the official Notion API doesn't yet provide support for image blocks. Since we are building a &lt;a href="https://github.com/twankruiswijk/Blion"&gt;blog template&lt;/a&gt;, we needed to develop a temporary solution to render images for the posts.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#solutions-that-didnt-cut-it"&gt;
  &lt;/a&gt;
  Solutions that didn't cut it
&lt;/h2&gt;

&lt;p&gt;We've looked at multiple ways to render an image for the posts:&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#1-wait-until-the-official-notion-api-adds-support-for-the-image-blocks"&gt;
  &lt;/a&gt;
  1. Wait until the official Notion API adds support for the image blocks
&lt;/h3&gt;

&lt;p&gt;This wasn't an option since having a blog without image support isn't appealing for many people, including myself. Also, it's been over a month, and we've had no updates on when new block types (like the image block) will get added.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#2-use-the-unofficial-notion-api-for-the-images"&gt;
  &lt;/a&gt;
  2. Use the unofficial notion API for the images
&lt;/h3&gt;

&lt;p&gt;We've looked into this, but we didn't want to rely on the unofficial API. We know that other platforms do, but having a mix of official and unofficial API calls would get messy and increase the complexity of the project, which we want to keep low.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#introducing-the-raw-postimagesource-endraw-array"&gt;
  &lt;/a&gt;
  Introducing the &lt;code&gt;postImageSource&lt;/code&gt; array
&lt;/h2&gt;

&lt;p&gt;Since the Notion API supports text links, we came up with the idea that the template users could specify domains that would render as an image instead of a link when added to their Notion post.&lt;/p&gt;

&lt;p&gt;Yes, this does mean that you can't use the same domain to render a text link.&lt;/p&gt;

&lt;p&gt;Since we have a configuration file, we added an array &lt;code&gt;postImageSource&lt;/code&gt; where users can specify which domains they want to render as an image when the template comes across a link with this domain.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="c1"&gt;// site.config.js&lt;/span&gt;
&lt;span class="nx"&gt;postImageSource&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
  &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;images.unsplash.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;res.cloudinary.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;dl.dropboxusercontent.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;],&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;To provide an upgrade path, we recommend that users still upload the image in their Notion document and place the text link below the image. This way, once the image block is ready in the official API, we can offer an option to make the &lt;code&gt;postImageSource&lt;/code&gt; work backwards, meaning that people can disable rendering text links that include domains from &lt;code&gt;postImageSource&lt;/code&gt;. Ultimately they can update all their posts and remove the &lt;code&gt;postImageSource&lt;/code&gt; permanently.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#dont-bore-us-get-to-the-chorus-code"&gt;
  &lt;/a&gt;
  Don't bore us, get to the &lt;del&gt;chorus&lt;/del&gt; code!
&lt;/h2&gt;

&lt;p&gt;So you are working on your project that utilizes the Notion API? Nice, I would love to hear about it in the comments! But I know why you are here, and you want the code. Without further ado, here is the bare minimum of code that is required to display the images.&lt;/p&gt;

&lt;p&gt;First, Add an array where you specify the domains you want to render as images&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;postImageSource&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
  &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;images.unsplash.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;res.cloudinary.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;dl.dropboxusercontent.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Second, determine if the text object has a link property.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;postImageSource&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
  &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;images.unsplash.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;res.cloudinary.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;dl.dropboxusercontent.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;];&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;text&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;link&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
 &lt;span class="p"&gt;....&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Finally, check if the link includes the domain and determine whether to render an image or a text link.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;postImageSource&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
  &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;images.unsplash.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;res.cloudinary.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;dl.dropboxusercontent.com&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;];&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;text&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;link&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;linkUrl&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;text&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;link&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;url&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;postImageSource&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;some&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;u&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;linkUrl&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;includes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;u&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;img&lt;/span&gt; &lt;span class="nx"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;linkUrl&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nx"&gt;alt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;insert alt&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt; &lt;span class="o"&gt;/&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="c1"&gt;// If the domain is not specified in the postImageSource, render a text link.&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;a&lt;/span&gt; &lt;span class="nx"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;linkUrl&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="nx"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;_blank&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt; &lt;span class="nx"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;noopener noreferrer&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;text&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;content&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="sr"&gt;/a&amp;gt;&lt;/span&gt;&lt;span class="err"&gt;;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Hopefully, this guide helps you add image support to your Notion-powered website for the time being. Let's hope that the fantastic developers over at Notion crack the formula and add support for images and videos soon because that would open up a world of beautiful possibilities.&lt;/p&gt;

</description>
      <category>webdev</category>
      <category>notion</category>
      <category>javascript</category>
    </item>
    <item>
      <title>Cloud Technology News of the Month: June 2021</title>
      <author>CAST AI</author>
      <pubDate>Fri, 09 Jul 2021 12:47:00 +0000</pubDate>
      <link>https://dev.to/castai/cloud-technology-news-of-the-month-june-2021-32d8</link>
      <guid>https://dev.to/castai/cloud-technology-news-of-the-month-june-2021-32d8</guid>
      <description>&lt;p&gt;We can‚Äôt believe the first half of 2021 is already over. Lots of interesting things have happened in the cloud space so far - but surely, there‚Äôs more to come.&lt;/p&gt;

&lt;p&gt;So, here‚Äôs another portion of fresh cloud technology news! This series brings you up to speed with the latest releases, acquisitions, research, and hidden gems in the world of cloud computing ‚Äì the stuff actually worth reading.¬†&lt;/p&gt;

&lt;p&gt;Here‚Äôs what the cloud world has been up to in June 2021.&lt;/p&gt;

&lt;p&gt;_____&lt;/p&gt;

&lt;h2&gt;Story of the month: AWS is on fire&lt;/h2&gt;

&lt;p&gt;On June 10, an availability zone in the AWS EU-Central region experienced a major outage (EUC_AZ-1).¬†&lt;/p&gt;

&lt;p&gt;At first, the breakdown caused connectivity issues for some EC2 instances. It then increased API error rates and latencies for the EC2 APIs and resulted in some further connectivity problems ‚Äúcaused by an increase in ambient temperature.‚Äù¬†&lt;/p&gt;


&lt;blockquote class="ltag__twitter-tweet"&gt;

  &lt;div class="ltag__twitter-tweet__main"&gt;
    &lt;div class="ltag__twitter-tweet__header"&gt;
      &lt;img class="ltag__twitter-tweet__profile-image" src="https://res.cloudinary.com/practicaldev/image/fetch/s--83a1mTxm--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://pbs.twimg.com/profile_images/1403025766875422720/x4ZU04Ao_normal.jpg" alt="Corey Quinn profile image"&gt;
      &lt;div class="ltag__twitter-tweet__full-name"&gt;
        Corey Quinn
      &lt;/div&gt;
      &lt;div class="ltag__twitter-tweet__username"&gt;
        @quinnypig
      &lt;/div&gt;
      &lt;div class="ltag__twitter-tweet__twitter-logo"&gt;
        &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ir1kO05j--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/twitter-f95605061196010f91e64806688390eb1a4dbc9e913682e043eb8b1e06ca484f.svg" alt="twitter logo"&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="ltag__twitter-tweet__body"&gt;
      BREAKING: There is currently a fire in a data center that's part of &lt;a href="https://twitter.com/awscloud"&gt;@awscloud&lt;/a&gt;'s eu-central-1 region. Impact limited to a single AZ, obviously. All humans reportedly safe.
    &lt;/div&gt;
    &lt;div class="ltag__twitter-tweet__date"&gt;
      21:24 PM - 10 Jun 2021
    &lt;/div&gt;


    &lt;div class="ltag__twitter-tweet__actions"&gt;
      &lt;a href="https://twitter.com/intent/tweet?in_reply_to=1403100781646028808" class="ltag__twitter-tweet__actions__button"&gt;
        &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--fFnoeFxk--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/twitter-reply-action-238fe0a37991706a6880ed13941c3efd6b371e4aefe288fe8e0db85250708bc4.svg" alt="Twitter reply action"&gt;
      &lt;/a&gt;
      &lt;a href="https://twitter.com/intent/retweet?tweet_id=1403100781646028808" class="ltag__twitter-tweet__actions__button"&gt;
        &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--k6dcrOn8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/twitter-retweet-action-632c83532a4e7de573c5c08dbb090ee18b348b13e2793175fea914827bc42046.svg" alt="Twitter retweet action"&gt;
      &lt;/a&gt;
      &lt;a href="https://twitter.com/intent/like?tweet_id=1403100781646028808" class="ltag__twitter-tweet__actions__button"&gt;
        &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--SRQc9lOp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/twitter-like-action-1ea89f4b87c7d37465b0eb78d51fcb7fe6c03a089805d7ea014ba71365be5171.svg" alt="Twitter like action"&gt;
      &lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/blockquote&gt;


&lt;p&gt;At some point, temperatures fell but engineers still couldn‚Äôt enter the affected part of the AZ for safety reasons. Three hours after the breakdown, services were restored.&lt;/p&gt;

&lt;p&gt;So, what exactly made this data center dangerous to enter? The most recent update from AWS showed that the incident was caused by the "failure of a control system which disabled multiple air handlers in the affected Availability Zone," leading to a larger number of EC2 instances in this AZ to lose network connectivity.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;Why risk going down when you can save your workloads using another provider?&lt;/strong&gt; This and many other incidents that happened over the last months show the pressing need for companies to invest in a multi cloud strategy.¬†&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Source: &lt;a href="https://www.theregister.com/2021/06/11/aws_eu_central_1_incident/"&gt;The Register&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--nIBPenOi--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cast.ai/wp-content/uploads/2021/07/image3-1200x1229.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--nIBPenOi--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cast.ai/wp-content/uploads/2021/07/image3-1200x1229.png" alt="recent cloud outages AWS Google Azure"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;_____&lt;/p&gt;

&lt;h2&gt;The Business of Cloud&lt;/h2&gt;

&lt;p&gt;Here‚Äôs one interesting acquisition: the tax and auditing giant &lt;strong&gt;Deloitte got its hands on the cloud security orchestration provider CloudQuest&lt;/strong&gt;. This is the company‚Äôs second security-related acquisition this year as Deloitte clearly aims to enhance its cybersecurity offering to help its customers in areas like CSPM and SOAR.&lt;/p&gt;

&lt;p&gt;Source: &lt;a href="https://www.zdnet.com/article/deloitte-acquires-cloud-security-orchestration-provider-cloudquest/"&gt;ZDNet&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A big win for Microsoft - &lt;strong&gt;AT&amp;amp;T is moving its 5G cloud network to Azure&lt;/strong&gt;. Following a 5G partnership initiated in 2019, this deal paves the way to Microsoft eventually handling all of the wireless carrier‚Äôs 5G traffic, starting with the core software that connects customers to the internet.&lt;/p&gt;

&lt;p&gt;Source: &lt;a href="https://www.bloomberg.com/news/articles/2021-06-30/at-t-agrees-to-outsource-its-5g-network-to-microsoft-s-azure"&gt;Bloomberg&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Chips are still hot on the market. One of the largest chip manufacturers &lt;strong&gt;Broadcom shared an impressive forecast&lt;/strong&gt; for quarterly sales driven by the growing demand for chips used in data centers and beyond. Its revenue in Q3 is set to reach a smashing &lt;strong&gt;$6.75 billion&lt;/strong&gt;.¬†&lt;/p&gt;

&lt;p&gt;Source: &lt;a href="https://finance.yahoo.com/news/broadcom-gives-bullish-forecast-persistent-203900208.html"&gt;Yahoo!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;_____&lt;/p&gt;

&lt;h2&gt;New in CAST AI&lt;/h2&gt;

&lt;h3&gt;Now available publicly: GKE Analyzer&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--amZ_0iR8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cast.ai/wp-content/uploads/2021/07/image2-1-1200x362.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--amZ_0iR8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cast.ai/wp-content/uploads/2021/07/image2-1-1200x362.png" alt="GKE cost optimization"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GKE Analyzer&lt;/strong&gt; goes through your cluster costs, pinpoints any potential savings you could achieve, and then tells you how to get there. If you‚Äôre a GKE user, connect your cluster, get your self-served savings report and &lt;a href="https://console.cast.ai/external-clusters/new"&gt;start optimizing your cloud costs&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here are some new product features hot off the press:¬†¬†&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;CAST AI now supports Organizations!&lt;/strong&gt; Multiple team members from a company can now join CAST AI, create an organization inside our console, and collaboratively manage K8s clusters.&lt;/li&gt;
&lt;li&gt;The connected AWS (EKS and kOps) clusters can now be &lt;strong&gt;paused and resumed&lt;/strong&gt; as easily as the clusters created in CAST AI. Functionality to pause and resume on a pre-set schedule is coming soon as well.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;node list is now accessible&lt;/strong&gt; as soon as the cluster is connected. You no longer need an onboard cluster to access this functionality.&lt;/li&gt;
&lt;li&gt;Clusters that were onboarded to CAST AI can now be &lt;strong&gt;disconnected via the UI&lt;/strong&gt;, users can delete or leave CAST AI-created nodes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;_____&lt;/p&gt;

</description>
      <category>cloudnative</category>
      <category>kubernetes</category>
      <category>devops</category>
      <category>aws</category>
    </item>
    <item>
      <title>A tech interview that doesn't suck</title>
      <author>Jacob Paris</author>
      <pubDate>Fri, 09 Jul 2021 12:09:53 +0000</pubDate>
      <link>https://dev.to/jacobmparis/a-tech-interview-that-doesn-t-suck-14o4</link>
      <guid>https://dev.to/jacobmparis/a-tech-interview-that-doesn-t-suck-14o4</guid>
      <description>&lt;p&gt;One of the many major things the tech industry is bad at is job interviews.&lt;/p&gt;

&lt;p&gt;No other profession has so little correlation between candidates who are good at interviews and good at the job they are interviewing for. Most tech interviews focus on testing skills that have nothing at all to do with the kind of work the candidate would be doing day-to-day.&lt;/p&gt;

&lt;p&gt;Good tech interviews are equally accessible to self-taught, bootcamp, or college graduates, and don't prefer developers who have enough free time to dedicate to drilling code trivia.&lt;/p&gt;

&lt;p&gt;Good tech interviews favour candidates who are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Comfortable solving problems autonomously&lt;/li&gt;
&lt;li&gt;Able to recognize gaps in their knowledge&lt;/li&gt;
&lt;li&gt;Learn things as they need to know them&lt;/li&gt;
&lt;li&gt;Able to maintain their code as requirements change&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Instead of white-boarding, code challenges, or testing knowledge of algorithms, I prefer to test candidates by giving them a small take-home TODO list application, written any way they want, followed by a live-coding segment where they add three small features.&lt;/p&gt;

&lt;p&gt;Writing code and then adding features to that code models exactly what developers are expected to do on the job. Developers who have the time to practice LeetCode questions aren't better at writing TODO applications than developers who don't. Stanford has a class teaching &lt;a href="https://web.stanford.edu/class/cs9/"&gt;how to pass the google exam&lt;/a&gt;, but Stanford students don't get an advantage here.&lt;/p&gt;

&lt;p&gt;TODO applications are the most common tutorial, so almost every developer has interacted with one at some point. They don't require complex algorithms which are only taught in universities, and there are so many unique ways to build them depending on the developer's preferences, skills, and choices.&lt;/p&gt;

&lt;p&gt;If you're hiring Frontend engineers, Backend engineers, DevOps engineers, or QA engineers, a TODO application can be written to stress the important skills for each role.&lt;/p&gt;

&lt;p&gt;This is the spec I've used for dozens of interviews, made generic enough to allow the candidate shape the application to best demonstrate their abilities.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#the-take-home-project"&gt;
  &lt;/a&gt;
  The Take Home Project
&lt;/h2&gt;

&lt;p&gt;Imagine the business has asked you to build a simple todo list application for the web.&lt;/p&gt;

&lt;p&gt;Requirements&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The user should be able to view a list of tasks&lt;/li&gt;
&lt;li&gt;Each task should contain a title&lt;/li&gt;
&lt;li&gt;The user should be able to create a task&lt;/li&gt;
&lt;li&gt;The user should be able to edit a task&lt;/li&gt;
&lt;li&gt;The user should be able to mark a task completed&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Try to spend no more than 3 hours of work on this assignment. If some areas lack polish, it will be reviewed with the understanding that there was a narrow time constraint.&lt;/p&gt;

&lt;p&gt;Use whatever tools, frameworks, and languages that you are most comfortable with. There are no extra points for using the same tech stack that we use. The more confident you are with the tools you've chosen, the more impressive your application will be. If you excel in a particular area, choose an architecture that allows you to demonstrate that.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The application can be server side, client side, or both&lt;/li&gt;
&lt;li&gt;Data can be persisted to a database, to local storage, or not at all&lt;/li&gt;
&lt;li&gt;Tests can be end-to-end, integration, unit, or none at all&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Create a repository on your preferred source control host (GitHub, Bitbucket, GitLab, etc) and commit your code to it, along with a README.md file that explains how to install and run the app. These instructions could be as simple as "clone the repo, run npm install, run npm start" but some projects take longer to set up.&lt;/p&gt;

&lt;p&gt;When you're finished, email the interviewer with a link (and invite if the repository is private).&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#the-followup-interview"&gt;
  &lt;/a&gt;
  The Follow-Up Interview
&lt;/h2&gt;

&lt;p&gt;Most candidates are nervous in interviews regardless of their confidence level on the job. Try to understand that getting or not getting the job will change the course of their career in one direction or the other.&lt;/p&gt;

&lt;p&gt;Start the interview with a few minutes of small-talk to establish a bit of rapport and get the candidate more comfortable speaking on camera.&lt;/p&gt;

&lt;p&gt;If you haven't already confirmed whether the candidate is legally able to get the job, do that now. Even if the requirements were listed explicitly in the job posting, don't assume it's been read or understood. In general, hiring contractors, even from out-of-country, is far easier than hiring employees and you'll have fewer questions to ask.&lt;/p&gt;

&lt;p&gt;For employees, you should determine if they're legally allowed to work in your country. For example, whether or not they're a citizen or a permanent resident or if they're on a work visa. If they're on a work visa, see how long it's eligible for and when it's going to expire. If you're looking to hire someone who will last a year or more at your company but their visa is due to expire in six months, that's something you want to find out sooner rather than later.&lt;/p&gt;

&lt;p&gt;Ask where they're currently living. This may not be the city they have listed on their resum√© or online profiles or any other documentation you've seen so far. It's important to make sure that the hours they intend to work are compatible with the rest of the team. Even if you're fully asynchronous, it's good to have an idea of when they can be expected to be online.&lt;/p&gt;

&lt;p&gt;I'd also recommend you ask what timeframe they would be looking to start once hired. Some candidates will be able to start right away and others might need weeks to transition from their current job, especially if they're relocating.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#the-livecoding-segment"&gt;
  &lt;/a&gt;
  The Live-Coding Segment
&lt;/h2&gt;

&lt;p&gt;Being able to see how people maintain code they've written themselves is a great signal for a developer who knows what they're doing&lt;/p&gt;

&lt;p&gt;To &lt;em&gt;maintain code&lt;/em&gt; is to modify it to handle a changing set of requirements.&lt;/p&gt;

&lt;p&gt;Have the candidate share their screen as you move into the live-coding portion of the interview. It's a good idea to remind them to turn on Do not Disturb mode so that no notifications appear while they're sharing. If they have a large screen, encourage them to zoom in or increase font size so their code is legible.&lt;/p&gt;

&lt;p&gt;Be prepared to walk them through allowing screen sharing permissions if they haven't already allowed those.&lt;/p&gt;

&lt;p&gt;I start by having them walk through the code, pointing out anything notable in their implementation&lt;/p&gt;

&lt;p&gt;They may have chosen to use a simple non-scalable architecture because that's all that the requirements of this demo project demanded. They also could have chosen to over-engineer the code as a demonstration of how they would handle a more complex project. Either decision is rational&lt;/p&gt;

&lt;p&gt;Be careful about prodding these questions on your own so you don't hint at preferring one decision over the other. If the candidate feels like they've already made a mistake, they're less likely to perform as confidently in the interview as they would on the job.&lt;/p&gt;

&lt;p&gt;Time-boxing this portion of the interview is a good idea. 45 minutes for the whole segment gives 15 for each task, and you can warn them if they're spending too long on any particular one.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#exercise-1-permanently-delete-all-completed-tasks"&gt;
  &lt;/a&gt;
  Exercise 1: Permanently delete all completed tasks
&lt;/h3&gt;

&lt;p&gt;Add a button that deletes all the tasks that have been marked as complete.&lt;/p&gt;

&lt;p&gt;The usual solution here is to replace the list of tasks with a new array that contains only the incomplete tasks.&lt;/p&gt;

&lt;p&gt;An easy way to make the new array is using Javascript's native array filter&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;incompleteTasks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;tasks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;completed&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The candidate might prefer stepping through the list of tasks in a loop to build the new array manually.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;incompleteTasks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;task&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="nx"&gt;tasks&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;completed&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;incompleteTasks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;push&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Another solution would be to remove the completed tasks directly from the list without making a new array. This can be tricky because they're stepping through the list one by one but also removing tasks from it, so it's easy to accidentally skip an item. If the candidate presses the button with two tasks in a row marked complete, and it fails to delete the second one, this is usually the reason why.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nx"&gt;tasks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;length&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;completed&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nx"&gt;tasks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;splice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;// Remove task number i&lt;/span&gt;
    &lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="o"&gt;--&lt;/span&gt; &lt;span class="c1"&gt;// If we deleted task 4, task 5 will slide up into its spot, so we need to check task 4 again next&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h3&gt;
  &lt;a href="#exercise-2-sort-tasks-in-descending-order"&gt;
  &lt;/a&gt;
  Exercise 2: Sort tasks in descending order
&lt;/h3&gt;

&lt;p&gt;Sort tasks in descending order, so that new items are added to the top of the list instead of the bottom.&lt;/p&gt;

&lt;p&gt;If the candidate is not currently storing dates on each task, that's the first step, but it's up to them to determine that. They'll have to add dates to any new tasks they're adding plus any they might have stored to show up by default (if any).&lt;/p&gt;

&lt;p&gt;There are a few ways to cheat here that should be discouraged. At the moment, every new task appears at the bottom of the list. That makes it look like it's already sorted in ascending order. The candidate might be tempted to render &lt;code&gt;tasks.reverse()&lt;/code&gt; or to add new tasks to the beginning of the array instead of the end.&lt;/p&gt;

&lt;p&gt;This only works by coincidence, and as soon as it's possible to add tasks with past or future dates, this fake sorting will break.&lt;/p&gt;

&lt;p&gt;The usual solution is using javascript's native sort method. After giving this question to dozens of candidates I've concluded that no one remembers how this method works. To me, this question is an exercise on whether the candidate is able to look up documentation to patch their knowledge on anything they're missing, which is an incredibly valuable skill to screen for.&lt;/p&gt;

&lt;p&gt;Sort works by comparing two tasks (A and B) in the list and returning &lt;code&gt;-1&lt;/code&gt;, &lt;code&gt;1&lt;/code&gt;, or &lt;code&gt;0&lt;/code&gt;, depending on whether task A should be sorted before, after, or equally with B.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="nx"&gt;tasks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;a&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dateCreated&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nx"&gt;b&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dateCreated&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;a&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dateCreated&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;b&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dateCreated&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Using ternary is common here. It's not a big deal if they don't handle the 0 case for identical dates.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="nx"&gt;tasks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;a&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dateCreated&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nx"&gt;b&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dateCreated&lt;/span&gt; &lt;span class="p"&gt;?&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;If the dates are stored as a number (for example, a timestamp rather than a date), they might just subtract them. I'm less fond of this but it's incredibly common.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="nx"&gt;tasks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nx"&gt;a&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dateCreated&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;b&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;dateCreated&lt;/span&gt;
&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;When candidates implement the sort method incorrectly, common mistakes are to compare &lt;code&gt;a - b&lt;/code&gt; directly, instead of &lt;code&gt;a.dateCreated - b.dateCreated&lt;/code&gt;, or to return true or false instead of 1 or -1. Nudge them toward the documentation if they're making these sorts of mistakes. Sometimes candidates try too hard not to look anything up during the interview even if they would be quick to do so on the job, so extra encouragement can help.&lt;/p&gt;

&lt;p&gt;When candidates implement the sort method correctly, the most common mistake here is to accidentally sort the wrong way first. If their sort doesn't appear to work the first time, it might be sorting into ascending order (which looks like nothing has changed). Most candidates will test swapping the order on their own, but feel free to suggest that if they seem confused.&lt;/p&gt;

&lt;p&gt;The second most common mistake is forgetting that the sort method mutates the original array. If they've built all their code from scratch, this probably won't be an issue, but frameworks like React and Vue will throw errors if they mutate state variables. There are a few ways to clone the list of tasks before running sort, including &lt;code&gt;Array().concat(tasks).sort&lt;/code&gt;, &lt;code&gt;tasks.slice().sort&lt;/code&gt;, &lt;code&gt;[...tasks].sort&lt;/code&gt;, or by chaining sort after a map or filter operation. If they're having trouble with this one, explain the problem, but give them time to find their own solution.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#exercise-3-split-the-tasks-into-two-lists"&gt;
  &lt;/a&gt;
  Exercise 3: Split the tasks into two lists
&lt;/h3&gt;

&lt;p&gt;Split the tasks into two lists, with incomplete tasks on top, completed tasks on the bottom, such that marking a task as complete moves it from one list to the other.&lt;/p&gt;

&lt;p&gt;It's up to you as the interviewer whether you require the sorting to still be in effect for this exercise. It's simpler if you don't, but optional.&lt;/p&gt;

&lt;p&gt;The ideal implementation is also the simplest: keep one main array of tasks, and render two lists filtered to either complete or incomplete.&lt;/p&gt;

&lt;p&gt;That might look something like this&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;completeTasks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;tasks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;complete&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;incompleteTasks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;tasks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;complete&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The more challenging implementation, which I've seen several candidates attempt but never complete within the time allowed, is to maintain two separate lists of tasks and move items from one to the other when marking as complete or incomplete. If they start to run out of time, I would suggest the simpler solution, but give them time to come to that conclusion on their own. The ability to realize when they're going down the wrong path and re-evaluate their chosen solution is a good skill to have, and this is a good place to watch for it.&lt;/p&gt;

</description>
      <category>career</category>
      <category>javascript</category>
    </item>
    <item>
      <title>How to build a React portfolio that gets you a job - Part 1</title>
      <author>Johannes Kettmann</author>
      <pubDate>Fri, 09 Jul 2021 12:09:24 +0000</pubDate>
      <link>https://dev.to/profydev/how-to-build-a-react-portfolio-that-gets-you-a-job-part-1-5fh9</link>
      <guid>https://dev.to/profydev/how-to-build-a-react-portfolio-that-gets-you-a-job-part-1-5fh9</guid>
      <description>&lt;p&gt;Let me guess: You've been learning React for a while already. Now it's time to build a portfolio of advanced React projects. And you're looking for inspiration. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The thing is you can't just build any project. Your portfolio has a purpose:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Your goal is to get a job.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, you'll hit one major roadblock on your journey: the Hiring Manager (capital letters).&lt;/p&gt;

&lt;p&gt;They are the gatekeeper who makes the decisions. They invite you to an interview. Or toss your application in the trash. And believe me, they have piles of applications to trash for any entry-level job. &lt;/p&gt;

&lt;p&gt;You need to convince the hiring manager that you're ready for the job.&lt;/p&gt;

&lt;p&gt;And the best way to prove that is to &lt;strong&gt;act like a professional React developer.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Build your portfolio projects with the technologies, libraries, techniques, and workflows that are used in professional dev teams in the real world. The doors to your new career will be wide open.&lt;/p&gt;

&lt;p&gt;Simple enough. Act like a professional dev...&lt;/p&gt;

&lt;p&gt;But hold on. How should you know all this? You've never worked in a real company before, have you?&lt;/p&gt;

&lt;p&gt;No worries. I got your back.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Unlike other articles, I don't just hand you a list of project ideas and call it a day.&lt;/strong&gt; I want you to understand how you can tailor your projects to impress your future employer. Be it one of the ideas in this series of articles or one of your own.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#what-youll-get-in-this-series"&gt;
  &lt;/a&gt;
  What you'll get in this series
&lt;/h2&gt;

&lt;p&gt;This guide consists of three parts. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In this first part, you'll learn how to build your projects like a pro.&lt;/strong&gt; We'll touch on topics like professional workflows, styles, and application logic.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The upcoming second part will be all about effectively presenting your project.&lt;/strong&gt; You've shed blood, sweat &amp;amp; tears for your portfolio project. Make sure that the hiring manager doesn't miss the important parts.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In the third part, you'll get a list of three uncommon project ideas:&lt;/strong&gt; Reddit Analytics, a UI kit, and an error monitoring tool. Build any of these for an outstanding React portfolio.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I'll release the two remaining parts in the next days here on dev.to. If you want to read all of them right away you can visit the original post at &lt;a href="https://profy.dev/article/react-projects-for-your-portfolio"&gt;profy.dev&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;
  &lt;a href="#part-1-how-to-build-your-react-portfolio-projects-like-a-pro"&gt;
  &lt;/a&gt;
  Part 1: How to build your React portfolio projects like a pro
&lt;/h2&gt;

&lt;p&gt;The idea sounds convincing: your future employer will be more likely to give you a shot if you build your portfolio projects like a pro. &lt;/p&gt;

&lt;p&gt;You'll look ambitious. You'll prove that you're eager to learn and level up. Some of the most important traits of a Junior developer.&lt;/p&gt;

&lt;p&gt;Unfortunately, this is a catch-22 situation: you don't know how to work like a pro until you've been part of a professional team.&lt;/p&gt;

&lt;p&gt;Luckily, I've been on both sides. And I'd like to share my experience with you in this chapter.&lt;/p&gt;

&lt;p&gt;We'll focus on the most important areas:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;working like a pro&lt;/li&gt;
&lt;li&gt;styles&lt;/li&gt;
&lt;li&gt;application logic&lt;/li&gt;
&lt;li&gt;Git&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#working-like-a-professional"&gt;
  &lt;/a&gt;
  Working like a professional
&lt;/h3&gt;

&lt;p&gt;There's a huge difference between working alone and on a professional team. In a team, your co-workers depend on your work the same way you depend on theirs. That's why you need to work with much more structure and transparency.&lt;/p&gt;

&lt;p&gt;But let's start with a story of a lone developer building a project. This is me at the beginning of my career in tech. Be careful, you might recognize yourself.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When I built my first projects I started with an idea. Let's say an Airbnb for pet owners (no joke, I really built this).&lt;/p&gt;

&lt;p&gt;I thought about the features it should have. The user should be able to create and update their profile. And there should be a list view that shows all the available apartments. Ideally searchable.&lt;/p&gt;

&lt;p&gt;Fair enough. Off I went into code-land. That's the fun part after all, right?&lt;/p&gt;

&lt;p&gt;Soon another interesting feature would pop into my head. I'd lose focus and start working on it straight away. Leaving me with a bunch of half-baked code. Entangled as the infamous spaghetti.&lt;/p&gt;

&lt;p&gt;The layout was another kind of problem. I'd obviously have a look at Airbnb and similar competitors to get design ideas. Then I'd start writing CSS.&lt;/p&gt;

&lt;p&gt;I'd fiddle around with my styles. I would move elements pixel by pixel. I'd change some colors here and increase some text size there. Make it bold, make it italic.&lt;/p&gt;

&lt;p&gt;Only to find out that it's actually harder than expected to make a website look good...&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;You see the problem? I'd make a plan, yeah. But only a very rough one and only in my head.&lt;/strong&gt; I'd waste a lot of time with unnecessary features and fiddling around with CSS details. And the awesome web app that I had in mind looked more like... ehm...&lt;/p&gt;

&lt;p&gt;So how does working on a professional dev team compare to that?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Professional frontend developers get two things before they start coding:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;tasks&lt;/li&gt;
&lt;li&gt;designs.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In a real-world job, it's not the developer's responsibility to come up with features or designs. Typically a product manager decides what has to be built. And a designer prepares the designs.&lt;/p&gt;

&lt;p&gt;It's the dev's job to turn them into working code.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The good news is, you can work the same way as the pros.&lt;/strong&gt; You start with designs. Then create the tasks. Only then you start to code.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;First, the designs.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Of course, you don't want to hire a designer just to build a couple of portfolio projects. And as I said, you shouldn't create the designs yourself either. That's not your responsibility on the job. &lt;/p&gt;

&lt;p&gt;So where to get designs from?&lt;/p&gt;

&lt;p&gt;A good place to start is the &lt;a href="https://www.figma.com/community/web_design"&gt;Figma Community&lt;/a&gt;. You'll find many professional designs that you can simply clone into your free Figma account. You might find a ready-made app design that you like. If not, you can use one of the UI kits to build a custom design yourself. Simply drag &amp;amp; drop the elements into place.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Next, you create the tasks.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is how it works in a nutshell.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;You take the designs and break them into smaller parts (aka features). &lt;/li&gt;
&lt;li&gt;For each feature, you create a task. You can use a free tool like &lt;a href="https://github.com/features/project-management/"&gt;GitHub project management&lt;/a&gt;, &lt;a href="https://clickup.com"&gt;ClickUp&lt;/a&gt;, or simply &lt;a href="https://trello.com"&gt;Trello&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For each task, you collect the requirements. What is the feature supposed to do? How can the user interact with it? Where does the data come from?&lt;/li&gt;
&lt;li&gt;If a task gets too big you can break it down into smaller subtasks.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Now you can start coding.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If you structure yourself this way you'll be much closer to a real job experience. Instead of randomly writing code for different parts of your app you'll start to think and work like a professional developer. &lt;/p&gt;

&lt;p&gt;And that in turn is impressive for any employer.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If this sounds like too much work&lt;/strong&gt; you can check out &lt;a href="#reddit-analytics"&gt;the Reddit Analytics app in the ideas chapter at the end of this guide&lt;/a&gt;. I've prepared this project for you including designs and tasks. But even if you put in the work yourself I'm sure it'll pay off in the long-term.&lt;/p&gt;

&lt;p&gt;Now that you know how to prepare your project and work on it like a pro let's dive into more technical topics.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#styles"&gt;
  &lt;/a&gt;
  Styles
&lt;/h3&gt;

&lt;p&gt;You might be tempted to use a UI library like Material UI or Bootstrap. And you're right, these are great libraries. They can be very valuable if you need to build an app quickly. For example, if you're working in an early-stage startup or building websites for clients as a freelancer.&lt;/p&gt;

&lt;p&gt;But most development teams work differently. &lt;/p&gt;

&lt;p&gt;Unique branding is super important for companies. That's why a designer prepares custom designs and styleguides. At least for the user-facing parts of the application.&lt;/p&gt;

&lt;p&gt;And as we mentioned in the last chapter, it's the developer's job to turn those designs into code.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;So to stay close to real production apps write custom CSS&lt;/strong&gt; instead of using ready-made UI libraries. Writing CSS is a much more flexible skill that you will use in any job.&lt;/p&gt;

&lt;p&gt;But UI libraries not only provide ready-made elements. They also simplify your life by taking the burden of responsiveness off your shoulders. Again, this might be good to get off the ground quickly.&lt;/p&gt;

&lt;p&gt;But you want to prove that you can work as a React developer under realistic conditions. &lt;strong&gt;And being able to build responsive layouts with CSS is very important nowadays.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In most cases, it's not very hard to make your app responsive. Let's say you have designs for desktops only. Make sure to test your app on different screen sizes e.g. using the Chrome dev tools' responsive mode.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--v3yA6ejD--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://media.graphcms.com/IBJOfKCgTmjuk7gyjQ19" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--v3yA6ejD--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://media.graphcms.com/IBJOfKCgTmjuk7gyjQ19" alt="Untitled.png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Apart from writing custom CSS and keeping responsiveness in mind I have one last advice regarding styles:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Don't use global classes.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I see global CSS classes quite often when reviewing Junior React developer's portfolio projects. It makes me question the knowledge of the candidate.&lt;/p&gt;

&lt;p&gt;The problem is that global class names are not scalable. Once you have a larger application you'll run into naming conflicts. You'll have to use more specific names. Finally, you'll end up using a naming convention like &lt;a href="https://css-tricks.com/bem-101/"&gt;BEM&lt;/a&gt;. That's so 2015!&lt;/p&gt;

&lt;p&gt;Good news, this is really easy to fix. The simple solution is to use &lt;a href="https://github.com/css-modules/css-modules"&gt;CSS Modules&lt;/a&gt; which works out of the box with Create React App, Next.js, or Gatsby. If you want to take it a step further have a look at one of the modern CSS-in-JS libraries like &lt;a href="https://styled-components.com/"&gt;styled-components&lt;/a&gt;. You might need to tweak your app's setup slightly but there should be tutorials in most cases.&lt;/p&gt;

&lt;p&gt;In case you want to see an example, here you go.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="c1"&gt;// don't use global classes like this&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;./index.css&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;MyComponent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="c1"&gt;// this will become class="box" in the HTML&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt; &lt;span class="na"&gt;className&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"box"&lt;/span&gt; &lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;// but rather scoped classes with CSS Modules&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nx"&gt;styles&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;./Box.module.css&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;MyComponent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="c1"&gt;// this will become something like class="Box‚Äîbox-3MbgH"&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt; &lt;span class="na"&gt;className&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;styles&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;box&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;// or styled-components (even better imo)&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nx"&gt;styled&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;styled-components&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;Box&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;styled&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;div&lt;/span&gt;&lt;span class="s2"&gt;`
  background: red;
`&lt;/span&gt;

&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;MyComponent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="c1"&gt;// this will be similar to class="Box‚Äîbox-3MbgH"&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nc"&gt;Box&lt;/span&gt; &lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h3&gt;
  &lt;a href="#application-logic"&gt;
  &lt;/a&gt;
  Application logic
&lt;/h3&gt;

&lt;p&gt;Application logic (aka your JS code) is what makes the difference between a website and a web application.&lt;/p&gt;

&lt;p&gt;If you plan to become a real software developer you need to prove that you can build more than a simple static website. That's one of the reasons &lt;a href="https://jkettmann.com/dont-waste-your-time-on-a-portfolio-website/"&gt;I'd recommend not to waste a lot of time on a portfolio website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Any real-world application touches three important areas: routing, state, and data. These are also the areas you should prove your skills in. As a bonus point, let me mention automated tests since they are super important in the daily life of many developers. &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;strong&gt;Routing:&lt;/strong&gt; You can use the de facto standard &lt;a href="https://reactrouter.com/"&gt;React Router&lt;/a&gt;. A route with URL parameters would be nice to have.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;State:&lt;/strong&gt; Any dynamic app relies on state. But no need to go fancy here. Since GraphQL or &lt;a href="https://react-query.tanstack.com/reference/useQuery"&gt;React Query&lt;/a&gt; I see more and more applications move away from state management solutions like Redux. So in my opinion, the native React hooks &lt;code&gt;useState&lt;/code&gt;, &lt;code&gt;useReducer&lt;/code&gt;, or &lt;code&gt;useContext&lt;/code&gt; should be sufficient.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;Data:&lt;/strong&gt; Your app should at least fetch some data from an API and render it. Ideally, the user can trigger requests dynamically. For example, by applying a filter or submitting a form. You can prove that you understand the data flow, that you can structure your data, and that you know the basic JS array functions like &lt;code&gt;map&lt;/code&gt;, &lt;code&gt;filter&lt;/code&gt;, or &lt;code&gt;reduce&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;Tests:&lt;/strong&gt; Automated tests are essential for any serious software product. And Senior developers value testing very highly. At the same time, most Junior developers have no experience in testing whatsoever. That can be your advantage. If you cover at least parts of your code with tests you'll have a huge advantage over other candidates. Take my word on it and give React Testing Library a try. Here you can find &lt;a href="https://jkettmann.com/beginners-guide-to-testing-react"&gt;a beginner's guide to testing React apps&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;
  &lt;a href="#git"&gt;
  &lt;/a&gt;
  Git
&lt;/h3&gt;

&lt;p&gt;As a software developer, you'll have to work with other developers eventually. And the one tool essential to collaboration among devs is Git.&lt;/p&gt;

&lt;p&gt;So starting to use Git in a proper way can't hurt in any case. But it might also impact your chances of getting a job.&lt;/p&gt;

&lt;p&gt;When I review a portfolio project to assess a candidate's skill level I tend to have a look at the commit history.&lt;/p&gt;

&lt;p&gt;Imagine looking at a project's Git history and seeing commits like these:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--S8xwN3_x--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://media.graphcms.com/sEIcyQ38RcW3cS86HdKu" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--S8xwN3_x--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://media.graphcms.com/sEIcyQ38RcW3cS86HdKu" alt="Untitled 1.png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This looks very unprofessional.&lt;/p&gt;

&lt;p&gt;I'll admit, I have commits like these in my personal projects as well. We all get tired or commit too many changes at once to find a proper name.&lt;/p&gt;

&lt;p&gt;But you want to impress potential employers with your portfolio project, right? &lt;strong&gt;So rather write concise yet descriptive commit messages.&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--EVfcyWs0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://media.graphcms.com/WKHx7EUKRQKBeAhVZmo9" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--EVfcyWs0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://media.graphcms.com/WKHx7EUKRQKBeAhVZmo9" alt="Untitled 2.png"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Look at this. Now it's immediately clear what this commit is about. Even though it's not proper English üôÇ&lt;/p&gt;

&lt;p&gt;If you want to take a step further consider &lt;strong&gt;working on branches and using Pull Requests&lt;/strong&gt; on GitHub to merge your branches.&lt;/p&gt;

&lt;p&gt;This will signal that you have a grasp of professional development workflows. &lt;a href="https://ooloo.io/project/github-flow"&gt;If you're interested in a professional Git workflow have a look at this free course&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#part-1-summary"&gt;
  &lt;/a&gt;
  Part 1: Summary
&lt;/h3&gt;

&lt;p&gt;In this part, we wanted to answer one question: How can you build your React portfolio projects like a pro? The goal is to impress your future employer and convince them that you can be a valuable member of their team. &lt;/p&gt;

&lt;p&gt;Here a short overview of the tips in this part:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Workflows: Write your code based on designs and tasks.&lt;/li&gt;
&lt;li&gt;Styles: write custom &amp;amp; responsive CSS, use styled-components or CSS Modules.&lt;/li&gt;
&lt;li&gt;Logic: your app should have multiple pages, be stateful, and fetch data from an API. I'd highly recommend covering at least part of your code with automated tests.&lt;/li&gt;
&lt;li&gt;Git: Write clear commit messages. Ideally use branches and Pull Requests.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="https://profy.dev/article/react-projects-for-your-portfolio#nl-4385791l5b9g3"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--5bjqjyJA--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/i5hi7fqeite6pv4xx91a.png" alt="checklist"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I'll release the two remaining parts in the next days here on dev.to. If you want to read all of them right away you can visit the original post at &lt;a href="https://profy.dev/article/react-projects-for-your-portfolio"&gt;profy.dev&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Illustration based on &lt;a href="https://www.drawkit.io/"&gt;drawkit.io&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

</description>
      <category>react</category>
      <category>career</category>
      <category>webdev</category>
      <category>javascript</category>
    </item>
  </channel>
</rss>
