<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>DEV Community</title>
    <author>DEV Community</author>
    <description>A constructive and inclusive social network for software developers. With you every step of your journey.</description>
    <link>https://dev.to</link>
    <language>en</language>
    <item>
      <title>üî• Next JS Tailwind Template Free using TypeScript, ESLint, Prettier and Husky</title>
      <author>Remi W.</author>
      <pubDate>Thu, 23 Sep 2021 11:05:01 +0000</pubDate>
      <link>https://dev.to/ixartz/next-js-tailwind-template-free-using-typescript-eslint-prettier-and-husky-97a</link>
      <guid>https://dev.to/ixartz/next-js-tailwind-template-free-using-typescript-eslint-prettier-and-husky-97a</guid>
      <description>&lt;p&gt;Next JS Tailwind Starter code free and open source with developer experience first with React, TypeScript, Tailwind CSS, ESLint, Prettier, Husky.&lt;/p&gt;

&lt;p&gt;The GitHub repo have already reached 500+ stars üåü.&lt;/p&gt;

&lt;p&gt;Built for production with high-quality:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;üî• Next JS 11&lt;/li&gt;
&lt;li&gt;üé® Integrate with Tailwind CSS 2 (w/ JIT mode)&lt;/li&gt;
&lt;li&gt;üéâ TypeScript&lt;/li&gt;
&lt;li&gt;‚öõÔ∏è React&lt;/li&gt;
&lt;li&gt;‚úèÔ∏è Linter with ESLint (default NextJS, NextJS Core Web Vitals and Airbnb configuration)&lt;/li&gt;
&lt;li&gt;üõ† Code Formatter with Prettier&lt;/li&gt;
&lt;li&gt;ü¶ä Husky for Git Hooks&lt;/li&gt;
&lt;li&gt;üö´ Lint-staged for running linters on Git staged files&lt;/li&gt;
&lt;li&gt;üóÇ VSCode configuration: Debug, Settings, Tasks and extension for PostCSS, ESLint, Prettier, TypeScript&lt;/li&gt;
&lt;li&gt;ü§ñ SEO-friendly&lt;/li&gt;
&lt;li&gt;‚öôÔ∏è Bundler Analyzer&lt;/li&gt;
&lt;li&gt;üñ±Ô∏è One click deployment with Vercel or Netlify (or manual deployment to any hosting services)&lt;/li&gt;
&lt;li&gt;üåà One minimalist theme&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can find a &lt;a href="https://creativedesignsguru.com/demo/Nextjs-Boilerplate/"&gt;NextJS Tailwind Template live demo&lt;/a&gt;&lt;/p&gt;


&lt;div class="ltag-github-readme-tag"&gt;
  &lt;div class="readme-overview"&gt;
    &lt;h2&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i3JOwpme--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/github-logo-ba8488d21cd8ee1fee097b8410db9deaa41d0ca30b004c0c63de0a479114156f.svg" alt="GitHub logo"&gt;
      &lt;a href="https://github.com/ixartz"&gt;
        ixartz
      &lt;/a&gt; / &lt;a href="https://github.com/ixartz/Next-js-Boilerplate"&gt;
        Next-js-Boilerplate
      &lt;/a&gt;
    &lt;/h2&gt;
    &lt;h3&gt;
      üöÄ Boilerplate and Starter for Next.js 11+, Tailwind CSS 2.0 and TypeScript ‚ö°Ô∏è Made with developer experience first: Next.js + TypeScript + ESLint + Prettier + Husky + Lint-Staged + VSCode + Netlify + PostCSS + Tailwind CSS
    &lt;/h3&gt;
  &lt;/div&gt;
  &lt;div class="ltag-github-body"&gt;
    
&lt;div id="readme" class="md"&gt;
&lt;h1&gt;
Boilerplate and Starter for Next JS 11+, Tailwind CSS 2.0 and TypeScript &lt;a href="https://twitter.com/ixartz" rel="nofollow"&gt;&lt;img src="https://camo.githubusercontent.com/22898de970db41d476e65546387c7b5147565904f1a4197980bb0e3eb30eb8ab/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f75726c2f68747470732f747769747465722e636f6d2f636c6f7564706f7373652e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f7725323025343049786172747a" alt="Twitter"&gt;&lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;
  &lt;a href="https://creativedesignsguru.com/demo/Nextjs-Boilerplate/" rel="nofollow"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--SOL9mcNA--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/ixartz/Next-js-Boilerplatepublic/assets/images/nextjs-starter-banner.png%3Fraw%3Dtrue" alt="Next js starter banner"&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;üöÄ Boilerplate and Starter for Next.js, Tailwind CSS and TypeScript ‚ö°Ô∏è Made with developer experience first: Next.js, TypeScript, ESLint, Prettier, Husky, Lint-Staged, VSCode, Netlify, PostCSS, Tailwind CSS.&lt;/p&gt;

&lt;p&gt;Clone this project and use it to create your own &lt;a href="https://nextjs.org" rel="nofollow"&gt;Next.js&lt;/a&gt; project. You can check a &lt;a href="https://creativedesignsguru.com/demo/Nextjs-Boilerplate/" rel="nofollow"&gt;Next js templates demo&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;
Features&lt;/h3&gt;

&lt;p&gt;Developer experience first:&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;
üî• &lt;a href="https://nextjs.org" rel="nofollow"&gt;Next.js&lt;/a&gt; for Static Site Generator&lt;/li&gt;
&lt;li&gt;
üé® Integrate with &lt;a href="https://tailwindcss.com" rel="nofollow"&gt;Tailwind CSS&lt;/a&gt; (w/ JIT mode)&lt;/li&gt;
&lt;li&gt;
üíÖ PostCSS for processing Tailwind CSS and integrated to &lt;code&gt;styled-jsx&lt;/code&gt;
&lt;/li&gt;
&lt;li&gt;
üéâ Type checking &lt;a href="https://www.typescriptlang.org" rel="nofollow"&gt;TypeScript&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
‚úÖ Strict Mode for TypeScript and React 17&lt;/li&gt;
&lt;li&gt;
‚úèÔ∏è Linter with &lt;a href="https://eslint.org" rel="nofollow"&gt;ESLint&lt;/a&gt; (default NextJS, NextJS Core Web Vitals and Airbnb configuration)&lt;/li&gt;
&lt;li&gt;
üõ† Code Formatter with &lt;a href="https://prettier.io" rel="nofollow"&gt;Prettier&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
ü¶ä Husky for Git Hooks&lt;/li&gt;
&lt;li&gt;
üö´ Lint-staged for running linters on Git staged files&lt;/li&gt;
&lt;li&gt;
üóÇ VSCode configuration: Debug, Settings, Tasks and extension for PostCSS, ESLint, Prettier, TypeScript&lt;/li&gt;
&lt;li&gt;
ü§ñ SEO metadata, JSON-LD and‚Ä¶&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;br&gt;
  &lt;/div&gt;
&lt;br&gt;
  &lt;div class="gh-btn-container"&gt;&lt;a class="gh-btn" href="https://github.com/ixartz/Next-js-Boilerplate"&gt;View on GitHub&lt;/a&gt;&lt;/div&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;br&gt;


&lt;h2&gt;
  &lt;a href="#build-your-saas-faster"&gt;
  &lt;/a&gt;
  Build your SaaS faster
&lt;/h2&gt;

&lt;p&gt;Building your SaaS product faster with &lt;a href="https://nextlessjs.com"&gt;Next JS SaaS Boilerplate&lt;/a&gt;. Save you 5 months of development and design time.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://nextlessjs.com"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--oq_SrpAB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://nextlessjs.com/assets/images/hero-image.png" alt="Next JS SaaS Boilerplate"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#other-next-js-templates-and-themes"&gt;
  &lt;/a&gt;
  Other Next JS Templates and Themes
&lt;/h2&gt;

&lt;p&gt;Checkout our &lt;a href="https://creativedesignsguru.com/category/nextjs/"&gt;Next JS Theme gallery&lt;/a&gt;&lt;/p&gt;

&lt;div class="table-wrapper-paragraph"&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;a href="https://creativedesignsguru.com/landing-green-modern-nextjs-theme/"&gt;Green Nextjs Landing Page Template&lt;/a&gt;&lt;/th&gt;
&lt;th&gt;&lt;a href="https://creativedesignsguru.com/landing-purple-modern-react-theme/"&gt;Blue Saas Nextjs Theme&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://creativedesignsguru.com/landing-green-modern-nextjs-theme/"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--4CbDAFVd--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://creativedesignsguru.com/assets/images/themes/landing-green-modern-nextjs-theme-xs.png" alt="Green Nextjs Landing Page Template"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href="https://creativedesignsguru.com/landing-blue-modern-react-theme/"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--az4i2Gg8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://creativedesignsguru.com/assets/images/themes/landing-blue-modern-nextjs-theme-xs.png" alt="Blue Landing Page Nextjs Theme"&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/div&gt;

</description>
      <category>react</category>
      <category>webdev</category>
      <category>showdev</category>
      <category>javascript</category>
    </item>
    <item>
      <title>Integrating Amazon Timestream in you Amazon Managed Workflows for Apache Airflow v2.x</title>
      <author>Ricardo Sueiras</author>
      <pubDate>Thu, 23 Sep 2021 10:58:30 +0000</pubDate>
      <link>https://dev.to/aws/integrating-amazon-timestream-in-you-amazon-managed-workflows-for-apache-airflow-v2-x-kld</link>
      <guid>https://dev.to/aws/integrating-amazon-timestream-in-you-amazon-managed-workflows-for-apache-airflow-v2-x-kld</guid>
      <description>&lt;p&gt;&lt;strong&gt;Integrating with Amazon Timestream in you Apache Airflow DAGs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Amazon Timestream is a fast, scalable, and serverless time series database service that you can use for use cases that generate huge amounts of events per day, optimised to make it faster and more cost effective that using relational databases.&lt;/p&gt;

&lt;p&gt;I have been playing around with Amazon Timestream to prepare for a talk I am doing with some colleagues, and wanted to see how I could integrate it with other AWS services in the context of leveraging some of the key capabilities of Amazon Timestream. For example, you might have a use case where you want to leverage some of the powerful capabilities of the Timestream query engine to create/export data that you want to store within a data lake. Maybe you need just a subset of the data within a data warehouse such as Amazon Redshift, or perhaps you need to make the data available within Timestream to other systems and applications.&lt;/p&gt;

&lt;p&gt;Interacting with Timestream to run queries is easy and you have several options, but how do you scale this and automate the process so that you do not need to rely on ad hoc queries? This is where data orchestration tools like Apache Airflow are super helpful, allowing you to create workflows that automate those steps and providing the orchestration features that all you to address many different use cases.&lt;/p&gt;

&lt;p&gt;In this post I will explore setting up Amazon Timestream and integrating this with Amazon Managed Workflows for Apache Airflow (MWAA). I will walk you through the setup, creating some example workflows, and then use some of the Amazon Timestream sample tools to generate some load and see it all working. Specifically we are going to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;simulate some Timestream data being ingested in real time over a period of time&lt;/li&gt;
&lt;li&gt;create a workflow where we want to run a query against the Timestream data and obtain a subset of that data and then export it to our data lake on Amazon S3&lt;/li&gt;
&lt;li&gt;orchestrate this workflow so that it runs hourly, and stores the exported data in csv format in folders that match when the timestream data was ingested&lt;/li&gt;
&lt;li&gt;simulate some real life situations such as workflows failing and how they recover and updating and re-running queries &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Costs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;When I ran through this and checked my AWS bill, it cost around $37 to run this over 24 hours. Please make sure you remember to remove/delete all the resources after you go through this so you do not incur further costs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Where can I find the code&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;All the source code in this blog post can be found in &lt;a href="https://github.com/094459/blog-mwaa-timestream"&gt;this GitHub repository&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#getting-started"&gt;
  &lt;/a&gt;
  Getting started
&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;What will you need&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;An AWS account with the right level of privileges&lt;/li&gt;
&lt;li&gt;An environment with the AWS CLI tools configured and running&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.aws.amazon.com/cdk/latest/guide/getting_started.html"&gt;AWS CDK set up an installed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Access to an AWS region where both Managed Workflows for Apache Airflow and Amazon Timestream are supported - for this walkthrough, I will be using eu-west-1&lt;/li&gt;
&lt;li&gt;An environment of Amazon Managed Workflows for Apache Airflow already setup - you can follow &lt;a href="https://aws-oss.beachgeek.co.uk/3h"&gt;my previous link here&lt;/a&gt; or check out the instructions in the GitHub repo which will walk you setting up an environment&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#setting-up-the-amazon-timestream"&gt;
  &lt;/a&gt;
  Setting up the Amazon Timestream
&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Setting up the Amazon Timestream database and tables&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;First we need to set up our Amazon Timestream database. Let's use AWS CDK to do this.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I have AWS CDK installed on my machine, if you do not, then follow &lt;a href="https://cdkworkshop.com/15-prerequisites/500-toolkit.html"&gt;this workshop&lt;/a&gt; or the &lt;a href="https://docs.aws.amazon.com/cdk/latest/guide/getting_started.html"&gt;documentation here&lt;/a&gt; to help you get this installed.&lt;br&gt;
I have also updated CDK to the latest version - at the time of writing, my version was 1.124.0. (I had used an earlier version, but it generated an error about unsupported CLI versions, and updating this resolved the issue for me) &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We create a directory where we will create our Timestream stack, and then run the CDK init command to create the skeleton outline of our application.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;mkdir amazon-timestream-airflow
cd amazon-timestream-airflow
cdk init sample-app --language python
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This will create something similar to what I have here&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ amazon_timestream_airflow
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ amazon_timestream_airflow_stack.py
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ cdk.json
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ setup.py
‚îú‚îÄ‚îÄ source.bat
‚îî‚îÄ‚îÄ tests
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îî‚îÄ‚îÄ unit
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îî‚îÄ‚îÄ test_amazon_timestream_airflow_stack.py
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The key files we are going to work on is the app.py and the corresponding stack, amazon_timestream_airflow_stack.py.&lt;/p&gt;

&lt;p&gt;I update the app.py file as follows, which is a standard baseline file I use and allows me to try and templatise this as much as possible to make it re-usable.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;#!/usr/bin/env python3

from aws_cdk import core
from amazon_timestream_airflow.amazon_timestream_airflow_stack import AmazonTimestreamAirflowStack

env_EU=core.Environment(region="eu-west-1", account="xxxxxxxx")
ts_props = {'timestream_db': 'airflow-db','timestream_table' : 'airflow-table' , 's3_export' : 'demo-airflow-ts-output'}

app = core.App()

timestream = AmazonTimestreamAirflowStack(
    scope=app,
    construct_id="timestream",
    env=env_EU,
    ts_props=ts_props
)

app.synth()
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;I set up a few properties, one for the AWS account this will run in, and then the other to hold the values I want to use when creating my Amazon Timestream resources (so in this instance, the Timestream database and tables, as well as the S3 bucket where my exported data will be copied). I then call the stack, passing in these two properties to the Timestream stack (AmazonTimestreamAirflowStack)&lt;/p&gt;

&lt;p&gt;The AmazonTimestreamAirflowStack stack that is initially created now need to be updated to create our resources. We need to do a couple of things. First, we need to create the actual resources. The second, is as we are planning to integrate this with MWAA, we need to create an IAM policy that will allow the MWAA workers to have the right level of access to these resources, and no more.&lt;/p&gt;

&lt;p&gt;The first thing we need to do is import the &lt;a href="https://docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_timestream/README.html"&gt;Timestream construct library&lt;/a&gt; using&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;aws_timestream as timestream,
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;As I do not have this construct installed, I need to install it via pip&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;pip install aws-cdk.aws-timestream
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We can now modify the amazon_timestream_airflow_stack.py file, which is just the default file that gets created.&lt;/p&gt;

&lt;p&gt;First, we need to pass in the parameters from the main python file that gets executed (app.py) so we modify this to include ts_props as follows:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;class AmazonTimestreamAirflowStack(core.Stack):

    def __init__(self, scope: core.Construct, construct_id: str, ts_props, **kwargs) -&amp;gt; None:
        super().__init__(scope, construct_id, **kwargs)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Next we need to create our Timestream database, which when we look at the &lt;a href="https://docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_timestream/CfnDatabase.html"&gt;documentation&lt;/a&gt; leads to creating this:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;        timedb = timestream.CfnDatabase(
            self,
            "TimestreamDB",
            database_name=f"{ts_props['timestream_db'].lower()}"
            #kms_key_id={string of kms_key_id if you want to use this}
            )
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We pass in the value of the database_name from the properties file. This construct will create the Timestream database, now we need to add our table, which looking at the same documentation link, we do with this:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;        tstable = timestream.CfnTable(
            self,
            "TimestreamDBTable",
            database_name=f"{ts_props['timestream_db'].lower()}",
            table_name=f"{ts_props['timestream_table'].lower()}",
            retention_properties= {"MemoryStoreRetentionPeriodInHours": "24","MagneticStoreRetentionPeriodInDays": "1"}
        )
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Here we are passing in both the database name (which we just created) and the table we want to create. We also define here some additional properties around the memory and long term storage for the Timestream data.&lt;/p&gt;

&lt;p&gt;This looks good, so we do a 'cdk ls' and we see that we have our timestream stack ready to go. We deploy it using&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;cdk deploy timestream
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;And after a few minutes we see red and failures. What is up, why did this not work? It turns out that we need to make sure that the database is created before the table is, so we need to add a dependency in the CDK application. We can do this easily enough by adding&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;tstable.node.add_dependency(timedb)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We end up with the stack that looks like this.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;
class AmazonTimestreamAirflowStack(core.Stack):

    def __init__(self, scope: core.Construct, construct_id: str, ts_props, **kwargs) -&amp;gt; None:
        super().__init__(scope, construct_id, **kwargs)

        timedb = timestream.CfnDatabase(
            self,
            "TimestreamDB",
            database_name=f"{ts_props['timestream_db'].lower()}"
            #kms_key_id={string of kms_key_id if you want to use this}
            )

        tstable = timestream.CfnTable(
            self,
            "TimestreamDBTable",
            database_name=f"{ts_props['timestream_db'].lower()}",
            table_name=f"{ts_props['timestream_table'].lower()}",
            retention_properties= {"MemoryStoreRetentionPeriodInHours": "24","MagneticStoreRetentionPeriodInDays": "1"}
        )

        tstable.node.add_dependency(timedb)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We re-run the cdk deploy timestream, and this time we have everything up and running. We can check my looking in the AWS console&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;timestream: deploying...
timestream: creating CloudFormation changeset...

 ‚úÖ  timestream

Stack ARN:
arn:aws:cloudformation:eu-west-1:704533066374:stack/timestream/a39735c0-1bb1-11ec-b3da-0a4cd6193fe1
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--GvAWYwT1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/timestream-db.png%3Fraw%3Dtrue" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--GvAWYwT1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/timestream-db.png%3Fraw%3Dtrue" alt="timestream-db"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--8X2A318s--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/timestream-table.png%3Fraw%3Dtrue" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--8X2A318s--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/timestream-table.png%3Fraw%3Dtrue" alt="timestream-table"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Running the load generator&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now that I have my Timestream database up, I want to try and generate some load and test this out. Luckily for me, the team has put some tools in the GitHub repository to help me out.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The load writer&lt;/em&gt; &lt;/p&gt;

&lt;p&gt;This is a simple demo application called the &lt;a href="https://github.com/awslabs/amazon-timestream-tools/tree/mainline/integrations/flink_connector"&gt;flink_connector&lt;/a&gt; is used to take sample load data and then stream it into the Timestream database. This project uses Amazon Kinesis to stream that data, so we need to create a stream which we can do using the following command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;aws kinesis create-stream --stream-name airflow-timestream --shard-count 1 --region=eu-west-1
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;When you run this, it does not return anything but if you go to the Amazon Kinesis console, you should now see your new data stream listed.&lt;/p&gt;

&lt;p&gt;Next you need to build this application using Apache Maven, so you will need to have this and a minimum of Java 11 (I am using Amazon Corretto 11). Once I have checked out the repo (using the link above) I can run this using the following command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;mvn clean compile
mvn exec:java -Dexec.mainClass="com.amazonaws.services.kinesisanalytics.StreamingJob" -Dexec.args="--InputStreamName airflow-timestream --Region eu-west-1 --TimestreamDbName airflow-db --TimestreamTableName airflow-table"
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This will generate a load of output, but the last few lines should be similar-ish to&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;16:04:50,957 INFO  org.apache.flink.streaming.connectors.kinesis.FlinkKinesisConsumer  - Subtask 7 will be seeded with initial shard StreamShardHandle{streamName='airflow-timestream', shard='{ShardId: shardId-000000000000,HashKeyRange: {StartingHashKey: 0,EndingHashKey: 340282366920938463463374607431768211455},SequenceNumberRange: {StartingSequenceNumber: 49622289611231482257551931446968748664912850071167434754,}}'}, starting state set as sequence number LATEST_SEQUENCE_NUM
16:04:50,957 INFO  org.apache.flink.streaming.connectors.kinesis.internals.KinesisDataFetcher  - Subtask 7 will start consuming seeded shard StreamShardHandle{streamName='airflow-timestream', shard='{ShardId: shardId-000000000000,HashKeyRange: {StartingHashKey: 0,EndingHashKey: 340282366920938463463374607431768211455},SequenceNumberRange: {StartingSequenceNumber: 49622289611231482257551931446968748664912850071167434754,}}'} from sequence number LATEST_SEQUENCE_NUM with ShardConsumer 0
16:04:50,960 INFO  org.apache.flink.streaming.connectors.kinesis.internals.KinesisDataFetcher  - Subtask 1 has no active shards to read on startup; marking the subtask as temporarily idle ...
16:04:50,986 INFO  org.apache.flink.streaming.connectors.kinesis.internals.KinesisDataFetcher  -
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Keep this terminal window open, as you need to leave this running when we generate load (the next step). Any time you want to exit, you can just CTRL + C to break out and back into the shell.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In the real world, you would package this up as an Apache Flink application and then run this via Amazon Kinesis analytics applications&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;The load generator&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/awslabs/amazon-timestream-tools/tree/mainline/tools/kinesis_ingestor"&gt;The kinesis_ingestor&lt;/a&gt; is a python script that creates random timestream data (server event info such as storage, cpu, memory, etc). It is super easy to run, all I need to do is supply the name of the Kinesis stream, which I created in the previous step.&lt;/p&gt;

&lt;p&gt;In a new, different terminal shell (you will have the previous and this one running side by side)&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;python3 timestream_kinesis_data_gen.py --stream airflow-timestream --region eu-west-1
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Which will give you output similar to the following:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;Namespace(hostScale=1, late_time=0, percent_late=0, profile=None, region='eu-west-1', sleep_time=0, stream='airflow-timestream')
zaZswmJk
Dimensions for metrics: 1000
Dimensions for events: 1200
Wrote 20 records to Kinesis Stream 'demo-airflow'
Wrote 20 records to Kinesis Stream 'demo-airflow'
Wrote 20 records to Kinesis Stream 'demo-airflow'
Wrote 20 records to Kinesis Stream 'demo-airflow'
Wrote 20 records to Kinesis Stream 'demo-airflow'
Wrote 20 records to Kinesis Stream 'demo-airflow'
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Leave this running for a few minutes. To exit, you can do CTRL+C, to return back to the shell.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Testing the setup&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We can now go to the Amazon Timestream console in the AWS console, and take a quick look at the test load data we have just ingested.&lt;/p&gt;

&lt;p&gt;From the Amazon Timestream hamburger menu, select Query Editor. Select airflow-db in the pull down for database, and you should see the airflow-table appear below.&lt;/p&gt;

&lt;p&gt;If you click on the three dots, an option to "Preview Data" will appear. Select this, and then click on the RUN button (in orange) which will then execute a query, and you should see output.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note! If this is longer than 15 min from when you ran the load generator, you may get nothing. Either re-run the load generator and try again, or change the query in the editor, to increase the time - by default, it looks for the last 15 mins "WHERE time between ago(15m) and now()"&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--D9OuAkTU--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/timstream-query.png%3Fraw%3Dtrue" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--D9OuAkTU--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/timstream-query.png%3Fraw%3Dtrue" alt="query"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#setting-up-mwaa"&gt;
  &lt;/a&gt;
  Setting up MWAA
&lt;/h3&gt;

&lt;p&gt;You should already have an MWAA environment up and running. You can follow &lt;a href="https://aws-oss.beachgeek.co.uk/3h"&gt;my previous link here&lt;/a&gt; which uses AWS CDK to build up an environment, or if you prefer, you can use the console to create one quickly using the online wizard.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Remember, this needs to be in the same AWS region as the Amazon Timestream database - I am using eu-west-1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Permissions for MWAA&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;One of the first thing we need to think about when we integrate MWAA with any AWS service is what permissions the MWAA workers will need. We do not want to provide blanket access, and we want to follow current practices around least privilege where we can.&lt;/p&gt;

&lt;p&gt;In our example, we are accessing a Timestream database and then exporting csv outputs to Amazon S3, so we need two new permissions&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Timestream&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We have created our Timestream database and table resources, so our IAM policy needs to look something like this. This will provide just READ access to the table we have created, and will not provide access to any other Timestream resources.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "timestream:Select",
                "timestream:DescribeTable",
                "timestream:ListTables"
            ],
            "Resource": "arn:aws:timestream:eu-west-1:704533066374:database/airflow-db/table/airflow-table*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "timestream:DescribeEndpoints",
                "timestream:SelectValues",
                "timestream:CancelQuery"
            ],
            "Resource": "*"
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;em&gt;Amazon S3&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We need to make sure that the Apache Airflow workers have access to write to a nominated folder in our data lake, and no more. We defined this as a property in our app.py ('s3_export' : 'demo-airflow-ts-output'). This is the policy needed.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetBucket*",
                "s3:GetObject*",
                "s3:List*"
            ],
            "Resource": [
                    "arn:aws:s3:::demo-airflow-ts-output/*",
                    "arn:aws:s3:::demo-airflow-ts-output"
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;To make this simple, we modify our CDK application to create this new policy document, and then attach it to our MWAA environment. Here is the code:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;        s3_export_bucket = s3.Bucket.from_bucket_name(self,"DataLakeExport",bucket_name=f"{ts_props['s3_export']}")
        s3_export_arn = s3_export_bucket.bucket_arn

        timestream_mwaa_policy = iam.ManagedPolicy(
            self,
            "TimeStreamPolicy",
            managed_policy_name="TimeStreamPolicyforMWAAIntegration",
            statements=[
                iam.PolicyStatement(
                    actions=[
                        "s3:GetBucket*",
                        "s3:List*",
                        "s3:GetObject*"
                    ],
                    effect=iam.Effect.ALLOW,
                    resources=[
                        f"{s3_export_arn}/*",
                        f"{s3_export_arn}"
                        ],
                ),
                iam.PolicyStatement(
                    actions=[
                        "timestream:Select",
                        "timestream:DescribeTable",
                        "timestream:ListTables"
                    ],
                    effect=iam.Effect.ALLOW,
                    resources=[f"arn:aws:timestream:{self.region}:{self.account}:database/{ts_props['timestream_db']}/table/{ts_props['timestream_table']}*"],
                ),
                iam.PolicyStatement(
                    actions=[
                        "timestream:DescribeEndpoints",
                        "timestream:SelectValues",
                        "timestream:CancelQuery"
                    ],
                    effect=iam.Effect.ALLOW,
                    resources=["*"],
                ),
            ]
        )

        core.CfnOutput(
            self,
            id="MWAATimestreamIAMPolicy",
            value=timestream_mwaa_policy.managed_policy_arn,
            description="MWAA to Timestream IAM policy arn"
        )
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We can then run cdk deploy timestream which will create the new IAM policy (managed_policy_name="TimeStreamPolicyforMWAAIntegration") ready for the next steps.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;cdk deploy timestream
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;If successful, you should see output that looks like:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;timestream: deploying...
timestream: creating CloudFormation changeset...

 ‚úÖ  timestream

Outputs:
timestream.MWAATimestreamIAMPolicy = arn:aws:iam::704533066374:policy/TimeStreamPolicyforMWAAIntegration

Stack ARN:
arn:aws:cloudformation:eu-west-1:704533066374:stack/timestream/5aecb140-1bb3-11ec-8bc1-0287e85bdc49
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;blockquote&gt;
&lt;p&gt;You can check to see this has been created by going to the IAM console, reviewing Policies by the creation date or searching for "TimeStreamPolicyforMWAAIntegration"&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We are going to need that arn output (in the above example, mine is arn:aws:iam::704533066374:policy/TimeStreamPolicyforMWAAIntegration) in the next step.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Attaching new policy to your MWAA execution role&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We have our policy, but we need to attach it to the execution role of our MWAA environment. To do this, we can run a few commands.&lt;/p&gt;

&lt;p&gt;First, lets find the current execution role our MWAA environment is using. My MWAA environment is called "airflow-timestream" so I run this command:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I am using jq here, but if you do not have this installed, you can run the command and just search the output for the ExecutionRoleArn value&lt;/p&gt;


&lt;/blockquote&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;aws mwaa get-environment --name airflow-timestream --region=eu-west-1  | jq -r '.Environment.ExecutionRoleArn'
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This will return a value which is your execution role.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;arn:aws:iam::704533066374:role/service-role/AmazonMWAA-airflow-timestream-KGRJPE
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;From this we can see our role is called "AmazonMWAA-airflow-timestream-KGRJPE". &lt;/p&gt;

&lt;p&gt;Using this, together with the output from the CDK application which has our IAM policy, we can now attach that to the MWAA execution role using this command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;aws iam attach-role-policy --policy-arn arn:aws:iam::704533066374:policy/TimeStreamPolicyforMWAAIntegration --role-name AmazonMWAA-airflow-timestream-KGRJPE

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This will not generate output if successful, but you can check this has worked by running the following command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;aws iam list-attached-role-policies --role-name AmazonMWAA-airflow-timestream-KGRJPE
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;And we should see something like this (your output will be different depending on how many other policies you may have added to your MWAA environment)&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;{
    "AttachedPolicies": [
        {
            "PolicyName": "TimeStreamPolicyforMWAAIntegration",
            "PolicyArn": "arn:aws:iam::704533066374:policy/TimeStreamPolicyforMWAAIntegration"
        },
        {
            "PolicyName": "MWAA-Execution-Policy-47773cc3-79b2-40c8-8622-61314788983a",
            "PolicyArn": "arn:aws:iam::704533066374:policy/service-role/MWAA-Execution-Policy-47773cc3-79b2-40c8-8622-61314788983a"
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We now have our MWAA environment set with the additional privileges to access our Amazon Timestream database and table as well as access to a specific bucket we can export the files to. We are ready for the next step.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#integrating-with-amazon-timestream"&gt;
  &lt;/a&gt;
  Integrating with Amazon Timestream
&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Hello AWS Data Wrangler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We now have all the pieces we need at an infrastructure level, and now we just need to write our workflow in Python. Within Apache Airflow, we typically look for existing operators that make it easy to work with systems and hundreds have been written by the Apache Airflow community. Currently there are no operators for Amazon Timestream (at least, not that I know about) and so that leaves writing in Python. We have a couple of options.&lt;/p&gt;

&lt;p&gt;First, we could write the code in Python using boto3. The Timestream documentation provides some coding examples to help you, and this provides you with lots of fine grain access to what you can do.&lt;/p&gt;

&lt;p&gt;The second option is to use a rather great open source project called &lt;a href="https://aws-oss.beachgeek.co.uk/xf"&gt;AWS Data Wrangler&lt;/a&gt;, which abstracts a lot of the complexity of working with AWS data services, and it supports Amazon Timestream. In fact, it makes working with Amazon Timestream REALLY easy - what is not to like! Here is a sample line of code to do a query&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;wr.timestream.query('{your timestream query here}')
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;For this example, I am going to use AWS Data Wrangler.&lt;/p&gt;

&lt;p&gt;When working with AWS Data Wrangler, it is as simple as installing the required Python libraries, including the correct import statement and away you go. Currently, the MWAA worker nodes do not have AWS Data Wrangler installed, and so if we want to write any workflows that can run on those worker nodes, we are going to have to fix that.&lt;/p&gt;

&lt;p&gt;The way we do this in MWAA is to create a requirements.txt file that is stored on an Amazon S3 bucket and is referred to by the MWAA environment. The worker nodes will then use this during their provisioning lifecycle phase, which will ensure that our code will have all the dependencies met.&lt;/p&gt;

&lt;p&gt;Here is our requirements.txt file&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;cython==0.29.21
pyarrow==2.0.0
awswrangler==2.4.0
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;You will have to update your MWAA environment in order to make these become active. I wrote an &lt;a href="https://aws-oss.beachgeek.co.uk/4t"&gt;earlier blog post&lt;/a&gt; if you want to know more on how to do this (go down to the section called Requirements).&lt;/p&gt;

&lt;p&gt;Once your MWAA environment has restarted, you are good to go.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#creating-the-workflow"&gt;
  &lt;/a&gt;
  Creating the workflow
&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Creating our workflow&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now that we have all the pieces, we can work on our workflow. This is just going to be a simple, single task workflow that runs a query and then exports the results of that query to an Amazon S3 bucket. I will set this query to run every hour, and we will export our data in separate folders in that S3 bucket by date and hour.&lt;/p&gt;

&lt;p&gt;When we design this workflow, I want to make sure that the workflow is idempotent. Every time it runs, it should generate the same output, either when run as part of a schedule, or when being run as part of a backfill and manual invocation.&lt;/p&gt;

&lt;p&gt;I start my workflow by importing the libraries I am going to use - pretty standard stuff, and the only thing to point out here is the use of AWS Data Wrangler. I then set up some defaults for the DAG itself, and you will notice that the start_date is set to yesterday. I have used this to demonstrate the way the queries work with some of the Apache Airflow date macros that you can use to ensure idempotent queries.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;import os
from airflow import DAG
from datetime import datetime, timedelta
from airflow.operators.python import PythonOperator
import awswrangler as wr
from airflow.utils.dates import days_ago

default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "start_date" : days_ago(1),
    "email": ["airflow@airflow.com"],
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 0,
    "retry_delay": timedelta(minutes=5)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Next we define a function that will run our query and then export the data to an S3 bucket. This function does a few things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;grab the date parameters and assign these to two variables (start and finish) which will be used within the query to only select the timestream data between these two times. These two times are the previous hour that the workflow is scheduled.&lt;/li&gt;
&lt;li&gt;get a name for the S3 bucket that matches when this workflow is executed - this uses the value "execution_date" which will be the same when run via the scheduler or as part of a backfill or catchup run&lt;/li&gt;
&lt;li&gt;create a variable which contains the query, passing in the value of the dates we configured earlier (the {start} and {finish} values)&lt;/li&gt;
&lt;li&gt;use AWS Data Wrangler to then run the query and export to S3 using wr.s3.to_csv - this will generate a csv file, but we could use one of the other methods supported by AWS Data Wrangler if we wanted.&lt;/li&gt;
&lt;li&gt;the call to AWS Data Wrangler is managed between a try: catch: block, as we may have situations where no data is returned which we want to handle gracefully
&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;def ts_query(**kwargs):
    start = str(kwargs['execution_date']).replace("T", " ")
    finish = str(kwargs['next_execution_date']).replace("T", " ")
    execution_time = str(kwargs['execution_date']).replace("T", "-")
    s3folder = execution_time[0:13]
    print ("Data will be uploaded to {target}".format(target=s3folder))
    query = "SELECT instance_name, BIN(time, 15s) AS binned_timestamp, ROUND(AVG(measure_value::double), 2) AS avg_cpu_utilization, ROUND(APPROX_PERCENTILE(measure_value::double, 0.9), 2) AS p90_cpu_utilization, ROUND(APPROX_PERCENTILE(measure_value::double, 0.95), 2) AS p95_cpu_utilization, ROUND(APPROX_PERCENTILE(measure_value::double, 0.99), 2) AS p99_cpu_utilization FROM \"airflow-db\".\"airflow-table\" WHERE measure_name = 'cpu_nice' AND time BETWEEN '{start}' AND '{end}' GROUP BY region, instance_name, availability_zone, BIN(time, 15s) ORDER BY binned_timestamp ASC ".format(start=start,end=finish)
    print("Query to be run: {query}".format(query=query))
    try:
        wr.s3.to_csv(df=wr.timestream.query(query), path='s3://demo-airflow-ts-output/{s3folder}/my_file.csv'.format(s3folder=s3folder,))
        print ("Timestream query processed successfully and copied to {s3folder}".format(s3folder=s3folder))
    except ValueError:
        print("Query returned no values - no data uploaded")
    except wr.exceptions.EmptyDataFrame:
        print("Query returned nothing - no data uploaded")
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;One of the things I did was the test the query I was going to use within the Amazon Timestream query editor to make sure that the query returned what I expected. For example in the query editor, I enter the following query (if you do this, make sure that you use the timestamp values that are correct for you)&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;SELECT instance_name, BIN(time, 15s) AS binned_timestamp, ROUND(AVG(measure_value::double), 2) AS avg_cpu_utilization, ROUND(APPROX_PERCENTILE(measure_value::double, 0.9), 2) AS p90_cpu_utilization, ROUND(APPROX_PERCENTILE(measure_value::double, 0.95), 2) AS p95_cpu_utilization, ROUND(APPROX_PERCENTILE(measure_value::double, 0.99), 2) AS p99_cpu_utilization FROM "airflow-db"."airflow-table" WHERE measure_name = 'cpu_nice' AND time BETWEEN '2021-09-22 13:00:00+00:00' AND '2021-09-22 16:00:00+00:00' GROUP BY region, instance_name, availability_zone, BIN(time, 15s) ORDER BY binned_timestamp ASC
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;and in the Timestream console I can see the following output. I would expect to see this when I start to run these via Apache Airflow in my S3 bucket.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--aSDRrTBU--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/timestream-demo.png%3Fraw%3Dtrue" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--aSDRrTBU--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/timestream-demo.png%3Fraw%3Dtrue" alt="timestream query"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The final part of our workflow now creates the DAG within Apache Airflow (using the filename as the name that will appear within the UI), passes in the default arguments and then sets up a schedule to run this every hour.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;with DAG(
        dag_id=os.path.basename(__file__).replace(".py", ""),
        default_args=default_args,
        dagrun_timeout=timedelta(hours=2),
        # set to every 10 mins for demo
        #schedule_interval="*/10 * * * *"
        # set to every 2 hours for demo
        #schedule_interval="0 */2 * * *"
        # set to every hour
        schedule_interval="0 */1 * * *"

) as dag:

    ts_query=PythonOperator(task_id='ts_query', python_callable=ts_query, dag=dag)
    ts_query
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;You can view the whole DAG here in the GitHub repo.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Deploying and running the workflow&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In my setup, I am using a &lt;a href="https://aws-oss.beachgeek.co.uk/4t"&gt;simple CI/CD system&lt;/a&gt; to deploy DAGs, but if you wanted to you can just copy this to your MWAA Dags folder using the cli (change these values to your own)&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;aws s3 cp timestream-airflow-demo.py s3://airflow-timestream-demo/dags/
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;And after about 2-3 minutes, you should see your new DAG in the Apache Airflow UI&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Ph9nlAqL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/airflow-ui.png%3Fraw%3Dtrue" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Ph9nlAqL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/airflow-ui.png%3Fraw%3Dtrue" alt="screen"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To run our workflow, all we need to do is enable it - unpause it. Once you unpause you should begin to see that the workflow quickly spawn and schedule tasks to execute the queries for the past 24 hours. This is because within our workflow, we have set the "start_date" : days_ago(1)," and so it uses this as the starting point, and then works out how many missed scheduled slots the task needs to complete. As the workflow is set to run every hour, you should have 24 scheduled tasks begin to appear in your Apache Airflow UI. They should be all green (complete) if everything has gone ok.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--6Hq7zEqh--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/dag_run.png%3Fraw%3Dtrue" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--6Hq7zEqh--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/dag_run.png%3Fraw%3Dtrue" alt="screen"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If we look at the logs of one of the first scheduled tasks, we can see the following:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;[2021-09-23 08:00:03,630] {{logging_mixin.py:104}} INFO - Data will be uploaded to 2021-09-23-07
[2021-09-23 08:00:03,654] {{logging_mixin.py:104}} INFO - Query to be run: SELECT instance_name, BIN(time, 15s) AS binned_timestamp, ROUND(AVG(measure_value::double), 2) AS avg_cpu_utilization, ROUND(APPROX_PERCENTILE(measure_value::double, 0.9), 2) AS p90_cpu_utilization, ROUND(APPROX_PERCENTILE(measure_value::double, 0.95), 2) AS p95_cpu_utilization, ROUND(APPROX_PERCENTILE(measure_value::double, 0.99), 2) AS p99_cpu_utilization FROM demoAirflow.kinesisdata1 WHERE measure_name = 'cpu_nice' AND time BETWEEN '2021-09-23 07:00:00+00:00' AND '2021-09-23 08:00:00+00:00' GROUP BY region, instance_name, availability_zone, BIN(time, 15s) ORDER BY binned_timestamp ASC
[2021-09-23 08:00:05,035] {{logging_mixin.py:104}} INFO - Query returned nothing - no data uploaded
[2021-09-23 08:00:05,060] {{python.py:118}} INFO - Done. Returned value was: None
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This is as expected as we did not have a Timestream database setup then, so it returned this message.&lt;/p&gt;

&lt;p&gt;If you leave this running for a few hours, with the load generator generating load in the back ground (the previous steps), what you will eventually see is the following in the task logs:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;[2021-09-22 14:00:02,930] {{logging_mixin.py:104}} INFO - Data will be uploaded to 2021-09-22-13
[2021-09-22 14:00:02,947] {{logging_mixin.py:104}} INFO - Query to be run: SELECT instance_name, BIN(time, 15s) AS binned_timestamp, ROUND(AVG(measure_value::double), 2) AS avg_cpu_utilization, ROUND(APPROX_PERCENTILE(measure_value::double, 0.9), 2) AS p90_cpu_utilization, ROUND(APPROX_PERCENTILE(measure_value::double, 0.95), 2) AS p95_cpu_utilization, ROUND(APPROX_PERCENTILE(measure_value::double, 0.99), 2) AS p99_cpu_utilization FROM demoAirflow.kinesisdata1 WHERE measure_name = 'cpu_nice' AND time BETWEEN '2021-09-22 13:00:00+00:00' AND '2021-09-22 14:00:00+00:00' GROUP BY region, instance_name, availability_zone, BIN(time, 15s) ORDER BY binned_timestamp ASC
[2021-09-22 14:00:06,688] {{logging_mixin.py:104}} INFO - Timestream query processed successfully and copied to 2021-09-22-13
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We can see here that the output shows the name of the S3 bucket that will be created, and if we look we can see&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Q32VTj0R--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/094459/blog-mwaa-timestream/main/images/s3-export.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Q32VTj0R--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/094459/blog-mwaa-timestream/main/images/s3-export.png" alt="s3bucket"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;As you can see from this screen shot, I have been running this over the past few days. I have run the load generator intermittently, which is why there are gaps in the folder names.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If we take a look at the contents of the folder, we can see we have our query export (a file called my_file.csv) which when we take a look at matches the query.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;,instance_name,binned_timestamp,avg_cpu_utilization,p90_cpu_utilization,p95_cpu_utilization,p99_cpu_utilization
0,i-zaZswmJk-zeus-0002.amazonaws.com,2021-09-22 13:03:15,0.54,0.89,0.91,0.95
1,i-zaZswmJk-apollo-0000.amazonaws.com,2021-09-22 13:03:15,0.58,0.96,0.96,0.96
2,i-zaZswmJk-demeter-0000.amazonaws.com,2021-09-22 13:03:15,0.48,0.93,0.94,0.94
3,i-zaZswmJk-zeus-0000.amazonaws.com,2021-09-22 13:03:15,0.45,0.76,0.82,0.98
4,i-zaZswmJk-hercules-0000.amazonaws.com,2021-09-22 13:03:15,0.52,0.84,0.85,0.93
...
...
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;Backfill&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Backfill is a really nice feature of Apache Airflow that allows you to run your workflow for a specific historical time period. You in effect pass in a "start_date" and "end_date" and the scheduler will use that in the context of the workflow to figure out how many scheduled slots that your workflow would have run, and then execute those tasks passing in the time/date details as if it was running during those times.&lt;/p&gt;

&lt;p&gt;This is great if you need to re-run your workflow because of a number of different reasons. Maybe your Apache Airflow environment was in maintenance mode and you missed some of your scheduled task runs, or perhaps you want to make a change to a query and re-run against all your source data. There are lots of ways that backfill is useful.&lt;/p&gt;

&lt;p&gt;Within Apache Airflow, you can execute backfill for your workflow by using this command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;airflow dags backfill --start-date START_DATE --end-date END_DATE dag_id

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;where the START_DATE and END_DATE are timestamps, and the dag_id is the name of your workflow.&lt;/p&gt;

&lt;p&gt;Within MWAA we do not have access to the Apache Airflow cli, so in order to run backfill we need to do this via another workflow.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# when running this DAG make sure you select the backfill command
# {"command": "backfill -s 2021-09-10 -e 2021-10-10 timestream-airflow-demo"} #mwaa 1.x
# {"command": "dags backfill -s 2021-09-10 -e 2021-10-10 timestream-airflow-demo"} #mwaa 2.x

from airflow import DAG

from airflow.operators.bash_operator import BashOperator

from datetime import timedelta,time,datetime
import os

DAG_ID = os.path.basename(__file__).replace(".py", "")

default_args = {
            "owner": "airflow",
            "start_date": datetime(2020, 9, 9),
            "depends_on_past": False,
            "email_on_failure": False,
            "email_on_retry": False,
            "email": "youremail@host.com",
            "retries": 0,
            "retry_delay": timedelta(minutes=5)
        }

from time import sleep
from datetime import datetime
from random import random

with DAG(dag_id=DAG_ID, schedule_interval=None, default_args=default_args, catchup=False) as dag:
    bash_task_1 = BashOperator(
        task_id="cli_command",
        bash_command="airflow {{ dag_run.conf['command'] }}"
    )
    bash_task_1
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;When we deploy and then enable this workflow within our MWAA environment, this will allow us to trigger a backfill task. When triggering the workflow, you pass into it a configuration file of the start, end and workflow name, as follows:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;{"command": "dags backfill -s 2021-09-10 -e 2021-10-10 timestream-airflow-demo"}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;In this example, I am asking MWAA to re-run these tasks between these two dates. When I fire it off, you should see those tasks start to run.&lt;/p&gt;

&lt;p&gt;This is what I see in the log file after I have submitted a backfill command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;[2021-09-23 09:20:41,813] {{bash.py:158}} INFO - Running command: airflow dags backfill -s 2021-09-21 -e 2021-09-22 timestream-airflow-demo
[2021-09-23 09:20:41,836] {{bash.py:169}} INFO - Output:
[2021-09-23 09:20:43,524] {{bash.py:173}} INFO - /usr/local/lib/python3.7/site-packages/airflow/cli/commands/dag_command.py:62 PendingDeprecationWarning: --ignore-first-depends-on-past is deprecated as the value is always set to True
[2021-09-23 09:20:43,544] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:43,524[0m] {{[34mdagbag.py:[0m451}} INFO[0m - Filling up the DagBag from /usr/local/airflow/dags[0m
[2021-09-23 09:20:43,566] {{bash.py:173}} INFO - /usr/local/lib/python3.7/site-packages/airflow/utils/decorators.py:94 DeprecationWarning: provide_context is deprecated as of 2.0 and is no longer required
[2021-09-23 09:20:49,003] {{bash.py:173}} INFO - 202109230920
[2021-09-23 09:20:49,036] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:48,994[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 00:00:00+00:00: backfill__2021-09-21T00:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,053] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,008[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 01:00:00+00:00: backfill__2021-09-21T01:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,105] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,021[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 02:00:00+00:00: backfill__2021-09-21T02:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,133] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,032[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 03:00:00+00:00: backfill__2021-09-21T03:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,205] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,048[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 04:00:00+00:00: backfill__2021-09-21T04:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,228] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,113[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 05:00:00+00:00: backfill__2021-09-21T05:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,247] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,125[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 06:00:00+00:00: backfill__2021-09-21T06:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,305] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,140[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 07:00:00+00:00: backfill__2021-09-21T07:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,326] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,152[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 08:00:00+00:00: backfill__2021-09-21T08:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,347] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,218[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 09:00:00+00:00: backfill__2021-09-21T09:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,404] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,234[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 10:00:00+00:00: backfill__2021-09-21T10:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,424] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,250[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 11:00:00+00:00: backfill__2021-09-21T11:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,863] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,315[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 12:00:00+00:00: backfill__2021-09-21T12:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,877] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,332[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 13:00:00+00:00: backfill__2021-09-21T13:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,897] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,344[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 14:00:00+00:00: backfill__2021-09-21T14:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,915] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,355[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 15:00:00+00:00: backfill__2021-09-21T15:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:49,935] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,407[0m] {{[34mbackfill_job.py:[0m388}} INFO[0m - [backfill progress] | finished run 16 of 25 | tasks waiting: 0 | succeeded: 16 | running: 0 | failed: 0 | skipped: 0 | deadlocked: 0 | not ready: 0[0m
[2021-09-23 09:20:49,952] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:49,408[0m] {{[34mbackfill_job.py:[0m818}} INFO[0m - max_active_runs limit for dag timestream-airflow-demo has been reached  - waiting for other dag runs to finish[0m
[2021-09-23 09:20:54,001] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:54,001[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 17:00:00+00:00: backfill__2021-09-21T17:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:54,024] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:54,010[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 18:00:00+00:00: backfill__2021-09-21T18:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:54,045] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:54,017[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 19:00:00+00:00: backfill__2021-09-21T19:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:54,063] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:54,024[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 20:00:00+00:00: backfill__2021-09-21T20:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:54,079] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:54,032[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 21:00:00+00:00: backfill__2021-09-21T21:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:54,114] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:54,039[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 22:00:00+00:00: backfill__2021-09-21T22:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:54,136] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:54,046[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 23:00:00+00:00: backfill__2021-09-21T23:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:54,156] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:54,054[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-22 00:00:00+00:00: backfill__2021-09-22T00:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:54,176] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:54,058[0m] {{[34mbackfill_job.py:[0m388}} INFO[0m - [backfill progress] | finished run 24 of 25 | tasks waiting: 0 | succeeded: 24 | running: 0 | failed: 0 | skipped: 0 | deadlocked: 0 | not ready: 0[0m
[2021-09-23 09:20:54,192] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:54,058[0m] {{[34mbackfill_job.py:[0m818}} INFO[0m - max_active_runs limit for dag timestream-airflow-demo has been reached  - waiting for other dag runs to finish[0m
[2021-09-23 09:20:59,013] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:59,013[0m] {{[34mdagrun.py:[0m445}} INFO[0m - Marking run &amp;lt;DagRun timestream-airflow-demo @ 2021-09-21 16:00:00+00:00: backfill__2021-09-21T16:00:00+00:00, externally triggered: False&amp;gt; successful[0m
[2021-09-23 09:20:59,040] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:59,019[0m] {{[34mbackfill_job.py:[0m388}} INFO[0m - [backfill progress] | finished run 25 of 25 | tasks waiting: 0 | succeeded: 25 | running: 0 | failed: 0 | skipped: 0 | deadlocked: 0 | not ready: 0[0m
[2021-09-23 09:20:59,069] {{bash.py:173}} INFO - [[34m2021-09-23 09:20:59,023[0m] {{[34mbackfill_job.py:[0m831}} INFO[0m - Backfill done. Exiting.[0m
[2021-09-23 09:20:59,326] {{bash.py:177}} INFO - Command exited with return code 0
[2021-09-23 09:20:59,370] {{taskinstance.py:1192}} INFO - Marking task as SUCCESS. dag_id=timestream-backfill, task_id=cli_command, execution_date=20210923T092039, start_date=20210923T092040, end_date=20210923T092059
[2021-09-23 09:20:59,420] {{taskinstance.py:1246}} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2021-09-23 09:20:59,476] {{logging_mixin.py:104}} INFO - [2021-09-23 09:20:59,476] {{local_task_job.py:146}} INFO - Task exited with return code 0
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;When I look at the historical view of my workflow, when I hover over the tasks during this time frame, I can see that they were run via backfill&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--c4gjsDCX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/backfill.png%3Fraw%3Dtrue" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--c4gjsDCX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://github.com/094459/blog-mwaa-timestream/blob/main/images/backfill.png%3Fraw%3Dtrue" alt="backfill"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#conclusion"&gt;
  &lt;/a&gt;
  Conclusion
&lt;/h3&gt;

&lt;p&gt;In this post I showed you how you can integrate and orchestrate Amazon Timestream data using Amazon's Managed Workflows for Apache Airflow. I walked you through how you can set this up, how you can use a great open source project called AWS Data Wrangler to interact with Amazon Timestream, and then use some of Apache Airflow's powerful capabilities such as backfill.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What next?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I had some ideas of how you could improve on this setup, which I ran out of time. The one I wanted to do (and may return back to complete) was to package up the code as a plugin so that it can be more easily deployed/shared. I could use other Apache Airflow operators such as the ECS and EKS operators, running the same Timeseries queries. I also want to experiment and explore some of the Timestream features such as interpolation. Hopefully this blog post will provide the foundation for that exploration and make it easier for you to experiment. &lt;/p&gt;

&lt;p&gt;Please let me know via the comments of any additional questions or comments you have on this post.&lt;/p&gt;

</description>
      <category>opensource</category>
      <category>aws</category>
    </item>
    <item>
      <title>We made an evolved News Feed Eradicator...now in Beta!</title>
      <author>Arsala Grey</author>
      <pubDate>Thu, 23 Sep 2021 10:57:29 +0000</pubDate>
      <link>https://dev.to/arsalabangash/we-made-an-evolved-news-feed-eradicator-now-in-beta-3dk1</link>
      <guid>https://dev.to/arsalabangash/we-made-an-evolved-news-feed-eradicator-now-in-beta-3dk1</guid>
      <description>&lt;p&gt;Hi Dev Community!&lt;/p&gt;

&lt;p&gt;Throughout the summer, @paul_designs, @avi_dave, and I were creating Grey Software's first public product: Focused Browsing. We would love for you to try it out!&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--iDQxxXHi--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/6rkgbnradlyt6oe3zv7a.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--iDQxxXHi--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/6rkgbnradlyt6oe3zv7a.png" alt="Focused Browsing Promo"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://grey.software/focused-browsing"&gt;Product Page&lt;/a&gt;&lt;br&gt;
&lt;a href="https://chrome.google.com/webstore/detail/ocbkghddheomencfpdiblibbjhjcojna"&gt;Get It on Chrome&lt;/a&gt;&lt;br&gt;
&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/focused-browsing/"&gt;Get It on Firefox&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Like 200,000 other people, we used News Feed Eradicator (NFE) to control the detrimental effects of consuming feeds. &lt;/p&gt;

&lt;p&gt;We loved the extension, but we had a few problems with it.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It was tedious to toggle between focused and unfocused modes. You had to open the extension's settings page, and click on the website that you want to enable/disable. &lt;/li&gt;
&lt;li&gt;The codebase had gained bloat and complexity over the years. Things like using 2 Redux stores made it difficult to reason about the program flow and we knew that adding new functionality like keyboard shortcuts and blocking promoted posts would be tricky. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our extension recently went into Beta and we're eager to hear everyone's feedback and find any edge cases we haven't covered. Thank You!&lt;/p&gt;

</description>
      <category>showdev</category>
      <category>news</category>
      <category>extension</category>
    </item>
    <item>
      <title>Debootstrap ile Pardus Chroot Olu≈üturmak</title>
      <author>Suleyman Poyraz</author>
      <pubDate>Thu, 23 Sep 2021 09:51:01 +0000</pubDate>
      <link>https://dev.to/zaryob/debootstrap-ile-pardus-chroot-olusturmak-581l</link>
      <guid>https://dev.to/zaryob/debootstrap-ile-pardus-chroot-olusturmak-581l</guid>
      <description>&lt;p&gt;&lt;strong&gt;debootstrap&lt;/strong&gt;, bir Debian temel sistemini girilen paket deposunu kullanarak √∂nceden kurulmu≈ü ba≈üka bir sistemin alt dizinine kurarak chroot ortamƒ± olu≈üturmak i√ßin kullanƒ±lan bir ara√ßtƒ±r. &lt;strong&gt;debootstrap&lt;/strong&gt; sayesinde kurulum CD'si kullanmaya gerek kalmadan, debian chroot'u olu≈üturmayƒ± saƒülar. &lt;br&gt;
&lt;strong&gt;debootstrap&lt;/strong&gt; ile kurulum i√ßin stabil bir internet baƒülantƒ±sƒ± gerekir, √ß√ºnk√º paketler bir Debian deposundan getirilir. Ayrƒ±ca bu ara√ß &lt;strong&gt;dpkg&lt;/strong&gt; paket kurucusunu i√ßeren ba≈üka bir i≈ületim sisteminden kurulabilir ve √ßalƒ±≈ütƒ±rƒ±labilir, bu nedenle, √∂rneƒüin, Debian'ƒ± √ßalƒ±≈üan bir Gentoo sisteminden kullanƒ±lmayan bir b√∂l√ºme kurmak i√ßin debootstrap'ƒ± kullanabilirsiniz. "√áapraz debootstrapping" olarak bilinen farklƒ± bir mimariye sahip bir makine i√ßin bir rootfs olu≈üturmak i√ßin de kullanƒ±labilir.&lt;/p&gt;

&lt;p&gt;Debootstrap, paketleri i√ßin yalnƒ±zca bir depo kullanabilir. Bir rootfs olu≈üturmak i√ßin farklƒ± depolardaki paketleri birle≈ütirmeniz gerekiyorsa (apt'nin yaptƒ±ƒüƒ± gibi) veya rootfs'yi otomatik olarak √∂zelle≈ütirmeniz gerekiyorsa, Multistrap gibi bir ara√ß kullanmak mantƒ±klƒ±dƒ±r.&lt;/p&gt;
&lt;h2&gt;
  &lt;a href="#her-iki-ad%C4%B1m-i%C3%A7in-gerekli-olan-bir-not"&gt;
  &lt;/a&gt;
  Her iki adƒ±m i√ßin gerekli olan bir not
&lt;/h2&gt;

&lt;p&gt;Ba≈ülamadan √∂nce bir kurulum betiƒüi symlink'i olu≈üturmamƒ±z lazƒ±m.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="c"&gt;# ln -s sid /usr/share/debootstrap/scripts/yirmibir&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;B√∂ylece daha doƒüru bir kurulum saƒülamƒ±≈ü olacaƒüƒ±z&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#pardus-chroot-olu%C5%9Fturmak"&gt;
  &lt;/a&gt;
  Pardus Chroot Olu≈üturmak
&lt;/h2&gt;

&lt;p&gt;Bu adƒ±mlarƒ± superkullanƒ±cƒ± olarak i≈üleyeceƒüiz. ƒ∞lk olarak bir dizin olu≈üturalƒ±m.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;main &lt;span class="c"&gt;# mkdir /pardus-chroot/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;≈ûimdi chroot ortamƒ± olu≈üturalƒ±m:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;main &lt;span class="c"&gt;# debootstrap yirmibir /pardus-chroot https://depo.pardus.org.tr/pardus/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h2&gt;
  &lt;a href="#debootstrapt-ile-pardus-kurulumu"&gt;
  &lt;/a&gt;
  Debootstrapt ile Pardus kurulumu
&lt;/h2&gt;

&lt;p&gt;Bu adƒ±mlarƒ± da superkullanƒ±cƒ± olarak i≈üleyeceƒüiz. Bu adƒ±mlarla bir disk √ºzerine Pardus 21 kurabiliriz. ƒ∞lk olarak &lt;code&gt;root&lt;/code&gt; diskimizi belirleyelim. Benim i√ßin &lt;code&gt;/dev/sda3&lt;/code&gt; olacak.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;main &lt;span class="c"&gt;# mkdir /pardus-chroot/&lt;/span&gt;
main &lt;span class="c"&gt;# mount /dev/sda3 /pardus-chroot&lt;/span&gt;
main &lt;span class="c"&gt;# export MY_CHROOT=/pardus-chroot&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;≈ûimdi Chroot √ßekelim&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;main &lt;span class="c"&gt;# cd / &lt;/span&gt;
main &lt;span class="c"&gt;# mkdir $MY_CHROOT&lt;/span&gt;
main &lt;span class="c"&gt;# debootstrap --arch i386 sid $MY_CHROOT http://deb.debian.org/debian/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;≈ûimdi fstab yazalƒ±m. Fstab i√ßerisine &lt;code&gt;proc&lt;/code&gt; ve &lt;code&gt;sysfs&lt;/code&gt; yazacaƒüƒ±z ve bunlarƒ± baƒülayacaƒüƒ±z:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;main &lt;span class="c"&gt;# echo "proc $MY_CHROOT/proc proc defaults 0 0" &amp;gt;&amp;gt; /etc/fstab&lt;/span&gt;
main &lt;span class="c"&gt;# mount proc $MY_CHROOT/proc -t proc&lt;/span&gt;
main &lt;span class="c"&gt;# echo "sysfs $MY_CHROOT/sys sysfs defaults 0 0" &amp;gt;&amp;gt; /etc/fstab&lt;/span&gt;
main &lt;span class="c"&gt;# mount sysfs $MY_CHROOT/sys -t sysfs&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;ƒ∞nternet baƒülantƒ±sƒ± saƒülamak i√ßin &lt;code&gt;hosts&lt;/code&gt; dosyasƒ±nƒ± kopyalayalƒ±m. Ayrƒ±ca baƒülƒ± disk listesi i√ßin &lt;code&gt;mtab&lt;/code&gt; dosyasƒ±nƒ± da kopyalayalƒ±m.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;main &lt;span class="c"&gt;# cp /etc/hosts $MY_CHROOT/etc/hosts&lt;/span&gt;
main &lt;span class="c"&gt;# cp /proc/mounts $MY_CHROOT/etc/mtab&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;≈ûimdi chroot i√ßerisine girelim:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;main &lt;span class="c"&gt;# chroot $MY_CHROOT /bin/bash&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;≈ûimdi &lt;code&gt;dselect&lt;/code&gt; ile gerekli olan paketleri kuralƒ±m:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="nb"&gt;chroot&lt;/span&gt; &lt;span class="c"&gt;# dselect&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;≈ûu methodlarƒ± kullanarak herhangi bir kurulum yapabiliriz.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;     dselect - list of access methods
       Abbrev.        Description
       cdrom          Install from a CD-ROM.
     * multi_cd       Install from a CD-ROM set.
       nfs            Install from an NFS server (not yet mounted).
       multi_nfs      Install from an NFS server (using the CD-ROM set) (not yet mounted).
       harddisk       Install from a hard disk partition (not yet mounted).
       mounted        Install from a filesystem which is already mounted.
       multi_mount    Install from a mounted partition with changing contents.
       floppy         Install from a pile of floppy disks.
       apt            APT Acquisition [file,http,ftp]
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;≈ûimdi login i√ßin √∂ntanƒ±mlƒ± bir tty belirleyelim:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="nb"&gt;chroot&lt;/span&gt; &lt;span class="c"&gt;# mknod tty8 c 4 8&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Ve root i√ßin bir ≈üifre belirleyelim&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="nb"&gt;chroot&lt;/span&gt; &lt;span class="c"&gt;# passwd&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;≈ûifreyi belirttikten sonra &lt;code&gt;chroot&lt;/code&gt;dan √ßƒ±kalƒ±m. Artƒ±k hazƒ±rƒ±z.&lt;/p&gt;

</description>
      <category>debootstrapt</category>
      <category>pardus</category>
      <category>linux</category>
      <category>debian</category>
    </item>
    <item>
      <title>Rate my first CSS drawing</title>
      <author>Temani Afif</author>
      <pubDate>Thu, 23 Sep 2021 09:38:16 +0000</pubDate>
      <link>https://dev.to/afif/rate-my-first-css-drawing-51m5</link>
      <guid>https://dev.to/afif/rate-my-first-css-drawing-51m5</guid>
      <description>&lt;p&gt;I have been hacking with CSS for a long period but I never made any CSS drawing or CSS art. I think it's time for another CSS hacker to join the club!&lt;/p&gt;

&lt;p&gt;I took one of my favorite anime character and I tried to do something in one day to see my level before spending more time.&lt;/p&gt;

&lt;p&gt;I came up with this &lt;/p&gt;

&lt;p&gt;&lt;sup&gt;It will not work on Safari, scroll down to the embed tweet to see a screenshot&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;iframe height="600" src="https://codepen.io/t_afif/embed/MWoXXRd?height=600&amp;amp;default-tab=result&amp;amp;embed-version=2"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;p&gt;Not that perfect but quite good for a &lt;code&gt;6h&lt;/code&gt; work. I would have done better if I considered an easier illustration but I took a complex one as a reference üò≥ üëá&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--sRZfn1nC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i.pinimg.com/originals/15/3a/be/153abee445a48e98bc10d8a29d6b7a16.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--sRZfn1nC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://i.pinimg.com/originals/15/3a/be/153abee445a48e98bc10d8a29d6b7a16.jpg" alt="Livai ackerman"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Few notes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It's responsive.&lt;/li&gt;
&lt;li&gt;I used a lot of &lt;code&gt;clip-path&lt;/code&gt;. A good technique for responsive but a pain to handle. &lt;/li&gt;
&lt;li&gt;I tried to keep a reduced HTML code&lt;/li&gt;
&lt;li&gt;I used an SVG filter to smooth up a few edges (related post: &lt;a href="https://dev.to/afif/css-shapes-with-rounded-corners-56h"&gt;https://dev.to/afif/css-shapes-with-rounded-corners-56h&lt;/a&gt;). I am not proud of this one but I wanted a fast solution to end my drawing before midnight. Next time it will be a CSS-only solution.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I tweeted about it yesterday in case you want to retweet it or draw the attention of a CSS artist üßê&lt;/p&gt;


&lt;blockquote class="ltag__twitter-tweet"&gt;
      &lt;div class="ltag__twitter-tweet__media"&gt;
        &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--v9IzKM4h--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://pbs.twimg.com/media/E_7dYPiVcAUo3bu.png" alt="unknown tweet media content"&gt;
      &lt;/div&gt;

  &lt;div class="ltag__twitter-tweet__main"&gt;
    &lt;div class="ltag__twitter-tweet__header"&gt;
      &lt;img class="ltag__twitter-tweet__profile-image" src="https://res.cloudinary.com/practicaldev/image/fetch/s--FmlYTCXC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://pbs.twimg.com/profile_images/1384162618290540551/jtuQodsv_normal.png" alt="CSS Challenges profile image"&gt;
      &lt;div class="ltag__twitter-tweet__full-name"&gt;
        CSS Challenges
      &lt;/div&gt;
      &lt;div class="ltag__twitter-tweet__username"&gt;
        @challengescss
      &lt;/div&gt;
      &lt;div class="ltag__twitter-tweet__twitter-logo"&gt;
        &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ir1kO05j--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/twitter-f95605061196010f91e64806688390eb1a4dbc9e913682e043eb8b1e06ca484f.svg" alt="twitter logo"&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="ltag__twitter-tweet__body"&gt;
      My first &lt;a href="https://twitter.com/hashtag/CSS"&gt;#CSS&lt;/a&gt; art ‚ò∫Ô∏è&lt;br&gt;&lt;br&gt;&lt;a href="https://twitter.com/idrinkcss"&gt;@idrinkcss&lt;/a&gt; made "Uchiha Itachi" so here I am with a "Livai Ackerman" &lt;a href="https://twitter.com/hashtag/AttackOnTitan"&gt;#AttackOnTitan&lt;/a&gt; &lt;a href="https://twitter.com/hashtag/ShingekiNoKyojin"&gt;#ShingekiNoKyojin&lt;/a&gt; &lt;br&gt;&lt;br&gt;&lt;a href="https://t.co/WaDjxZhPoV"&gt;codepen.io/t_afif/pen/MWo‚Ä¶&lt;/a&gt; via &lt;a href="https://twitter.com/CodePen"&gt;@CodePen&lt;/a&gt; &lt;a href="https://t.co/OWj6JF6GOY"&gt;twitter.com/idrinkcss/stat‚Ä¶&lt;/a&gt; 
    &lt;/div&gt;
    &lt;div class="ltag__twitter-tweet__date"&gt;
      00:28 AM - 23 Sep 2021
    &lt;/div&gt;

      &lt;div class="ltag__twitter-tweet__quote"&gt;
        &lt;div class="ltag__twitter-tweet__quote__header"&gt;
          &lt;span class="ltag__twitter-tweet__quote__header__name"&gt;
            Ronnie Lee
          &lt;/span&gt;
          &lt;a class="mentioned-user" href="https://dev.to/idrinkcss"&gt;@idrinkcss&lt;/a&gt;

        &lt;/div&gt;
        'Uchiha Itachi' Made with #CSS 

This one took me quite a long time, was a bit complicated than expected.

*I'll be sharing the Codepen link in a while in the replies.*

RETWEETS ARE APPRECIATED! https://t.co/TIziBB1t4L
      &lt;/div&gt;

    &lt;div class="ltag__twitter-tweet__actions"&gt;
      &lt;a href="https://twitter.com/intent/tweet?in_reply_to=1440835309801918464" class="ltag__twitter-tweet__actions__button"&gt;
        &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--fFnoeFxk--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/twitter-reply-action-238fe0a37991706a6880ed13941c3efd6b371e4aefe288fe8e0db85250708bc4.svg" alt="Twitter reply action"&gt;
      &lt;/a&gt;
      &lt;a href="https://twitter.com/intent/retweet?tweet_id=1440835309801918464" class="ltag__twitter-tweet__actions__button"&gt;
        &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--k6dcrOn8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/twitter-retweet-action-632c83532a4e7de573c5c08dbb090ee18b348b13e2793175fea914827bc42046.svg" alt="Twitter retweet action"&gt;
      &lt;/a&gt;
      &lt;a href="https://twitter.com/intent/like?tweet_id=1440835309801918464" class="ltag__twitter-tweet__actions__button"&gt;
        &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--SRQc9lOp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev.to/assets/twitter-like-action-1ea89f4b87c7d37465b0eb78d51fcb7fe6c03a089805d7ea014ba71365be5171.svg" alt="Twitter like action"&gt;
      &lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/blockquote&gt;


&lt;p&gt;Let me know what do you think üëáüëá&lt;/p&gt;

&lt;p&gt;‚úîÔ∏è This is amazing, we want more like this!&lt;br&gt;
‚ùå Don't do this anymore ü§Æ we want more tutorials and funny collections but no more drawing please!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PS&lt;/strong&gt;: If you will choose the ‚ùå, I will haunt your dreams for the rest of your life üëπ&lt;/p&gt;

</description>
      <category>showdev</category>
      <category>css</category>
      <category>html</category>
    </item>
    <item>
      <title>Setting up new project</title>
      <author>Ilyos Olimov</author>
      <pubDate>Thu, 23 Sep 2021 09:36:43 +0000</pubDate>
      <link>https://dev.to/ilyosdev/setting-up-new-project-57h8</link>
      <guid>https://dev.to/ilyosdev/setting-up-new-project-57h8</guid>
      <description>&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--YzFCkUh8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ovaem45ea3lmxe4josic.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--YzFCkUh8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ovaem45ea3lmxe4josic.png" alt="image"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;What do you know about solid, kiss and bunch of other things?&lt;br&gt;
Fug them.&lt;br&gt;
When you are writing any kind of code. Just write and see the result. You do not like it? Go change it. &lt;/p&gt;

&lt;p&gt;&lt;em&gt;Do not forget one thing, Rome is not built in one day or night üòâ&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Let`s assume we all have nodejs installed. Create folder named like boilerplate and open that folder in your code editor.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;initiate - &lt;code&gt;npm init -y&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I like MVC, like a lot. So create bunch of folders such as controllers, models, services, middlewares, database(migrations, seeds), utils&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--HZQp9yyJ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/xrw1jcl75r2m5mexeza2.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--HZQp9yyJ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/xrw1jcl75r2m5mexeza2.png" alt="image"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h5&gt;
  &lt;a href="#install-necessary-packages"&gt;
  &lt;/a&gt;
  Install necessary packages
&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;npm install knex -g&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;npm install objection knex mysql --save&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;npm install express dotenv --save&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Go grab the code from &lt;a href="https://github.com/ilyosdev/boilerplate"&gt;here&lt;/a&gt;&lt;br&gt;
and continue.&lt;/p&gt;

&lt;p&gt;First of all check the codebase, if you like it you are more than welcome to use it. If no, what the hell are you doing here then? Go leave my blog. Kidding üòÅ.&lt;/p&gt;

&lt;p&gt;Let me show you some things here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;code&gt;npx knex migrate:make posts&lt;/code&gt; - this will create migration file&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;npx knex migrate:latest&lt;/code&gt; - this will create tables in your db&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;npx knex migrate:rollback&lt;/code&gt; - if you forgot something to add in your latest migration and you change it, try this then you are good to migrate again, without this your terminal spits right in your face.&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;npx knex seed:make posts&lt;/code&gt; - this creates file which you can populate with good old friend faker then you can insert it with &lt;code&gt;npx knex seed:run&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

</description>
      <category>expressjs</category>
      <category>knex</category>
      <category>objection</category>
    </item>
    <item>
      <title>How to add a class to the element?</title>
      <author>101samovar</author>
      <pubDate>Thu, 23 Sep 2021 09:25:03 +0000</pubDate>
      <link>https://dev.to/101samovar/how-to-add-a-class-to-the-element-896</link>
      <guid>https://dev.to/101samovar/how-to-add-a-class-to-the-element-896</guid>
      <description>&lt;p&gt;There‚Äôs some site.&lt;br&gt;
There‚Äôs an element on that site.&lt;br&gt;
There‚Äôs a class named ‚Äòorange‚Äô.&lt;br&gt;
We need to set the className property of the object.&lt;br&gt;
That‚Äôs all.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;element&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;getElementById&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;element&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nx"&gt;element&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;className&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;orange&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;





&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight css"&gt;&lt;code&gt;&lt;span class="nc"&gt;.orange&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;color&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="no"&gt;orange&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We have got an element with added class.&lt;/p&gt;




&lt;p&gt;I hope you found this article useful, if you need any help please let me know in the comment section.&lt;/p&gt;

&lt;p&gt;üëã See you next time. Have a nice day!&lt;/p&gt;

&lt;p&gt;Subscribe to our channel:&lt;br&gt;
&lt;a href="https://www.youtube.com/c/Samovar101"&gt;https://www.youtube.com/c/Samovar101&lt;/a&gt;&lt;/p&gt;

</description>
      <category>javascript</category>
      <category>beginners</category>
    </item>
    <item>
      <title>Step by Step: Block and Inline CSS (2021)</title>
      <author>Phan C√¥ng Th·∫Øng</author>
      <pubDate>Thu, 23 Sep 2021 09:19:56 +0000</pubDate>
      <link>https://dev.to/thangphan37/step-by-step-block-and-inline-css-2021-4ekn</link>
      <guid>https://dev.to/thangphan37/step-by-step-block-and-inline-css-2021-4ekn</guid>
      <description>&lt;p&gt;I usually use &lt;code&gt;display: block&lt;/code&gt;, &lt;code&gt;display: inline&lt;/code&gt; to CSS the HTML elements. But I only stop at the basic level of understanding these. In this post, I'm going to discover some properties that I thought it is interesting about &lt;code&gt;block&lt;/code&gt;, &lt;code&gt;inline&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#review"&gt;
  &lt;/a&gt;
  Review
&lt;/h3&gt;

&lt;p&gt;Before I go forward, let's take a slight review of what I know so far.&lt;/p&gt;

&lt;h4&gt;
  &lt;a href="#block"&gt;
  &lt;/a&gt;
  Block
&lt;/h4&gt;

&lt;p&gt;When I set:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight css"&gt;&lt;code&gt;&lt;span class="nt"&gt;display&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;block&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The HTML element can have some benefits like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Be able to set width, height.&lt;/li&gt;
&lt;li&gt;Break the next element to new line.&lt;/li&gt;
&lt;li&gt;Be able to set padding, margin, border.&lt;/li&gt;
&lt;li&gt;Element's width automatically is the full width of its parent.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;
  &lt;a href="#inline"&gt;
  &lt;/a&gt;
  Inline
&lt;/h4&gt;

&lt;p&gt;When I set:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight css"&gt;&lt;code&gt;&lt;span class="nt"&gt;display&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;inline&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;The HTML element can be had some benefits like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Don't be able to set width, height.&lt;/li&gt;
&lt;li&gt;Don't break the next element to new line.&lt;/li&gt;
&lt;li&gt;Be able to set padding, margin, border.&lt;/li&gt;
&lt;li&gt;Element's width doesn't automatically be the full width of its parent.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It's simple! Right! But I think it's not enough to make sure we can custom the layout of content. Let's move on next step to see what we can discover further.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#writing-mode"&gt;
  &lt;/a&gt;
  Writing Mode
&lt;/h3&gt;

&lt;p&gt;Normally, text in the HTML element has the layout from left to right( some language that renders from right to left). If I want to set the direction of my content from right to left, how can I handle it?&lt;/p&gt;

&lt;p&gt;Fortunately, we have &lt;code&gt;writing mode&lt;/code&gt;, we can set the direction: horizontal, vertical for our content.&lt;/p&gt;

&lt;p&gt;You might think: &lt;em&gt;what am I talking about? Does it relate to &lt;code&gt;block&lt;/code&gt; and &lt;code&gt;inline&lt;/code&gt;?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Don't rush! My friend! We will learn about it step by step.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#writing-mode-css"&gt;
  &lt;/a&gt;
  Writing Mode CSS
&lt;/h3&gt;

&lt;p&gt;In order to turn on writing mode, I need to use the CSS below.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight css"&gt;&lt;code&gt;&lt;span class="c"&gt;/* The content will be normal(horizontal direction) */&lt;/span&gt;
&lt;span class="nt"&gt;writing-mode&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;horizontal-tb&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="c"&gt;/* The content will be vertical(left to right) */&lt;/span&gt;
&lt;span class="nt"&gt;writing-mode&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;vertical-lr&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;

&lt;span class="c"&gt;/* The content will be vertical(right to left) */&lt;/span&gt;
&lt;span class="nt"&gt;writing-mode&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;vertical-rl&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;iframe src="https://codesandbox.io/embed/dazzling-banzai-bz9rk"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;p&gt;Toggle the comment that was defined in &lt;code&gt;style&lt;/code&gt; element, you can see the difference in the layout in three cases.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;code&gt;horizontal-tb&lt;/code&gt;: content is rendered normally.&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;vertical-lr&lt;/code&gt;: content is rendered vertical direction, header appear on the &lt;strong&gt;left&lt;/strong&gt; side, paragraph on the &lt;strong&gt;right&lt;/strong&gt; side.&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;vertical-rl&lt;/code&gt;: content is rendered vertical direction, header appear on the &lt;strong&gt;right&lt;/strong&gt; side, paragraph on the &lt;strong&gt;left&lt;/strong&gt; side.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So far, nothing special! But I want to introduce to you one thing in &lt;code&gt;writing mode&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;When we turn on &lt;code&gt;writing mode&lt;/code&gt;, it creates two directions, they are: &lt;code&gt;inline&lt;/code&gt;, &lt;code&gt;block&lt;/code&gt;, both of them are injected into the HTML element, and the direction of them depends on the property that we set on &lt;code&gt;writing-mode&lt;/code&gt; CSS.&lt;/p&gt;

&lt;p&gt;Hmm, It might look a little bit confusing here. Let's see three pictures below.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;writing-mode: horizontal-tb&lt;/code&gt;&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Azhhm2du--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7nffbcixoppxk1enqp05.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Azhhm2du--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7nffbcixoppxk1enqp05.png" alt="Horizontal In Writing Mode"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;writing-mode: vertical-lr&lt;/code&gt;&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--2p-8Anfk--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/u20k9a3u6k0adlczaiwx.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--2p-8Anfk--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/u20k9a3u6k0adlczaiwx.png" alt="Vertical Left To Right In Writing Mode"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;writing-mode: vertical-rl&lt;/code&gt;&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Y6mngzJu--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/evn1eck97nhywd4jqsv5.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Y6mngzJu--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/evn1eck97nhywd4jqsv5.png" alt="Vertical Right To Left In Writing Mode"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What do &lt;code&gt;inline&lt;/code&gt;, &lt;code&gt;block&lt;/code&gt; mean in these pictures above?.&lt;/p&gt;

&lt;p&gt;These directions are defined in &lt;code&gt;writing-mode&lt;/code&gt; for making the base, and other properties CSS in &lt;code&gt;writing-mode&lt;/code&gt; will be based on these directions(&lt;code&gt;block&lt;/code&gt;, &lt;code&gt;inline&lt;/code&gt;) to reflect. We need to use them later on.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Tip: For easy to remember what directions will be &lt;code&gt;block&lt;/code&gt; or &lt;code&gt;inline&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;code&gt;block&lt;/code&gt; direction: the flow that content is displayed.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;code&gt;inline&lt;/code&gt; direction: the sentences flow&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let's use the tip above.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;writting-mode: horizontal-tb&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;em&gt;header&lt;/em&gt; -&amp;gt; &lt;em&gt;paragraph&lt;/em&gt; is displayed from top to bottom, you can see they take a break from &lt;em&gt;header&lt;/em&gt; to &lt;em&gt;paragraph&lt;/em&gt; -&amp;gt; vertical is the &lt;code&gt;block&lt;/code&gt; direction.&lt;/li&gt;
&lt;li&gt;The sentences flow is horizontal -&amp;gt; horizontal is the &lt;code&gt;inline&lt;/code&gt; direction.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;writting-mode: vertical-lr&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;em&gt;header&lt;/em&gt; -&amp;gt; &lt;em&gt;paragraph&lt;/em&gt; is displayed from left to right, you can see they take a break from &lt;em&gt;header&lt;/em&gt; to &lt;em&gt;paragraph&lt;/em&gt; -&amp;gt; horizontal is the &lt;code&gt;block&lt;/code&gt; direction.&lt;/li&gt;
&lt;li&gt;The sentences flow is vertical -&amp;gt; vertical is the &lt;code&gt;inline&lt;/code&gt; direction.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;writting-mode: vertical-rl&lt;/code&gt; I save it for you.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#custom-content"&gt;
  &lt;/a&gt;
  Custom Content
&lt;/h3&gt;

&lt;p&gt;Now, we already had the basic knowledge about &lt;code&gt;writing-mode&lt;/code&gt;. Let's use it to custom the content.&lt;/p&gt;

&lt;p&gt;I have two blocks: &lt;code&gt;writing-mode: horizontal-tb&lt;/code&gt;, &lt;code&gt;writing-mode: vertical-lr&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;iframe src="https://codesandbox.io/embed/writing-mode-2-pu5y5"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;p&gt;Using the tip above I can determine that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The first block directions: horizontal: &lt;code&gt;inline&lt;/code&gt;, vertical: &lt;code&gt;block&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The second block directions: horizontal: &lt;code&gt;block&lt;/code&gt;, vertical: &lt;code&gt;inline&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, I'm able to use other CSS(logical CSS: the CSS use for &lt;code&gt;writing-mode&lt;/code&gt;) to&lt;br&gt;
custom the content.&lt;/p&gt;

&lt;p&gt;I'm going to use the &lt;code&gt;inline-size&lt;/code&gt; property. You need to remember that&lt;br&gt;
&lt;code&gt;inline-size&lt;/code&gt; will define the dimension for &lt;code&gt;inline&lt;/code&gt; direction that we talked&lt;br&gt;
about above. In this case, &lt;code&gt;inline-size&lt;/code&gt; will define the dimension of horizontal&lt;br&gt;
for the first block(you can think it defines width dimension), and define the&lt;br&gt;
dimension of vertical for the second block(height dimension).&lt;/p&gt;

&lt;p&gt;Replace &lt;code&gt;width: 100px&lt;/code&gt; using&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight css"&gt;&lt;code&gt;&lt;span class="nt"&gt;inline-size&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="err"&gt;200&lt;/span&gt;&lt;span class="nt"&gt;px&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;I will have the result below.&lt;/p&gt;

&lt;p&gt;&lt;iframe src="https://codesandbox.io/embed/writing-mode-3-ftbwp"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#go-further"&gt;
  &lt;/a&gt;
  Go further
&lt;/h3&gt;

&lt;p&gt;There are tons of properties in &lt;code&gt;writing-mode&lt;/code&gt;, and they are called &lt;code&gt;Logical Properties&lt;/code&gt;. &lt;br&gt;
You can learn more &lt;a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Logical_Properties"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I have ever met some CSS like &lt;code&gt;margin-block-start&lt;/code&gt;, and didn't know what is it?&lt;/p&gt;

&lt;p&gt;It turns out I met &lt;code&gt;Logical Properties&lt;/code&gt; CSS.&lt;/p&gt;

&lt;p&gt;Let's use some &lt;code&gt;Logical Properties&lt;/code&gt; to illustrate.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight css"&gt;&lt;code&gt;&lt;span class="c"&gt;/*
- The first case
    - margin-top: 20px, padding-left: 20px, border-right: solid 2px red;
- The second case
    - margin-left: 20px, padding-top: 20px, border-bottom: solid 2px red; 
*/&lt;/span&gt;
&lt;span class="nt"&gt;margin-block-start&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="err"&gt;20&lt;/span&gt;&lt;span class="nt"&gt;px&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="nt"&gt;padding-inline-start&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="err"&gt;20&lt;/span&gt;&lt;span class="nt"&gt;px&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;span class="nt"&gt;border-inline-end&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;solid&lt;/span&gt; &lt;span class="err"&gt;2&lt;/span&gt;&lt;span class="nt"&gt;px&lt;/span&gt; &lt;span class="nt"&gt;red&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;And we have the result below.&lt;/p&gt;

&lt;p&gt;&lt;iframe src="https://codesandbox.io/embed/writing-mode-4-g9olt"&gt;
&lt;/iframe&gt;
&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#conclusion"&gt;
  &lt;/a&gt;
  Conclusion
&lt;/h3&gt;

&lt;p&gt;I have covered about &lt;code&gt;writing-mode&lt;/code&gt; in this article. But can you remember the most important concept? Why don't take a review and practice with some example ?&lt;br&gt;
I think it's worth understanding the concepts of &lt;code&gt;writing-mode&lt;/code&gt; before we moving on to &lt;code&gt;CSS layout&lt;/code&gt;.&lt;/p&gt;

</description>
      <category>css</category>
      <category>tutorial</category>
      <category>webdev</category>
      <category>beginners</category>
    </item>
    <item>
      <title>Creating a Continuous Deployment workflow using Github Actions to deploy your application to ECS</title>
      <author>Mohammed Ali Chherawalla (MAC)</author>
      <pubDate>Thu, 23 Sep 2021 09:16:34 +0000</pubDate>
      <link>https://dev.to/alichherawalla/creating-a-continuous-deployment-workflow-using-github-actions-to-deploy-your-application-to-ecs-4l78</link>
      <guid>https://dev.to/alichherawalla/creating-a-continuous-deployment-workflow-using-github-actions-to-deploy-your-application-to-ecs-4l78</guid>
      <description>&lt;p&gt;A well-written Continuous Deployment (CD) pipeline ensures that on every merge to a release branch, an artifact is created and deployed to the correct environment.  &lt;/p&gt;

&lt;p&gt;While working with containerized applications the CD pipeline needs to contain the following steps&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Code checkout&lt;/li&gt;
&lt;li&gt;Install dependencies&lt;/li&gt;
&lt;li&gt;Build the image&lt;/li&gt;
&lt;li&gt;Push to a container registry&lt;/li&gt;
&lt;li&gt;Use the latest image for the next deployment&lt;/li&gt;
&lt;li&gt;Trigger a new deployment&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this tutorial, we will write a CD pipeline that does all of the above tasks using Github Actions. We will deploy our application using AWS ECS.&lt;/p&gt;

&lt;p&gt;AWS ECS is a fully managed container orchestration service from AWS. It helps you easily deploy, manage and scale containerized applications. &lt;/p&gt;

&lt;p&gt;This tutorial assumes that you have a solid understanding of &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.aws.amazon.com/ecs/index.html"&gt;AWS ECS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.github.com/en/actions"&gt;Github Actions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It also makes the implicit assumption that your application is already deployed on ECS. At the end of this tutorial you will be able automate your deployments on merge to a release branch. &lt;/p&gt;

&lt;p&gt;In this tutorial I will take you through how to&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Trigger a workflow on merge to a release branch.&lt;/li&gt;
&lt;li&gt;Build and push the image to the Elastic Container Registry&lt;/li&gt;
&lt;li&gt;Update the task-definition using the newly created image&lt;/li&gt;
&lt;li&gt;Deploy your application to the new environment&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;
  &lt;a href="#starter-project"&gt;
  &lt;/a&gt;
  Starter Project
&lt;/h2&gt;

&lt;p&gt;Please clone the following repository: &lt;a href="https://github.com/wednesday-solutions/ecs-cd-starter"&gt;https://github.com/wednesday-solutions/ecs-cd-starter&lt;/a&gt; &lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#setup-database-connection"&gt;
  &lt;/a&gt;
  Setup database connection
&lt;/h2&gt;

&lt;p&gt;Update the relevant database connection details in the &lt;code&gt;.env.development&lt;/code&gt;&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="nx"&gt;DB_URI&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;postgres&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="c1"&gt;//&amp;lt;role&amp;gt;:&amp;lt;password&amp;gt;@&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;db&amp;gt;&lt;/span&gt;
&lt;span class="nx"&gt;POSTGRES_HOST&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;host&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
POSTGRES_DB=&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;db&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
POSTGRES_USER=&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;user&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
POSTGRES_PASSWORD=&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;password&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h2&gt;
  &lt;a href="#add-secrets"&gt;
  &lt;/a&gt;
  Add secrets
&lt;/h2&gt;

&lt;p&gt;We need to add the following secrets&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;AWS_ACCESS_KEY_ID
ACCESS_KEY_ID with access to deploy&lt;/li&gt;
&lt;li&gt;AWS_SECRET_ACCESS_KEY
Associated SECRET_ACCESS_KEY&lt;/li&gt;
&lt;li&gt;AWS_REGION
Region in which the cluster is deployed&lt;/li&gt;
&lt;li&gt;AWS_ECR_REPOSITORY
Name of the ECR repository that we will push the image to.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Add the &lt;strong&gt;AWS_ACCESS_KEY_ID&lt;/strong&gt; and &lt;strong&gt;AWS_SECRET_ACCESS_KEY&lt;/strong&gt; secrets*&lt;em&gt;.&lt;/em&gt;*&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--c5cG6tes--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7vyl3yoir82nqem9dfbh.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--c5cG6tes--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7vyl3yoir82nqem9dfbh.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--ggg9sYDV--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/soqwi4pi8btgoicr4zwi.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ggg9sYDV--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/soqwi4pi8btgoicr4zwi.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Add the AWS deployment region&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--leAgRS54--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/adihop4emv6sbu5dl5mm.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--leAgRS54--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/adihop4emv6sbu5dl5mm.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Get the repository name from the AWS console and add it as a secret.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--qd72ezVe--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/rzj2j7wp1e1rnlr9qym9.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--qd72ezVe--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/rzj2j7wp1e1rnlr9qym9.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have omitted the &lt;code&gt;-dev&lt;/code&gt; since that represents the stage. We will be using the same workflow to deploy to multiple environments and will hence infer the stage at runtime.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--b2_65GOu--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/t22lguy96a0p7ngwcg9f.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--b2_65GOu--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/t22lguy96a0p7ngwcg9f.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#create-the-taskdefinitionjson-for-all-the-environments"&gt;
  &lt;/a&gt;
  Create the task-definition.json for all the environments
&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Go to the following URL: &lt;a href="https://ap-south-1.console.aws.amazon.com/ecs/home?region=ap-south-1#/taskDefinitions"&gt;https://ap-south-1.console.aws.amazon.com/ecs/home?region=ap-south-1#/taskDefinitions&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I'm using &lt;code&gt;ap-south-1&lt;/code&gt; as the AWS region. Please change the URL according to the region you are in&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--_pajiDCV--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/f6lgw6zmi7brd1qkbpcd.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--_pajiDCV--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/f6lgw6zmi7brd1qkbpcd.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt;&lt;br&gt;
Select the task definition for your environment and project. In my case its the &lt;code&gt;ecs-cd-starter-dev&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--MCglExRZ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7uizly9279e64gl3pt0q.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--MCglExRZ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7uizly9279e64gl3pt0q.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Select the latest revision and go to the &lt;code&gt;JSON&lt;/code&gt; tab&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--d6KnRfWT--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3cqwo6yku9aceijhaza0.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--d6KnRfWT--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3cqwo6yku9aceijhaza0.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 4&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Copy the JSON.&lt;br&gt;
Run the following snippet in the terminal&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="nx"&gt;mkdir&lt;/span&gt; &lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;definition&lt;/span&gt;
&lt;span class="nx"&gt;touch&lt;/span&gt; &lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;definition&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;dev&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;json&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Paste the JSON from the AWS console into the newly created file.&lt;/p&gt;

&lt;p&gt;I use &lt;code&gt;dev.json&lt;/code&gt; since &lt;code&gt;dev&lt;/code&gt; is my default branch name. I want the code that is pushed to this branch deployed to the &lt;code&gt;dev&lt;/code&gt; environment.&lt;/p&gt;

&lt;p&gt;You will need to repeat this step for the &lt;code&gt;qa&lt;/code&gt; and &lt;code&gt;production&lt;/code&gt;  environments.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#trigger-the-workflow-to-run-on-merge-to-a-release-branch"&gt;
  &lt;/a&gt;
  Trigger  the workflow to run on merge to a release branch
&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Step 1 - Create workflow&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Create a new workflow for continuous deployment in the &lt;code&gt;.github/workflows&lt;/code&gt; folder&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="nx"&gt;touch&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;github&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;workflows&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;cd&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;yml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;Step 2 - Setup triggers&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Identify your release branches. The first release branch will be your default branch which should also be the branch that the team typically raises a pull request to when they want to add a new feature.&lt;/p&gt;

&lt;p&gt;In my case this is the &lt;code&gt;dev&lt;/code&gt; branch. Typically you would have 2 more environments.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;qa&lt;/li&gt;
&lt;li&gt;production&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So let's trigger this workflow whenever there is a push on one of these branches.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;ECS&lt;/span&gt; &lt;span class="nx"&gt;Starter&lt;/span&gt; &lt;span class="nx"&gt;CD&lt;/span&gt; &lt;span class="nx"&gt;Develop&lt;/span&gt;

&lt;span class="nx"&gt;on&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nx"&gt;push&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nx"&gt;branches&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;dev&lt;/span&gt;
      &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;qa&lt;/span&gt;
      &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;master&lt;/span&gt;
&lt;span class="nx"&gt;jobs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nx"&gt;docker&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;build&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;push&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;deploy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;Docker&lt;/span&gt; &lt;span class="nx"&gt;build&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;push&lt;/span&gt; &lt;span class="nx"&gt;and&lt;/span&gt; &lt;span class="nx"&gt;deploy&lt;/span&gt;
    &lt;span class="nx"&gt;runs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;on&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;latest&lt;/span&gt;
    &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Paste the above code into the newly created &lt;code&gt;cd.yml&lt;/code&gt; file&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 3 - Checkout code&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This step pulls the latest code.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="p"&gt;...&lt;/span&gt;
    &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;Checkout&lt;/span&gt;
        &lt;span class="nx"&gt;uses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;actions&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;checkout&lt;/span&gt;&lt;span class="p"&gt;@&lt;/span&gt;&lt;span class="nd"&gt;v2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;Step 4 - Get branch name&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Get the current branch name. This step will fetch the current git branch name and store it. It can now be accessed like so: &lt;code&gt;${{steps.vars.outputs.stage}}&lt;/code&gt;&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="p"&gt;...&lt;/span&gt;
    &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="p"&gt;...&lt;/span&gt;
            &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;Get&lt;/span&gt; &lt;span class="nx"&gt;branch&lt;/span&gt; &lt;span class="nx"&gt;name&lt;/span&gt;
        &lt;span class="nx"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;vars&lt;/span&gt;
        &lt;span class="nx"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;echo&lt;/span&gt; &lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="kd"&gt;set&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;output&lt;/span&gt; &lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;GITHUB_REF&lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="nx"&gt;refs&lt;/span&gt;&lt;span class="cm"&gt;/*/}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;Step 5 - Configure AWS Credentials&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Configure AWS Credentials and region. Use the values from Github secrets to configure the AWS Credentials.&lt;br&gt;
To get a better understanding of all of the configuration options please go through the documentation here: &lt;a href="https://github.com/aws-actions/configure-aws-credentials#usage"&gt;https://github.com/aws-actions/configure-aws-credentials#usage&lt;/a&gt;&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="p"&gt;...&lt;/span&gt;
    &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="p"&gt;...&lt;/span&gt;
            &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;Configure&lt;/span&gt; &lt;span class="nx"&gt;AWS&lt;/span&gt; &lt;span class="nx"&gt;credentials&lt;/span&gt;
        &lt;span class="nx"&gt;uses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;actions&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;configure&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;credentials&lt;/span&gt;&lt;span class="p"&gt;@&lt;/span&gt;&lt;span class="nd"&gt;v1&lt;/span&gt;
        &lt;span class="kd"&gt;with&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
          &lt;span class="nx"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;access&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nx"&gt;secrets&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AWS_ACCESS_KEY_ID&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;
          &lt;span class="nx"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;secret&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;access&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;key&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nx"&gt;secrets&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AWS_SECRET_ACCESS_KEY&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;
          &lt;span class="nx"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;region&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nx"&gt;secrets&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AWS_REGION&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;Step 6 - Login to ECR&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Use the aws-actions/amazon-ecr action to log in to AWS ECR. &lt;/p&gt;

&lt;p&gt;To get a better understanding of all of the configuration options please go through the documentation here: &lt;a href="https://github.com/aws-actions/configure-aws-credentials#usage"&gt;https://github.com/aws-actions/amazon-ecr-login#usage&lt;/a&gt;&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="p"&gt;...&lt;/span&gt;
    &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="p"&gt;...&lt;/span&gt;
            &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;Login&lt;/span&gt; &lt;span class="nx"&gt;to&lt;/span&gt; &lt;span class="nx"&gt;Amazon&lt;/span&gt; &lt;span class="nx"&gt;ECR&lt;/span&gt;
        &lt;span class="nx"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;login&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;ecr&lt;/span&gt;
        &lt;span class="nx"&gt;uses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;actions&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;amazon&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;ecr&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;login&lt;/span&gt;&lt;span class="p"&gt;@&lt;/span&gt;&lt;span class="nd"&gt;v1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;Step 7 - Build tag and push image to ECR&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We now need to build the docker image,. tag and push it to AWS ECR. Use the commit hash to tag the image.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="p"&gt;...&lt;/span&gt;
    &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="p"&gt;...&lt;/span&gt;
            &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;Build&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;tag&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;and&lt;/span&gt; &lt;span class="nx"&gt;push&lt;/span&gt; &lt;span class="nx"&gt;image&lt;/span&gt; &lt;span class="nx"&gt;to&lt;/span&gt; &lt;span class="nx"&gt;Amazon&lt;/span&gt; &lt;span class="nx"&gt;ECR&lt;/span&gt;
        &lt;span class="nx"&gt;env&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
          &lt;span class="nx"&gt;ECR_REGISTRY&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;login&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;ecr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;registry&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;
          &lt;span class="nl"&gt;ECR_REPOSITORY&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nx"&gt;secrets&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AWS_ECR_REPOSITORY&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt;&lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;vars&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;}}&lt;/span&gt;
          &lt;span class="nl"&gt;AWS_REGION&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nx"&gt;secrets&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;AWS_REGION&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;
          &lt;span class="nl"&gt;IMAGE_TAG&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nx"&gt;github&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;sha&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;
        &lt;span class="nl"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
          &lt;span class="nx"&gt;docker&lt;/span&gt; &lt;span class="nx"&gt;build&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;t&lt;/span&gt; &lt;span class="nx"&gt;$ECR_REGISTRY&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;$ECR_REPOSITORY&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nx"&gt;$IMAGE_TAG&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt;
          &lt;span class="nx"&gt;docker&lt;/span&gt; &lt;span class="nx"&gt;push&lt;/span&gt; &lt;span class="nx"&gt;$ECR_REGISTRY&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;$ECR_REPOSITORY&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nx"&gt;$IMAGE_TAG3&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;Step 8 - Render the task definition&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We create a new task-definition revision by updating the value of image. We will point to the image that we just pushed to ECR.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="p"&gt;...&lt;/span&gt;
    &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="p"&gt;...&lt;/span&gt;
            &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;Render&lt;/span&gt; &lt;span class="nx"&gt;Amazon&lt;/span&gt; &lt;span class="nx"&gt;ECS&lt;/span&gt; &lt;span class="nx"&gt;task&lt;/span&gt; &lt;span class="nx"&gt;definition&lt;/span&gt;
        &lt;span class="nx"&gt;id&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;ecs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;cd&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;starter&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;container&lt;/span&gt;
        &lt;span class="nx"&gt;uses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;actions&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;amazon&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;ecs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;render&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;definition&lt;/span&gt;&lt;span class="p"&gt;@&lt;/span&gt;&lt;span class="nd"&gt;v1&lt;/span&gt;
        &lt;span class="kd"&gt;with&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
          &lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;definition&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;task&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;definition&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt;&lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;vars&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;}}.&lt;/span&gt;&lt;span class="nx"&gt;json&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
          &lt;span class="nx"&gt;container&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;ecs&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;cd&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;starter&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt;&lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;vars&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;}}&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
          &lt;span class="nx"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;login&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;ecr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;registry&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;&lt;span class="sr"&gt;/${{ secrets.AWS_ECR_REPOSITORY }}-${{steps.vars.outputs.stage}}:${{ github.sha }&lt;/span&gt;&lt;span class="err"&gt;}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;ol&gt;
&lt;li&gt;the task-definition folder will contain task-definitions for all of the environments. I create json files with the name of the environment and access it using &lt;code&gt;${{steps.vars.outputs.stage}}.json&lt;/code&gt;  in the workflow&lt;/li&gt;
&lt;li&gt;I name my containers with the stage as the suffix. I reference it using &lt;code&gt;&amp;lt;container-name&amp;gt;${{steps.vars.outputs.stage}}.json&lt;/code&gt; in the workflow. &lt;/li&gt;
&lt;li&gt;We reference the image that we just pushed to the ECR registry.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Step 9 - Deploy to ECS&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We use the latest revision of the task-definition that we just created to deploy the application to ECS. I use the same &lt;code&gt;-branchName&lt;/code&gt; suffix when naming my service and cluster&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="p"&gt;...&lt;/span&gt;
    &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="p"&gt;...&lt;/span&gt;
      &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;Logout&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="nx"&gt;Amazon&lt;/span&gt; &lt;span class="nx"&gt;ECR&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;always&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="nx"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;docker&lt;/span&gt; &lt;span class="nx"&gt;logout&lt;/span&gt; &lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;login&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;ecr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;registry&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;Step 10 - Logout of ECR&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Once the deployment is done logout of ECR&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight jsx"&gt;&lt;code&gt;&lt;span class="p"&gt;...&lt;/span&gt;
    &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="p"&gt;...&lt;/span&gt;
      &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="nx"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;Logout&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="nx"&gt;Amazon&lt;/span&gt; &lt;span class="nx"&gt;ECR&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;always&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="nx"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;docker&lt;/span&gt; &lt;span class="nx"&gt;logout&lt;/span&gt; &lt;span class="nx"&gt;$&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nx"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;login&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nx"&gt;ecr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;registry&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h2&gt;
  &lt;a href="#where-to-go-from-here"&gt;
  &lt;/a&gt;
  Where to go from here
&lt;/h2&gt;

&lt;p&gt;Now that you have setup a CD pipeline to deploy your application to ECS I would recommend reading our article on &lt;a href="https://www.wednesday.is/writing-tutorials/part-1-executing-batch-jobs-in-a-multi-container-environment-using-nodejs-and-express"&gt;"how to execute batch jobs in a multi-container environment"&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I hope you enjoyed this tutorial on how to create a CD pipeline to deploy your ECS application. If you have any questions or comments, please join the forum discussion below.&lt;/p&gt;

</description>
      <category>aws</category>
      <category>docker</category>
      <category>github</category>
      <category>devops</category>
    </item>
    <item>
      <title>TimeLy- An app that every student must have</title>
      <author>Android Club - VITC</author>
      <pubDate>Thu, 23 Sep 2021 09:15:49 +0000</pubDate>
      <link>https://dev.to/androidvitc/timely-an-app-that-every-student-must-have-47n6</link>
      <guid>https://dev.to/androidvitc/timely-an-app-that-every-student-must-have-47n6</guid>
      <description>&lt;div class="ltag__link"&gt;
  &lt;a href="/erbmu" class="ltag__link__link"&gt;
    &lt;div class="ltag__link__pic"&gt;
      &lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--PvPSZyw1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://res.cloudinary.com/practicaldev/image/fetch/s--lVonU9td--/c_fill%2Cf_auto%2Cfl_progressive%2Ch_150%2Cq_auto%2Cw_150/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/696887/21510bc4-9edb-4cf3-a07a-973f3c7e54fd.png" alt="erbmu"&gt;
    &lt;/div&gt;
  &lt;/a&gt;
  &lt;a href="/erbmu/timely-3pk3" class="ltag__link__link"&gt;
    &lt;div class="ltag__link__content"&gt;
      &lt;h2&gt;TimeLy&lt;/h2&gt;
      &lt;h3&gt;Atharva Umbre „Éª Sep 23 „Éª 2 min read&lt;/h3&gt;
      &lt;div class="ltag__link__taglist"&gt;
        &lt;span class="ltag__link__tag"&gt;#androidclubvit&lt;/span&gt;
        &lt;span class="ltag__link__tag"&gt;#android&lt;/span&gt;
        &lt;span class="ltag__link__tag"&gt;#reactnative&lt;/span&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/a&gt;
&lt;/div&gt;


</description>
      <category>react</category>
      <category>productivity</category>
      <category>android</category>
      <category>androidclub</category>
    </item>
    <item>
      <title>Choosing a Rad Web Hosting KVM VPS Hosting</title>
      <author>Larry Johnson</author>
      <pubDate>Thu, 23 Sep 2021 09:13:35 +0000</pubDate>
      <link>https://dev.to/sitedata/choosing-a-rad-web-hosting-kvm-vps-hosting-1ipb</link>
      <guid>https://dev.to/sitedata/choosing-a-rad-web-hosting-kvm-vps-hosting-1ipb</guid>
      <description>&lt;p&gt;RAD WEB HOSTING is a leading provider of website hosting, reseller hosting, VPS Servers, performance cloud solutions, and dedicated server hosting in Dallas, TX. RAD WEB HOSTING provides a platform for clients to register and manage their domain names, as well as protect their websites and visitors with FREE Domain Privacy and SSL Certificates. Headquartered in the former Federal Reserve Bank of Dallas, all hosting services benefit from enhanced security and multi-homed network up streams for redundancy and faster connection speeds. RAD WEB HOSTING‚Äôs core service offering revolves around providing hosting solutions for small to medium businesses, but also providing customized scalable hosting solutions for Growing and Enterprise clients.&lt;/p&gt;

&lt;p&gt;Why Rad Web Hosting&lt;br&gt;
&lt;a href="https://radwebhosting.com/kvm-vps-servers"&gt;KVM VPS&lt;/a&gt; in which Premium Intel Server Hardware, SSD storage, and KVM hypervisors are standard Features of Linux VPS Servers. KVM VPS Servers are Fully Customizable and Provide a Reliable, High-Availability Hosting Platform for Your Needs.&lt;/p&gt;

&lt;p&gt;Windows VPS Hosting in which Windows VPS Servers are instantly upgradeable, DDoS protected, and backed by our premium network and 24/7 Support. Manage your Windows VPS directly from your Hosting Dashboard with on-demand OS reloads, power control, reverse DNS management, IPMI and more. Windows VPS Servers feature KVM virtualization with RAID 10 SSD.&lt;/p&gt;

</description>
      <category>vpshosting</category>
      <category>vps</category>
      <category>kvm</category>
      <category>vpsserver</category>
    </item>
    <item>
      <title>TimeLy</title>
      <author>Atharva Umbre</author>
      <pubDate>Thu, 23 Sep 2021 09:04:36 +0000</pubDate>
      <link>https://dev.to/erbmu/timely-3pk3</link>
      <guid>https://dev.to/erbmu/timely-3pk3</guid>
      <description>&lt;p&gt;Ever got tired of remembering which class you have? Constantly having the urge to check the class hours?&lt;br&gt;
What if I told you - you could have your timetable in your pocket? No more fussing over it again?&lt;/p&gt;

&lt;p&gt;TimeLy, an app developed by Android Club VITC, is designed to fulfil the same and make life easier for every student!&lt;/p&gt;

&lt;p&gt;Let‚Äôs have a quick glance at some of the prominent features of this app.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.Simple UI:&lt;/strong&gt;&lt;br&gt;
The Graphical User Interface of this app is simple and easy on the eyes. With a minimalistic background and the absence of unnecessary features, this makes the app extremely user friendly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.No Signup:&lt;/strong&gt;&lt;br&gt;
No registration is required. One does not have to go through any hustle of providing personal details. TimeLy is a one of a sort, straight to the point app, directly catering to your needs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.No ads:&lt;/strong&gt;&lt;br&gt;
With no annoying ads to waste your time, TimeLy ensures you get to check your timetable without any disturbances.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.Radiant Colors:&lt;/strong&gt;&lt;br&gt;
TimeLy also allows the user to use various colors for particular classes. With a range of modest colors, your entire experience is made much more comfortable and pleasant.&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#tutorial"&gt;
  &lt;/a&gt;
  Tutorial:
&lt;/h1&gt;

&lt;p&gt;Let‚Äôs now have a quick look on how to use this app:&lt;/p&gt;

&lt;p&gt;To start off simply click on the ‚Äò+‚Äô sign on the top right corner of your screen.&lt;/p&gt;

&lt;p&gt;Let‚Äôs say I have a Lab class of Cyber Security with a C2 slot. Adding in these details with the timings and day of the class (along with your preferred color choice), click on the ‚ÄòAdd‚Äô button. &lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Eoitz19k--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/neo5rlq7xiz1kn19uy75.jpeg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Eoitz19k--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/neo5rlq7xiz1kn19uy75.jpeg" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--37INtr7a--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ux6t3v0carrdwicea6x4.jpeg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--37INtr7a--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ux6t3v0carrdwicea6x4.jpeg" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And that‚Äôs literally all there was to it! Your class has been added to your timetable. Now all that remains is adding the rest of your classes, and all your timetable worries have been solved!&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--AxzOsT66--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fx7043tp22tjb8af7m1v.jpeg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--AxzOsT66--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fx7043tp22tjb8af7m1v.jpeg" alt="Alt Text"&gt;&lt;/a&gt;&lt;br&gt;
Couldn‚Äôt have asked for anything better huh?&lt;/p&gt;

&lt;p&gt;TimeLy is as Barney Stinson would say -&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--as5NN8Xg--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/cyyhhpefegdqia4mvqa7.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--as5NN8Xg--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/cyyhhpefegdqia4mvqa7.jpg" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

</description>
      <category>androidclubvit</category>
      <category>android</category>
      <category>reactnative</category>
    </item>
  </channel>
</rss>
