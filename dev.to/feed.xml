<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>DEV Community</title>
    <author>DEV Community</author>
    <description>A constructive and inclusive social network for software developers. With you every step of your journey.</description>
    <link>https://dev.to</link>
    <language>en</language>
    <item>
      <title>S3 types of Storage</title>
      <author>Ajit Singh</author>
      <pubDate>Wed, 04 Aug 2021 13:43:43 +0000</pubDate>
      <link>https://dev.to/this-is-learning/s3-types-of-storage-1535</link>
      <guid>https://dev.to/this-is-learning/s3-types-of-storage-1535</guid>
      <description>&lt;p&gt;We store files in S3 but we may need different types of storage based on our needs. Like some files that are infrequently accessed some that are needed once a year so paying the same charges as a normal storage does not make sense for these. So, based on our needs AWS has given us various types of storage based on needs.There are 6 types of storage types in AWS S3 &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;strong&gt;S3 Standard&lt;/strong&gt; for general-purpose storage of frequently accessed data&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;S3 Intelligent-Tiering&lt;/strong&gt; for data with unknown or changing access patterns&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;S3 Standard-Infrequent Access&lt;/strong&gt; (S3 Standard-IA)for long-lived, but less frequently accessed data&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;S3 One Zone-Infrequent Access&lt;/strong&gt; (S3 One Zone-IA) for long-lived, but less frequently accessed data&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;Amazon S3 Glacier&lt;/strong&gt; (S3 Glacier) for archives&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;Amazon S3 Glacier Deep Archive&lt;/strong&gt; (S3 Glacier Deep Archive) for long-term archive and digital preservation.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;All these storage classes varies on the availability of our objects in our S3 buckets for usage. Let us study each one of them in detail&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#s3-standard"&gt;
  &lt;/a&gt;
  S3 Standard
&lt;/h2&gt;

&lt;p&gt;This is the storage type we have been using until now,it is the default for our S3 buckets. It has low latency and high availability. This is used when the data has a very frequent access. It has very high availability and AWS is bound by the &lt;a href="https://aws.amazon.com/s3/sla/"&gt;SLA agreement&lt;/a&gt; on this which makes sure its always highly available. It is used for dynamic websites, content distribution, mobile and gaming applications, and big data analytics.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#s3-standardinfrequent-access"&gt;
  &lt;/a&gt;
  S3 Standard-Infrequent Access
&lt;/h2&gt;

&lt;p&gt;This has 99.9% percent availability. Suitable for data when is accessed less but requires immediate access when needed. It requires less money for storage but whenever we retrieve the objects under this class we have to pay a fee so its not good for frequent access. It is mainly used for  long-term storage, backups, and as a data store for disaster recovery files. &lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#s3-intelligenttiering"&gt;
  &lt;/a&gt;
  S3 Intelligent-Tiering
&lt;/h2&gt;

&lt;p&gt;If you don't know where to put your data in standard access or Infrequent Access. We have this storage class in which S3 automatically stores data according to pour retrieval rates. If data is frequently accessed then it is put in standard storage other wise in Infrequent Access . This is the most cost optimized class if you don't want to think in which class to put your data. It is the ideal storage class for data sets with unknown storage access patterns, like new applications, or unpredictable access patterns, like data lakes. &lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#s3-one-zoneinfrequent-access"&gt;
  &lt;/a&gt;
  S3 One Zone-Infrequent Access
&lt;/h2&gt;

&lt;p&gt;One Zone-Infrequent Access it has all the same properties of Infrequent access except all the above storage are in 3 availability zones but this storage class is only in one AZ so is prone to disasters. It is ideal for customers who want a lower-cost option for infrequently accessed data but do not require the availability and resilience of S3 Standard or S3 Standard-IA. It’s a good choice for storing secondary backup copies of on-premises data or easily re-creatable data. You can also use it as cost-effective storage for data that is replicated from another AWS Region using S3 Cross-Region Replication. It is normally used for data that you want ti copy across regions as copying it across 3 AZ may not make sense.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#amazon-s3-glacier"&gt;
  &lt;/a&gt;
  Amazon S3 Glacier
&lt;/h2&gt;

&lt;p&gt;S3 glacier is a very low cost storage available on S3. Normally data stored here is kept for years. you normally use it for data archiving. You can reliably store any amount of data at costs that are competitive with or cheaper than on-premises solutions. It has 3 sub classes of data retrievals available in S3 glacier &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Expedited - Data retrieval in 1 to 5 min&lt;/li&gt;
&lt;li&gt;Standard - Data retrieval in 3 to 5 hours&lt;/li&gt;
&lt;li&gt;Bulk - Data retrieval in 5 to 12 hours&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;
  &lt;a href="#amazon-s3-deep-glacier"&gt;
  &lt;/a&gt;
  Amazon S3 Deep Glacier
&lt;/h2&gt;

&lt;p&gt;S3 Glacier Deep Archive is Amazon S3’s lowest-cost storage class and supports long-term retention and digital preservation for data that may be accessed once or twice in a year. It is designed for customers — particularly those in highly-regulated industries, such as the Financial Services, Healthcare, and Public Sectors — that retain data sets for 7-10 years or longer to meet regulatory compliance requirements. S3 Glacier Deep Archive can also be used for backup and disaster recovery use cases, and is a cost-effective and easy-to-manage alternative to magnetic tape systems, whether they are on-premises libraries or off-premises services. S3 Glacier Deep Archive complements Amazon S3 Glacier, which is ideal for archives where data is regularly retrieved and some of the data may be needed in minutes. It has 3 sub classes of data retrievals available in S3 deep glacier &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Standard - Data retrieval in 12 hours&lt;/li&gt;
&lt;li&gt;Bulk - Data retrieval in 48 hours&lt;/li&gt;
&lt;/ol&gt;

&lt;div class="table-wrapper-paragraph"&gt;&lt;table&gt;

&lt;tbody&gt;

&lt;tr&gt;

&lt;th&gt; &lt;/th&gt;

&lt;th&gt;S3 Standard&lt;/th&gt;

&lt;th&gt;S3 Intelligent-Tiering*&lt;/th&gt;

&lt;th&gt;S3 Standard-IA&lt;/th&gt;

&lt;th&gt;S3 One Zone-IA†&lt;/th&gt;

&lt;th&gt;S3 Glacier&lt;/th&gt;

&lt;th&gt;S3 Glacier Deep Archive&lt;/th&gt;

&lt;/tr&gt;

&lt;tr&gt;

&lt;td&gt;Designed for durability&lt;/td&gt;

&lt;td&gt;99.999999999% (11 9’s)&lt;/td&gt;

&lt;td&gt;99.999999999% (11 9’s)&lt;/td&gt;

&lt;td&gt;99.999999999% (11 9’s)&lt;/td&gt;

&lt;td&gt;99.999999999% (11 9’s)&lt;/td&gt;

&lt;td&gt;99.999999999% (11 9’s)&lt;/td&gt;

&lt;td&gt;99.999999999% (11 9’s)&lt;/td&gt;

&lt;/tr&gt;

&lt;tr&gt;

&lt;td&gt;Designed for availability&lt;/td&gt;

&lt;td&gt;99.99%&lt;/td&gt;

&lt;td&gt;99.9%&lt;/td&gt;

&lt;td&gt;99.9%&lt;/td&gt;

&lt;td&gt;99.5%&lt;/td&gt;

&lt;td&gt;99.99%&lt;/td&gt;

&lt;td&gt;99.99%&lt;/td&gt;

&lt;/tr&gt;

&lt;tr&gt;

&lt;td&gt;Availability SLA&lt;/td&gt;

&lt;td&gt;99.9%&lt;/td&gt;

&lt;td&gt;99%&lt;/td&gt;

&lt;td&gt;99%&lt;/td&gt;

&lt;td&gt;99%&lt;/td&gt;

&lt;td&gt;99.9%&lt;/td&gt;

&lt;td&gt;99.9%&lt;/td&gt;

&lt;/tr&gt;

&lt;tr&gt;

&lt;td&gt;Availability Zones&lt;/td&gt;

&lt;td&gt;≥3&lt;/td&gt;

&lt;td&gt;≥3&lt;/td&gt;

&lt;td&gt;≥3&lt;/td&gt;

&lt;td&gt;1&lt;/td&gt;

&lt;td&gt;≥3&lt;/td&gt;

&lt;td&gt;≥3&lt;/td&gt;

&lt;/tr&gt;

&lt;tr&gt;

&lt;td&gt;Minimum capacity charge per object&lt;/td&gt;

&lt;td&gt;N/A&lt;/td&gt;

&lt;td&gt;N/A&lt;/td&gt;

&lt;td&gt;128KB&lt;/td&gt;

&lt;td&gt;128KB&lt;/td&gt;

&lt;td&gt;40KB&lt;/td&gt;

&lt;td&gt;40KB&lt;/td&gt;

&lt;/tr&gt;

&lt;tr&gt;

&lt;td&gt;Minimum storage duration charge&lt;/td&gt;

&lt;td&gt;N/A&lt;/td&gt;

&lt;td&gt;30 days&lt;/td&gt;

&lt;td&gt;30 days&lt;/td&gt;

&lt;td&gt;30 days&lt;/td&gt;

&lt;td&gt;90 days&lt;/td&gt;

&lt;td&gt;180 days&lt;/td&gt;

&lt;/tr&gt;

&lt;tr&gt;

&lt;td&gt;Retrieval fee&lt;/td&gt;

&lt;td&gt;N/A&lt;/td&gt;

&lt;td&gt;N/A&lt;/td&gt;

&lt;td&gt;per GB retrieved&lt;/td&gt;

&lt;td&gt;per GB retrieved&lt;/td&gt;

&lt;td&gt;per GB retrieved&lt;/td&gt;

&lt;td&gt;per GB retrieved&lt;/td&gt;

&lt;/tr&gt;

&lt;tr&gt;

&lt;td&gt;First byte latency&lt;/td&gt;

&lt;td&gt;milliseconds&lt;/td&gt;

&lt;td&gt;milliseconds&lt;/td&gt;

&lt;td&gt;milliseconds&lt;/td&gt;

&lt;td&gt;milliseconds&lt;/td&gt;

&lt;td&gt;select minutes or hours&lt;/td&gt;

&lt;td&gt;select hours&lt;/td&gt;

&lt;/tr&gt;

&lt;tr&gt;

&lt;td&gt;Storage type&lt;/td&gt;

&lt;td&gt;Object&lt;/td&gt;

&lt;td&gt;Object&lt;/td&gt;

&lt;td&gt;Object&lt;/td&gt;

&lt;td&gt;Object&lt;/td&gt;

&lt;td&gt;Object&lt;/td&gt;

&lt;td&gt;Object&lt;/td&gt;

&lt;/tr&gt;

&lt;tr&gt;

&lt;td&gt;Lifecycle transitions&lt;/td&gt;

&lt;td&gt;Yes&lt;/td&gt;

&lt;td&gt;Yes&lt;/td&gt;

&lt;td&gt;Yes&lt;/td&gt;

&lt;td&gt;Yes&lt;/td&gt;

&lt;td&gt;Yes&lt;/td&gt;

&lt;td&gt;Yes&lt;/td&gt;

&lt;/tr&gt;

&lt;/tbody&gt;

&lt;/table&gt;&lt;/div&gt;

&lt;p&gt;In this article we studies about the various S3 classes in the next article we will study how to use them and move various things into different storage classes.&lt;/p&gt;

</description>
      <category>aws</category>
      <category>beginners</category>
      <category>cloud</category>
      <category>devops</category>
    </item>
    <item>
      <title>
Best Practices for Cloud Disaster Recovery in Microsoft Azure</title>
      <author>We are IOD</author>
      <pubDate>Wed, 04 Aug 2021 13:36:57 +0000</pubDate>
      <link>https://dev.to/iod/best-practices-for-cloud-disaster-recovery-in-microsoft-azure-2dg0</link>
      <guid>https://dev.to/iod/best-practices-for-cloud-disaster-recovery-in-microsoft-azure-2dg0</guid>
      <description>&lt;p&gt;In today’s cloud era, the ability to bounce back after downtime can make or break your business. Disaster recovery (DR) capabilities should therefore be a key consideration when choosing a cloud platform. Leveraging the cloud as a secondary data center for DR is often the first step in cloud adoption, and disaster recovery as a service (DRaaS) offerings from various cloud service providers underline this fact.&lt;/p&gt;

&lt;p&gt;Azure packs a punch with multiple DR options for services like VMs, storage, databases, and containers. In this blog post, I’ll explore these options and discuss how you can develop a robust business continuity and disaster recovery (BCDR) strategy for your workloads hosted in Azure.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#what-to-consider-when-creating-your-dr-plan-in-azure"&gt;
  &lt;/a&gt;
  What to Consider When Creating Your DR Plan in Azure
&lt;/h2&gt;

&lt;p&gt;Contrary to popular belief, applications hosted in the cloud are not foolproof—failures happen. Since application downtime can be disastrous for your business, you need a well-defined DR strategy to be prepared to handle failures. This strategy should cover the entire application stack, not just the services you think are important.&lt;/p&gt;

&lt;p&gt;You might need to manually trigger the DR process yourself in order to differentiate between transient failures and actual downtimes. However, the failover process in Azure should be automated as much as possible. &lt;a href="https://stagemarketer.wpengine.com/blog/monitoring-in-azure-the-high-level-fundamentals/"&gt;Configure alerts&lt;/a&gt; so you can stay informed about failures and take necessary actions to trigger your DR plan.&lt;/p&gt;

&lt;p&gt;With Azure, you can choose to deploy application components across Azure regions to protect from regional failures. If applications are regional, you can deploy them in availability zones (physically separated zones within a region) to protect from data center failures. Your choice will depend on the type of resiliency you want to deliver for your application. In addition to a DR strategy that protects from cateroscopic failures, you should have a backup strategy for  preventing unavailability due to data corruption or application configuration.&lt;/p&gt;

&lt;p&gt;Your DR strategy should also clearly define the DR process, which activities will be completed when the plan is triggered, and who will be responsible for executing the plan. However, a detailed DR strategy won’t really help unless you test and fine-tune it regularly. This is where services that offer non-disruptive DR testing, such as Azure’s DR solution, come into play. Similarly, executing a regular test restore of backups in a test environment will help avoid surprises during an eventuality.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#disaster-recovery-in-azure-what-are-your-options"&gt;
  &lt;/a&gt;
  Disaster Recovery in Azure: What Are Your Options?
&lt;/h2&gt;

&lt;p&gt;Before developing a DR strategy, you should be clear about the recovery point objective (RPO) and recovery time objective (RTO) for your workloads. For example, if a bit of downtime is okay with you (i.e., non-prod and test environments), a complete redeployment of applications is a good choice. You can also choose to adopt an active/passive or warm-spare approach, where a &lt;a href="https://stagemarketer.wpengine.com/blog/cost-optimization-in-azure-the-building-blocks-part-1/"&gt;scaled-down secondary service&lt;/a&gt; is ready to take over in the event of a failure. It’s most effective to use an active/active or hot-spare architecture, where instances of the application are available in multiple regions in order to accept production traffic.&lt;/p&gt;

&lt;p&gt;Azure offers native capabilities built into most of its services, which can be leveraged to develop a well-rounded DR strategy. Note that it’s important to start from the ground up (i.e., covering infrastructure, if applicable, as well as data and application layers) in order to develop a comprehensive solution. Below I’ll explore the DR options for common Azure services.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#virtual-machines"&gt;
  &lt;/a&gt;
  Virtual Machines
&lt;/h2&gt;

&lt;p&gt;Azure Site Recovery, Azure’s DRaaS offering, helps protect your VMs from outages by continuously replicating them to a different paired region. In the event of a disaster, the VMs can be failed over to the secondary region, and you can enable access from there. You can also fail back to the primary region once the outage is over. Organizations often use Azure Site Recovery to leverage Azure as their DR site, as it supports replicating VMs in VMware/Hyper-V or in physical machines to Azure.&lt;/p&gt;

&lt;p&gt;Azure Backup is another solution you can include in the BCDR strategy for your VMs. You can use this cloud-based backup service to take point-in-time copies of data in the VMs. The backup copies can then be restored to bring your application back online in the event of data loss or corruption. For the highest level of availability and resiliency from failure, use a &lt;a href="https://docs.microsoft.com/en-us/azure/architecture/reference-architectures/n-tier/multi-region-sql-server"&gt;multi-region architecture&lt;/a&gt;, in which both primary and secondary regions are factored into the design.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#storage"&gt;
  &lt;/a&gt;
  Storage
&lt;/h2&gt;

&lt;p&gt;An Azure Storage account can be deployed as geo-redundant, allowing data in the storage account to be replicated to the secondary region asynchronously. In case of an outage that renders the primary end point unavailable, you can initiate an account failover for &lt;a href="https://docs.microsoft.com/en-us/azure/backup/azure-file-share-backup-overview"&gt;Azure Storage&lt;/a&gt;. The failover process will cause the secondary endpoint to become the primary one so that applications can continue to use the storage. &lt;/p&gt;

&lt;p&gt;For Azure Blob, you can use snapshots to create read-only point-in-time copies of the data. Azure files can be protected through a scheduled Azure backup. You can also use the snapshot feature to create point-in-time copies of the data, similar to Azure Blob. If your application is utilizing Azure Table storage, use the &lt;a href="https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10"&gt;AzCopy&lt;/a&gt; tool to copy the data to a different storage account in another Azure region for DR purposes.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#databases"&gt;
  &lt;/a&gt;
  Databases
&lt;/h2&gt;

&lt;p&gt;Your DR strategy for databases will depend on whether you are using IaaS or PaaS as the deployment approach. For SQL Server and SAP HANA databases hosted in VMs, you can use the integrated Azure Backup feature to discover and configure regular backup without deploying any additional infrastructure. &lt;/p&gt;

&lt;p&gt;There are also managed databases like Azure SQL, MySQL, PostgreSQL, and Cosmos DB, delivered as PaaS services. For those databases, Azure offers an automated backup service that takes regular snapshot-based backups of the database to a separate storage account. If you need the backups to be retained for a longer period of time, Azure SQL offers a &lt;a href="https://docs.microsoft.com/en-us/azure/azure-sql/database/long-term-retention-overview"&gt;long-term backup retention feature&lt;/a&gt; that allows you to store your backup copies in a storage account for up to 10 years.  &lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#containers"&gt;
  &lt;/a&gt;
  Containers
&lt;/h2&gt;

&lt;p&gt;Azure provides a robust ecosystem of services to support &lt;a href="https://stagemarketer.wpengine.com/blog/what-you-should-know-about-containers-in-azure/"&gt;container-based workloads&lt;/a&gt;, including: &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Azure Kubernetes Service (AKS)&lt;/li&gt;
&lt;li&gt;Azure Container Instances (ACI)&lt;/li&gt;
&lt;li&gt;Azure App Service&lt;/li&gt;
&lt;li&gt;Azure Container Registry (ACR)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;AKS uses VM scale sets that can protect your workloads from node failures. However, to protect from regional outages, you should consider multi-region deployments that &lt;a href="https://docs.microsoft.com/en-us/azure/aks/operator-best-practices-multi-region#use-azure-traffic-manager-to-route-traffic"&gt;leverage Azure Traffic Manager&lt;/a&gt; to route traffic to available regions.&lt;/p&gt;

&lt;p&gt;It’s also important to segregate the process of recovering your application and data. You can leverage Azure Storage solutions like disks and file shares to create &lt;a href="https://docs.microsoft.com/en-us/azure/aks/concepts-storage#persistent-volumes"&gt;persistent volumes&lt;/a&gt; for applications hosted in containers, then protect that data using Azure Backup. ACR’s geo-replication feature allows you to access your container images from a secondary region, should the primary endpoint go down due to a regional outage. &lt;/p&gt;

&lt;p&gt;In addition, you should have a well-defined DevOps process for redeploying infrastructure to a different region through IAC, and for redeploying applications through a CI/CD process, should there be a downtime due to a cloud outage.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#azure-app-service"&gt;
  &lt;/a&gt;
  Azure App Service
&lt;/h2&gt;

&lt;p&gt;For Azure App Service, &lt;a href="https://docs.microsoft.com/en-us/azure/architecture/reference-architectures/app-service-web-app/multi-region"&gt;multi-region deployment&lt;/a&gt; is the best way to minimize application downtime. You can also leverage the backup and restore feature of Azure App Service, which automatically creates a backup of your application configuration, file content, and databases connected to the app. In case of regional outages, applications hosted in Azure App Service will be placed in DR mode. In this mode, you can restore your app contents to a destination app in a different Azure region.&lt;/p&gt;

&lt;p&gt;With a mature DevOps practice in place, you can also restore the application by redeploying the code targeting the new destination app. For serverless apps like Azure Functions and microservices-based deployments, it’s best to separate the configuration from the code in cloud-scale deployments. You can use &lt;a href="https://docs.microsoft.com/en-us/azure/azure-app-configuration/overview"&gt;Azure App Configuration&lt;/a&gt; to store configuration information that can be accessed during runtime. This approach also helps fast-track the redeployment process of applications during a disaster.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#conclusion"&gt;
  &lt;/a&gt;
  Conclusion
&lt;/h2&gt;

&lt;p&gt;The modern cloud-scale applications deployed in Azure offer multiple options for DR. Be it end-to-end replication using Azure Site Recovery for VMs, leveraging CI/CD pipelines for redeployment, or the more traditional backup/restore approach for services like Azure apps, databases, and containers, the best solution for you will depend on your RPO and RTO. In most cases, you can create an effective solution using Azure-native tools and services and by integrating elements of DR into your application architecture.&lt;/p&gt;

</description>
      <category>cloud</category>
      <category>azure</category>
    </item>
    <item>
      <title>A lightweight markdown + WYSWYG editor by elastic UI</title>
      <author>Rahul kumar</author>
      <pubDate>Wed, 04 Aug 2021 13:05:19 +0000</pubDate>
      <link>https://dev.to/ats1999/a-lightweight-markdown-wyswyg-editor-by-elastic-ui-1hph</link>
      <guid>https://dev.to/ats1999/a-lightweight-markdown-wyswyg-editor-by-elastic-ui-1hph</guid>
      <description>&lt;p&gt;&lt;a href="https://elastic.github.io/eui/#/editors-syntax/markdown-editor#base-editor"&gt;editor-link&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I am very impressed with this editor, i was looking for such an editor for a very long time. &lt;/p&gt;

&lt;p&gt;I want to use this in a project, but it dose't available as standalone editor. &lt;/p&gt;

&lt;p&gt;Does anyone knows such an standalone editor??&lt;/p&gt;

</description>
    </item>
    <item>
      <title>How IHP uses Haskell's Type System to enforce good patterns</title>
      <author>digitallyinduced</author>
      <pubDate>Wed, 04 Aug 2021 12:56:30 +0000</pubDate>
      <link>https://dev.to/digitallyinduced/how-ihp-uses-haskell-s-type-system-to-enforce-good-patterns-2kjn</link>
      <guid>https://dev.to/digitallyinduced/how-ihp-uses-haskell-s-type-system-to-enforce-good-patterns-2kjn</guid>
      <description>&lt;p&gt;Good patterns and clean code are what differentiates a production application from a legacy application. In a lot of cases, many production applications become legacy applications with time, because patterns aren't enforced and therefore ignored, wrongly interpreted, or otherwise abandoned.&lt;/p&gt;

&lt;p&gt;IHP uses Haskell as its language of choice, and one big reason for this is the typesafety that Haskell provides. After reading this article you'll hopefully understand how IHP is making use of Haskell's strong typesystem to enforce proper use of patterns shared between all IHP applications, which prevents your production webapp from becoming a legacy webapp.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Sidenote:&lt;/em&gt; at digitally induced we have multiple older IHP apps, none of which we consider "legacy", even if they've been running for quite some time. If we need to make changes to them, it is very easy to get back into them and understand what is going on, as all IHP apps follow similar patterns. We know what to expect, and where to find the code we're looking for.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#modelviewcontroller"&gt;
  &lt;/a&gt;
  Model-View-Controller
&lt;/h2&gt;

&lt;p&gt;Let's get the biggest point out of the way first. IHP uses the popular Model-View-Controller pattern, which is characterized by the three parts giving the pattern its name:&lt;/p&gt;

&lt;p&gt;The Model is the data of the application, which has a static structure when running, but variable content, as the content is user-generated. In IHP all data types are auto-generated from the database schema, ensuring that the code you write is always compatible with the database.&lt;/p&gt;

&lt;p&gt;The View is a simple mapping that turns data into Html. Using Haskell's type system, this is enforced by defining every view as a pure function (a function without side-effects that always produces the same output if it receives the same input). You might have heard that that's the core idea of React as well, and it's a reason React is so popular: the render function should simply take the current component's state and render Html based on that. However, React has the problem that everything else is also possible in the view, and in a way even requires it to be there, including updating state. In IHP, the view really fulfills this promise, and it's enforced by the type system.&lt;/p&gt;

&lt;p&gt;The Controller is the part of the application that contains the actual business logic, and should be the only place in the application that is able to interact with the outside world, including the database (also known as IO: Input and Output). In Haskell, doing IO isn't possible everywhere, only in functions that have been declared to be able to do it. IHP makes use of that by defining the actions (endpoints of controllers) as the only functions that can run IO things. Even if someone is tempted to fetch data from the database in the View, they can't, because the controller is simply going to prevent it from working.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#fetch-all-required-information"&gt;
  &lt;/a&gt;
  Fetch all required information
&lt;/h2&gt;

&lt;p&gt;As described above, the View is a function mapping data to Html. However, this data is different from view to view of course. Since the data has to be fetched by the controller, the view defines a data structure which the controller needs to completely fetch the information for to render the view, which makes sure that no information is ever missing in the view, not even accidentally. And when some information is not necessary anymore, you can just remove it from the view data structure, which will cause compiler errors everywhere where you're still fetching it (where there could now be unnecessary code).&lt;/p&gt;

&lt;p&gt;To read more about how passing the data from controller actions to the view works, &lt;a href="https://ihp.digitallyinduced.com/Guide/controller.html#passing-data-from-the-action-to-the-view"&gt;read the documentation here&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#no-missing-information-for-links"&gt;
  &lt;/a&gt;
  No missing information for links
&lt;/h2&gt;

&lt;p&gt;When the user wants to interact with the website, they mainly do so via links. Usually links are simply strings, which means that if parameters are required but missing, this can only be detected via trial-and-error. Using IHP's &lt;code&gt;pathTo&lt;/code&gt; and &lt;code&gt;urlTo&lt;/code&gt; functions, you can build the links between pages of your application in a typesafe way, which means you're not going to forget to send new necessary information when an endpoint requires it, and will not forget to remove it when it's unnecessary anymore. Renaming is a non-issue as well, and typos are (again) compiler errors.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#ids-cannot-be-used-to-query-the-wrong-database-table"&gt;
  &lt;/a&gt;
  IDs cannot be used to query the wrong database table
&lt;/h2&gt;

&lt;p&gt;In IHP, IDs are (by default) UUIDs. But even if you use Integer-based IDs instead, you could run into a situation where you'd accidentally use a user-ID for querying a different table, and wouldn't be any wiser, since both are UUIDs. In IHP on the other hand, all IDs are wrapped once more, making the type of the ID &lt;code&gt;Id User&lt;/code&gt; for example. You then can't use this ID to for example fetch a product.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If for some obscure reason you still need to do this, or you get the ID as another type and need to convert it to this special type, that's of course possible.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This special type also allows the &lt;code&gt;fetch&lt;/code&gt; function that queries the database for a single row with the given ID to be super simple to call: since the ID already contains the information of which table it's for, you don't have to do any more work than passing the ID to the function, and it will take care of the rest.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#ensuring-proper-html"&gt;
  &lt;/a&gt;
  Ensuring proper HTML
&lt;/h2&gt;

&lt;p&gt;Views in IHP are written in Haskell, using something called HSX, which is the same basic idea as JSX in React. That means you write the HTML you would normally write, and can easily include dynamic Haskell code where needed.&lt;/p&gt;

&lt;p&gt;Since HSX is just syntactic sugar for other Haskell functions though, it is typesafe! That means you can't use attributes for elements where the spec doesn't allow for it, and many markup errors (like forgetting to close a tag) are caught at compile-time.&lt;/p&gt;

&lt;p&gt;If you need to use custom attributes, that's what &lt;code&gt;data-&lt;/code&gt; attributes are for, and they are fully supported. Just like custom web components.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Bonus:&lt;/em&gt; beginners in React often want to quickly output the content of some data they have, and try to just inline the variable in their JSX. They are then often surprised to see &lt;code&gt;[Object object]&lt;/code&gt;, since converting an object to a string in JS will lead to this result. In HSX, this will call &lt;code&gt;show&lt;/code&gt; on the provided data if possible, leading to the expected result.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#-raw-maybe-endraw-and-the-dreaded-raw-nullpointerexception-endraw-or-raw-typeerror-variable-is-undefined-endraw-"&gt;
  &lt;/a&gt;
  &lt;code&gt;Maybe&lt;/code&gt; and the dreaded &lt;code&gt;NullPointerException&lt;/code&gt; (or &lt;code&gt;TypeError: variable is undefined&lt;/code&gt;)
&lt;/h2&gt;

&lt;p&gt;While technically not IHP-exclusive, &lt;code&gt;null&lt;/code&gt; and &lt;code&gt;undefined&lt;/code&gt; do not exist in Haskell. Instead, if you need to represent something not being there, you can use &lt;code&gt;Nothing&lt;/code&gt;, which is a value for the &lt;code&gt;Maybe&lt;/code&gt; type. Using this, you can represent that something might not be there, which will force you to handle that case. But once you've handled that case, you don't have to handle it again - something that I've seen a lot in medium to larger codebases, where it's not always entirely clear where a value might come from.&lt;/p&gt;

&lt;p&gt;What this means in essence is that you will never get a &lt;code&gt;NullPointerException&lt;/code&gt; or a &lt;code&gt;TypeError: yourVariable is undefined&lt;/code&gt; when using IHP!&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#conclusion"&gt;
  &lt;/a&gt;
  Conclusion
&lt;/h2&gt;

&lt;p&gt;IHP makes as much use of Haskell's types as possible, leading to less bugs and an easier-to-grasp codebase that won't become legacy. If this article peaked your interest in IHP, &lt;a href="https://ihp.digitallyinduced.com/Guide/installation.html"&gt;you can get started using the Guide&lt;/a&gt;.&lt;/p&gt;

</description>
      <category>functional</category>
      <category>typescript</category>
      <category>haskell</category>
      <category>ihp</category>
    </item>
    <item>
      <title>Upcoming event: Live AMA with Jason &amp; Kishore, Typesense</title>
      <author>Amazer786</author>
      <pubDate>Wed, 04 Aug 2021 12:45:07 +0000</pubDate>
      <link>https://dev.to/amazer786/upcoming-event-live-ama-with-jason-kishore-typesense-2bki</link>
      <guid>https://dev.to/amazer786/upcoming-event-live-ama-with-jason-kishore-typesense-2bki</guid>
      <description>&lt;p&gt;Typesense is a modern, privacy-friendly, open-source search engine built from the ground up using cutting-edge search algorithms that take advantage of the latest advances in hardware capabilities.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why should you join?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1) Typesense is on a mission to democratize search with an Open Source, out-of-the-box, easier-to-use alternative to Algolia and Elastic search.&lt;/p&gt;

&lt;p&gt;2) Typesense is built specifically for decreasing the "time to market". It is a lightweight yet powerful &amp;amp; scalable alternative that focuses on Developer Happiness and Experience with a clean well-documented API, clear semantics and smart defaults.&lt;/p&gt;

&lt;p&gt;3) Typesense has been built from scratch to offer a delightful search experience with minimal effort using cutting-edge search algorithms that take advantage of the latest advances in hardware capabilities&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Let’s talk about Search engines, Open-Source and everything in between.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;✍ Join and ask all your questions in the comments&lt;/p&gt;

&lt;p&gt;Join Here 👉🏻 &lt;a href="https://bit.ly/3ypFE8s"&gt;https://bit.ly/3ypFE8s&lt;/a&gt; 👈🏻&lt;/p&gt;

&lt;p&gt;Save the date: 📆&lt;strong&gt;Friday, Aug 6th, 2021&lt;/strong&gt;  &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Part I&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;🚩Jason &amp;amp; Kishore, Maintainer, Typesense.Time-&lt;strong&gt;7 PM IST  (Asia)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Part II&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;🚩Jason &amp;amp; Kishore, Maintainer, Typesense.Time-&lt;strong&gt;7 PM PST (North America)&lt;/strong&gt;&lt;/p&gt;

</description>
    </item>
    <item>
      <title>10 GitHub repos based on HTML</title>
      <author>Pasca Vlad</author>
      <pubDate>Wed, 04 Aug 2021 12:21:05 +0000</pubDate>
      <link>https://dev.to/pascavld/10-github-repos-based-on-html-256n</link>
      <guid>https://dev.to/pascavld/10-github-repos-based-on-html-256n</guid>
      <description>&lt;p&gt;&lt;em&gt;If you found value in this thread you will most likely enjoy my tweets too so make sure you follow me on &lt;a href="https://twitter.com/VladPasca5"&gt;Twitter&lt;/a&gt;  for more information about web development and how to improve as a developer. This article was first published on my &lt;a href="https://vladpasca.hashnode.dev/"&gt;Blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#1-html5boilerplate"&gt;
  &lt;/a&gt;
  1. html5-boilerplate
&lt;/h3&gt;

&lt;p&gt;A professional front-end template for building fast, robust, and adaptable web apps or sites.&lt;/p&gt;

&lt;p&gt;🔗&lt;a href="https://github.com/h5bp/html5-boilerplate"&gt;https://github.com/h5bp/html5-boilerplate&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#2-html5reset"&gt;
  &lt;/a&gt;
  2. HTML5-Reset
&lt;/h3&gt;

&lt;p&gt;A simple set of best practices to get HTML5 projects off on the right foot.&lt;/p&gt;

&lt;p&gt;🔗&lt;a href="https://github.com/murtaugh/HTML5-Reset"&gt;https://github.com/murtaugh/HTML5-Reset&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#3-html5devicemockups"&gt;
  &lt;/a&gt;
  3. html5-device-mockups
&lt;/h3&gt;

&lt;p&gt;HTML5 mockups of popular devices, to showcase your portfolio and spice up your website.&lt;/p&gt;

&lt;p&gt;🔗&lt;a href="https://github.com/pixelsign/html5-device-mockups"&gt;https://github.com/pixelsign/html5-device-mockups&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#4-awesomehtml5"&gt;
  &lt;/a&gt;
  4. Awesome-html5
&lt;/h3&gt;

&lt;p&gt;A curated list of awesome HTML5 resource&lt;/p&gt;

&lt;p&gt;🔗&lt;a href="https://github.com/diegocard/awesome-html5"&gt;https://github.com/diegocard/awesome-html5&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#5-htmlminifier"&gt;
  &lt;/a&gt;
  5. html-minifier
&lt;/h3&gt;

&lt;p&gt;Javascript-based HTML compressor/minifier (with Node.js support)&lt;/p&gt;

&lt;p&gt;🔗&lt;a href="https://github.com/kangax/html-minifier"&gt;https://github.com/kangax/html-minifier&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#6-shower"&gt;
  &lt;/a&gt;
  6. shower
&lt;/h3&gt;

&lt;p&gt;Shower HTML presentation engine&lt;/p&gt;

&lt;p&gt;🔗&lt;a href="https://github.com/shower/shower"&gt;https://github.com/shower/shower&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#7-htmldom"&gt;
  &lt;/a&gt;
  7. html-dom
&lt;/h3&gt;

&lt;p&gt;Common tasks of managing HTML DOM with vanilla JavaScript.&lt;/p&gt;

&lt;p&gt;🔗&lt;a href="https://github.com/phuoc-ng/html-dom"&gt;https://github.com/phuoc-ng/html-dom&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#8-materialdesignlite"&gt;
  &lt;/a&gt;
  8. material-design-lite
&lt;/h3&gt;

&lt;p&gt;Material Design Components in HTML/CSS/JS&lt;/p&gt;

&lt;p&gt;🔗&lt;a href="https://github.com/google/material-design-lite"&gt;https://github.com/google/material-design-lite&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#9-tabler"&gt;
  &lt;/a&gt;
  9. tabler
&lt;/h3&gt;

&lt;p&gt;Tabler is free and open-source HTML Dashboard UI Kit built on Bootstrap&lt;/p&gt;

&lt;p&gt;🔗&lt;a href="https://github.com/tabler/tabler"&gt;https://github.com/tabler/tabler&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#10-framework7"&gt;
  &lt;/a&gt;
  10. framework7
&lt;/h3&gt;

&lt;p&gt;Full featured HTML framework for building iOS &amp;amp; Android apps&lt;/p&gt;

&lt;p&gt;🔗&lt;a href="https://github.com/framework7io/framework7"&gt;https://github.com/framework7io/framework7&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#the-end"&gt;
  &lt;/a&gt;
  The end
&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;I hope found this useful and if you did please let me know. If you have any question feel free to DM me on  &lt;a href="https://twitter.com/VladPasca5"&gt;Twitter&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

</description>
      <category>webdev</category>
      <category>programming</category>
      <category>codenewbie</category>
      <category>html</category>
    </item>
    <item>
      <title>Project Collaboration And Pair Programming</title>
      <author>Ayu Adiati</author>
      <pubDate>Wed, 04 Aug 2021 11:49:14 +0000</pubDate>
      <link>https://dev.to/adiatiayu/project-collaboration-and-pair-programming-4be6</link>
      <guid>https://dev.to/adiatiayu/project-collaboration-and-pair-programming-4be6</guid>
      <description>&lt;p&gt;Hello Fellow Codenewbies 👋,&lt;/p&gt;

&lt;p&gt;A bit of background, I am a self-taught front-end developer. &lt;br&gt;
In this article, I want to share my experience in project collaboration and pair programming.&lt;/p&gt;

&lt;p&gt;A while ago, I had a chance to collaborate in creating a project with vanilla Javascript.&lt;br&gt;
One of the approaches that we did to collaborate was pair programming.&lt;/p&gt;

&lt;p&gt;The first time I heard the term &lt;em&gt;pair programming&lt;/em&gt;, I imagined two (or more) developers learning the same topics together. &lt;br&gt;
But that wasn't it! 😅&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#pair-programming"&gt;
  &lt;/a&gt;
  Pair Programming
&lt;/h2&gt;

&lt;p&gt;So, what is pair programming?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Pair programming is an agile software development technique in which two programmers work together at one workstation. One, the &lt;strong&gt;driver&lt;/strong&gt;, writes code while the other, the &lt;strong&gt;observer&lt;/strong&gt; or &lt;strong&gt;navigator&lt;/strong&gt;, reviews each line of code as it is typed in. The two programmers switch roles frequently.&lt;br&gt;
-- &lt;a href="https://en.wikipedia.org/wiki/Pair_programming"&gt;Wikipedia&lt;/a&gt; &lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;
  &lt;a href="#first-experience-doing-pair-programming"&gt;
  &lt;/a&gt;
  First Experience Doing Pair Programming
&lt;/h2&gt;

&lt;p&gt;As a self-taught, I spent my time learning and coding solo. I solve problems and make decisions alone.&lt;br&gt;
So when I had the chance, I saw the team project as a good opportunity to learn to collaborate.&lt;/p&gt;

&lt;p&gt;As the first step, we had a meeting to decide on a project app that we would create and how this app would work in general.&lt;/p&gt;

&lt;p&gt;Next, we planned the features that we want for the app and started pair programming to create those features.&lt;br&gt;
So the pair programming journey began.&lt;/p&gt;

&lt;p&gt;In the first couple of sessions, I only observed how pair programming works to get a grip on it.&lt;br&gt;
But then, I got confused about what's going on and freaked out!&lt;/p&gt;

&lt;p&gt;Before the navigation, some of us were talking over the solutions. But those solutions were not what I would think of as my first approach. So I needed some time to digest them. When two or more people are having the same thoughts, the pace goes faster. That is exactly what happened. I didn't want to break the flow by asking questions or asking them to slow down. And while I was still trying to figure things out, the problems were solved. &lt;/p&gt;

&lt;p&gt;The confusion in trying to wrap my head around what's going on while having a somewhat fast pace was the thing that freaked me out. I faced the famous imposter syndrome until I did the next session a few weeks later.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#be-the-driver"&gt;
  &lt;/a&gt;
  Be The Driver
&lt;/h2&gt;

&lt;p&gt;Although I'm an introvert, I don't have trouble with general communication. But communicating codes and go through them with other people requires another skill. A skill that I'm sure everyone can get better at with practice.&lt;/p&gt;

&lt;p&gt;On the next session of pair programming, I got the opportunity to be the driver, the one who writes the code.&lt;br&gt;
This was when I finally learned so many things about pair programming and its benefits.&lt;/p&gt;

&lt;p&gt;As the driver, I need to listen to the navigators' instructions and type/write the codes in a good structure.&lt;br&gt;
There were times when the navigators were talking too fast. And there were also times when the given instructions were not too clear, or when I wasn't sure how to write the codes.&lt;br&gt;
When it happened, I &lt;em&gt;had&lt;/em&gt; to ask them to slow down, or repeat and give clearer instructions, or told them that I need a minute to google the syntax. These were necessary for me to write the codes.&lt;br&gt;
By listening, writing the codes, and asking questions, I started to understand what's going on and was able to follow the whole process.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#final-thoughts"&gt;
  &lt;/a&gt;
  Final Thoughts
&lt;/h2&gt;

&lt;p&gt;Pair programming gives many benefits. Some of them that I've experienced are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Learn to work in a team.&lt;/li&gt;
&lt;li&gt;With more heads solving the problems, the project is done faster.&lt;/li&gt;
&lt;li&gt;When people talking through solutions, we could gain new knowledge.&lt;/li&gt;
&lt;li&gt;Everyone learns to listen and communicate better as a team.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For self-taught developers, it would be a challenge to get this experience, but it's not impossible.&lt;br&gt;
Try to &lt;a href="https://dev.to/adiatiayu/networking-community-4kp3"&gt;find a community&lt;/a&gt; to open up a chance for you to collaborate on a project, and even for networking. &lt;br&gt;
If you're doing an online course on Udemy or any other platforms, you can try to find a study buddy and do pair programming from there.&lt;/p&gt;

&lt;p&gt;And if it is your first time, volunteering to be the driver could give you a better view of pair programming. Also, it's okay for you to ask questions or to ask other collaborators to slow down.&lt;/p&gt;

&lt;p&gt;It's completely normal if you feel confused or uncomfortable in your first sessions. Like other things, pair programming takes practice.&lt;br&gt;
Well, I'm still practicing myself 😊.&lt;/p&gt;




&lt;p&gt;Thank you for reading!&lt;br&gt;
Last but not least, you can find me on &lt;a href="https://twitter.com/AdiatiAyu"&gt;Twitter&lt;/a&gt;. Let's connect! 😊&lt;/p&gt;

</description>
      <category>webdev</category>
      <category>codenewbie</category>
      <category>watercooler</category>
      <category>productivity</category>
    </item>
    <item>
      <title>Webpack Academy #1: Loaders</title>
      <author>CodeOzz</author>
      <pubDate>Wed, 04 Aug 2021 10:50:47 +0000</pubDate>
      <link>https://dev.to/codeozz/webpack-academy-1-loaders-hf4</link>
      <guid>https://dev.to/codeozz/webpack-academy-1-loaders-hf4</guid>
      <description>&lt;p&gt;As we saw in the last course, webpack can handle &lt;code&gt;js&lt;/code&gt; and &lt;code&gt;json&lt;/code&gt; file !&lt;/p&gt;

&lt;p&gt;But what happened if we need to import css file ?&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#add-css-file"&gt;
  &lt;/a&gt;
  Add css file
&lt;/h3&gt;

&lt;p&gt;We need add a new entry point to your application since we have no entry file for css file yet !&lt;/p&gt;

&lt;p&gt;webpack.config.js&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;    &lt;span class="nx"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nl"&gt;myApp&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
            &lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;./src/style.css&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="s2"&gt;./src/main.js&lt;/span&gt;&lt;span class="dl"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;],&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;style.css&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight css"&gt;&lt;code&gt;&lt;span class="nc"&gt;.toto&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nl"&gt;color&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="no"&gt;blue&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Let's go to &lt;code&gt;build&lt;/code&gt; this !&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;ERROR in ./src/style.css 1:0
Module parse failed: Unexpected token (1:0)
You may need an appropriate loader to handle this file type, currently no loaders are configured to process this file. See https://webpack.js.org/concepts#loaders
&amp;gt; .toto {
|     color: blue;
| }
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;What? why?&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#loader"&gt;
  &lt;/a&gt;
  Loader
&lt;/h3&gt;

&lt;p&gt;As we saw before, webpack only handle &lt;code&gt;js&lt;/code&gt; and &lt;code&gt;json&lt;/code&gt; file, but webpack let us to use &lt;code&gt;loader&lt;/code&gt;, this function is simple -&amp;gt; translate file to webpack in order to handle it !&lt;/p&gt;

&lt;p&gt;For handle css file, we will use two loader !&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight javascript"&gt;&lt;code&gt;    &lt;span class="nx"&gt;module&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nl"&gt;rules&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="c1"&gt;// Match file extension&lt;/span&gt;
                &lt;span class="na"&gt;test&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="sr"&gt;/&lt;/span&gt;&lt;span class="se"&gt;\.&lt;/span&gt;&lt;span class="sr"&gt;css$/&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="c1"&gt;// Order of loader from bottom to up&lt;/span&gt;
                &lt;span class="na"&gt;use&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
                    &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;style-loader&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="dl"&gt;'&lt;/span&gt;&lt;span class="s1"&gt;css-loader&lt;/span&gt;&lt;span class="dl"&gt;'&lt;/span&gt;
                &lt;span class="p"&gt;],&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;First &lt;code&gt;css-loader&lt;/code&gt; will resolve css import issue, and after &lt;code&gt;style-loader&lt;/code&gt; will &lt;strong&gt;inject&lt;/strong&gt; css into the &lt;strong&gt;DOM&lt;/strong&gt; !&lt;/p&gt;

&lt;p&gt;So if we add a html file&lt;/p&gt;

&lt;p&gt;index.html&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight html"&gt;&lt;code&gt;&lt;span class="cp"&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;html&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;body&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;h1&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"toto"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;My First Heading&lt;span class="nt"&gt;&amp;lt;/h1&amp;gt;&lt;/span&gt;

    &lt;span class="nt"&gt;&amp;lt;p&amp;gt;&lt;/span&gt;My first paragraph.&lt;span class="nt"&gt;&amp;lt;/p&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;script &lt;/span&gt;&lt;span class="na"&gt;src=&lt;/span&gt;&lt;span class="s"&gt;"dist/bundle.js"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We can see that your &lt;code&gt;&amp;lt;h1&amp;gt;&lt;/code&gt; is blue !&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#conclusion"&gt;
  &lt;/a&gt;
  Conclusion
&lt;/h3&gt;

&lt;p&gt;It's just a little example but if you use webpack, you will have a lot of loader, for exemple if you are using &lt;code&gt;ts&lt;/code&gt; you will need loader to handle &lt;code&gt;.ts&lt;/code&gt; file, if we need to import image we will need another loader etc...&lt;/p&gt;

&lt;p&gt;Code here -&amp;gt; &lt;a href="https://github.com/Code-Oz/webpack-academy/tree/5e80e4c080c156d1ebd261fc80e3c505d92473a7"&gt;https://github.com/Code-Oz/webpack-academy/tree/5e80e4c080c156d1ebd261fc80e3c505d92473a7&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I hope you want to learn more about &lt;code&gt;webpack&lt;/code&gt; in my academy !&lt;/p&gt;

&lt;p&gt;If you want to have nice article to read about web dev, you can subscribe to my &lt;strong&gt;FREE newsletter&lt;/strong&gt; at this url -&amp;gt; &lt;a href="https://codeoz.substack.com/welcome"&gt;https://codeoz.substack.com/welcome&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And you can follow me on :&lt;/p&gt;

&lt;p&gt;Twitter : &lt;a href="https://twitter.com/code__oz"&gt;https://twitter.com/code__oz&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Github: &lt;a href="https://github.com/Code-Oz"&gt;https://github.com/Code-Oz&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And if you want to buy me a coffee :D -&amp;gt; &lt;a href="https://www.buymeacoffee.com/CodeoZ"&gt;https://www.buymeacoffee.com/CodeoZ&lt;/a&gt;&lt;/p&gt;

</description>
      <category>webpack</category>
      <category>webdev</category>
      <category>javascript</category>
      <category>css</category>
    </item>
    <item>
      <title>How to create a Skeleton Loader in Tailwindcss ?</title>
      <author>jobpick.in</author>
      <pubDate>Wed, 04 Aug 2021 10:37:47 +0000</pubDate>
      <link>https://dev.to/jobpick/how-to-create-a-skeleton-loader-in-tailwindcss-38gh</link>
      <guid>https://dev.to/jobpick/how-to-create-a-skeleton-loader-in-tailwindcss-38gh</guid>
      <description>&lt;p&gt;In this tutorial we are going to see how to make skeleton loaders in tailwind. Skeleton Loaders are used show the loading state. Many big websites such as youtube, linkedIn and even dev.to uses such loaders while loading the data!&lt;/p&gt;

&lt;p&gt;Here we are going to create a Loader Like below:&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--tcHcc6Xw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qeqx8swh96th3jo7g2ap.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--tcHcc6Xw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qeqx8swh96th3jo7g2ap.gif" alt="Skeleton loader example"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The simple code in html is below:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight html"&gt;&lt;code&gt;&lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"w-60 h-24 border-2 rounded-md mx-auto mt-20"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"flex animate-pulse flex-row items-center h-full justify-center space-x-5"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"w-12 bg-gray-300 h-12 rounded-full "&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"flex flex-col space-y-3"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"w-36 bg-gray-300 h-6 rounded-md "&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;"w-24 bg-gray-300 h-6 rounded-md "&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Here we have simply created a div with the border in which we have a 3 solid div. We have given the gray-300 color to those div.&lt;/p&gt;

&lt;p&gt;So far nothing Special!&lt;br&gt;
Wait but how to create that pulse effect 🤔? Do not worry we have tailwind thats it! In &lt;strong&gt;Tailwindcss&lt;/strong&gt; we have animation class called as &lt;strong&gt;animate-pulse&lt;/strong&gt; which give the effect we needed.&lt;/p&gt;

&lt;p&gt;Here is the &lt;a href="https://play.tailwindcss.com/UOqCq8WJme"&gt;tailwind playground&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Isn't it simple? If you find useful like and share😇.&lt;br&gt;
Any thoughts comment below👇.&lt;/p&gt;

&lt;p&gt;connnect us:&lt;br&gt;
Twitter : &lt;a href="https://twitter.com/job_pick"&gt;@job_pick&lt;/a&gt;&lt;br&gt;
Website : &lt;a href="https://jobpick.in/"&gt;jobpick.in&lt;/a&gt; - Frontend Developer Jobs Board&lt;/p&gt;

</description>
      <category>tailwindcss</category>
      <category>html</category>
      <category>css</category>
    </item>
    <item>
      <title>Writing logs into Elastic with NLog , ELK and .Net 5.0</title>
      <author>Majid Qafouri</author>
      <pubDate>Wed, 04 Aug 2021 10:25:58 +0000</pubDate>
      <link>https://dev.to/majidqafouri/writing-logs-into-elastic-with-nlog-elk-and-net-5-0-246c</link>
      <guid>https://dev.to/majidqafouri/writing-logs-into-elastic-with-nlog-elk-and-net-5-0-246c</guid>
      <description>&lt;p&gt;If you are using Microservice-based architecture, one of the challenges is to integrate and monitor application logs from different services and ability to search on this data based on message string or sources, etc&lt;/p&gt;

&lt;p&gt;So, what is the &lt;a href="https://www.elastic.co/what-is/elk-stack"&gt;ELK&lt;/a&gt; Stack? &lt;br&gt;
"ELK" is the acronym for three open source projects: &lt;strong&gt;Elasticsearch&lt;/strong&gt;, &lt;strong&gt;Logstash&lt;/strong&gt;, and Kibana. Elasticsearch is a search and analytics engine. Logstash is a server-side data processing pipeline that ingests data from multiple sources simultaneously, transforms it, and then sends it to a "stash" like Elasticsearch. &lt;a href="https://www.elastic.co/kibana/"&gt;Kibana&lt;/a&gt; lets users visualize data with charts and graphs in Elasticsearch.&lt;/p&gt;

&lt;p&gt;On the other hand, &lt;a href="https://nlog-project.org/"&gt;NLog&lt;/a&gt; is a flexible and free &lt;strong&gt;logging platform&lt;/strong&gt; for various .NET platforms, including .NET standard. NLog makes it easy to write to several targets. (&lt;strong&gt;database&lt;/strong&gt;, &lt;strong&gt;file&lt;/strong&gt;, &lt;strong&gt;console&lt;/strong&gt;) and change the logging configuration on-the-fly.&lt;/p&gt;

&lt;p&gt;If you combine these two powerful tools, you can get a good and easy way for processing and persisting your application's logs&lt;/p&gt;

&lt;p&gt;In this article, I'm going to use &lt;strong&gt;NLog&lt;/strong&gt; to write my &lt;strong&gt;.Net 5.0&lt;/strong&gt; web application logs into Elastic. after that, I will show you how you can monitor and search your logs with different filters by Kibana.&lt;/p&gt;

&lt;p&gt;First of all Open Visual Studio and select a new project (&lt;strong&gt;ASP.NET Core Web API&lt;/strong&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Ra9WWJl8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/kowygw86fo6sj1sanw3n.PNG" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Ra9WWJl8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/kowygw86fo6sj1sanw3n.PNG" alt="test"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;On the next page set the target framework on &lt;strong&gt;.Net 5.0(current)&lt;/strong&gt; and also check Enable &lt;strong&gt;OpenAPI support&lt;/strong&gt; option for using swagger in the project.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--keEwMTIr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bfjpzgoqajgh7fx1pbb6.PNG" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--keEwMTIr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bfjpzgoqajgh7fx1pbb6.PNG" alt="test"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We need some Nuget packages, In order to install them, from the &lt;strong&gt;Tools&lt;/strong&gt; menu select  &lt;strong&gt;Nuget Package Manager&lt;/strong&gt; and then select &lt;strong&gt;Manage Nuget packages for solutions&lt;/strong&gt;. &lt;br&gt;
In the opened panel search the below packages and install them one by one &lt;/p&gt;

&lt;p&gt;&lt;code&gt;NLog.Web.AspNetCore&lt;/code&gt;&lt;br&gt;
&lt;code&gt;NLog.Targets.ElasticSearch&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--i6ixxB04--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/lr03os5v5jdtpvxruffv.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i6ixxB04--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/lr03os5v5jdtpvxruffv.png" alt="test"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After you installed the packages, you need to add a config file for NLog. In order to add the file, right-click on the current project in the solution and select &lt;strong&gt;add&lt;/strong&gt; =&amp;gt; &lt;strong&gt;new Item&lt;/strong&gt;, then add a &lt;code&gt;web configuration&lt;/code&gt; file and name it &lt;code&gt;nlog.config&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--E78Djnxj--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/x88x7oaeqz1m0i3shish.PNG" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--E78Djnxj--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/x88x7oaeqz1m0i3shish.PNG" alt="test"&gt;&lt;/a&gt;&lt;br&gt;
Open the newly added file and paste the below codes&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight csharp"&gt;&lt;code&gt;&lt;span class="p"&gt;&amp;lt;?&lt;/span&gt;&lt;span class="n"&gt;xml&lt;/span&gt; &lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"1.0"&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"utf-8"&lt;/span&gt; &lt;span class="p"&gt;?&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;nlog&lt;/span&gt; &lt;span class="n"&gt;xmlns&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"http://www.nlog-project.org/schemas/NLog.xsd"&lt;/span&gt;
      &lt;span class="n"&gt;xmlns&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;xsi&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"http://www.w3.org/2001/XMLSchema-instance"&lt;/span&gt;
      &lt;span class="n"&gt;autoReload&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"true"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;

    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;extensions&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;add&lt;/span&gt; &lt;span class="n"&gt;assembly&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"NLog.Web.AspNetCore"&lt;/span&gt;&lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;add&lt;/span&gt; &lt;span class="n"&gt;assembly&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"NLog.Targets.ElasticSearch"&lt;/span&gt;&lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;extensions&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;


    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;targets&lt;/span&gt; &lt;span class="k"&gt;async&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"true"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;

        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"elastic"&lt;/span&gt; &lt;span class="n"&gt;xsi&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"ElasticSearch"&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;" MyServiceName-${date:format=yyyy.MM.dd}"&lt;/span&gt;
                &lt;span class="n"&gt;uri&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"http://localhost:9200"&lt;/span&gt;
                &lt;span class="n"&gt;layout&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"API:MyServiceName|${longdate}|${event-properties:item=EventId_Id}|${uppercase:${level}}|${logger}|${message} ${exception:format=tostring}|url: ${aspnet-request-url}|action: ${aspnet-mvc-action}"&lt;/span&gt; &lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;

    &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;targets&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;

    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;rules&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;logger&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"*"&lt;/span&gt; &lt;span class="n"&gt;minlevel&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"Debug"&lt;/span&gt; &lt;span class="n"&gt;writeTo&lt;/span&gt;&lt;span class="p"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"elastic"&lt;/span&gt; &lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;rules&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;nlog&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;In the target tag, we define our configuration like Elastic service URI, layout pattern, Elastic index name and etc.&lt;br&gt;
Let’s take a look at these tags and their attributes&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Index&lt;/strong&gt;: &lt;code&gt;MyServiceName -${date:format=yyyy.MM.dd}&lt;/code&gt;: it means we will have different index for every day’s log. For example, &lt;code&gt;MyServiceName-2021.08.03&lt;/code&gt; related to all the logs of the third of August  &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ElasticUri&lt;/strong&gt;:  Elastic URI address.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Layout&lt;/strong&gt;: your log message pattern, you can determine which information you want to have in the message of your log.&lt;/p&gt;

&lt;p&gt;In the &lt;strong&gt;rules&lt;/strong&gt; tag, the &lt;code&gt;minimum level&lt;/code&gt; for the writing log is defined.&lt;/p&gt;

&lt;p&gt;You can read more detail about nlog tag config  &lt;a href="https://github.com/NLog/NLog/wiki/Getting-started-with-ASP.NET-Core-5"&gt;Here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After we understand the structure and meaning of the config file, the next step is to set up NLog logger instead of &lt;strong&gt;.Net build-in logger&lt;/strong&gt;. To achieve this, Open &lt;strong&gt;program.cs&lt;/strong&gt; and change Main method like this&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight csharp"&gt;&lt;code&gt;&lt;span class="kt"&gt;var&lt;/span&gt; &lt;span class="n"&gt;logger&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NLogBuilder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;ConfigureNLog&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"nlog.config"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;GetCurrentClassLogger&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
            &lt;span class="k"&gt;try&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;Debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"init main"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
                &lt;span class="nf"&gt;CreateHostBuilder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;Build&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="nf"&gt;Run&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="k"&gt;catch&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Exception&lt;/span&gt; &lt;span class="n"&gt;exception&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;Error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;exception&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"Stopped program because of exception"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
                &lt;span class="k"&gt;throw&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="k"&gt;finally&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;NLog&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LogManager&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;Shutdown&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Change the &lt;strong&gt;CreateHostBuilder&lt;/strong&gt; in &lt;strong&gt;program.cs&lt;/strong&gt; as well:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight csharp"&gt;&lt;code&gt;&lt;span class="k"&gt;public&lt;/span&gt; &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="n"&gt;IHostBuilder&lt;/span&gt; &lt;span class="nf"&gt;CreateHostBuilder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt;
            &lt;span class="n"&gt;Host&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;CreateDefaultBuilder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;ConfigureWebHostDefaults&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;webBuilder&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt;
                &lt;span class="p"&gt;{&lt;/span&gt;
                    &lt;span class="n"&gt;webBuilder&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;UseStartup&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Startup&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;();&lt;/span&gt;
                &lt;span class="p"&gt;})&lt;/span&gt;
                &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;ConfigureLogging&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt; &lt;span class="p"&gt;=&amp;gt;&lt;/span&gt;
                &lt;span class="p"&gt;{&lt;/span&gt;
                    &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;ClearProviders&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
                    &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;SetMinimumLevel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LogLevel&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Trace&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
                &lt;span class="p"&gt;})&lt;/span&gt;
                &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;UseNLog&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;  &lt;span class="c1"&gt;// NLog: Setup NLog for Dependency injection&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;In the next step, open &lt;strong&gt;Startup.cs&lt;/strong&gt; and in the &lt;strong&gt;ConfigureService&lt;/strong&gt; method add below code&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight csharp"&gt;&lt;code&gt;&lt;span class="n"&gt;services&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;AddLogging&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now you are able to write your log into elastic with Injecting &lt;strong&gt;ILogger&lt;/strong&gt; in every class constructor.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight csharp"&gt;&lt;code&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ApiController&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nf"&gt;Route&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"[controller]"&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="k"&gt;public&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;WeatherForecastController&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ControllerBase&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;private&lt;/span&gt; &lt;span class="n"&gt;ILogger&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;WeatherForecastController&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;_logger&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

        &lt;span class="k"&gt;public&lt;/span&gt; &lt;span class="nf"&gt;WeatherForecastController&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ILogger&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;WeatherForecastController&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;_logger&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logger&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;

        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;HttpGet&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;public&lt;/span&gt; &lt;span class="n"&gt;IActionResult&lt;/span&gt; &lt;span class="nf"&gt;Get&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;   
            &lt;span class="n"&gt;_logger&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;LogDebug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Debug message"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
            &lt;span class="n"&gt;_logger&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;LogTrace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Trace message"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
            &lt;span class="n"&gt;_logger&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;LogError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Error message"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
            &lt;span class="n"&gt;_logger&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;LogWarning&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Warning message"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
            &lt;span class="n"&gt;_logger&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;LogCritical&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Critical message"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
            &lt;span class="n"&gt;_logger&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;LogInformation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Information message"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nf"&gt;Ok&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;From now on, If you run your application and send a request with Postman, all types of logs will be written into Elastic.&lt;/p&gt;

&lt;p&gt;Well, We successfully configured our application to write the logs into Elastic, but how we can monitor and search out logs. For this purpose, Elastic has Kibana as a tool that lets users visualize data with charts and graphs in Elasticsearch.&lt;br&gt;
After you install the Elastic, you can have access to &lt;a href="http://localhost:5601/app/kibana/"&gt;Kibana&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--9w7D3JrO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vwjhm515fy4fkyf8o1ja.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--9w7D3JrO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vwjhm515fy4fkyf8o1ja.png" alt="test"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;First of all, we should be able to create a pattern which our application's log will be fetched by that pattern. For doing this, select the &lt;code&gt;Management&lt;/code&gt; option in the left panel&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--3_zUqII---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/rarp5ql2qcvjbelqk7ml.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--3_zUqII---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/rarp5ql2qcvjbelqk7ml.png" alt="test"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the management panel select &lt;code&gt;Index Pattern&lt;/code&gt; link in the left side&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--8ArAL2nF--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/o6n8ogfb71lkaaoq1sp3.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--8ArAL2nF--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/o6n8ogfb71lkaaoq1sp3.png" alt="test"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the showed panel click on &lt;code&gt;Create index pattern&lt;/code&gt; button. You will see  &lt;code&gt;Create index pattern&lt;/code&gt; panel, there is an &lt;code&gt;Index pattern&lt;/code&gt; input box which you should input your &lt;code&gt;Index name&lt;/code&gt;(in our example we set the index name in the &lt;strong&gt;nlog.config&lt;/strong&gt; file like this &lt;code&gt;MyServiceName-${date:format=yyyy.MM.dd}&lt;/code&gt;.)&lt;br&gt;
If you want your pattern to include wild character instead of the date you should write down &lt;code&gt;myservicename-*&lt;/code&gt; in the input(it means we want to create a pattern that is able to load all logs with a prefix of &lt;code&gt;myservicename-&lt;/code&gt; ).&lt;/p&gt;

&lt;p&gt;If there were any logs with this pattern, a Success message will be shown beneath the input box. You can select the pattern and click on Next step.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--ClcYiccz--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qds6rn0dlrany5l6215g.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ClcYiccz--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qds6rn0dlrany5l6215g.png" alt="test"&gt;&lt;/a&gt;&lt;br&gt;
In the next panel, you can add a &lt;code&gt;Time filter&lt;/code&gt; to your pattern, which means you will be able to filter logs according to the insertion date. After you selected &lt;code&gt;@timestamp&lt;/code&gt;, click on &lt;code&gt;Create index pattern&lt;/code&gt; button to complete this process.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--mkFLXjyT--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/lsp8hbezchd2hngipz2h.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--mkFLXjyT--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/lsp8hbezchd2hngipz2h.png" alt="test"&gt;&lt;/a&gt;&lt;br&gt;
Now click on the &lt;code&gt;discover&lt;/code&gt; link on the left panel to redirect to the logged dashboard.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--JCLiRJeI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/w0lfdobxunpxvj38qaxj.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--JCLiRJeI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/w0lfdobxunpxvj38qaxj.png" alt="test"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As you see, we have several logs with different types related to our application. If you do not see any log, be sure that you have selected your newly defined pattern on the left side of the dashboard&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--kHqci7J0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1i5htvc6dulcr0qvede4.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--kHqci7J0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1i5htvc6dulcr0qvede4.png" alt="test"&gt;&lt;/a&gt;&lt;br&gt;
For filtering our logs according to the log message or insertion date you can use the filter bar located beneath the menu bar.&lt;/p&gt;

&lt;p&gt;For example, in this picture, I have search logs that contain &lt;strong&gt;critical&lt;/strong&gt; word in their log messages. &lt;br&gt;
After you set your filter click on the green &lt;code&gt;update&lt;/code&gt; button on the right side.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--qOYg2zSy--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/y4bn4mopn3e5741hh665.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--qOYg2zSy--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/y4bn4mopn3e5741hh665.png" alt="test"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;That’s it. Now you can easily filter your application's logs with different patterns. &lt;/p&gt;

&lt;p&gt;For more information about Kibana features you can use this &lt;a href="https://www.elastic.co/guide/en/kibana/current/get-started.html"&gt;link&lt;/a&gt;  &lt;/p&gt;

</description>
      <category>dotnet</category>
      <category>elasticsearch</category>
      <category>csharp</category>
      <category>logstash</category>
    </item>
    <item>
      <title>GitLab CI: Cache and Artifacts explained by example</title>
      <author>Anton Yakutovich</author>
      <pubDate>Wed, 04 Aug 2021 10:13:46 +0000</pubDate>
      <link>https://dev.to/drakulavich/gitlab-ci-cache-and-artifacts-explained-by-example-2opi</link>
      <guid>https://dev.to/drakulavich/gitlab-ci-cache-and-artifacts-explained-by-example-2opi</guid>
      <description>&lt;p&gt;Hi, DEV Community! I've been working in the software testing field for more than eight years. Apart from web services testing, I maintain CI/CD Pipelines in our team's GitLab.&lt;/p&gt;

&lt;p&gt;Let's discuss the difference between GitLab cache and artifacts. I'll show how to configure the Pipeline for the Node.js app in a pragmatic way to achieve good performance and resource utilization.&lt;/p&gt;

&lt;p&gt;There are three things you can watch forever: fire burning, water falling, and the build is passing after your next commit. Nobody wants to wait for the CI completion too much, it's better to set up all the tweaks to avoid long waiting between the commit the build status. Cache and artifacts to the rescue! They help reduce the time it takes to run a Pipeline drastically.&lt;/p&gt;

&lt;p&gt;People are confused when they have to choose between cache and artifacts. GitLab has bright documentation, but &lt;a href="https://docs.gitlab.com/ee/ci/caching/#cache-nodejs-dependencies"&gt;the Node.js app with cache example&lt;/a&gt; and the Pipeline &lt;a href="https://gitlab.com/gitlab-org/gitlab/-/blob/master/lib/gitlab/ci/templates/Nodejs.gitlab-ci.yml"&gt;template for Node.js&lt;/a&gt; contradict each other.&lt;/p&gt;

&lt;p&gt;Let's see what the Pipeline in GitLab terms means. The &lt;a href="https://docs.gitlab.com/ee/ci/pipelines/pipeline_architectures.html"&gt;Pipeline&lt;/a&gt; is a set of stages and each stage can have one or more jobs. Jobs work on a distributed farm of runners. When we start a Pipeline, a random runner with free resources executes the needed job. The GitLab-runner is the agent that can run jobs. For simplicity, let's consider Docker as an executor for all runners.&lt;/p&gt;

&lt;p&gt;Each job starts with a clean slate and doesn't know the results of the previous one. If you don't use cache and artifacts, the runner will have to go to the internet or local registry and download the necessary packages when installing project dependencies.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#what-is-cache"&gt;
  &lt;/a&gt;
  What is cache?
&lt;/h3&gt;

&lt;p&gt;It's a set of files that a job can download before running and upload after execution. By default, the cache is stored in the same place where GitLab Runner is installed. If the distributed cache is configured, S3 works as storage.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Et1ysp_Y--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/az3xa3hssyj8q12s6fiw.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Et1ysp_Y--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/az3xa3hssyj8q12s6fiw.png" alt="GitLab Cache"&gt;&lt;/a&gt;&lt;br&gt;
Let's suppose you run a Pipeline for the first time with a local cache. The job will not find the cache but will upload one after the execution to runner01. The second job will execute on runner02, it won't find the cache on it either and will work without it. The result will be saved to runner02. Lint, the third job, will find the cache on runner01 and use it (pull). After execution, it will upload the cache back (push).&lt;/p&gt;
&lt;h3&gt;
  &lt;a href="#what-are-artifacts"&gt;
  &lt;/a&gt;
  What are artifacts?
&lt;/h3&gt;

&lt;p&gt;Artifacts are files stored on the GitLab server after a job is executed. Subsequent jobs will download the artifact before script execution.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s---Bx07U40--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pappaj15pbvty5z7k38q.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s---Bx07U40--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pappaj15pbvty5z7k38q.png" alt="GitLab artifacts"&gt;&lt;/a&gt;&lt;br&gt;
Build job creates a DEF artifact and saves it on the server. The second job, Test, downloads the artifact from the server before running the commands. The third job, Lint, similarly downloads the artifact from the server. &lt;/p&gt;

&lt;p&gt;To compare the artifact is created in the first job and is used in the following ones. The cache is created within each job.&lt;/p&gt;

&lt;p&gt;Consider the CI template example for Node.js recommended by GitLab:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;image: node:latest # (1)

# This folder is cached between builds
cache:
  paths:
    - node_modules/ # (2)

test_async:
  script:
    - npm install # (3)
    - node ./specs/start.js ./specs/async.spec.js

test_db:
  script:
    - npm install # (4)
    - node ./specs/start.js ./specs/db-postgres.spec.js
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Line #1 specifies the docker image, which will be used in all jobs. The first problem is the &lt;code&gt;latest&lt;/code&gt; tag. This tag ruins the reproducibility of the builds. It always points to the latest release of Node.js. If the GitLab runner caches docker images, the first run will download the image, and all subsequent runs will use the locally available image. So, even if a node is upgraded from version XX to YY, our Pipeline will know nothing about it. Therefore, I suggest specifying the version of the image. And not just the release branch (&lt;code&gt;node:14&lt;/code&gt;), but the full version tag (&lt;code&gt;node:14.2.5&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Line #2 is related to lines 3 and 4. The &lt;code&gt;node_modules&lt;/code&gt; directory is specified for caching, the installation of packages (npm install) is performed for every job. The installation should be faster because packages are available inside &lt;code&gt;node_modules&lt;/code&gt;. Since no key is specified for the cache, the word &lt;code&gt;default&lt;/code&gt; will be used as a key. It means that the cache will be permanent, shared between all git branches.&lt;/p&gt;

&lt;p&gt;Let me remind you, the main goal is to keep the pipeline &lt;em&gt;reproducible&lt;/em&gt;. &lt;strong&gt;The Pipeline launched today should work the same way in a year&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;NPM stores dependencies in two files — &lt;em&gt;package.json&lt;/em&gt; and &lt;em&gt;package-lock.json&lt;/em&gt;. If you use &lt;em&gt;package.json&lt;/em&gt;, the build is not reproducible. When you run &lt;code&gt;npm install&lt;/code&gt; the package manager puts the last minor release for not strict dependencies. To fix the dependency tree, we use the &lt;em&gt;package-lock.json&lt;/em&gt; file. All versions of packages are strictly specified there.&lt;/p&gt;

&lt;p&gt;But there is another problem, &lt;code&gt;npm install&lt;/code&gt; rewrites package-lock.json, and this is not what we expect. Therefore, we use the special command &lt;code&gt;npm ci&lt;/code&gt; which:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;removes the node_modules directory;&lt;/li&gt;
&lt;li&gt;installs packages from package-lock.json.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What shall we do if &lt;code&gt;node_modules&lt;/code&gt; will be deleted every time? We can specify NPM cache using the environment variable &lt;code&gt;npm_config_cache&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;And the last thing, the config does not explicitly specify the stage where jobs are executed. By default, the job runs inside the test stage. It turns out that both jobs will run in parallel. Perfect! Let's add jobs stages and fix all the issues we found.&lt;/p&gt;

&lt;p&gt;What we got after the first iteration:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;image: node: 16.3.0 # (1)

stages:
  - test

variables:
  npm_config_cache: "$CI_PROJECT_DIR/.npm" (5)

# This folder is cached between builds
cache:
  key:
    files:
      - package-lock.json (6)
  paths:
    - .npm # (2)

test_async:
  stage: test
  script:
    - npm ci # (3)
    - node ./specs/start.js ./specs/async.spec.js

test_db:
  stage: test
  script:
    - npm ci # (4)
    - node ./specs/start.js ./specs/db-postgres.spec.js
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We improved Pipeline and make it reproducible. There are two drawbacks left. First, the cache is shared. Every job will pull the cache and push the new version after executing the job. It's a good practice to update cache only once inside Pipeline. Second, every job installs the package dependencies and wastes time.&lt;/p&gt;

&lt;p&gt;To fix the first problem we describe the cache management explicitly. Let's add a "hidden" job and enable only pull policy (download cache without updating):&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# Define a hidden job to be used with extends
# Better than default to avoid activating cache for all jobs
.dependencies_cache:
  cache:
    key:
      files:
        - package-lock.json
    paths:
      - .npm
    policy: pull
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;To connect the cache you need to inherit the job via &lt;code&gt;extends&lt;/code&gt; keyword.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;...
extends: .dependencies_cache
...
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;To fix the second issue we use artifacts. Let's create the job that archives package dependencies and passes the artifact with &lt;code&gt;node_modules&lt;/code&gt; further. Subsequent jobs will run tests from the spot.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;setup:
  stage: setup
  script:
    - npm ci
  extends: .dependencies_cache
  cache:
    policy: pull-push
  artifacts:
    expire_in: 1h
    paths:
      - node_modules
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We install the npm dependencies and use the cache described in the hidden dependencies_cache job. Then we specify how to update the cache via a pull-push policy. A short lifetime (1 hour) helps to save space for the artifacts. There is no need to keep &lt;code&gt;node_modules&lt;/code&gt; artifact for a long time on the GitLab server.&lt;/p&gt;

&lt;p&gt;The full config after the changes:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;image: node: 16.3.0 # (1)

stages:
  - setup
  - test

variables:
  npm_config_cache: "$CI_PROJECT_DIR/.npm" (5)

# Define a hidden job to be used with extends
# Better than default to avoid activating cache for all jobs
.dependencies_cache:
  cache:
    key:
      files:
        - package-lock.json
    paths:
      - .npm
    policy: pull

setup:
  stage: setup
  script:
    - npm ci
  extends: .dependencies_cache
  cache:
    policy: pull-push
  artifacts:
    expire_in: 1h
    paths:
      - node_modules

test_async:
  stage: test
  script:
    - node ./specs/start.js ./specs/async.spec.js

test_db:
  stage: test
  script:
    - node ./specs/start.js ./specs/db-postgres.spec.js
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;We learned what's the difference between cache and artifacts. We built a reproducible Pipeline that works predictably and uses resources efficiently. This article shows some common mistakes and how to avoid them when you are setting up CI in GitLab.&lt;br&gt;
I wish you green builds and fast pipelines. Would appreciate your feedback in the comments!&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#links"&gt;
  &lt;/a&gt;
  Links
&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://docs.gitlab.com/ee/ci/pipelines/pipeline_architectures.html"&gt;Pipeline architecture&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://docs.gitlab.com/ee/ci/caching/"&gt;Caching in GitLab CI/CD&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

</description>
      <category>devops</category>
      <category>node</category>
      <category>cicd</category>
      <category>gitlab</category>
    </item>
    <item>
      <title>The C Roguelike Tutorial - Part 0: The Setup</title>
      <author>Ignacio Oyarzabal</author>
      <pubDate>Wed, 04 Aug 2021 09:29:31 +0000</pubDate>
      <link>https://dev.to/ignaoya/the-c-roguelike-tutorial-part-0-the-setup-1pfo</link>
      <guid>https://dev.to/ignaoya/the-c-roguelike-tutorial-part-0-the-setup-1pfo</guid>
      <description>&lt;h2&gt;
  &lt;a href="#intro"&gt;
  &lt;/a&gt;
  Intro
&lt;/h2&gt;

&lt;p&gt;This tutorial will teach you the basics of how to make a classic retro roguelike game entirely in C using the Ncurses library. By the end of the tutorial you will have built a simple ASCII roguelike that will feature procedurally generated dungeons, increasing enemy difficulty, leveling up, equipment, spells, and a final boss at level 10 to give you a sense of closure.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#requirements"&gt;
  &lt;/a&gt;
  Requirements
&lt;/h2&gt;

&lt;p&gt;The tutorial assumes a basic knowledge of C or similar languages. If you've never programmed before you might be able to follow along with the code, but it will be difficult for you to actually understand what you're doing. If that is the case I would recommend choosing a book from &lt;a href="https://stackoverflow.com/questions/562303/the-definitive-c-book-guide-and-list"&gt;The Definitive C Book Guide&lt;/a&gt; over at StackOverflow to read up on the basics of C programming. I will be explaining some of the logic and decisions behind the code presented, but I won't go into the very basics of coding in C. &lt;/p&gt;

&lt;p&gt;In order to follow along with the code you will need to have a C compiler such as GCC(Linux) or MinGW(Windows), and the ncurses library. Let's take a brief look at those now.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#c-compiler-and-ncurses"&gt;
  &lt;/a&gt;
  C Compiler and Ncurses
&lt;/h2&gt;

&lt;h3&gt;
  &lt;a href="#-linux"&gt;
  &lt;/a&gt;
  - Linux
&lt;/h3&gt;

&lt;p&gt;If you are working on a Linux machine chances are you already have GCC installed, which is the GNU Compiler Collection. Use the following command in your terminal to verify it:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;$ gcc --version
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;If you get something like &lt;code&gt;bash: gcc: command not found&lt;/code&gt;, you will have to install it yourself. If you are using Ubuntu or one of its derivatives the following commands will install GCC and a few other necessary programs:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;$ sudo apt update
$ sudo apt install build-essential
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;After this, try again the first command to verify that you have gcc installed.&lt;/p&gt;

&lt;p&gt;Now that gcc is installed, use the following command to install ncurses:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;$ sudo apt install libncurses5-dev libncursesw5-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now you should be setup with GCC and Ncurses. At the bottom of the chapter we'll go through a small program to verify that everything's working properly.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#-windows"&gt;
  &lt;/a&gt;
  - Windows
&lt;/h3&gt;

&lt;p&gt;Ncurses is a Unix/Linux-based library meant for use in unix-like terminals, but for Windows you can use the alternative PDcurses, which is the Public Domain curses port.&lt;/p&gt;

&lt;p&gt;Windows doesn't come preinstalled with a C compiler so you will have to install your own. I suggest installing MinGW, which is the Windows port of GCC, as it has a simple installer that allows you to install the PDcurses library at the same time. The easiest way to do it is by downloading the MinGW installer from &lt;a href="https://sourceforge.net/projects/mingw/files/Installer/mingw-get-setup.exe/download"&gt;SourceForge&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Choose the default folder location for the installation. In the installation manager you will reach a step where you can choose which packages to install; mark the boxes on all of the options from the 'Basic Setup' tab, there should be seven of them. Then go to the 'All Packages' tab and mark all of the following for installation:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;mingw32-libncurses (dll)&lt;/li&gt;
&lt;li&gt;mingw32-libncurses (dev)&lt;/li&gt;
&lt;li&gt;mingw32-libpdcurses (dll)&lt;/li&gt;
&lt;li&gt;mingw32-libpdcurses (dev)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After these are selected go to 'Installation'-&amp;gt; 'Apply Changes'  and click &lt;code&gt;Apply&lt;/code&gt; to continue with the installation. &lt;/p&gt;

&lt;p&gt;Once the installation is finished you need to add the path to MinGW\bin to your PATH environment variable. In the Windows start bar search for &lt;code&gt;Edit environment variables for your account&lt;/code&gt;. Edit the PATH variable and click on 'New' to add a new path. If you installed it in the default location, the folder path should be &lt;code&gt;C:\MinGW\bin&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You should now have MinGW installed in your system. To verify it, open the Windows Command Prompt and type:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;$ gcc --version
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;h3&gt;
  &lt;a href="#-macos"&gt;
  &lt;/a&gt;
  - MacOS
&lt;/h3&gt;

&lt;p&gt;Unfortunately I don't have a Mac system to try this on, so I can only provide what I've read online without personal validation of its effectiveness. From what I've read, you should be able to use Homebrew to install both GCC and Ncurses on Mac:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;$ brew install gcc
$ brew install ncurses
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Hope that works for you or at least gets you started. This is the only mention I will do in this tutorial about how to do things in MacOS. I think you can still follow along with most of what I do here since MacOS is a UNIX-family OS and its command line works fairly similar to the Linux command line.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#testing-gcc-and-ncurses"&gt;
  &lt;/a&gt;
  Testing GCC and Ncurses
&lt;/h2&gt;

&lt;p&gt;In order to verify that everything is working we'll make a short program to validate our setup. Create a folder where you want to start your project and open a new file in your editor of choice. Call the file &lt;code&gt;main.c&lt;/code&gt; and put the following code in it:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight c"&gt;&lt;code&gt;&lt;span class="cp"&gt;#include &amp;lt;ncurses.h&amp;gt;
&lt;/span&gt;
&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;initscr&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
  &lt;span class="n"&gt;endwin&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;If you are using Windows, you will have to replace the first line to include the curses.h file instead of the ncurses.h file, like so:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight diff"&gt;&lt;code&gt;&lt;span class="gd"&gt;-#include &amp;lt;ncurses.h&amp;gt;
&lt;/span&gt;&lt;span class="gi"&gt;+#include &amp;lt;curses.h&amp;gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This change and a similarly small replacement in our makefile will be the only differences in the code for Windows. Apart from this minor change in the include statement, everything else in the code will be the same on any machine.&lt;/p&gt;

&lt;p&gt;I will explain &lt;code&gt;initscr()&lt;/code&gt; and &lt;code&gt;endwin()&lt;/code&gt; in the next part of this tutorial. For now, simply compile the file to verify that the compiler is able to include the header correctly.&lt;/p&gt;

&lt;p&gt;On Linux&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;$ gcc main.c -lncurses
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;On Windows&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;$ gcc main.c -lpdcurses
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;If you do not get any error messages you should now have either an &lt;code&gt;a.out&lt;/code&gt; file in Linux or an &lt;code&gt;a.exe&lt;/code&gt; file in Windows. The &lt;code&gt;-lncurses&lt;/code&gt; and &lt;code&gt;-lpdcurses&lt;/code&gt; options used above ask the compiler to link the ncurses or the pdcurses libraries respectively. You can try running the program, which will close immediately after starting. &lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#other-resources"&gt;
  &lt;/a&gt;
  Other Resources
&lt;/h2&gt;

&lt;p&gt;If you want to learn more about Ncurses you can click &lt;a href="https://invisible-island.net/ncurses/announce.html"&gt;here&lt;/a&gt; or check out this &lt;a href="https://tldp.org/HOWTO/NCURSES-Programming-HOWTO/"&gt;Programming How-To&lt;/a&gt; If you ever need help with anything roguelike related you can go to the &lt;a href="https://www.reddit.com/r/roguelikedev/"&gt;Roguelike Dev Subreddit&lt;/a&gt; which is a very welcoming community exclusively for roguelike developers!&lt;/p&gt;

&lt;p&gt;Now you're all set to start coding! See you on Part 1!&lt;/p&gt;

</description>
      <category>c</category>
      <category>gamedev</category>
      <category>tutorial</category>
      <category>roguelike</category>
    </item>
  </channel>
</rss>
