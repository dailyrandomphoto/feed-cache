<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>DEV Community</title>
    <author>DEV Community</author>
    <description>A constructive and inclusive social network for software developers. With you every step of your journey.</description>
    <link>https://dev.to</link>
    <language>en</language>
    <item>
      <title>How To Choose The Right Frontend Framework</title>
      <author>Eddy Vinck</author>
      <pubDate>Sat, 11 Sep 2021 14:55:06 +0000</pubDate>
      <link>https://dev.to/eddyvinck/how-to-choose-the-right-frontend-framework-1ben</link>
      <guid>https://dev.to/eddyvinck/how-to-choose-the-right-frontend-framework-1ben</guid>
      <description>&lt;p&gt;Should you learn React, Vue, Angular? Or is something like Svelte a better choice?&lt;/p&gt;

&lt;p&gt;This question plagues many frontend developers looking to break into the industry.&lt;/p&gt;

&lt;p&gt;I've seen this question asked and answered hundreds of times online.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#most-of-the-advice-on-social-media-is-not-very-helpful"&gt;
  &lt;/a&gt;
  Most of the advice on social media is not very helpful
&lt;/h2&gt;

&lt;p&gt;That's a pretty bold claim, but hear me out: the advice is not helpful because it most likely does not apply to your circumstances.&lt;/p&gt;

&lt;p&gt;When people are comparing frameworks, they are often comparing one of the following things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Amount of GitHub stars&lt;/li&gt;
&lt;li&gt;Amount of NPM downloads&lt;/li&gt;
&lt;li&gt;Amount of code required to build something&lt;/li&gt;
&lt;li&gt;Performance&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It's pretty much always one of those things. Or people are just advocating for their favorite framework.&lt;/p&gt;

&lt;p&gt;Those comparisons are all valid and can help you make a decision, but in my opinion there is a better way to tackle this question.&lt;/p&gt;

&lt;p&gt;The area where most of the popularity comparisons fall flat, however, is that there is not a single one framework that is the most popular in every part of the world. Whereas in some areas it could be React, in other areas it might be Vue (or any other framework).&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#finding-out-what-framework-to-learn"&gt;
  &lt;/a&gt;
  Finding out what framework to learn
&lt;/h2&gt;

&lt;p&gt;You should choose a framework that aligns with your goals. &lt;/p&gt;

&lt;p&gt;Chances are that if you are reading this article you are an aspiring or entry-level developer. &lt;/p&gt;

&lt;p&gt;If that is the case, then wouldn't it make more sense to choose the frontend framework that will most likely get you a job? I'm assuming that is why you are reading this in the first place.&lt;/p&gt;

&lt;p&gt;So how do we find out what framework will get you a job?&lt;/p&gt;

&lt;p&gt;Simple: You need to find out what companies are hiring for. You have to do market research.&lt;/p&gt;

&lt;p&gt;The easiest way would be to look at job posts for companies in your area. &lt;/p&gt;

&lt;p&gt;You can do this by going to websites like &lt;a href="https://indeed.com"&gt;Indeed&lt;/a&gt; or your local equivalent. &lt;/p&gt;

&lt;p&gt;Some companies don't hire via websites like that though, so I would advise you to also look at the individual websites of companies in your area or the area where you would like to work.&lt;/p&gt;

&lt;p&gt;If companies in your area are organising Meetups / developer networking events via &lt;a href="https://meetup.com"&gt;meetup.com&lt;/a&gt; or other platforms that would also be a great way to find out what you should learn.&lt;/p&gt;

&lt;p&gt;After doing this research you should take some time to think about what companies you would like to work for. Then learn the framework that is most commonly used amongst those companies.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#you-can-learn-more-than-one-framework"&gt;
  &lt;/a&gt;
  You can learn more than one framework
&lt;/h2&gt;

&lt;p&gt;Maybe after doing your market research you come to the conclusion that companies aren't hiring for the framework you would really like to learn.&lt;/p&gt;

&lt;p&gt;My advice would be to still learn the framework that is most desired by those potential employers. Build some projects. Get a job. Get real world experience. &lt;/p&gt;

&lt;p&gt;You can always learn other frameworks once you have gotten your foot in the door.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#what-companies-to-apply-for"&gt;
  &lt;/a&gt;
  What companies to apply for?
&lt;/h2&gt;

&lt;p&gt;I recently wrote an article called &lt;a href="https://dev.to/eddyvinck/transform-your-career-and-personal-life-finding-a-great-job-nh2"&gt;Transform Your Career And Personal Life: Finding A Great Job&lt;/a&gt; that could help.&lt;/p&gt;

&lt;p&gt;I also am writing an eBook about this subject. It's called &lt;a href="https://eddyvinck.gumroad.com/l/developer-job-searching"&gt;Developer Job Searching: The Not So Technical Parts&lt;/a&gt;. Right now you can get it for 40% off. It releases September 21st.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://eddyvinck.gumroad.com/l/developer-job-searching"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--5o_0TiQy--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uc0nj21luz8k06c8h5iz.png" alt="Link to the eBook"&gt;&lt;/a&gt;&lt;br&gt;
Click 👆 for more information&lt;/p&gt;

</description>
      <category>javascript</category>
      <category>beginners</category>
      <category>career</category>
      <category>webdev</category>
    </item>
    <item>
      <title>What is Open Source Debt? And How to repay it?</title>
      <author>Rajvir Singh</author>
      <pubDate>Sat, 11 Sep 2021 14:26:40 +0000</pubDate>
      <link>https://dev.to/byteslash/what-is-open-source-debt-and-how-to-repay-it-4a46</link>
      <guid>https://dev.to/byteslash/what-is-open-source-debt-and-how-to-repay-it-4a46</guid>
      <description>&lt;p&gt;If you are a developer, then I would say you're in debt to unknown people. Don't worry it is good debt and there's nothing to be worried about whilst you repay it. But, yea, it is a never-ending one.&lt;/p&gt;

&lt;p&gt;Let me explain&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#what-is-open-source"&gt;
  &lt;/a&gt;
  What is Open Source
&lt;/h1&gt;

&lt;p&gt;First of all, what is open source?, and I would assume you know it. But if you are getting into this new world of programming so for that, here's the explanation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Open-source software is computer software that is released under a license in which the copyright holder grants users the rights to use, study, change, and distribute the software and its source code to anyone and for any purpose. Open-source software may be developed in a collaborative public manner.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--QKUGYKb5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://c.tenor.com/smOFBj4VakkAAAAC/spongebob-rainbow-open-source-opensource-linux.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--QKUGYKb5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://c.tenor.com/smOFBj4VakkAAAAC/spongebob-rainbow-open-source-opensource-linux.gif" alt=""&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Those were the first lines I could find when searching for open source.&lt;br&gt;
So now you know what open source is so let's talk about the good never-ending debt you are in.&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#what-is-open-source-debt"&gt;
  &lt;/a&gt;
  What is Open Source Debt?
&lt;/h1&gt;

&lt;p&gt;Let me break this down into few pieces&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#why-do-people-create-things-for-free"&gt;
  &lt;/a&gt;
  Why do people create things for free?
&lt;/h2&gt;

&lt;p&gt;Open source is all about accessibility for everyone, with ease.&lt;/p&gt;

&lt;p&gt;I am good with examples so let me show one example of me. &lt;br&gt;
I am working on this project named &lt;a href="https://github.com/RajvirSingh1313/elecrue"&gt;Elecrue&lt;/a&gt;. I started this project and made it public for two reasons, I created it for my own because I was looking for a good starter code for electron-react in js but I didn't found one so I created one myself, the second I wanted to repay my open-source debt as &lt;a href="https://github.com/facebook/react"&gt;React&lt;/a&gt;, &lt;a href="https://github.com/electron/electron"&gt;Electron&lt;/a&gt;, &lt;a href="https://github.com/vuejs/vue"&gt;Vue&lt;/a&gt; is open source. And the third and bit selfish one, Is that I wanted to beef up my resume.&lt;/p&gt;

&lt;p&gt;By doing so, I helped a lot of other developers who were having the same problem, now they can use it to create other things to make more amazing things open source, like &lt;a href="https://github.com/yyx990803"&gt;Evan You&lt;/a&gt; did by creating &lt;a href="https://github.com/vuejs/vue"&gt;Vue&lt;/a&gt; open-source, and now hundreds of hundreds of developers and companies use it to create more amazing things. In this great loop, everyone makes their contributions.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#how-to-repay-open-source-debt"&gt;
  &lt;/a&gt;
  How to repay Open Source Debt?
&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--XInq67bI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://c.tenor.com/vqtfwk0H9VgAAAAC/im-finally-gonna-be-able-to-pay-off-all-the-money-i-owe-stan.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--XInq67bI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://c.tenor.com/vqtfwk0H9VgAAAAC/im-finally-gonna-be-able-to-pay-off-all-the-money-i-owe-stan.gif" alt=""&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now you understood the debt, now let's talk about the ways you can repay it.&lt;br&gt;
There are many ways of repaying this debt, let's talk about some that are most common ways&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you want someone to give you something good then you need to give something good too&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;By writing quality code for a problem and then sharing it&lt;/strong&gt;:-&lt;br&gt;
As the statement itself explains, You should just do like me or Evan You, write a code for a problem or a fun project that you think will both make your resume good and will help someone&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;By Educating others&lt;/strong&gt;:-&lt;br&gt;
Another way is to educate others. There are many ways to do this, Like creating tutorials on youtube, writing blogs, or making Github repositories for storing and sharing learning material like &lt;a href="https://github.com/microsoft/IoT-For-Beginners"&gt;IoT Course from Microsoft&lt;/a&gt; (which I am learning IoT from).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;By Helping Others&lt;/strong&gt;:-&lt;br&gt;
Open Source is all about helping each other, so if you happened to find any bug in your favorite library or framework, then create an issue on its repository. If you have a solution for that bug, make a pull request on it. By doing so you are helping yourself and others, And it will add a big pulse to your resume.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;By Sponsoring the creator or project&lt;/strong&gt;:-&lt;br&gt;
I used Evan You as an example a lot of times to let's use him as the last example too. If you have seen his &lt;a href="https://github.com/yyx990803"&gt;Github profile&lt;/a&gt; and &lt;a href="https://github.com/vuejs/vue"&gt;Vue Github Page&lt;/a&gt; then you would have noticed that there is an option to sponsor a project or the developer, it means you can pay the developer or the project via Github to backup developer. As the project grows large like Vue it needs a lot of maintenance so often developers don't have the time or energy to maintain the project as there is a lot of work and time they need to pour in. So the people or the companies who uses the project, pays the developer a small amount so the developer keep maintaining the project&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;As October is coming up, there is a month-long celebration called &lt;a href="https://hacktoberfest.digitalocean.com/"&gt;Hacktoberfest&lt;/a&gt;, to promote open source. I think it is a good way to remember to repay your open-source debt. To learn about it more check out their website:-  &lt;a href="https://hacktoberfest.digitalocean.com/"&gt;https://hacktoberfest.digitalocean.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;That's it, I hope I explained well this great debt that never ends for good, If you liked it then share this article, If not then don't forget to give me feedback so I can improve myself.&lt;/p&gt;

&lt;p&gt;Have a good day,&lt;br&gt;
Rajvir Singh&lt;/p&gt;

</description>
      <category>hacktoberfest</category>
      <category>opensource</category>
      <category>opensourcedebt</category>
    </item>
    <item>
      <title>AWSSDK.CloudFormation (for AWS CloudFormation)</title>
      <author>Ahmed Adel</author>
      <pubDate>Sat, 11 Sep 2021 14:26:31 +0000</pubDate>
      <link>https://dev.to/ahmedadel/awssdk-cloudformation-o16</link>
      <guid>https://dev.to/ahmedadel/awssdk-cloudformation-o16</guid>
      <description>&lt;p&gt;✦ The Fourth SDK we are going to talk about is &lt;code&gt;AWSSDK.CloudFormation&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;First of all, let's have a brief about &lt;code&gt;Amazon CloudFormation&lt;/code&gt; in AWS...&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#%E2%9E%BDwhat-is-amazon-cloudformation"&gt;
  &lt;/a&gt;
  ➽What is Amazon CloudFormation?
&lt;/h1&gt;

&lt;p&gt;☞ &lt;code&gt;AWS CloudFormation&lt;/code&gt; is a service that helps you model and set up your &lt;strong&gt;AWS resources&lt;/strong&gt; so that you can spend less time managing those resources and more time focusing on your applications that run in AWS. &lt;br&gt;
☞ You create a template that describes all the AWS resources that you want (like &lt;code&gt;Amazon EC2&lt;/code&gt; instances or &lt;code&gt;Amazon RDS&lt;/code&gt; DB instances), and &lt;code&gt;CloudFormation&lt;/code&gt; takes care of provisioning and configuring those resources for you.&lt;br&gt;
☞ You don't need to individually create and configure AWS resources and figure out what's dependent on what; &lt;code&gt;CloudFormation&lt;/code&gt; handles that.&lt;br&gt;
☞ Read more about &lt;a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html"&gt;Amazon CloudFormation&lt;/a&gt;&lt;/p&gt;


&lt;h1&gt;
  &lt;a href="#%E2%9E%BDinstalling-awssdkcloudformation-"&gt;
  &lt;/a&gt;
  ➽Installing AWSSDK.CloudFormation :
&lt;/h1&gt;

&lt;p&gt;☞&lt;code&gt;AWSSDK.CloudFormation&lt;/code&gt; is installed mainly from &lt;a href="https://www.nuget.org/"&gt;Nuget&lt;/a&gt;&lt;br&gt;
☞There is 3 ways to install &lt;code&gt;AWSSDK.CloudFormation&lt;/code&gt;, they are the same as installing &lt;code&gt;AWSSDK.S3&lt;/code&gt; from &lt;a href="https://dev.to/ahmedadel/aws-sdks-for-net-1-awssdk-s3-5e36"&gt;Part 1 of this series&lt;/a&gt;&lt;br&gt;
☞let's use the easiest one, from Package Manager Console by using the Install-Package command.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight csharp"&gt;&lt;code&gt;&lt;span class="n"&gt;PM&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Install&lt;/span&gt;&lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Package&lt;/span&gt; &lt;span class="n"&gt;AWSSDK&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CloudFormation&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;






&lt;p&gt;🌟 Second step is to connect to our AWS account using __ Access keys (Access Key ID and Secret Access Key)__, this was explained before briefly in the &lt;a href="https://dev.to/ahmedadel/aws-sdks-for-net-1-awssdk-s3-5e36#%E2%9E%BDso-how-can-we-use-it-"&gt;first article under (Get AWS Access keys) &lt;/a&gt;&lt;/p&gt;




&lt;p&gt;✦ The AWS SDK for .NET provides APIs for &lt;code&gt;AWS CloudFormation&lt;/code&gt; clients. The APIs enable you to work with &lt;code&gt;AWS CloudFormation&lt;/code&gt; features such as &lt;strong&gt;templates&lt;/strong&gt; and &lt;strong&gt;stacks&lt;/strong&gt;.&lt;br&gt;
✦ The example uses the low-level API. The application takes no arguments, but simply gathers information for all stacks that are accessible to the user's credentials and then displays information&lt;br&gt;
about those stacks.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight csharp"&gt;&lt;code&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="nn"&gt;System&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="nn"&gt;System.Threading.Tasks&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="nn"&gt;Amazon.CloudFormation&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="nn"&gt;Amazon.CloudFormation.Model&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;namespace&lt;/span&gt; &lt;span class="nn"&gt;CFNListResources&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Program&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="n"&gt;Task&lt;/span&gt; &lt;span class="nf"&gt;Main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="c1"&gt;// Create the CloudFormation client&lt;/span&gt;
            &lt;span class="kt"&gt;var&lt;/span&gt; &lt;span class="n"&gt;cfnClient&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nf"&gt;AmazonCloudFormationClient&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;

            &lt;span class="c1"&gt;// List the resources for each stack&lt;/span&gt;
            &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="nf"&gt;ListResources&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cfnClient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;cfnClient&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;DescribeStacksAsync&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;

        &lt;span class="c1"&gt;//&lt;/span&gt;
        &lt;span class="c1"&gt;// Method to list stack resources and other information&lt;/span&gt;
        &lt;span class="k"&gt;private&lt;/span&gt; &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="n"&gt;Task&lt;/span&gt; &lt;span class="nf"&gt;ListResources&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
          &lt;span class="n"&gt;IAmazonCloudFormation&lt;/span&gt; &lt;span class="n"&gt;cfnClient&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DescribeStacksResponse&lt;/span&gt; &lt;span class="n"&gt;responseDescribeStacks&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;Console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Getting CloudFormation stack information..."&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

            &lt;span class="k"&gt;foreach&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Stack&lt;/span&gt; &lt;span class="n"&gt;stack&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;responseDescribeStacks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Stacks&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="c1"&gt;// Basic information for each stack&lt;/span&gt;
                &lt;span class="n"&gt;Console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"\n------------------------------------------------"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
                &lt;span class="n"&gt;Console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;$"\nStack: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;StackName&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
                &lt;span class="n"&gt;Console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;$"  Status: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;StackStatus&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
                &lt;span class="n"&gt;Console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;$"  Created: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CreationTime&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

                &lt;span class="c1"&gt;// The tags of each stack (etc.)&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Tags&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Count&lt;/span&gt; &lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="p"&gt;{&lt;/span&gt;
                    &lt;span class="n"&gt;Console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"  Tags:"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
                    &lt;span class="k"&gt;foreach&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Tag&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Tags&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                        &lt;span class="n"&gt;Console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;$"    &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Key&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s"&gt;, &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
                &lt;span class="p"&gt;}&lt;/span&gt;

                &lt;span class="c1"&gt;// The resources of each stack&lt;/span&gt;
                &lt;span class="n"&gt;DescribeStackResourcesResponse&lt;/span&gt; &lt;span class="n"&gt;responseDescribeResources&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt;
                  &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;cfnClient&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;DescribeStackResourcesAsync&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="n"&gt;DescribeStackResourcesRequest&lt;/span&gt;
                  &lt;span class="p"&gt;{&lt;/span&gt;
                      &lt;span class="n"&gt;StackName&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;StackName&lt;/span&gt;
                  &lt;span class="p"&gt;});&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;responseDescribeResources&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;StackResources&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Count&lt;/span&gt; &lt;span class="p"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="p"&gt;{&lt;/span&gt;
                    &lt;span class="n"&gt;Console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"  Resources:"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
                    &lt;span class="k"&gt;foreach&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;StackResource&lt;/span&gt; &lt;span class="n"&gt;resource&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="n"&gt;responseDescribeResources&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;StackResources&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                        &lt;span class="n"&gt;Console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;$"    &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;resource&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LogicalResourceId&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s"&gt;: &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;resource&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ResourceStatus&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
                &lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="p"&gt;}&lt;/span&gt;
            &lt;span class="n"&gt;Console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;WriteLine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"\n------------------------------------------------"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt; &lt;a href="https://docs.aws.amazon.com/index.html"&gt;AWS official Documentation&lt;/a&gt;&lt;/p&gt;

</description>
      <category>dotnet</category>
      <category>cloud</category>
      <category>aws</category>
      <category>csharp</category>
    </item>
    <item>
      <title>What are OAuth 2.0 and OIDC (OpenID Connect)? Step By Step Authorization Code Flow With Endpoints</title>
      <author>Engincan VESKE</author>
      <pubDate>Sat, 11 Sep 2021 14:20:24 +0000</pubDate>
      <link>https://dev.to/engincanv/what-are-oauth-2-0-and-oidc-openid-connect-with-endpoints-25kd</link>
      <guid>https://dev.to/engincanv/what-are-oauth-2-0-and-oidc-openid-connect-with-endpoints-25kd</guid>
      <description>&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;In this article, I would like to talk about OAuth 2.0, which is used as a protocol (industry standard) for &lt;strong&gt;Authorization&lt;/strong&gt; and OIDC (OpenID Connect) which is a top layer of the OAuth 2.0 and used for &lt;strong&gt;Authentication&lt;/strong&gt;.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#what-are-oauth-20-and-oidc-what-are-they-used-for"&gt;
  &lt;/a&gt;
  What are OAuth 2.0 and OIDC? What are they used for?
&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;OAuth 2.0 and OIDC are industry standards used for &lt;strong&gt;Authorization&lt;/strong&gt; and &lt;strong&gt;Authentication&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Every day we use mobile or web applications for our works. Defining username and password for each application, getting harder at some point. Some "password management" applications come into place etc.&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#history"&gt;
  &lt;/a&gt;
  History
&lt;/h3&gt;

&lt;p&gt;In 2005 Brad Fitzpatrick developed an authentication protocol to remove these difficulties.&lt;/p&gt;

&lt;p&gt;The main purpose of this protocol was to enable users to define user credentials to a central system/application (for example, Google) and to enable other applications using this protocol to perform relevant transactions using only the necessary information of the users. And this was done through certificates.&lt;/p&gt;

&lt;p&gt;This developed protocol was not an open protocol, and at the same time, it was making the related transactions through certificates. &lt;strong&gt;OAuth Discussion Group&lt;/strong&gt; which was created in 2007, started to create an open authorization protocol. In December 2007, the OAuth protocol was openly made available as v1.0 and in October 2012 it was finalized as &lt;strong&gt;OAuth 2.0&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In this way, OAuth 2.0 was filled the missing &lt;strong&gt;Authorization&lt;/strong&gt; part of the OpenID protocol with a &lt;strong&gt;token based&lt;/strong&gt; structure. Instead of certificates, identity-related transactions started to do with tokens.&lt;/p&gt;

&lt;p&gt;Then, in 2004 an identity layer called OIDC (OpenID Connect) developed on the OAuth 2.0 Framework was added and thus Authentication processes were defined within a standard.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#oauth-20-structure"&gt;
  &lt;/a&gt;
  OAuth 2.0 Structure
&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--V59oyzjP--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/cayd6nrh8g3gmubr5k9t.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--V59oyzjP--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/cayd6nrh8g3gmubr5k9t.png" alt="OAuth 2.0 Structure"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the above picture, you can see the base structure of OAuth 2.0. &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;In the most basic sense, when we as a user (&lt;strong&gt;Resource Owner&lt;/strong&gt;) want to access our own data, we enter the relevant website (&lt;strong&gt;Client&lt;/strong&gt;) and send a request to the relevant URL. The relevant website communicates with the &lt;strong&gt;Authorization Server&lt;/strong&gt; to query whether we have access to that resource. As a result, the relevant server indicates that we have authorization. We reach the information we want to access as a result that returned by the &lt;strong&gt;Resource Server&lt;/strong&gt;. &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;The &lt;strong&gt;Resource Owner&lt;/strong&gt;, &lt;strong&gt;Client&lt;/strong&gt;, &lt;strong&gt;Authorization Server&lt;/strong&gt;, and &lt;strong&gt;Resource Server&lt;/strong&gt; are defined as Roles in OAuth 2.0 protocol. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;OAuth 2.0 offers different types of &lt;strong&gt;Authorization Flows&lt;/strong&gt; according to different usage conditions and these flows are named as follows. 

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Authorization Code Flow&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Implicit Flow&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Resource Owner Password Credential Flow&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Client Credential Flow&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Authorization Code Flow is used in &lt;strong&gt;Server Side&lt;/strong&gt; applications and Implicit Flow is used in &lt;strong&gt;Browser Based (SPA's)&lt;/strong&gt; applications.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In these flows, although the basic logic is the same (authorization, token exchange, etc.), the number of steps and methods applied are different. As an example, let's examine the frequently used &lt;strong&gt;Authorization Code Flow&lt;/strong&gt; together with the related endpoints. &lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#example-oauth-20-authorization-code-flow"&gt;
  &lt;/a&gt;
  Example: OAuth 2.0 - Authorization Code Flow
&lt;/h3&gt;

&lt;p&gt;We can examine this flow in 4 steps:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1-) Authorization Request&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--v_LIXl1k--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fbot8wl9vxiik0h7xkgf.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--v_LIXl1k--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fbot8wl9vxiik0h7xkgf.png" alt="Authorization Request"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If we examine the related request, we can see that we passed a query parameter named &lt;strong&gt;"client_id"&lt;/strong&gt;. This "client_id" represents our application defined within the OAuth 2.0 protocol. In other word, it's a value that identifies the relevant application. The &lt;strong&gt;"scope"&lt;/strong&gt; parameter specifies the scope of the relevant authorization. In other words, the user is only allowed to see the relevant information in the &lt;code&gt;resource&lt;/code&gt; and &lt;code&gt;profile&lt;/code&gt; scope above. User can't access any other part of the application (e.g. delete contact) by using the generated token. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;"Redirect_uri" represents the URL where the application we are using will get and use the relevant token.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The most important parameter here, the &lt;strong&gt;"response_type"&lt;/strong&gt; parameter, shows which flow the request will be made with. (&lt;strong&gt;“code”&lt;/strong&gt; for Authorization Code Flow) &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2-) Authorization Response&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;After the &lt;strong&gt;Authorization Server&lt;/strong&gt; ensure that the relevant request is valid and in the correct format as well, it sends a GET request with the &lt;strong&gt;Authorization Code&lt;/strong&gt; to the relevant callback url (redirect_uri) specified in the request.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--_KHm2EyC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9utr5ezo8mvsuwcipei4.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--_KHm2EyC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9utr5ezo8mvsuwcipei4.png" alt="Authorization Response"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3-) Token Request&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;After obtaining the &lt;strong&gt;Authorization Code&lt;/strong&gt;, a token request is made by using the relevant Authorization Code to obtain a &lt;strong&gt;Access Token&lt;/strong&gt;. (Token exchange =&amp;gt; Authorization Code ↔ Access Token)&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--IaOF8xFQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0g0iw4m44d15gj0hkj8p.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--IaOF8xFQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0g0iw4m44d15gj0hkj8p.png" alt="Token Request"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;As can be seen in this request, &lt;strong&gt;Authorization Code&lt;/strong&gt; is specified as the &lt;code&gt;grant_type&lt;/code&gt; and if this request is successful Authorization Server redirects us to the route specified in the "redirect_uri" parameter.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;4-) Token Response&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If the "Token Request" we made in the third step is successful, a similar response returns as below and can be used by the &lt;strong&gt;Client&lt;/strong&gt; (the application we want to use).&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--CH9UxgoT--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/imhuzmrsphbbvgd6hp80.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--CH9UxgoT--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/imhuzmrsphbbvgd6hp80.png" alt="Token Response"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Now, with this "access_token" the user can access its own data from &lt;strong&gt;Resource Server&lt;/strong&gt; through the &lt;strong&gt;Client&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Here, if the "refresh_token" is also returned as a result of the request, when the "access_token" expires, a request can be made to renew the related "access_token" with this token. &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;
  &lt;a href="#oidc-openid-connect-structure"&gt;
  &lt;/a&gt;
  OIDC (OpenID Connect) Structure
&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Xzp6JFKB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qvyqpzisvvnlhhkg92lk.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Xzp6JFKB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qvyqpzisvvnlhhkg92lk.png" alt="OIDC"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Simple &lt;strong&gt;identity layer&lt;/strong&gt; on top of the OAuth 2.0 protocol.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;OpenID Connect can be thought of as an &lt;strong&gt;identity layer&lt;/strong&gt; added on top of the OAuth 2.0 protocol to enable the OAuth 2.0 protocol to be used for &lt;strong&gt;Authentication&lt;/strong&gt;. &lt;/p&gt;

&lt;p&gt;OpenID Connect contains a meta-data document (&lt;strong&gt;.well-known/openid-configuration&lt;/strong&gt;) that defines the information required to login through an application. (Which urls should be used, which scopes it contains, etc.) &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you want to view the relevant metadata document as an example, you can access the Microsoft's OIDC metadata document by navigating to &lt;a href="https://login.microsoftonline.com/common/v2.0/.well-known/openid-configuration"&gt;https://login.microsoftonline.com/common/v2.0/.well-known/openid-configuration&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As in OAuth 2.0, transactions are performed using flows in OIDC. As an example, let's examine the endpoints of &lt;strong&gt;Authorization Code Flow&lt;/strong&gt; for OIDC as in OAuth 2.0. &lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#example-oauth-20-authorization-code-flow"&gt;
  &lt;/a&gt;
  Example: OAuth 2.0 - Authorization Code Flow
&lt;/h3&gt;

&lt;p&gt;We can examine this flow in 6 steps:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1-) Authentication Request&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--pf7GXyzP--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bd5fed5c8evacmvhzhg1.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--pf7GXyzP--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bd5fed5c8evacmvhzhg1.png" alt="Authentication Request"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If we examine the related endpoint, we can see that a value called &lt;strong&gt;openid&lt;/strong&gt; is passed in the scope section. We can actually think of this as the equivalent of the identity layer concept we used when defining OIDC. With this scope added to the OAuth 2.0 protocol, Authorization Server now handles the relevant request within the scope of OIDC. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2-) Authentication Response&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--0QxUpz3h--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9t05qw2399ydpwhx9i4u.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--0QxUpz3h--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9t05qw2399ydpwhx9i4u.png" alt="Authentication Response"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Here, as in OAuth 2.0, a &lt;strong&gt;GET&lt;/strong&gt; request is sent to the callback-url (redirect-uri) with the &lt;code&gt;Authorization Code&lt;/code&gt;. In this way, the Client becomes aware of the relevant authorization code. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3-) Token Request&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--2Ja-8G-W--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/5sw7xwsqiqipdozgj40u.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--2Ja-8G-W--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/5sw7xwsqiqipdozgj40u.png" alt="Token Request"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Then, the relevant Client requests a token from the Authorization Server with the "authorization_code" it has obtained. (Token exchange =&amp;gt; Authorization Code ↔ Access Token)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;4-) Token Response&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--OdL-bo8E--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hsicgbg5j8qv8ids1nis.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--OdL-bo8E--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hsicgbg5j8qv8ids1nis.png" alt="Token Response"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If we examine the response we can see the "id_token" section.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;ID_Token&lt;/strong&gt;: It can be thought of as an identity card. Contains information about the end user. It is in JWT format. It can be thought of as the add-on that OIDC brings to OAuth 2.0. In this way, the Authentication process can happen. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--QprdJd90--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ty2f6ljvlut5on8psgrz.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--QprdJd90--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ty2f6ljvlut5on8psgrz.png" alt="ID_Token"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5-) UserInfo Request - Obtaining End User's Information&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--wrIeRimM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/w7aidu01ih0ghab6f4hy.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--wrIeRimM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/w7aidu01ih0ghab6f4hy.png" alt="UserInfo Request"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The UserInfo endpoint returns information about the logged in user (name, surname, etc.). When the client needs the information of the relevant user, he can obtain the necessary information by using this endpoint. (Note that the relevant user is now authenticated and a request is made to the endpoint using the Bearer Authorization.) &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;6-) UserInfo Response&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--vG95h6Rt--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8u3o5pkngv1g7m5dz6g8.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--vG95h6Rt--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8u3o5pkngv1g7m5dz6g8.png" alt="UserInfo Response"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If the request that we made in the previous step is successful, the user's information receives. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;As another method, the user's relevant information can be accessed by decoding the previously generated "Id_Token" value. &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;




&lt;p&gt;Thanks for reading this article, I hope you've enjoyed it. See you in the next article...&lt;/p&gt;

</description>
      <category>oauth2</category>
      <category>authorization</category>
      <category>authentication</category>
      <category>identity</category>
    </item>
    <item>
      <title>GTM - Ferramenta oficial de features temporárias que viverão para sempre.</title>
      <author>Gregory Russo</author>
      <pubDate>Sat, 11 Sep 2021 13:53:36 +0000</pubDate>
      <link>https://dev.to/gregoryjvrusso/gtm-ferramenta-oficial-de-features-temporarias-que-viverao-para-sempre-3c88</link>
      <guid>https://dev.to/gregoryjvrusso/gtm-ferramenta-oficial-de-features-temporarias-que-viverao-para-sempre-3c88</guid>
      <description>&lt;p&gt;No dia a dia de um time de desenvolvimento, a pressão para a implementação de uma feature ou principalmente a correção de um bug é gigantesca e realmente explicável, mas essa pressão acaba nos levando a tomar decisões que a longo prazo podem onerar muito a performance do site.&lt;/p&gt;

&lt;p&gt;Se você precisa ter em mãos os dados de sua página, provavelmente você utiliza a dupla: Google Analytics (GA) e o Google Tag Manager (GTM). Aqui não estarei tão focado em explicar as suas funções, neste &lt;a href="https://www.alura.com.br/artigos/google-analytics-e-google-tag-manager"&gt;artigo da Alura&lt;/a&gt;, temos uma explicação clara sobre a função e importância de cada um. Minha intenção é conseguir te ajudar a argumentar com seu PO sobre o porquê priorizar a soluções definitivas o mais rápido possível sempre que o GTM for utilizado da maneira errada.&lt;/p&gt;

&lt;p&gt;O GTM implementa uma série de tags na nossa página, isso é, blocos de código, com essa facilidade, a área de marketing tem uma ferramenta fácil e rápida para integrar scripts de terceiros na página, manipular cookies ou implementar trackings do GA, porém, junto disso, trazemos a possibilidade de alterar o front-end do nosso site em produção, tornando-se a ferramenta oficial para features temporárias que viverão para sempre no seu site.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#qual-o-problema-com-o-gtm"&gt;
  &lt;/a&gt;
  Qual o problema com o GTM?
&lt;/h2&gt;

&lt;p&gt;O GTM nos traz a possibilidade de implementarmos HTML na página, incluindo a tag &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;, isso é, podemos rodar qualquer código Javascript, manipulando qualquer elemento do DOM. &lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--kczXgs4o--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/gw7stkm3mi42hh2lomzu.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--kczXgs4o--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/gw7stkm3mi42hh2lomzu.png" alt="Imagem de uma tag da ferramenta Google Tag Manager"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Porém, sabemos que muitas vezes criar uma feature dentro do fluxo comum de deploy é custoso, algumas empresas passam por processos de aprovação de GMUD’s, podendo levar até dias para que um deploy esteja de fato no ar, nesse momento, ferramentas como o GTM se tornam tentadoras.&lt;/p&gt;

&lt;p&gt;É lógico que, dentro desse cenário citado, caso aconteça um deploy que gere um bug em produção, a busca por uma solução rápida faz todo sentido, não estou aqui para julgar e criticar quem pensa em resolver, antes de qualquer outra coisa, minha crítica é quando não realizamos a priorização dessa correção no código fonte de maneira imediata. &lt;/p&gt;

&lt;p&gt;O script do GTM é implementado no código fonte da sua página, quando se inicia o carregamento do seu site no navegador, uma requisição é realizada para a sua API que responde todas as tags que serão implementadas na sua página, incluindo as suas gambiarras. Apesar da ferramenta até possui um sistema de gatilho para que uma tag seja disparada apenas no momento desejado, por exemplo, podendo definir que uma tag carregue apenas em uma URL específica, porém, independentemente se essa tag será disparada, o seu código é retornado pela API, aumentando o tamanho dessa resposta e carregando mais conteúdo que o necessário.&lt;/p&gt;

&lt;p&gt;De maneira simplória, quanto mais tag criada tivemos no GTM, maior o tamanho do retorno do script, consequentemente, mais lento será o carregamento da sua página.&lt;/p&gt;

&lt;p&gt;Por conta desse carregamento ser feito no navegador, caso você realize uma manipulação no DOM para alterar um elemento HTML, por exemplo, corre o risco que o usuário veja essa mudança acontecendo, gerando um efeito indesejado na página. A grosso modo, o fluxo funcionaria mais ou menos assim: o servidor devolveria o código fonte da sua página com o seu elemento HTML já montado, posteriormente o script do GTM é acionado, realizando uma chamada para a API e aguardando seu retorno, após essa resposta acontecer, as tags serão carregadas uma a uma na sua página e aí sim, sendo disparadas, somente nesse momento que a sua gambiarra aparecerá de fato.&lt;/p&gt;

&lt;p&gt;A minha intenção, caro leitor, é instigar o time de desenvolvedores para que sempre que uma mudança desse tipo seja realizada no GTM, logo, seja priorizada para corrigir em definitivo e excluir a gambiarra nessa ferramenta, que apesar de muito fácil, pode gerar grandes problemas a longo prazo se não for gerenciada da maneira certa.&lt;/p&gt;

&lt;p&gt;E você, qual sua experiência com o GTM? Muita gambiarra implementada nele? Me diga nos comentários.&lt;/p&gt;

</description>
      <category>performance</category>
      <category>javascript</category>
      <category>gtm</category>
      <category>tagmanager</category>
    </item>
    <item>
      <title>Cyber Security Tools</title>
      <author>Ketan Patil</author>
      <pubDate>Sat, 11 Sep 2021 13:21:14 +0000</pubDate>
      <link>https://dev.to/ketan_patil/cyber-security-tools-4d17</link>
      <guid>https://dev.to/ketan_patil/cyber-security-tools-4d17</guid>
      <description>&lt;p&gt;It is very important to protect systems againts various cyber attacks. There are number of cyber attacks happening on the internet everyday. It is essential for every organization to keep IT environment secure, for that variouse important cyber security tools are used to ensure the security of orgnaization. Out of which 20 most commonly used tools are as follow:&lt;/p&gt;

&lt;h3&gt;
  &lt;a href="#1-wireshark"&gt;
  &lt;/a&gt;
  1. &lt;a href="https://www.wireshark.org/"&gt;Wireshark&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;Wireshark is a open source software which is use to monitor network traffic in real-time. It efficiently captures data packets and tries to display that packet data as detailed as possible. &lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Free software&lt;/li&gt;
&lt;li&gt;Available for multiple platforms – Windows &amp;amp; UNIX&lt;/li&gt;
&lt;li&gt;Can see detailed information about packets within a network&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#2-nmap"&gt;
  &lt;/a&gt;
  2. &lt;a href="https://nmap.org/"&gt;Nmap&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;Nmap is open source free tool which IP packets to determine what hosts are available on the network, Services that are enabled, Operating systems and version of the hosts and many other aspects of network. &lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Free and open source&lt;/li&gt;
&lt;li&gt;Powerful: capable to scan huge network &lt;/li&gt;
&lt;li&gt;Portable: Most operating systems are supported, including Linux, Microsoft Windows&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#3-kali-linux"&gt;
  &lt;/a&gt;
  3. &lt;a href="https://www.kali.org/"&gt;Kali Linux&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;It is the excellent penetration testing tool use by many organizations. This contains various security tools used for security auditing. Some of these tools are executable while some are command line based. &lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Advanced Penetration Testing tools&lt;/li&gt;
&lt;li&gt;Open sourced&lt;/li&gt;
&lt;li&gt;provide more security &amp;amp; Stability&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#4-john-the-ripper"&gt;
  &lt;/a&gt;
  4. &lt;a href="https://www.openwall.com/john/"&gt;John the Ripper&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;This tool is used for testing password strength. This tool can quickly look for complex ciphers, encrypted logins, hash-type passwords and identify weak passwords. &lt;a href="https://www.varonis.com/blog/john-the-ripper/"&gt;Download and setup guide&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Automates hash generation&lt;/li&gt;
&lt;li&gt;Makes it easier to run brute-force &lt;/li&gt;
&lt;li&gt;Automates work with sessions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#5-xerxes"&gt;
  &lt;/a&gt;
  5. &lt;a href="https://github.com/XCHADXFAQ77X/XERXES"&gt;Xerxes&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;Xerxes is the most powerful DOS tool.It provides the capacity to launch multiple independent attacks against several target sites without necessarily requiring a botnet.&lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TLS Support&lt;/li&gt;
&lt;li&gt;Multiprocessing support&lt;/li&gt;
&lt;li&gt;Multiple Attack vectors&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#6-keepass"&gt;
  &lt;/a&gt;
  6. &lt;a href="https://keepass.info/"&gt;KeePass&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;KeePass is a free open source password manager, which helps you to manage your passwords in a secure way. You can store all your passwords in one database, which is locked with a master key. So you only have to remember one single master key to unlock the whole database. Database files are encrypted using the best and most secure encryption algorithms like AES-256.&lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Your information is protected by a very high level of encryption.&lt;/li&gt;
&lt;li&gt;You only have to remember one master password.&lt;/li&gt;
&lt;li&gt;You can use this single password to unlock a database that contains all your stored passwords.&lt;/li&gt;
&lt;li&gt;You can organize passwords into groups.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#7-vipre"&gt;
  &lt;/a&gt;
  7. &lt;a href="https://www.vipre.com/"&gt;VIPRE&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;VIPRE is one of the most widely used cyber security tools used to protect computers from malicious attacks, malware, and spam messages with no hassle. It helps to stay safe against new cyber threats and crimes.&lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It is quite effective against all kinds of viruses and provides 360-degree protection.&lt;/li&gt;
&lt;li&gt;Its scanning action is quite fast and less time taking.&lt;/li&gt;
&lt;li&gt;It has the ability to scan emails too, from viruses.&lt;/li&gt;
&lt;li&gt;It is reliable, easy-to-use, and provides excellent protection.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#8-metasploit"&gt;
  &lt;/a&gt;
  8. &lt;a href="https://www.metasploit.com/"&gt;Metasploit&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;It is a Penetration testing software.It discovering vulnerabilities in the system. These penetration testing tools can examine the different security systems, including web-based apps, servers, networks, and so on.&lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Open source.&lt;/li&gt;
&lt;li&gt;Supports large networks.&lt;/li&gt;
&lt;li&gt;GUI environment.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#9-cain-and-abel"&gt;
  &lt;/a&gt;
  9. &lt;a href="https://en.wikipedia.org/wiki/Cain_and_Abel_(software)"&gt;Cain and Abel&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;It is a password recovery tool for Microsoft Windows. It could recover many kinds of passwords using methods such as network packet sniffing, cracking various password hashes by using methods such as dictionary attacks, brute force.&lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Have various supporting functionalities.&lt;/li&gt;
&lt;li&gt;Open source free software.&lt;/li&gt;
&lt;li&gt;Good start for all kinds of packet sniffing exercises&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#10-tcpdump"&gt;
  &lt;/a&gt;
  10. &lt;a href="https://www.tcpdump.org/"&gt;Tcpdump&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;It is an efficient packet sniffer security tools used to monitor and log TCP/IP traffic connected via a network. it is a command-based tool, it can efficiently define network security and the packet contents of system traffic. &lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt; &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It can save the captured packets in a file for an advanced analysis.&lt;/li&gt;
&lt;li&gt;Several configuration options are available&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#11-nikto"&gt;
  &lt;/a&gt;
  11. &lt;a href="https://cirt.net/Nikto2"&gt;Nikto&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;It is used to detect web vulnerabilities and take appropriate actions accordingly. The software contains a database that includes around 6400 different threats. Security professionals keep updating this database so that the users may easily identify the new vulnerabilities.&lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt; &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Open source, Fast and portable.&lt;/li&gt;
&lt;li&gt;Easy to integrate in other penetration testing tools.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#12-paros-proxy"&gt;
  &lt;/a&gt;
  12. &lt;a href="https://paros.soft112.com/"&gt;Paros Proxy&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;Paros Proxy is a Java-based security tool that contains a variety of other tools like vulnerability scanners, traffic recorder, web spider, etc. this tool helps to scan security tests for identifying web vulnerabilities and maintaining network activities in real-time.&lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt; &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Web based light weight tool&lt;/li&gt;
&lt;li&gt;Protection And Security&lt;/li&gt;
&lt;li&gt;Anonymity When Using The Internet&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#13-nessus-professional"&gt;
  &lt;/a&gt;
  13. &lt;a href="https://www.tenable.com/products/nessus"&gt;Nessus Professional&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;It is a vulnerability assessment tool created by Tenable Inc. that can search out various vulnerabilities in a network such as the denial of service vulnerabilities. It helps in finding vulnerabilities that might allow access to unauthorized users or the loss of sensitive information.&lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;vulnerability scans on a regular basis and provides a full report.&lt;/li&gt;
&lt;li&gt;Understand the current threats and issues with current network devices.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#14-aircrackng"&gt;
  &lt;/a&gt;
  14. &lt;a href="https://www.aircrack-ng.org/"&gt;Aircrack-ng&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;Aircrack-ng is a tool that comes pre-installed in Kali Linux and is used for wifi network security and hacking. Aircrack is an all in one packet sniffer, WEP and WPA/WPA2 cracker, analyzing tool and a hash capturing tool. &lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To list all network interfaces.&lt;/li&gt;
&lt;li&gt;To Star a network interface at a specific channel.&lt;/li&gt;
&lt;li&gt;Free and open source&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;
  &lt;a href="#15-tor"&gt;
  &lt;/a&gt;
  15. &lt;a href=""&gt;Tor&lt;/a&gt;
&lt;/h3&gt;

&lt;p&gt;Tor or &lt;strong&gt;The Onion Router&lt;/strong&gt; is a service created to allow people to anonymously browse the Internet. It is a decentralized system that allows users to connect through a network of relays rather than making a direct connection. The benefit of this method is that your IP address is hidden from the sites you visit by bouncing your connection from server to server at random.&lt;br&gt;
&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Free and portable&lt;/li&gt;
&lt;li&gt;Deep web access&lt;/li&gt;
&lt;li&gt;Hides information&lt;/li&gt;
&lt;/ul&gt;

</description>
      <category>cybersecurity</category>
      <category>security</category>
      <category>beginners</category>
    </item>
    <item>
      <title>Intro to Git and GitHub</title>
      <author>samkb@420</author>
      <pubDate>Sat, 11 Sep 2021 13:08:40 +0000</pubDate>
      <link>https://dev.to/samkb420/intro-to-git-and-github-5fig</link>
      <guid>https://dev.to/samkb420/intro-to-git-and-github-5fig</guid>
      <description>&lt;p&gt;Git is  Version Control System(VCS) for tracking changes in computer files&lt;br&gt;
It entails the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Distributed Version Control&lt;/li&gt;
&lt;li&gt;Coordinates work between Multiple developers (Collaboration)&lt;/li&gt;
&lt;li&gt;Who made What changes and When&lt;/li&gt;
&lt;li&gt;Revert back at anytime (rollback)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GitHub is a for-profit company that offers a cloud-based Git repository hosting service.&lt;/p&gt;
&lt;h2&gt;
  &lt;a href="#concepts-of-github"&gt;
  &lt;/a&gt;
  Concepts of GitHub
&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Keep track of code history&lt;/li&gt;
&lt;li&gt;Take 'snapshots' of your files&lt;/li&gt;
&lt;li&gt;You can visit any snapshot at anytime&lt;/li&gt;
&lt;li&gt;Local &amp;amp; Remote repositories&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Lets make our hands Dirty and get Started by installing and performing basic git commands&lt;/p&gt;
&lt;h3&gt;
  &lt;a href="#installation"&gt;
  &lt;/a&gt;
  Installation
&lt;/h3&gt;

&lt;p&gt;Click on the below link it will take you to git download page then choose your OS and continue with the installation process follow the Instruction&lt;br&gt;
&lt;a href="https://git-scm.com/downloads"&gt;https://git-scm.com/downloads&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;
  &lt;a href="#getting-started"&gt;
  &lt;/a&gt;
  Getting started
&lt;/h2&gt;

&lt;p&gt;Love command-line let's Dive in.😎&lt;/p&gt;

&lt;p&gt;Check Git version&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;git &lt;span class="nt"&gt;--version&lt;/span&gt;

git version 2.25.1

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Configuring git on Your machine&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;git config &lt;span class="nt"&gt;--global&lt;/span&gt; user.name &lt;span class="s1"&gt;'yourusername'&lt;/span&gt;
&lt;span class="nv"&gt;$ &lt;/span&gt;git config &lt;span class="nt"&gt;--global&lt;/span&gt; user.email &lt;span class="s1"&gt;'youremail@abc.com'&lt;/span&gt;

&lt;span class="nv"&gt;$ &lt;/span&gt;git config &lt;span class="nt"&gt;--list&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Need help?&lt;br&gt;
&lt;code&gt;git help &amp;lt;verb&amp;gt;&lt;/code&gt; or &lt;code&gt;git &amp;lt;verb&amp;gt; --help&lt;/code&gt;&lt;br&gt;
ie. &lt;code&gt;git git help branch&lt;/code&gt; or &lt;code&gt;git branch --help&lt;/code&gt;&lt;br&gt;
Lets create a directory where we shall do git operation and navigate into the directory&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;$ mkdir Learning_git 
$ cd Learning_git

&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;that's pretty easy,&lt;/p&gt;

&lt;p&gt;Initializing a Git Repository&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;git init 
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;expected output&lt;br&gt;
&lt;code&gt;Initialized empty Git repository in /home/samkb420/MyHobby/Learning_git/.git/&lt;br&gt;
&lt;/code&gt;&lt;br&gt;
Adding file(s) to index&lt;br&gt;
let use the ls command to list file and folders.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;ls&lt;/span&gt; &lt;span class="nt"&gt;-la&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;output&lt;br&gt;
&lt;code&gt;total 12&lt;br&gt;
drwxrwxr-x  3 samkb420 samkb420 4096 Aug 19 02:14 ./&lt;br&gt;
drwxrwxr-x 52 samkb420 samkb420 4096 Aug 18 19:11 ../&lt;br&gt;
drwxrwxr-x  7 samkb420 samkb420 4096 Aug 19 02:14 .git/&lt;br&gt;
&lt;/code&gt;&lt;br&gt;
lets create a file.&lt;br&gt;
we shall build a simple calculator in python don't worry if you don't know python its not that complex.&lt;br&gt;
let's open our text editor for me am using vscode.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;touch &lt;/span&gt;calc.py
&lt;span class="nv"&gt;$ &lt;/span&gt;code &lt;span class="nb"&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;let do simple add method in python&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;def add(a,b):

    return a + b
print(add(5,5))
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;having done that let do the following&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;$ git add -A  
$ git commit -m "[First commit #0001 ]"
$ git status 
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;output&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;On branch main
nothing to commit, working tree clean
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now lets push the code in a remote repo in this case I Will use github.&lt;br&gt;
continue into github and create a repo.&lt;br&gt;
lets add the github remote url &lt;br&gt;
i.e&lt;br&gt;
&lt;code&gt;git remote add origin https://github.com/BitgritCampus/Learn_Git_Github.git&lt;/code&gt;&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;$git remote add origin remote_github_url
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;let now push to GitHub&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git push -u origin main
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now add you credentials username and PAT(personal access token)&lt;br&gt;
Hurrryy !! Done &lt;/p&gt;

&lt;p&gt;Next on Merging.&lt;/p&gt;

</description>
      <category>programming</category>
      <category>github</category>
      <category>codenewbie</category>
      <category>datascience</category>
    </item>
    <item>
      <title>How to deploy a strict Content Security Policy (CSP) with Next.js</title>
      <author>Guy Dumais</author>
      <pubDate>Sat, 11 Sep 2021 13:05:07 +0000</pubDate>
      <link>https://dev.to/guydumais/how-to-deploy-a-strict-content-security-policy-csp-with-next-js-nfj</link>
      <guid>https://dev.to/guydumais/how-to-deploy-a-strict-content-security-policy-csp-with-next-js-nfj</guid>
      <description>&lt;p&gt;Based on the most comprehensive study to date from Google, 95% of real-world Content Security Policy (CSP) deployments are bypassed and 99.34% of hosts with CSP use policies that offer no benefit against XSS.&lt;/p&gt;

&lt;p&gt;This is why Google suggests that the model of designating trust by specifying URL whitelists from which scripts can execute should be replaced with an approach based on nonces and hashes, already defined by the CSP specification and available in major browser implementations. Hence the name strict CSP.&lt;/p&gt;

&lt;p&gt;In the context of a Single Page App (SPA) such as the Next.js React framework, we need to use a Hashed-based CSP in order to properly integrate a strict CSP which will offer real protection against CSS attacks.&lt;/p&gt;

&lt;p&gt;Depending on the complexity of your application, the integration of a hash-based Content Security Policy could be trivial and require a lot of code manipulation. That’s why I’ve come to build a package on NPM specifically designed for Next.js to allow developers to integrate strict CSP in a snap with just a few lines of code.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#nextstrictcsp"&gt;
  &lt;/a&gt;
  next-strict-csp
&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://www.npmjs.com/package/next-strict-csp"&gt;next-strict-csp&lt;/a&gt; is a hash-based Strict Content Security Policy generator for Next.js that is easily integrated in the _document.tsx file of your Next.js application. Once in production, it will automatically inject the hashes into the content security policy meta tag and protect against XSS once deployed and cached on CDN.&lt;/p&gt;

&lt;p&gt;Here is an example of &lt;strong&gt;_document.tsx&lt;/strong&gt; with basic integration of next-strict-csp:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;...

// Next.js libraries
import Document, { Html, Head, Main, NextScript } from 'next/document'

// Next Strict Content Security Policy
import { NextStrictCSP } from 'next-strict-csp'

...

// Enable Head Strict CSP in production mode only
const HeadCSP = process.env.NODE_ENV === 'production' ? NextStrictCSP : Head

...

// Document component
class MyDoc extends Document {

  render() {
    return (
      &amp;lt;Html&amp;gt;
        &amp;lt;HeadCSP&amp;gt;
          { process.env.NODE_ENV === 'production' &amp;amp;&amp;amp; 
          &amp;lt;meta httpEquiv="Content-Security-Policy" /&amp;gt;
          }

          ...

        &amp;lt;/HeadCSP&amp;gt;
        &amp;lt;body&amp;gt;

          ...

          &amp;lt;Main /&amp;gt;
          &amp;lt;NextScript /&amp;gt;

          ...

        &amp;lt;/body&amp;gt;
      &amp;lt;/Html&amp;gt;
    )
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Once put live in production, you'll get a content security policy meta tag that looks like this:&lt;br&gt;
&lt;code&gt;&amp;lt;meta http-equiv="Content-Security-Policy" content="script-src 'strict-dynamic' 'sha256-XOzjewwkvGMLaoj+oYCiOZ3kRwb6RT1Ph6vn4qL+XI0=' 'unsafe-inline' http: https:;" slug="/"&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;With a strict CSP, you need to hash your inline scripts as well. This could be easily achieved with next-strict-csp by integrating your inline scripts in an array like this in &lt;strong&gt;_document.tsx&lt;/strong&gt;:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;...

// Next.js libraries
import Document, { Html, Head, Main, NextScript } from 'next/document'

// Next Strict Content Security Policy
import { NextStrictCSP } from 'next-strict-csp'

...

// Cloudflare Insights Script (Optional)
const cloudflareJs = `var s = document.createElement('script')
s.src = 'https://static.cloudflareinsights.com/beacon.min.js'
s.setAttribute('data-cf-beacon', '{"token": "YOUR CLOUDFLARE WEB ANALYTICS TOKEN STRING"}')
document.body.appendChild(s)`

// Google Tag Manager Script (Optional)
const GTMJs = `(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&amp;amp;l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','YOUR GOOGLE TAG MANAGER ID STRING');`

// Next Strict CSP
// Inline scripts to hash  (Optional)
NextStrictCSP.inlineJs = [
  cloudflareJs,
  GTMJs
]

...

// Enable Head Strict CSP in production mode only
const HeadCSP = process.env.NODE_ENV === 'production' ? NextStrictCSP : Head

...

// Document component
class MyDoc extends Document {

  render() {
    return (
      &amp;lt;Html&amp;gt;
        &amp;lt;HeadCSP&amp;gt;
          { process.env.NODE_ENV === 'production' &amp;amp;&amp;amp; 
          &amp;lt;meta httpEquiv="Content-Security-Policy" /&amp;gt;
          }

          ...

          {/* Google Tag Manager */}
          { process.env.NODE_ENV === 'production' &amp;amp;&amp;amp; 
          &amp;lt;script 
            dangerouslySetInnerHTML={{
                __html: GTMJs
            }}
          /&amp;gt;
          }
          {/* End Google Tag Manager */}

        &amp;lt;/HeadCSP&amp;gt;
        &amp;lt;body&amp;gt;
          { process.env.NODE_ENV === 'production' &amp;amp;&amp;amp; 
          &amp;lt;noscript
            dangerouslySetInnerHTML={{
                __html: `&amp;lt;iframe src="https://www.googletagmanager.com/ns.html?id=YOUR GOOGLE TAG MANAGER ID STRING" height="0" width="0" style="display:none;visibility:hidden"&amp;gt;&amp;lt;/iframe&amp;gt;`,
            }}
          /&amp;gt;
          }

          ...

          &amp;lt;Main /&amp;gt;
          &amp;lt;NextScript /&amp;gt;
          {/* Cloudflare Web Analytics */}
          {/*&amp;lt;script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon={`{"token": "YOUR CLOUDFLARE WEB ANALYTICS TOKEN STRING"}`}&amp;gt;&amp;lt;/script&amp;gt;*/}
          {process.env.NODE_ENV === 'production' &amp;amp;&amp;amp; 
          &amp;lt;script dangerouslySetInnerHTML={{
            __html: cloudflareJs
          }} /&amp;gt;
          }
          {/* End Cloudflare Web Analytics */}

          ...

        &amp;lt;/body&amp;gt;
      &amp;lt;/Html&amp;gt;
    )
  }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Once live, your inline scripts hashes will be injected into the content security policy meta tag like this:&lt;br&gt;
&lt;code&gt;&amp;lt;meta http-equiv="Content-Security-Policy" content="script-src 'strict-dynamic' 'sha256-XOzjewwkvGMLaoj+oYCiOZ3kRwb6RT1Ph6vn4qL+XI0=' 'sha256-QSxH3dqIUPdeBvyxSZSuIbZfgtCo/yuqnzU+5gtq9Ak=' 'sha256-7V8IQTE3j8PL2rD62J9XsmUhchGnkkyNIQfwoYVK04I=' 'unsafe-inline' http: https:;" slug="/"&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#last-word"&gt;
  &lt;/a&gt;
  Last word
&lt;/h2&gt;

&lt;p&gt;Hope you enjoyed next-strict-csp and don't hesitate to leave a comment to let me know what you think about it.&lt;/p&gt;

&lt;p&gt;Thanks for reading, see you!&lt;/p&gt;

</description>
      <category>nextjs</category>
      <category>security</category>
    </item>
    <item>
      <title>5 Reasons Why Software Engineers Are in High Demand</title>
      <author>Sumeet Vishwakarma</author>
      <pubDate>Sat, 11 Sep 2021 12:39:03 +0000</pubDate>
      <link>https://dev.to/legendsumeet/5-reasons-why-software-engineers-are-in-high-demand-3np</link>
      <guid>https://dev.to/legendsumeet/5-reasons-why-software-engineers-are-in-high-demand-3np</guid>
      <description>&lt;p&gt;‘Software Engineer’ – it is one of the most demanded and rewarding career profiles of the current times all across the world. Whether we talk about higher salary packages, career growth opportunities, collaborative work environment, amazing perks, or any other related aspect – a Software Engineer job at almost every renowned tech company offers you these things! As per a few standard reports, the demand &amp;amp; job opportunities for software engineers are likely to grow by 20-25% in the coming years.  &lt;/p&gt;

&lt;p&gt;But have you ever thought about the reasons behind such rapidly increasing demand for Software Engineers in the professional world…?? No worries, as here in this article, we’re going to discuss the same.  &lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Gl7c8wo---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/e3hhkqkn7k49nwuef4gq.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Gl7c8wo---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/e3hhkqkn7k49nwuef4gq.png" alt="Alt Text"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, before moving further, let’s have a quick look at – Who are Software Engineers and What do they do? A Software Engineer is a tech professional who implements the software engineering principles or concepts in each phase of building a system/product including designing, development, testing, and maintenance. He is basically engaged with the product from the requirements gathering phase to its successful final development &amp;amp; deployment. Though the roles and responsibilities of a Software Engineer majorly depend on his specific domain and the company requirements. &lt;/p&gt;

&lt;p&gt;For example – a Blockchain Software Engineer is usually responsible for analyzing the company’s tech requirements or client’s demands and then concerned with the designing &amp;amp; development of blockchain software/product along with handling or managing several other tasks like testing, troubleshooting, etc.    &lt;/p&gt;

&lt;p&gt;Now, let’s get to know some of the major reasons that why Software Engineers are in great demand in the tech world:  &lt;/p&gt;

&lt;p&gt;Rapid Advent of Tech Advancements  &lt;/p&gt;

&lt;p&gt;One of the primary reasons behind such an immensely increasing demand for Software Engineers is the rapid growth of technology. The exponential growth &amp;amp; evolution of technology in the last few years can clearly be seen considering all the recent tech trends like Quantum Computing, Artificial Intelligence &amp;amp; Machine Learning, 5G, Hyperautomation, Internet of Behaviors (IoB), etc. We’re seeing how almost everything around us in the present day scenario including smartphones, IoT devices, virtual reality and augmented reality platforms, cryptocurrencies, and many other are all supported by the respective software.  &lt;/p&gt;

&lt;p&gt;And thus, there is a huge demand &amp;amp; need for software engineers who can look after the designing, development, and maintenance of this software. And undoubtedly, since the technologies are expected to keep growing at such a fast pace, the future of software engineer looks promising in the upcoming years as well with the generation of numerous job opportunities for these professionals in the tech world.&lt;/p&gt;

&lt;p&gt;The World is Moving Online&lt;/p&gt;

&lt;p&gt;Moving ahead, the massive shift of everyone whether it be an individual or an offline business or education domain or any other, to the digital platforms can be considered as another prominent reason that why the demand for software engineers is surging. Especially after the global covid-19 pandemic, the digital presence for individuals or businesses has remained no more optional but it has become something very much necessary for them to keep going with their respective workflow or operations.  &lt;/p&gt;

&lt;p&gt;The platforms like Uber, Zomato, Flipkart, Paytm, Zoom, etc. are some of the renowned examples that represent today’s digitalized world. And behind all these digital platforms there exists the respective team of software engineers who ensures the successful development and running of the particular product whether it be an app, a website, or any other software. So, tech companies are in great need of skilled software engineers that can help them to create/build such ideal software solutions to thrive in the industry.  &lt;/p&gt;

&lt;p&gt;Code Requires Timely Upgradation/Changes&lt;/p&gt;

&lt;p&gt;This is something very crucial to know to understand the scenario of increasing demand for software engineers. So, most individuals, especially beginners, usually come with a doubt in their mind that once the code is completed and the product is successfully developed, now the project should be over for software engineers except for the tasks like regular maintenance, etc. But the real scenario differs from it, let us tell you why…??  &lt;/p&gt;

&lt;p&gt;You need to know that code usually becomes outdated or obsolete due to various reasons like the advent of new technologies, need for new features, etc. hence it requires regular &amp;amp; consistent updation/changes throughout time. Let us tell you that there are instances where the organization opts to rebuild the existing software or rewrite the entire code from scratch using the latest technologies for various reasons like better &amp;amp; fast performance, cost reduction, etc. And that’s why a software engineer or a team of software engineers is associated and required for the particular product/software even after its successful deployment.  &lt;/p&gt;

&lt;p&gt;Software Engineers are Concerned With Mulitple Phases like Designing, Development, Testing, etc.&lt;/p&gt;

&lt;p&gt;Going down the list, another prominent reason behind such a great demand for software engineers in the tech world is that these professionals are concerned with almost every crucial phase of the product building whether it be designing, development, testing, etc. They work closely with the designing team to let them know the required functionalities of the product (as per the user requirements), they collaborate with programmers for code writing, then they work with the testing team for testing &amp;amp; assessing the code, and so on. Not only this, but also technical design documentation, identifying the improvement areas in the product &amp;amp; recommending the solution for it, improving existing codes, and various other such tasks are also often handled by software engineers. And this vast &amp;amp; impactful role of software engineers in product development is one of the major reasons that why software engineers significantly hold a strong place, popularity, and demand in the tech industry.  &lt;/p&gt;

&lt;p&gt;Lesser Supply of Skilled Software Engineers  &lt;/p&gt;

&lt;p&gt;Last but not least, there comes the supply and demand concept. So, we need to understand that there are not adequate software engineers who’re quite proficient and skillful as per the industries’ requirements and as known to everyone short supply always lead to high and high demand! For example – a software engineer is required to have a strong familiarity with the Software Development Life Cycle (SDLC), should have a decent knowledge of programming concepts and data structures &amp;amp; algorithms, proficiency with the relevant tools, etc. Along with it, if a software engineer is quite updated with the latest development trends &amp;amp; possesses some required soft skills as well like communication, teamwork, etc., it makes his profile more strong. However, as many of the individuals who aspire to start their career as a software engineer lacks the mentioned skills, the software engineers continue to be in great demand.&lt;/p&gt;

&lt;p&gt;So, these are some of the prominent reasons behind the great demand for Software Engineers in the tech industry and job market. And again, the future of software engineer seems quite bright – hence, if you’re looking forward to building your career in this particular domain then you can go for it without giving a second thought and learn all the required skills accordingly!&lt;/p&gt;

</description>
    </item>
    <item>
      <title>DNS introduction</title>
      <author>tcpdump-examples</author>
      <pubDate>Sat, 11 Sep 2021 12:14:50 +0000</pubDate>
      <link>https://dev.to/learnlinux/dns-introduction-54m6</link>
      <guid>https://dev.to/learnlinux/dns-introduction-54m6</guid>
      <description>&lt;p&gt;DNS is short for Domain Name System. It is simply a database that links meaningful names (known as hostnames), such as howtouselinux.com, to a specific IP address, such as 185.230.63.171. &lt;/p&gt;

&lt;p&gt;Each device connected to the Internet has a unique IP address. With the system of DNS, we don't have to memorize IP addresses.&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#dns-records"&gt;
  &lt;/a&gt;
  DNS records
&lt;/h1&gt;

&lt;p&gt;All domains are required to have at least a few essential DNS records for a user to be able to access their website using a domain name. This is the key concept of DNS.&lt;/p&gt;

&lt;p&gt;Here are 4 commonly used DNS records.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A record - A record is used to map a domain (e.g., howtouselinux.com) or a sub-domain (e.g., blog.howtouselinux.com) to an IP address or many ips.&lt;/li&gt;
&lt;li&gt;PTR record - Provides a domain name in reverse-lookups. eg. (23.236.62.147 -- howtouselinux.com)  check more about A record. &lt;a href="https://www.howtouselinux.com/post/dns-a-record"&gt;Understanding DNS A Record with Examples&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;CNAME record - also known as canonical name records, are used to create aliases that point to other names. They are commonly used to map WWW, FTP and MAIL sub-domains to a domain.&lt;/li&gt;
&lt;li&gt;MX record - MX (Mail Exchange) records control how incoming email is routed for your domain. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Check this post to learn more about DNS records. &lt;a href="https://www.howtouselinux.com/post/linux-dns-ptr-mx-srv-spf-aaaa-dns-records"&gt;Understanding DNS Records - PTR MX SRV CNAME AAAA &lt;/a&gt;.&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#how-to-query-dns-record"&gt;
  &lt;/a&gt;
  How to query DNS record
&lt;/h1&gt;

&lt;p&gt;Each application like Chrome has its own mechanism to get the DNS record. We will explain how to use the Linux command to query DNS records.&lt;/p&gt;

&lt;p&gt;We can use dig name  +   record type + @dns server to query the DNS info from a DNS server. By default, dig performs a lookup for an A record if no type argument is specified.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;server – the IP address or hostname of the name server to query. It is optional and if we don’t provide a server argument then dig uses the name server listed in /etc/resolv.conf.&lt;/li&gt;
&lt;li&gt;name – the name of the resource record that is to be looked up.&lt;/li&gt;
&lt;li&gt;record type – the type of query requested by dig. For example, it can be an A record, MX record, SOA record or any other types. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;check more about &lt;a href="https://www.howtouselinux.com/post/linux-command-use-dig-to-query-dns"&gt;how to use dig command to query DNS info&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#example-of-dns-record"&gt;
  &lt;/a&gt;
  Example of DNS record
&lt;/h1&gt;

&lt;p&gt;We can see that google.com has 6 A records with the following example. The main purpose of this is for load balance and fault tolerance.&lt;/p&gt;

&lt;p&gt;$ dig google.com +short&lt;br&gt;
172.217.194.138&lt;br&gt;
172.217.194.139&lt;br&gt;
172.217.194.102&lt;br&gt;
172.217.194.101&lt;br&gt;
172.217.194.100&lt;br&gt;
172.217.194.113&lt;/p&gt;
&lt;h1&gt;
  &lt;a href="#which-port-does-dns-use"&gt;
  &lt;/a&gt;
  Which port does DNS use?
&lt;/h1&gt;

&lt;p&gt;DNS uses both TCP and UDP port 53. The most frequently used port for DNS is UDP 53. This is used for DNS queries on the client-side. Check more info about &lt;a href="https://www.howtouselinux.com/post/dns-port"&gt;DNS port&lt;/a&gt; here. &lt;/p&gt;
&lt;h1&gt;
  &lt;a href="#how-to-use-tcpdump-to-filter-dns-query-packets"&gt;
  &lt;/a&gt;
  How to use tcpdump to filter DNS Query packets?
&lt;/h1&gt;

&lt;p&gt;We can use this tcpdump command to filter DNS query packets.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;tcpdump -i eth0 udp port 53
We can write these packets to a file with this tcpdump command and analyze these packets with Wireshark GUI.&lt;/li&gt;
&lt;li&gt;tcpdump -i eth0  -w /tmp/dns.pcap udp port 53
We can read these packets from dns.pcap file to get more details about the DNS query.&lt;/li&gt;
&lt;li&gt;tcpdump -vvv -r /tmp/dns.pcap port 53 &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;check more info about &lt;a href="https://www.howtouselinux.com/post/tcpdump-filter-dns-packets"&gt;how to use tcpdump to capture DNS packet&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;
  &lt;a href="#example-of-dns-packet-analysis"&gt;
  &lt;/a&gt;
  Example of DNS Packet Analysis
&lt;/h1&gt;

&lt;p&gt;We can get the A record for google.com with the flowing command.&lt;/p&gt;

&lt;p&gt;dig google.com +short&lt;/p&gt;

&lt;p&gt;This is the output of tcpdump command after we run the above dig command. Check more info about how to use dig command to query DNS records here.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;20:11:00.466866 IP 10.79.98.233.54127 &amp;gt; 64.104.76.247.53: 60712+ [1au] A? google.com. (39)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This is the packet we get from the DNS server for this DNS query.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;20:11:00.560294 IP 64.104.76.247.53 &amp;gt; 10.79.98.233.54127: 60712 6/4/1 A 74.125.24.113, A 74.125.24.102, A 74.125.24.139, A 74.125.24.138, A 74.125.24.100, A 74.125.24.101 (207)
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;By default, the dig command query the A record for that domain name with UDP protocol. Check this post to learn more about other DNS records like AAAA, MX, PTR etc.&lt;/p&gt;

&lt;h1&gt;
  &lt;a href="#reference"&gt;
  &lt;/a&gt;
  Reference:
&lt;/h1&gt;

&lt;p&gt;&lt;a href="https://www.howtouselinux.com/post/free-dns-servers-in-2021"&gt;Free DNS Servers in 2021&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.howtouselinux.com/post/flush-dns-cache-with-command"&gt;Flush DNS Cache with Command Quick Guide&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.howtouselinux.com/post/dns-ttl"&gt;Exploring DNS TTL with Examples&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.howtouselinux.com/post/linux-dig-dns"&gt;Understanding Linux Dig Command&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.howtouselinux.com/post/dns_edns"&gt;Exploring EDNS with Examples&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.howtouselinux.com/post/best-dns-server-for-ps4-ps5"&gt;Best and Fastest DNS Server For PS4 PS5&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.howtouselinux.com/post/best-dns-servers-for-gaming"&gt;Best and Fastest DNS Servers For Gaming&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.howtouselinux.com/post/what-is-dns-dns-meaning"&gt;What is DNS? DNS Meaning&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.howtouselinux.com/post/dig-dns-txt-record"&gt;Query DNS Txt Record with Dig Command&lt;/a&gt;&lt;/p&gt;

</description>
    </item>
    <item>
      <title>Git and GitHub: The Complete Guides - Chapter 4</title>
      <author>Goran Kortjie</author>
      <pubDate>Sat, 11 Sep 2021 12:07:26 +0000</pubDate>
      <link>https://dev.to/ifierygod/git-and-github-the-complete-guides-chapter-4-a00</link>
      <guid>https://dev.to/ifierygod/git-and-github-the-complete-guides-chapter-4-a00</guid>
      <description>&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--3q61M1mV--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7nibchqo9rpy0i3ks35u.png" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--3q61M1mV--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7nibchqo9rpy0i3ks35u.png" alt="Goran-hi-friend"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Welcome to this chapter, we are going to discuss one of the important features of Git which is called &lt;strong&gt;branching&lt;/strong&gt;. In Git branches is part of your everyday development process. For example when you want to add a new feature to your project or maybe you might need to fix a bug, then you can use &lt;strong&gt;branching&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Here we will cover how to:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create a branch&lt;/li&gt;
&lt;li&gt;Create and switch to a new branch&lt;/li&gt;
&lt;li&gt;Delete a branch&lt;/li&gt;
&lt;li&gt;Push branch to Github&lt;/li&gt;
&lt;li&gt;Pull branch from remote to local&lt;/li&gt;
&lt;li&gt;Delete a branch&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--oU93e1Ok--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ppibreuioamrdj8z7pqs.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--oU93e1Ok--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ppibreuioamrdj8z7pqs.gif" alt="branching"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As shown in the above diagram, we have a project timeline with different commits. This time-line is actually a branch. By default when you create a repository and make commits, you are working on the &lt;em&gt;master&lt;/em&gt; branch. This is what we have already seen in previous chapters.&lt;/p&gt;

&lt;p&gt;Continuing with our example, sometimes you need to add a new feature to your project, but at the same time you don't want to touch or break the current state of the project. In that case the best solution is to create a new branch and then work on that newly created branch &lt;u&gt;(adding files, making commits etc..).&lt;/u&gt;&lt;/p&gt;

&lt;p&gt;Then after creating and testing the new feature, if you are happy with it, you can then merge your branch to the master branch. &lt;strong&gt;You are able to create as many branches as you wish.&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;It becomes really helpful when several developers are working on the same project, each of them can work on a different branch without breaking another developers work.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--_G60vxrz--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/d7v1z1qonptn921j97bg.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--_G60vxrz--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/d7v1z1qonptn921j97bg.gif" alt="project-branch"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Create a branch&lt;/h2&gt;

&lt;p&gt;Lets go and see in practice how to work with branches, We go back to our project, where we are working on the default master branch. To create a new branch we have to run the following command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git branch 
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This command is followed by the name of the branch. For example:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git branch feature-1
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;In order to see what branch we are working on and to see how many branches we have, we need to run the following command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git branch
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now we can see overall we have two branches and currently we are working on the *master branch, as indicated by the asterisk and green-colour text.&lt;/p&gt;

&lt;p&gt;Lets see how we can switch to a different branch, for that we have to run the command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git checkout feature-1
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now we will be working on the feature-1 branch. If we check the commit history, we will get all the commits we have made so far. We are able to change these commits and also make new ones, which won't be available on the master branch.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--oGu2hGTi--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/kwypp3ggl60q9rqgbobx.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--oGu2hGTi--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/kwypp3ggl60q9rqgbobx.gif" alt="git-branch"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you remember from previous chapters, we can switch back to our master branch by running the following command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git checkout master
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Note that changes or commits we make on our branch will not be seen by the master branch and we can prove this by making a new commit on our feature-1 branch and then checking if the commit is tracked on the commit history on the master branch.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--lyc4P1OQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hf14asf9l1oh43lxr7hj.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--lyc4P1OQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hf14asf9l1oh43lxr7hj.gif" alt="git-branches"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Create and switch to a new branch&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s---9i-_2cX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bpgmfqqtc1j08pk7edeh.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s---9i-_2cX--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bpgmfqqtc1j08pk7edeh.gif" alt="switch"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Lets move on, time to see how we can create and switch to a new created branch with just one command. Suppose we want to create a new branch called feature-2 and switch to it immediately. To do this we need to run the following command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git checkout -b
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This command is followed by the name of the new branch. For example:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git checkout -b feature-2
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now when we run &lt;code&gt;git branch&lt;/code&gt; we will see we have three branches and we have switched to our new branch as well.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--yE6wY5a0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3cns1s296xf7wz9ch3eo.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--yE6wY5a0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3cns1s296xf7wz9ch3eo.gif" alt="branch-immediately"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Delete a branch&lt;/h2&gt;

&lt;p&gt;Next we have to discuss how to delete branches. To do this we need to run the following command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git branch -D
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This command is followed by the name of the branch we want to delete.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Remember we cannot delete the branch which we are currently working on, if we try to delete a branch we are currently on, we will get an error that says we can't delete it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Once we delete our branch we can see how many branches we have left with the command &lt;code&gt;git branch&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--zaHT2nbY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1ygv6rxy8nkju1mjmu46.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--zaHT2nbY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1ygv6rxy8nkju1mjmu46.gif" alt="branch-delete"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Push branch to Github&lt;/h2&gt;

&lt;p&gt;We can push our example feature branch to our remote repository by running the following command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git push origin feature-2
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;To do this we first have to make a commit on our branch, which can been seen here.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--pC8-964K--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9ejsi0e0dfp4lbfzjs3s.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--pC8-964K--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9ejsi0e0dfp4lbfzjs3s.gif" alt="push-branch-Github"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When we push our local branch to GitHub, we can see that our branch has been added, we can then go to our branch and see the commits that were made. GitHub will even tell us by how many commits we are ahead of our master branch.&lt;/p&gt;

&lt;h2&gt;Create a branch from GitHub&lt;/h2&gt;

&lt;p&gt;We can also create a branch from the Github website. It is pretty simple. We click the button that says &lt;strong&gt;master&lt;/strong&gt; and give a name for our branch, then click create branch. We can see our new branch has been created. &lt;/p&gt;

&lt;p&gt;We can even go to the &lt;strong&gt;branches&lt;/strong&gt; button to see all our branches. When we hover over the numbers, we can see by how many commits our branch is ahead of the master.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--l3Jyi2bD--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4w6hhsp9p4m5ioyb3gx7.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--l3Jyi2bD--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4w6hhsp9p4m5ioyb3gx7.gif" alt="branch-Github"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Pull branch from remote to local&lt;/h2&gt;

&lt;p&gt;If we created a branch on GitHub and we want to work with that branch on our local repository, we have to pull the data from our remote to our local. To do this we run the following command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git pull origin
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Then we follow the command with the name of our remote branch. For example:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git pull origin feature-1
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Then we need to run the command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git checkout --track origin/feature-1
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;Now we have pulled the data from GitHub to our local repo and we have switched to it. We can check this by running the command: &lt;code&gt;git branch&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;We can make a change to our remote branch on GitHub and make a commit to it. But to have access to the changes, we need to pull the data from the remote branch with the command: &lt;code&gt;git pull origin feature-1&lt;/code&gt;. &lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--_NftunFq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/mse7dwu6ttvz3obt51b8.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--_NftunFq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/mse7dwu6ttvz3obt51b8.gif" alt="Github-pull"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You may have noticed Git showing us that our pull request is not really the best method. This is true. We haven't covered some of the topics yet so ignore it for now.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We can then check the commit history to see that our commits are up to date with the remote branch.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--UeVd9d1T--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8tu9egyfnr9zoe7ysgt5.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--UeVd9d1T--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8tu9egyfnr9zoe7ysgt5.gif" alt="git-log"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Each time when we make a new commit on the feature-1 branch on GitHub, remember we have to pull it to our local repository,  by running the command &lt;code&gt;git pull origin feature-1&lt;/code&gt;&lt;/p&gt;

&lt;h2&gt;Delete a branch&lt;/h2&gt;

&lt;p&gt;We can delete a branch on GitHub by going to our branches, click the branches button. On the right side of our branches we can see the little recycle bin, which when clicked allows us to delete a branch.&lt;/p&gt;

&lt;p&gt;Now when we go to branches we won't see our branch anymore. We can even delete our remote branches from our local repo by running the following command:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git push origin --delete
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;This command is followed by the branch we want to delete. For example:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;git push origin --delete feature-2
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;



&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--aRBmoVpB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/i1tksnwbwue6dncs62uf.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--aRBmoVpB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/i1tksnwbwue6dncs62uf.gif" alt="GitHub-delete"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;By going back to GitHub we can see this branch has been deleted. But deleting it this way does not mean it is deleted on our local repo, in fact if we check to see how many branches we have on our local repo we will see all our branches are still here.&lt;/p&gt;

&lt;p&gt;We know how to delete a branch on our local repo, we do this by running the command: &lt;code&gt;git branch -D&lt;/code&gt; followed by the name of the branch we want to delete.&lt;/p&gt;

&lt;p&gt;We can check our local branches with the command: &lt;code&gt;git branch&lt;/code&gt; which will show us only the master branch.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--gMO2zpoQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/gjrjx5sh1bmi44tthx8h.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--gMO2zpoQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/gjrjx5sh1bmi44tthx8h.gif" alt="git-delete"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;That concludes this chapter on branches, however we will be discussing more about branches in the coming chapter. I hope you enjoyed it. See ya!&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--iZgfFBgq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8ks5wjmy35cqcw6wx28j.gif" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--iZgfFBgq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8ks5wjmy35cqcw6wx28j.gif" alt="thor-wink"&gt;&lt;/a&gt;&lt;/p&gt;

</description>
      <category>github</category>
      <category>git</category>
      <category>webdev</category>
      <category>beginners</category>
    </item>
    <item>
      <title>Deep dive into Linux Networking and Docker - Bridge, vETH and IPTables</title>
      <author>Farhan</author>
      <pubDate>Sat, 11 Sep 2021 12:00:40 +0000</pubDate>
      <link>https://dev.to/arriqaaq/diving-into-linux-networking-and-docker-bridge-veth-and-iptables-419a</link>
      <guid>https://dev.to/arriqaaq/diving-into-linux-networking-and-docker-bridge-veth-and-iptables-419a</guid>
      <description>&lt;p&gt;This was originally published here: &lt;a href="https://aly.arriqaaq.com/linux-networking-bridge-iptables-and-docker/"&gt;https://aly.arriqaaq.com/linux-networking-bridge-iptables-and-docker/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;These series of articles are my log of learning about various networking concepts related to Container Orchestration Platforms (Docker, Kubernetes, etc)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--5oo8Fl7O--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn-images-1.medium.com/max/2560/1%2Av5c5nl2BoA0BqwqWoj5Y1w.jpeg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--5oo8Fl7O--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn-images-1.medium.com/max/2560/1%2Av5c5nl2BoA0BqwqWoj5Y1w.jpeg" alt=""&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Linux Networking is a very interesting topic. In this series, my aim is to dig deep to understand the various ways in which these container orchestration platforms implement network internals underneath.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#getting-started"&gt;
  &lt;/a&gt;
  Getting Started
&lt;/h2&gt;

&lt;p&gt;A few questions before getting started.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1) What are namespaces?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://medium.com/@teddyking/linux-namespaces-850489d3ccf"&gt;TLDR&lt;/a&gt;, a linux namespace is an abstraction over resources in the operating system. Namespaces are like separate houses with their own sets of isolated resources. There are currently 7 types of namespaces Cgroup, IPC, Network, Mount, PID, User, UTS&lt;/p&gt;

&lt;p&gt;Network isolation is what we are interested in, so we will be discussing in depth about network namespaces.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2) How to follow along?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;All the examples in this article have been made on a fresh &lt;em&gt;vagrant&lt;/em&gt; &lt;a href="https://app.vagrantup.com/ubuntu/boxes/bionic64"&gt;Ubuntu Bionic&lt;/a&gt; virtual machine.&lt;/p&gt;

&lt;p&gt;Linux Networking is a very interesting topic. In this series, my aim is to dig deep to understand the various ways in which these container orchestration platforms implement network internals underneath.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#getting-started"&gt;
  &lt;/a&gt;
  Getting Started
&lt;/h2&gt;

&lt;p&gt;A few questions before getting started.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1) What are namespaces?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://medium.com/@teddyking/linux-namespaces-850489d3ccf"&gt;TLDR&lt;/a&gt;, a linux namespace is an abstraction over resources in the operating system. Namespaces are like separate houses with their own sets of isolated resources. There are currently 7 types of namespaces Cgroup, IPC, Network, Mount, PID, User, UTS&lt;/p&gt;

&lt;p&gt;Network isolation is what we are interested in, so we will be discussing in depth about network namespaces.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2) How to follow along?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;All the examples in this article have been made on a fresh &lt;em&gt;vagrant&lt;/em&gt; &lt;a href="https://app.vagrantup.com/ubuntu/boxes/bionic64"&gt;Ubuntu Bionic&lt;/a&gt; virtual machine.&lt;/p&gt;

&lt;p&gt;Linux Networking is a very interesting topic. In this series, my aim is to dig deep to understand the various ways in which these container orchestration platforms implement network internals underneath.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#getting-started"&gt;
  &lt;/a&gt;
  Getting Started
&lt;/h2&gt;

&lt;p&gt;A few questions before getting started.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1) What are namespaces?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://medium.com/@teddyking/linux-namespaces-850489d3ccf"&gt;TLDR&lt;/a&gt;, a linux namespace is an abstraction over resources in the operating system. Namespaces are like separate houses with their own sets of isolated resources. There are currently 7 types of namespaces Cgroup, IPC, Network, Mount, PID, User, UTS&lt;/p&gt;

&lt;p&gt;Network isolation is what we are interested in, so we will be discussing in depth about network namespaces.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2) How to follow along?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;All the examples in this article have been made on a fresh &lt;em&gt;vagrant&lt;/em&gt; &lt;a href="https://app.vagrantup.com/ubuntu/boxes/bionic64"&gt;Ubuntu Bionic&lt;/a&gt; virtual machine.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;vagrant init ubuntu/bionic64
vagrant up
vagrant ssh
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;
&lt;h2&gt;
  &lt;a href="#exploring-network-namespaces"&gt;
  &lt;/a&gt;
  Exploring Network Namespaces
&lt;/h2&gt;

&lt;p&gt;How do platforms virtualise network resources to isolate containers by assigning them a dedicated network stack, and making sure these containers do not interfere with the host (or neighbouring containers)? Network Namespace. A network namespace isolates network related resources — a process running in a distinct network namespace has its own networking devices, routing tables, firewall rules etc.Let’s create one quickly.&lt;/p&gt;
&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;ip netns add ns1
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;And voila! You have your isolated network namespace (&lt;strong&gt;ns1&lt;/strong&gt;) created just like that. Now you can go ahead and run any process inside this namespace.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;ip netns exec ns1 python3 -m http.server 8000
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;This was pretty neat! The exec $namespace $command executes $command in the named network namespace $namespace. This means that the process runs within its own network stack, separate from the host, and can communicate only through the interfaces defined in the network namespace.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Host Namespace&lt;/strong&gt;Before you read ahead, I’d like to draw your attention on the default namespace for the **host **network. Let’s list down all the namespaces&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;ip netns

# all namespaces
ns1
default
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;You can notice the &lt;strong&gt;default **namespace that is created. This is the **host&lt;/strong&gt; namespace, which implies whatever services that you run simply on your VM or your machine, is run under this namespace. This would be important to note moving forward.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Creating a Network Namespace&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So with that said, let’s quickly move forward and create two isolated network namespaces (similar to two containers)&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;#!/usr/bin/env bash

NS1="ns1"
NS2="ns2"

# create namespace
ip netns add $NS1
ip netns add $NS2
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Connecting the cables&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We need to go ahead and connect these namespaces to our host network. The vETH (virtual Ethernet) device helps in making this connection. vETH is a local Ethernet tunnel, and devices are created in pairs.Packets transmitted on one device in the pair are immediately received on the other device. When either device is down, the link state of the pair is down.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;#!/usr/bin/env bash

NS1="ns1"
VETH1="veth1"
VPEER1="vpeer1"

NS2="ns2"
VETH2="veth2"
VPEER2="vpeer2"

# create namespace
ip netns add $NS1
ip netns add $NS2

# create veth link
ip link add ${VETH1} type veth peer name ${VPEER1}
ip link add ${VETH2} type veth peer name ${VPEER2}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;Think of VETH like a network cable. One end is attached to the host network, and the other end to the network namespace created. Let’s go ahead and connect the cable, and bring these interfaces up.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# setup veth link
ip link set ${VETH1} up
ip link set ${VETH2} up

# add peers to ns
ip link set ${VPEER1} netns ${NS1}
ip link set ${VPEER2} netns ${NS2}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Localhost&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Ever wondered how localhost works? Well, the loopback interface directs the traffic to remain within the local system. So when you run something on localhost (127.0.0.1), you are essentially using the loopback interface to route the traffic through. Let’s bring the loopback interface up in case we’d want to run a service locally, and also bring up the peer interfaces inside our network namespace to start accepting traffic.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# setup loopback interface
ip netns exec ${NS1} ip link set lo up
ip netns exec ${NS2} ip link set lo up

# setup peer ns interface
ip netns exec ${NS1} ip link set ${VPEER1} up
ip netns exec ${NS2} ip link set ${VPEER2} up
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;In order to connect to the network, a computer must have at least one network interface. Each network interface must have its own unique IP address. The IP address that you give to a host is assigned to its network interface.But does every network interface require an IP address right? Well, not really. We’ll see that in the coming steps.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# assign ip address to ns interfaces
VPEER_ADDR1="10.10.0.10"
VPEER_ADDR2="10.10.0.20"

ip netns exec ${NS1} ip addr add ${VPEER_ADDR1}/16 dev ${VPEER1}
ip netns exec ${NS2} ip addr add ${VPEER_ADDR2}/16 dev ${VPEER2}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;Remember, here we’ve only assigned network addresses to the interfaces inside the network namespaces (&lt;strong&gt;ns1 (vpeer1), ns2 (vpeer2)&lt;/strong&gt;). The host namespaces interfaces do not have an IP assigned (&lt;strong&gt;veth1, veth2&lt;/strong&gt;). Why? Do we need it? Well, not really.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Build Bridges, Not Walls&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Men build too many walls and not enough bridges&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Remember that when you have multiple containers running, and want to send traffic to these containers, we’d require a bridge to connect them. A &lt;strong&gt;network bridge&lt;/strong&gt; creates a single, aggregate network from multiple communication networks or network segments. &lt;em&gt;A bridge is a way to connect two Ethernet segments together in a protocol independent way. **Packets are forwarded based on Ethernet address&lt;/em&gt;*, rather than IP address (like a router). *Since forwarding is done at Layer 2, all protocols can go transparently through a bridge. Bridging is distinct from &lt;a href="https://en.wikipedia.org/wiki/Routing"&gt;routing&lt;/a&gt;. Routing allows multiple networks to communicate independently and yet remain separate, whereas bridging connects two separate networks as if they were a single network.&lt;/p&gt;

&lt;p&gt;Docker has a **docker0 **bridge underneath to direct traffic. When Docker service starts, a Linux bridge is created on the host machine. The various interfaces on the containers talk to the bridge, and the bridge proxies to the external world. Multiple containers on the same host can talk to each other through the Linux bridge.&lt;/p&gt;

&lt;p&gt;So let’s go ahead and create a bridge.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;BR_ADDR="10.10.0.1"
BR_DEV="br0"

# setup bridge
ip link add ${BR_DEV} type bridge
ip link set ${BR_DEV} up

# assign veth pairs to bridge
ip link set ${VETH1} master ${BR_DEV}
ip link set ${VETH2} master ${BR_DEV}

# setup bridge ip
ip addr add ${BR_ADDR}/16 dev ${BR_DEV}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;Now that we have out network interfaces connected to the bridge, how do these interfaces know how to direct the traffic to the host? The route tables in both network namespaces only have route entries for their respective subnet IP range.&lt;/p&gt;

&lt;p&gt;Since we have the VETH pairs connected to the bridge, the bridge network address is available to these network namespaces. Let’s add a default route to direct the traffic to the bridge.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# add default routes for ns
ip netns exec ${NS1} ip route add default via ${BR_ADDR}
ip netns exec ${NS2} ip route add default via ${BR_ADDR}
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;Done. Sweet! We have a proper setup to test if our containers can talk to each other. Let’s finally interact with the namespaces.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# add default routes for ns
ip netns exec ${NS1} ping ${VPEER_ADDR2}

PING 10.10.0.20 (10.10.0.20) 56(84) bytes of data.
64 bytes from 10.10.0.20: icmp_seq=1 ttl=64 time=0.045 ms
64 bytes from 10.10.0.20: icmp_seq=2 ttl=64 time=0.039 ms

ip netns exec ${NS2} ping ${VPEER_ADDR1}
PING 10.10.0.10 (10.10.0.10) 56(84) bytes of data.
64 bytes from 10.10.0.10: icmp_seq=1 ttl=64 time=0.045 ms
64 bytes from 10.10.0.10: icmp_seq=2 ttl=64 time=0.039 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;MASQUERADE&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We are able to send traffic between the namespaces, but we haven’t tested sending traffic outside the container. And for that, we’d need to use IPTables to masquerade the outgoing traffic from our namespace.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# enable ip forwarding
bash -c 'echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward'

iptables -t nat -A POSTROUTING -s ${BR_ADDR}/16 ! -o ${BR_DEV} -j MASQUERADE
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;MASQUERADE modifies the source address of the packet, replacing it with the address of a specified network interface. This is similar to SNAT, except that it does not require the machine’s IP address to be known in advance.Basically, what we are doing here is that we are adding an entry to NAT table, to masquerade the outgoing traffic from the bridge, except for the bridge traffic itself. With this, we are done with a basic setup on how docker actually implements linux network stack to isolate containers. You can find the entire script here.&lt;/p&gt;

&lt;p&gt;Now let’s dive deep into how docker works with various networking setups.&lt;/p&gt;

&lt;h2&gt;
  &lt;a href="#how-does-docker-work"&gt;
  &lt;/a&gt;
  How does Docker work?
&lt;/h2&gt;

&lt;p&gt;Each Docker container has its own network stack, where a new network namespace is created for each container, isolated from other containers. When a Docker container launches, the Docker engine assigns it a network interface with an IP address, a default gateway, and other components, such as a routing table and DNS services.&lt;/p&gt;

&lt;p&gt;Docker offers five network types. All these network types are configured through docker0 via the --net flag&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Host Networking (&lt;/strong&gt;--net=host*&lt;em&gt;)&lt;/em&gt;*: The container shares the same network namespace of the default host.&lt;/p&gt;

&lt;p&gt;You can verify this easily.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# check the network interfaces on the host
ip addr

1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: enp0s3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 02:98:b0:9b:6c:78 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3
       valid_lft 85994sec preferred_lft 85994sec
    inet6 fe80::98:b0ff:fe9b:6c78/64 scope link
       valid_lft forever preferred_lft forever
3: docker0: &amp;lt;NO-CARRIER,BROADCAST,MULTICAST,UP&amp;gt; mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:e5:72:10:c0 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;Run docker in host mode, and you will see it lists out the same set of interfaces.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# check the network interfaces in the container
docker run --net=host -it --rm alpine ip addr

1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: enp0s3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 02:98:b0:9b:6c:78 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3
       valid_lft 85994sec preferred_lft 85994sec
    inet6 fe80::98:b0ff:fe9b:6c78/64 scope link
       valid_lft forever preferred_lft forever
3: docker0: &amp;lt;NO-CARRIER,BROADCAST,MULTICAST,UP&amp;gt; mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:e5:72:10:c0 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;2. Bridge Networking (&lt;/strong&gt; — net=bridge/default*&lt;em&gt;):&lt;/em&gt;* In this mode, the default bridge is used as the bridge for containers to connect to each other.The container runs in an isolated network namespace. Communication is open to other containers in the same network. Communication with services outside of the host goes through network address translation (NAT) before exiting the host. We’ve already seen above, the creation of a bridge network.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# check the network interfaces in the container
docker run --net=bridge -it --rm alpine ip addr

1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
16: eth0@if17: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu 1500 qdisc noqueue state UP
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;You can notice that there is an eth0 veth pair that has been created for this container and the corresponding pair should exist on the host machine&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# check the network interfaces on the host
ip addr

21: veth8a812a3@if20: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue master docker0 state UP group default
    link/ether d2:c4:4e:d4:08:ad brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet6 fe80::d0c4:4eff:fed4:8ad/64 scope link
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;3. Custom bridge network (&lt;/strong&gt; — network=xxx*&lt;em&gt;):&lt;/em&gt;* This is the same as Bridge Networking but uses a custom bridge explicitly created for containers.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# create custom bridge
docker network create foo
2b25342b1d883dd134ed8a36e3371ef9c3ec77cdb9e24a0365165232e31b17b6

# check the bridge interface on the host
22: br-2b25342b1d88: &amp;lt;NO-CARRIER,BROADCAST,MULTICAST,UP&amp;gt; mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:49:79:07:30 brd ff:ff:ff:ff:ff:ff
    inet 172.18.0.1/16 brd 172.18.255.255 scope global br-2b25342b1d88
       valid_lft forever preferred_lft forever
    inet6 fe80::42:49ff:fe79:730/64 scope link
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;You can see that on the custom creation of a bridge, a bridge interface is added to the host. Now, all containers in a custom bridge can communicate with the ports of other containers on that bridge. This provides better isolation and security.&lt;/p&gt;

&lt;p&gt;Now let’s run two containers in different terminals&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# terminal 1
docker run -it --rm --name=container1 --network=foo alpine sh

# terminal 2
docker run -it --rm --name=container2 --network=foo alpine sh

# check the network interfaces on the host
ip addr

22: br-2b25342b1d88: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default
    link/ether 02:42:49:79:07:30 brd ff:ff:ff:ff:ff:ff
    inet 172.18.0.1/16 brd 172.18.255.255 scope global br-2b25342b1d88
       valid_lft forever preferred_lft forever
    inet6 fe80::42:49ff:fe79:730/64 scope link
       valid_lft forever preferred_lft forever
30: veth86ca323@if29: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue master br-2b25342b1d88 state UP group default
    link/ether 1e:5e:66:ea:47:1e brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet6 fe80::1c5e:66ff:feea:471e/64 scope link
       valid_lft forever preferred_lft forever
32: vethdf5e755@if31: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue master br-2b25342b1d88 state UP group default
    link/ether ba:2b:25:23:a3:40 brd ff:ff:ff:ff:ff:ff link-netnsid 1
    inet6 fe80::b82b:25ff:fe23:a340/64 scope link
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;As expected, with bridge networking, both containers (container1, container2) have got their respective veth (veth86ca323, vethdf5e755) cable attached. You can verify this bridge simply by running:&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# you can notice both the containers are connected via the same bridge
brctl show br-2b25342b1d88

bridge name bridge id       STP enabled interfaces
br-2b25342b1d88     8000.024249790730   no  veth86ca323
                            vethdf5e755
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;4. Container-defined Networking(&lt;/strong&gt; — net=container:$container2*&lt;em&gt;):&lt;/em&gt;* With this enabled, the container created shares its network namespace with the container called $container2.&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;# create a container in terminal 1
docker run -it --rm --name=container1  alpine sh

# ip addr
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
33: eth0@if34: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu 1500 qdisc noqueue state UP
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever

# create a container in terminal 1
docker run -it --rm --name=container2 --network=container:container1 alpine ip addr

1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
33: eth0@if34: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu 1500 qdisc noqueue state UP
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;You can see that both the container share the same network interface.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5. No networking:&lt;/strong&gt; This option disables all networking for the container&lt;/p&gt;

&lt;div class="highlight js-code-highlight"&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;docker run --net=none alpine ip addr

1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;You can notice that only the lo (loopback) interface is enabled, nothing else is configured in this container.&lt;/p&gt;

&lt;p&gt;In the next article, we will dive deeper (inshaAllah) into how docker manipulates iptables rules to provide network isolation.&lt;/p&gt;

</description>
      <category>kubernetes</category>
      <category>docker</category>
      <category>networking</category>
      <category>linux</category>
    </item>
  </channel>
</rss>
