<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <title>The Verge -  Apples</title>
  <icon>https://cdn.vox-cdn.com/community_logos/52801/VER_Logomark_32x32..png</icon>
  <updated>2021-08-07T15:55:22-04:00</updated>
  <id>https://www.theverge.com/rss/apple/index.xml</id>
  <link type="text/html" href="https://www.theverge.com/apple" rel="alternate"/>
  <entry>
    <published>2021-08-07T15:55:22-04:00</published>
    <updated>2021-08-07T15:55:22-04:00</updated>
    <title>WhatsApp lead and other tech experts fire back at Apple’s Child Safety plan</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/TGtA_nWVkDJWCy43HTsdInDqf6Q=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69691082/acastro_170731_1777_0006_v4.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="ai81Iq"&gt;The chorus of voices expressing concern and dismay over &lt;a href="https://www.apple.com/child-safety/"&gt;Apple’s new Child Safety measures&lt;/a&gt; grew louder over the weekend, as an open letter with more than 4,000 signatures made the rounds online. &lt;a href="https://appleprivacyletter.com/"&gt;The Apple Privacy Letter&lt;/a&gt; asked the iPhone maker to “reconsider its technology rollout,” lest it undo “decades of work by technologists, academics and policy advocates” on privacy-preserving measures.&lt;/p&gt;
&lt;p id="UPWw1g"&gt;Apple’s plan, &lt;a href="https://www.theverge.com/2021/8/5/22611721/apple-csam-child-abuse-scanning-hash-system-ncmec"&gt;which it announced on Thursday&lt;/a&gt;, involves taking hashes of images uploaded to iCloud and comparing them to a database that contains hashes of known CSAM images. According to Apple, this allows it to keep user data encrypted and &lt;a href="https://twitter.com/reneritchie/status/1423726172849033216?s=20"&gt;run the analysis on-device&lt;/a&gt; while still allowing it to report users to the authorities if they’re found to be sharing child abuse imagery. Another prong of Apple’s Child Safety strategy involves optionally warning parents if their child &lt;a href="https://twitter.com/rsgnl/status/1423389211542032384"&gt;under 13 years old&lt;/a&gt; sends or views photos containing sexually explicit content. &lt;a href="https://www.theverge.com/2021/8/6/22612934/apple-vp-memo-concerns-privacy-new-scanning-photos-images-ios"&gt;An internal memo at Apple&lt;/a&gt; acknowledged that people would be “worried about the implications” of the systems.&lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="1dseaO"&gt;&lt;q&gt;Cathcart calls Apple’s approach “very concerning,” and he’s not alone&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="yIGcHp"&gt;&lt;a href="https://twitter.com/wcathcart/status/1423701473624395784?s=20"&gt;WhatsApp’s head Will Cathcart&lt;/a&gt; said in a Twitter thread that his company wouldn’t be adopting the safety measures, &lt;a href="https://twitter.com/wcathcart/status/1423701476841385988?s=20"&gt;calling Apple’s approach&lt;/a&gt; “very concerning.” Cathcart said WhatsApp’s system to fight child exploitation, which partly utilizes user reports, preserves encryption like Apple’s and has led to the company &lt;a href="https://twitter.com/wcathcart/status/1423701475595755524?s=20"&gt;reporting over 400,000 cases&lt;/a&gt; to the National Center for Missing and Exploited Children in 2020. (Apple is also working with the Center for its CSAM detection efforts.)&lt;/p&gt;
&lt;p id="iuhKXJ"&gt;WhatsApp’s owner, Facebook, has reasons to pounce on Apple for privacy concerns. Apple’s &lt;a href="https://www.theverge.com/2021/4/27/22405474/apple-app-tracking-transparency-ios-14-5-privacy-update-facebook-data"&gt;changes to how ad tracking works in iOS 14.5&lt;/a&gt; started a fight between the two companies, with Facebook &lt;a href="https://www.theverge.com/2020/12/16/22178068/facebook-apple-newspaper-ads-ios-privacy-changes"&gt;buying newspaper ads&lt;/a&gt; criticizing Apple’s privacy changes as harmful to small businesses. &lt;a href="https://www.theverge.com/2020/12/16/22179721/apple-defends-upcoming-privacy-changes-standing-up-for-users-facebook-data"&gt;Apple fired back&lt;/a&gt;, saying that the change “simply requires” that users be given a choice on whether to be tracked.&lt;/p&gt;
&lt;p id="7HaVEp"&gt;The list of people and organizations raising concerns about Apple’s policy includes Edward Snowden, the Electronic Frontier Foundation, professors, and more. We’ve collected some of those reactions here to act as an overview of some of the criticisms levied against Apple’s new policy.&lt;/p&gt;
&lt;hr class="p-entry-hr" id="TJSuYM"&gt;
&lt;p id="ZZcaWR"&gt;Matthew Green, an associate professor at Johns Hopkins University, pushed back on the feature before it was publicly announced. He tweeted about Apple’s plans and about how the hashing system could be abused by governments and malicious actors.&lt;/p&gt;
&lt;div id="My9zJN"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;These tools will allow Apple to scan your iPhone photos for photos that match a specific perceptual hash, and report them to Apple servers if too many appear.&lt;/p&gt;— Matthew Green (@matthew_d_green) &lt;a href="https://twitter.com/matthew_d_green/status/1423072476888805376?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="AKpR2F"&gt;The EFF &lt;a href="https://www.eff.org/deeplinks/2021/08/apples-plan-think-different-about-encryption-opens-backdoor-your-private-life"&gt;released a statement&lt;/a&gt; that blasted Apple’s plan, more or less calling it a “thoroughly documented, carefully thought-out, and narrowly-scoped backdoor.” The EFF’s press release goes into detail on how it believes Apple’s Child Safety measures could be abused by governments and how they decrease user privacy.&lt;/p&gt;
&lt;div id="jacoNW"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;Apple's filtering of iMessage and iCloud is not a slippery slope to backdoors that suppress speech and make our communications less secure. We’re already there: this is a fully-built system just waiting for external pressure to make the slightest change. &lt;a href="https://t.co/f2nv062t2n"&gt;https://t.co/f2nv062t2n&lt;/a&gt;&lt;/p&gt;— EFF (@EFF) &lt;a href="https://twitter.com/EFF/status/1423375818693038084?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="Yuo1qD"&gt;Kendra Albert, an instructor at Harvard’s Cyberlaw Clinic, has a thread on the potential dangers to queer children and Apple’s initial lack of clarity around age ranges for the parental notifications feature.&lt;/p&gt;
&lt;div id="6bBV1n"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;The idea that parents are safe people for teens to have conversations about sex or sexting with is admirable, but in many cases, not true. (And as far as I can tell, this stuff doesn't just apply to kids under the age for 13.)&lt;/p&gt;— Kendra Albert (@KendraSerra) &lt;a href="https://twitter.com/KendraSerra/status/1423367106972852228?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id="p5xtGT"&gt;
&lt;blockquote class="twitter-tweet" data-conversation="none"&gt;
&lt;p lang="en" dir="ltr"&gt;EFF reports that the iMessage nudity notifications will not go to parents if the kid is between 13-17 but that is not anywhere in the Apple documentation that I can find. &lt;a href="https://t.co/Ma1BdyqZfW"&gt;https://t.co/Ma1BdyqZfW&lt;/a&gt;&lt;/p&gt;— Kendra Albert (@KendraSerra) &lt;a href="https://twitter.com/KendraSerra/status/1423436593696854018?ref_src=twsrc%5Etfw"&gt;August 6, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="CEqw4k"&gt;Edward Snowden retweeted the &lt;em&gt;Financial Time&lt;/em&gt;s article about the system, giving his own characterization of what Apple is doing.&lt;/p&gt;
&lt;div id="CCaMt8"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;Apple plans to modify iPhones to constantly scan for contraband: &lt;br&gt;&lt;br&gt;“It is an absolutely appalling idea, because it is going to lead to distributed bulk surveillance of our phones and laptops,” said Ross Anderson, professor of security engineering. &lt;a href="https://t.co/rS92HR3pUZ"&gt;https://t.co/rS92HR3pUZ&lt;/a&gt;&lt;/p&gt;— Edward Snowden (@Snowden) &lt;a href="https://twitter.com/Snowden/status/1423387232963022848?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="sceSPL"&gt;Politician Brianna Wu called the system “the worst idea in Apple History.”&lt;/p&gt;
&lt;div id="wB779u"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;This is the worst idea in Apple history, and I don't say that lightly.&lt;br&gt;&lt;br&gt;It destroys their credibility on privacy. It will be abused by governments. It will get gay children killed and disowned. This is the worst idea ever. &lt;a href="https://t.co/M2EIn2jUK2"&gt;https://t.co/M2EIn2jUK2&lt;/a&gt;&lt;/p&gt;— Brianna Wu (@BriannaWu) &lt;a href="https://twitter.com/BriannaWu/status/1423384759858774026?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id="H0QULK"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;Just to state: Apple's scanning does not detect photos of child abuse. It detects a list of known banned images added to a database, which are initially child abuse imagery found circulating elsewhere. What images are added over time is arbitrary. It doesn't know what a child is.&lt;/p&gt;— SoS (@SwiftOnSecurity) &lt;a href="https://twitter.com/SwiftOnSecurity/status/1423383256003747840?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="r1g6Co"&gt;Writer Matt Blaze also tweeted about the concerns that the technology could be abused by overreaching governments, trying to prevent content other than CSAM.&lt;/p&gt;
&lt;div id="PouZDU"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;In other words, not only does the policy have to be exceptionally robust, so does the implementation.&lt;/p&gt;— matt blaze (@mattblaze) &lt;a href="https://twitter.com/mattblaze/status/1423476875817635840?ref_src=twsrc%5Etfw"&gt;August 6, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="rvN3WU"&gt;Epic CEO Tim Sweeney also criticized Apple, saying that the company “vacuums up everybody’s data into iCloud by default.” He also promised to share more thoughts specifically about Apple’s Child Safety system.&lt;/p&gt;
&lt;div id="wfglq3"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;It’s atrocious how Apple vacuums up everybody’s data into iCloud by default, hides the 15+ separate options to turn parts of it off in Settings underneath your name, and forces you to have an unwanted email account. Apple would NEVER allow a third party to ship an app like this.&lt;/p&gt;— Tim Sweeney (@TimSweeneyEpic) &lt;a href="https://twitter.com/TimSweeneyEpic/status/1423728945225211908?ref_src=twsrc%5Etfw"&gt;August 6, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id="kuuOuE"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;I will share some very detailed thoughts on this related topic later.&lt;/p&gt;— Tim Sweeney (@TimSweeneyEpic) &lt;a href="https://twitter.com/TimSweeneyEpic/status/1423730378234376206?ref_src=twsrc%5Etfw"&gt;August 6, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="7YCGmI"&gt;Not every reaction has been critical, however. Ashton Kutcher (who has done &lt;a href="https://thecnnfreedomproject.blogs.cnn.com/2011/04/14/moore-kutcher-join-our-crusade-to-end-child-sex-trafficking/"&gt;advocacy work to end child sex trafficking since 2011&lt;/a&gt;) calls Apple’s work “a major step forward” for efforts to eliminate CSAM.&lt;/p&gt;
&lt;div id="SFDxLg"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;I believe in privacy - including for kids whose sexual abuse is documented and spread online without consent. These efforts announced by &lt;a href="https://twitter.com/Apple?ref_src=twsrc%5Etfw"&gt;@Apple&lt;/a&gt; are a major step forward in the fight to eliminate CSAM from the internet. &lt;a href="https://t.co/TQIxHlu4EX"&gt;https://t.co/TQIxHlu4EX&lt;/a&gt;&lt;/p&gt;— ashton kutcher (@aplusk) &lt;a href="https://twitter.com/aplusk/status/1423387418451922950?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/6/22613365/apple-icloud-csam-scanning-whatsapp-surveillance-reactions"/>
    <id>https://www.theverge.com/2021/8/6/22613365/apple-icloud-csam-scanning-whatsapp-surveillance-reactions</id>
    <author>
      <name>Mitchell Clark</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-06T18:47:42-04:00</published>
    <updated>2021-08-06T18:47:42-04:00</updated>
    <title>Spotify says it plans to add AirPlay 2 to its iOS app — eventually</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/DDD20yR_WaPMtNUO2rsOrGSinnc=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69690480/acastro_180213_1777_0004.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="qolgag"&gt;Spotify still hasn’t added AirPlay 2 support to its iOS app — but despite the delay, it’s still “working to make [it] a reality,” the company tells &lt;em&gt;The Verge&lt;/em&gt;. Some doubt was cast on AirPlay 2 inclusion when &lt;a href="https://www.macrumors.com/2021/08/06/spotify-pauses-airplay-2-support-for-ios-app/"&gt;&lt;em&gt;MacRumors&lt;/em&gt; spotted a forum post&lt;/a&gt; where a Spotify forum moderator claimed that &lt;a href="https://community.spotify.com/t5/Closed-Ideas/iOS-Airplay-2-Support-for-iOS/idc-p/5244350/highlight/true#M235171"&gt;“audio driver compatibility issues”&lt;/a&gt; might mean the feature wouldn’t be added for the foreseeable future. Spotify now claims that’s wrong.&lt;/p&gt;
&lt;p id="lIlb4R"&gt;&lt;em&gt;The Verge&lt;/em&gt; received the following statement from Spotify regarding AirPlay 2:&lt;/p&gt;
&lt;blockquote&gt;&lt;p id="l6Ose4"&gt;A post on one of Spotify’s Community pages contained incomplete information regarding our plans for AirPlay2. Spotify will support AirPlay2 and we’re working to make that a reality.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p id="5hM8lP"&gt;AirPlay 2, &lt;a href="https://www.theverge.com/2018/5/29/17403684/airplay-2-ios-114-stereo-homepod-available-now"&gt;added as part of iOS 11 update&lt;/a&gt;, introduced multiroom audio, Siri voice control, and fairly broad support across a wide swath of speakers, &lt;a href="https://www.theverge.com/2019/1/8/18173637/tv-airplay-2-apple-lg-samsung-sony-vizio-ces-2019"&gt;televisions&lt;/a&gt;, and streaming services. It was a real first for Apple’s “casting” feature, which had previously been somewhat poorly supported outside of Apple’s own devices. &lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="BIY2Ct"&gt;&lt;q&gt;I’m not going to call it petty, but...&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="w59IH1"&gt;Spotify has its own way to get audio from its service to other devices in the form of &lt;a href="https://www.spotify.com/us/connect/"&gt;Spotify Connect&lt;/a&gt;, but considering Spotify already supports Google Cast, skipping Apple’s newest streaming protocol would seem like an odd omission. As &lt;em&gt;MacRumors&lt;/em&gt; notes, Apple provides a seemingly simple &lt;a href="https://developer.apple.com/documentation/avfoundation/media_playback_and_selection/getting_airplay_2_into_your_app"&gt;four step developer document&lt;/a&gt; explaining how to enable the feature. However, &lt;a href="https://twitter.com/marcoarment/status/1423744958541058052?s=20"&gt;developer Marco Arment points&lt;/a&gt; out that the fourth step (adopting a new API that supports enhanced buffering) is a bigger hurdle than it appears. &lt;/p&gt;
&lt;div id="BhtYf6"&gt;
&lt;blockquote class="twitter-tweet" data-conversation="none"&gt;
&lt;p lang="en" dir="ltr"&gt;…and that new API:&lt;br&gt;&lt;br&gt;- is barely documented&lt;br&gt;&lt;br&gt;- has no public sample code&lt;br&gt;&lt;br&gt;- is full of major gotchas&lt;br&gt;&lt;br&gt;- can’t change speeds seamlessly&lt;br&gt;&lt;br&gt;- doesn’t provide precise timing&lt;br&gt;&lt;br&gt;- requires much more complex logic&lt;br&gt;&lt;br&gt;- is less efficient, which can cause background CPU-overage terminations&lt;/p&gt;— Marco Arment (@marcoarment) &lt;a href="https://twitter.com/marcoarment/status/1423744958541058052?ref_src=twsrc%5Etfw"&gt;August 6, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="d6ALoR"&gt;But add in that Spotify has a less-than-friendly relationship with Apple, even going as far as &lt;a href="https://www.theverge.com/2019/3/13/18263453/spotify-apple-app-store-antitrust-complaint-ec-30-percent-cut-unfair"&gt;filing an antitrust complaint&lt;/a&gt; and &lt;a href="https://www.theverge.com/22457400/spotify-horacio-gutierrez-apple-app-store-interview-decoder"&gt;publicly calling it a bully&lt;/a&gt;, and a choice to not prioritize incorporating AirPlay 2 makes even more sense. It’s good that it’s still happening, but for any Spotify subscriber on iOS, it’s hard to not feel like you’re caught in the crossfire between two tech giants on the outs. &lt;/p&gt;
&lt;p id="XlsirN"&gt;&lt;em&gt;&lt;strong&gt;Update August 6th, 6:47PM ET:&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt; &lt;/strong&gt;&lt;em&gt;Changed headline and added statement from Spotify confirming it is working on AirPlay2 support.&lt;/em&gt;&lt;/p&gt;
&lt;p id="2tmCRK"&gt;&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/6/22613420/spotify-airplay2-support-audio-issues-drivers"/>
    <id>https://www.theverge.com/2021/8/6/22613420/spotify-airplay2-support-audio-issues-drivers</id>
    <author>
      <name>Ian Carlos Campbell</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-06T12:01:35-04:00</published>
    <updated>2021-08-06T12:01:35-04:00</updated>
    <title>Apple VP acknowledges concerns about new scanning feature in internal memo</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/VSGhQl7q43Qpftf2KZ6WSgH_o0I=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69688995/acstro_190902_apple_event_0004.0.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="OrjUON"&gt;Apple’s &lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.apple.com%2Fchild-safety%2F&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F2021%2F8%2F6%2F22612934%2Fapple-vp-memo-concerns-privacy-new-scanning-photos-images-ios" rel="sponsored nofollow noopener" target="_blank"&gt;forthcoming feature&lt;/a&gt; that will scan iOS devices for images of child abuse is an “important mission,” a software vice president at the company wrote in an internal memo. First reported by&lt;a href="https://9to5mac.com/2021/08/06/apple-internal-memo-icloud-photo-scanning-concerns/"&gt; &lt;em&gt;9to5 Mac&lt;/em&gt;&lt;/a&gt;, the memo by Sebastian Marineau-Mes acknowledges that the new protections have some people “worried about the implications” but that the company will “maintain Apple’s deep commitment to user privacy.”&lt;/p&gt;
&lt;p id="8Ig9yv"&gt;As part of its Expanded Protections for Children, &lt;a href="https://www.theverge.com/2021/8/5/22611721/apple-csam-child-abuse-scanning-hash-system-ncmec"&gt;Apple plans to scan images&lt;/a&gt; on iPhones and other devices before they are uploaded to iCloud. If it finds an image that matches one in the database of the National Center for Missing and Exploited Children (NCMEC), a human at Apple will review the image to confirm whether it contains child pornography. If it’s confirmed, NCMEC will be notified and the user’s account will be disabled. &lt;/p&gt;
&lt;p id="3HB3oD"&gt;The announcement raised concerns among privacy advocates who questioned how Apple could prevent the system from being exploited by bad actors. The Electronic Frontier Foundation &lt;a href="https://www.eff.org/deeplinks/2021/08/apples-plan-think-different-about-encryption-opens-backdoor-your-private-life"&gt;said in a statement&lt;/a&gt; that “it’s impossible to build a client-side scanning system that can only be used for sexually explicit images sent or received by children” and that the system, however well-intended, “will break key promises of the messenger’s encryption itself and open the door to broader abuses.”&lt;/p&gt;
&lt;p id="7BFvDx"&gt;According to &lt;em&gt;9to5Mac&lt;/em&gt;, Marineau-Mes wrote in the memo that the project involved “deep cross-functional commitment” across the company that “delivers tools to protect children, but also maintain Apple’s deep commitment to user privacy.”&lt;/p&gt;
&lt;p id="uGfQad"&gt;Apple did not immediately reply to a request for comment Friday.&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/6/22612934/apple-vp-memo-concerns-privacy-new-scanning-photos-images-ios"/>
    <id>https://www.theverge.com/2021/8/6/22612934/apple-vp-memo-concerns-privacy-new-scanning-photos-images-ios</id>
    <author>
      <name>Kim Lyons</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-05T17:59:34-04:00</published>
    <updated>2021-08-05T17:59:34-04:00</updated>
    <title>IMDb TV app finally arrives on iOS and Android</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/YWBqDDedP4ZmG3dxwZYKciScfbY=/0x157:947x788/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69685791/iOS_Image.0.jpg" /&gt;
        &lt;figcaption&gt;Image: IMDb TV&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="jKRoK9"&gt;Amazon’s free streaming service IMDb TV now has its own dedicated app for the iPhone, iPad, and Android after launching on other major platforms earlier this year. &lt;/p&gt;
&lt;p id="43jTsV"&gt;IMDb TV is a dedicated hub for free, ad-supported movies and series as well as its own dedicated originals produced by Amazon Studios. Previously, you could find IMDb TV’s content slate in the primary IMDb app, but a standalone streaming app for the service was not available for iOS and Android. A spokesperson told &lt;em&gt;The Verge&lt;/em&gt; the content is still available to stream through IMDb, but the new IMDb TV app was “designed for the streaming experience.”&lt;/p&gt;
&lt;p id="4C2Opp"&gt;IMDb TV’s content slate is quite good, even if its originals have struggled to make as much of a splash as titles from larger premium services. But if you don’t mind ads, there’s a ton of great stuff to stream for free on the service, including documentaries, sci-fi titles, dramas, and plenty of TV to binge. &lt;em&gt;Mad Men&lt;/em&gt;, &lt;em&gt;How to Train Your Dragon&lt;/em&gt;, &lt;em&gt;Schitt’s Creek&lt;/em&gt;, and &lt;em&gt;Lost&lt;/em&gt; are all currently streamable on the service. &lt;/p&gt;
&lt;p id="RxmqnT"&gt;Plus, through a recently announced deal with Universal, IMDb TV will also &lt;a href="https://www.theverge.com/2021/7/9/22570590/universal-films-prime-video-streaming-peacock"&gt;exclusively stream&lt;/a&gt; some live-action and animated titles from the studio following their release in theaters and a brief pay-one premiere on Peacock.&lt;/p&gt;
&lt;p id="gEuOWw"&gt;The app was previously made available on the majority of major streaming devices and some smart TVs, including Fire TV, Roku, Xbox, Android TV, Android TV OS devices, newer LG Smart TVs, PlayStation 4, Chromecast with Google TV, and Nvidia Shield. It’s also available as a free channel within the Prime Video experience.&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/5/22611993/imdb-tv-mobile-app-ios-ipad-android"/>
    <id>https://www.theverge.com/2021/8/5/22611993/imdb-tv-mobile-app-ios-ipad-android</id>
    <author>
      <name>Catie Keck</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-05T16:02:58-04:00</published>
    <updated>2021-08-05T16:02:58-04:00</updated>
    <title>Apple reveals new efforts to fight child abuse imagery</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/gok31hxdir1iv9lGvMHre9icNaQ=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69685176/acastro_180130_1777_0005_v2.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="ijVtvE"&gt;In a briefing on Thursday afternoon, Apple confirmed &lt;a href="https://www.theverge.com/2021/8/5/22611305/apple-scan-photos-iphones-icloud-child-abuse-imagery-neuralmatch"&gt;previously reported plans&lt;/a&gt; to deploy new technology within iOS, macOS, watchOS, and iMessage that will detect potential child abuse imagery, but clarified crucial details from the ongoing project. For devices in the US, new versions of iOS and iPadOS rolling out this fall have “new applications of cryptography to help limit the spread of CSAM [child sexual abuse material] online, while designing for user privacy.” &lt;/p&gt;
&lt;p id="wVAAte"&gt;The project is also detailed in &lt;a href="https://www.apple.com/child-safety/"&gt;a new “Child Safety” page on Apple’s website&lt;/a&gt;. The most invasive and potentially controversial implementation is the system that performs on-device scanning before an image is backed up in iCloud. From the description, scanning does not occur until a file is getting backed up to iCloud, and Apple only receives data about a match if the cryptographic vouchers (uploaded to iCloud along with the image) for a particular account meet a threshold of matching known CSAM.&lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="s7c9Mt"&gt;&lt;q&gt;Apple described several restrictions that are included to protect privacy&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="MWQ3zI"&gt;For years, Apple has used hash systems to scan for child abuse imagery sent over email, in line with similar systems at Gmail and other cloud email providers. The program announced today will apply the same scans to user images stored in iCloud Photos, even if the images are never sent to another user or otherwise shared.&lt;/p&gt;
&lt;p id="TVFdM5"&gt;In a &lt;a href="https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf"&gt;PDF&lt;/a&gt; provided along with the briefing, Apple justified its moves for image scanning by describing several restrictions that are included to protect privacy:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p id="SWQhU3"&gt;Apple does not learn anything about images that do not match the known CSAM&lt;/p&gt;
&lt;p id="mnepX8"&gt;database.&lt;/p&gt;
&lt;p id="eyjJWd"&gt;Apple can’t access metadata or visual derivatives for matched CSAM images until a&lt;/p&gt;
&lt;p id="eFPm9k"&gt;threshold of matches is exceeded for an iCloud Photos account.&lt;/p&gt;
&lt;p id="8hlnFE"&gt;The risk of the system incorrectly flagging an account is extremely low. In addition,&lt;/p&gt;
&lt;p id="YWYbmK"&gt;Apple manually reviews all reports made to NCMEC to ensure reporting accuracy.&lt;/p&gt;
&lt;p id="o7XIpC"&gt;Users can’t access or view the database of known CSAM images.&lt;/p&gt;
&lt;p id="kNtzsj"&gt;Users can’t identify which images were flagged as CSAM by the system&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p id="xsxTtI"&gt;The new details build on concerns leaked earlier this week, but also add a number of safeguards that should guard against the privacy risks of such a system. In particular, the threshold system ensures that lone errors will not generate alerts, allowing apple to target an error rate of one false alert per trillion users per year. The hashing system is also limited to material flagged by the National Center for Missing and Exploited Children (NCMEC), and images uploaded to iCloud Photos. Once an alert is generated, it is reviewed by Apple and NCMEC before alerting law enforcement, providing an additional safeguard against the system being used to detect non-CSAM content.&lt;/p&gt;
&lt;p id="E5RQd2"&gt;Apple commissioned technical assessments of the system from three independent cryptographers (&lt;a href="https://www.apple.com/child-safety/pdf/Technical_Assessment_of_CSAM_Detection_Benny_Pinkas.pdf"&gt;PDFs 1&lt;/a&gt;, &lt;a href="https://www.apple.com/child-safety/pdf/Technical_Assessment_of_CSAM_Detection_David_Forsyth.pdf"&gt;2&lt;/a&gt;, and &lt;a href="https://www.apple.com/child-safety/pdf/Technical_Assessment_of_CSAM_Detection_Mihir_Bellare.pdf"&gt;3&lt;/a&gt;), who found it to be mathematically robust. “In my judgement this system will likely significantly increase the likelihood that people who own or traffic in such pictures (harmful users) are found; this should help protect children,” said professor David Forsyth, chair of computer science at University of Illinois, in &lt;a href="https://www.apple.com/child-safety/pdf/Technical_Assessment_of_CSAM_Detection_David_Forsyth.pdf"&gt;one of the assessments&lt;/a&gt;. “The accuracy of the matching system, combined with the threshold, makes it very unlikely that pictures that are not known CSAM pictures will be revealed.”&lt;/p&gt;
&lt;p id="DNvsmU"&gt;However, Apple said other child safety groups were likely to be added as hash sources as the program expands, and the company did not commit to making the list of partners publicly available going forward. That is likely to heighten anxieties about how the system might be exploited by the Chinese government, which has long sought greater access to iPhone user data within the country.&lt;/p&gt;
&lt;p id="iVILkJ"&gt;&lt;/p&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt="Sample Messages warning for children and parents when sexually explicit photos are detected" data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/YMgiqX4ORjTh6vSUvHOAFrLTHr8=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22764418/child_safety__evd7tla79kqe_large.jpg"&gt;
      &lt;cite&gt;Photo: Apple&lt;/cite&gt;
      &lt;figcaption&gt;&lt;em&gt;Sample Messages warning for children and parents when sexually explicit photos are detected.&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;p id="erd5tl"&gt;Alongside the new measures in iCloud Photos, Apple added two additional systems to protect young iPhone owners at risk of child abuse. The Messages app already did on-device scanning of image attachments for children’s accounts to detect content that’s potentially sexually explicit. Once detected, the content is blurred and a warning appears. A new setting that parents can enable on their family iCloud accounts will trigger a message telling the child that if they view (incoming) or send (outgoing) the detected image, their parents will get a message about it.&lt;/p&gt;
&lt;p id="obkAvI"&gt;Apple is also updating how Siri and the Search app respond to queries about child abuse imagery. Under the new system, the apps “will explain to users that interest in this topic is harmful and problematic, and provide resources from partners to get help with this issue.”&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/5/22611721/apple-csam-child-abuse-scanning-hash-system-ncmec"/>
    <id>https://www.theverge.com/2021/8/5/22611721/apple-csam-child-abuse-scanning-hash-system-ncmec</id>
    <author>
      <name>Russell Brandom</name>
      <name>Richard Lawler</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-05T12:55:26-04:00</published>
    <updated>2021-08-05T12:55:26-04:00</updated>
    <title>Apple will scan photos stored on iPhones and iCloud for child abuse imagery</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="The iPhone 12, in blue." src="https://cdn.vox-cdn.com/thumbor/KsFKmmiIIY2DKiRyCwL_H-zqdNk=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69683696/vpavic_4243_20201018_0121.0.0.jpg" /&gt;
        &lt;figcaption&gt;Photo by Vjeran Pavic / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="Eo4wHZ"&gt;&lt;em&gt;&lt;strong&gt;Update August 5th, 3:21PM ET:&lt;/strong&gt;&lt;/em&gt;&lt;em&gt; Apple has announced more about what the &lt;/em&gt;Financial Times&lt;em&gt; reported and revealed new tools coming to iMessage that warn children about sexually explicit photos. The new features will be coming later this year as updates to iOS 15, iPadOS 15, watchOS 8, and macOS Monterey. You can read &lt;/em&gt;&lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.apple.com%2Fchild-safety%2F&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F2021%2F8%2F5%2F22611305%2Fapple-scan-photos-iphones-icloud-child-abuse-imagery-neuralmatch" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;em&gt;more about them on Apple’s website&lt;/em&gt;&lt;/a&gt;&lt;em&gt;. Our original article follows.&lt;/em&gt;&lt;/p&gt;
&lt;hr class="p-entry-hr" id="1GNi4O"&gt;
&lt;p id="yUDRuC"&gt;Apple plans to scan photos stored on iPhones and iCloud for child abuse imagery, &lt;a href="https://www.ft.com/content/14440f81-d405-452f-97e2-a81458f5411f?accessToken=zwAAAXsXFw3Akc8URA-B1AVFL9OX4qgUWPVBHw.MEQCIAlL-dncQ3QfMOhh2uX_WQcMbz9dxjkEyYqIbvpX7pNnAiBPOFPraAkWgtfFk9Z_X3XiV5f1-mI4Mvos0mL8SCQqUg&amp;amp;sharetype=gift?token=076dc4a2-d758-4db8-8114-bc29b71cf72f"&gt;according the &lt;em&gt;Financial Times&lt;/em&gt;&lt;/a&gt;. The new system could help law enforcement in criminal investigations but may open the door to increased legal and government demands for user data.&lt;/p&gt;
&lt;p id="qCd5ME"&gt;The system, called neuralMatch, will “proactively alert a team of human reviewers if it believes illegal imagery is detected, who would then contact law enforcement if the material can be verified,” the &lt;em&gt;Financial Times&lt;/em&gt; said. neuralMatch, which was trained using 200,000 images from the National Center for Missing &amp;amp; Exploited Children, will roll out first in the US. Photos will be hashed and compared with a database of known images of child sexual abuse. &lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="pv6k39"&gt;&lt;q&gt;The system will be used first in the US&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="VByGry"&gt;“According to people briefed on the plans, every photo uploaded to iCloud in the US will be given a ‘safety voucher,’ saying whether it is suspect or not,” the &lt;em&gt;Financial Times&lt;/em&gt; said. “Once a certain number of photos are marked as suspect, Apple will enable all the suspect photos to be decrypted and, if apparently illegal, passed on to the relevant authorities.”&lt;/p&gt;
&lt;p id="id__uo580rn63xk"&gt;John Hopkins University professor and cryptographer Matthew Green raised concerns about the system on Twitter Wednesday night. “This sort of tool can be a boon for finding child pornography in people’s phones,” &lt;a href="https://twitter.com/matthew_d_green/status/1423075906894106625"&gt;Green said&lt;/a&gt;. “But imagine what it could do in the hands of an authoritarian government?”&lt;/p&gt;
&lt;p id="XIfczG"&gt;“Even if you believe Apple won’t allow these tools to be misused [crossed fingers emoji] there’s still a lot to be concerned about,” &lt;a href="https://twitter.com/matthew_d_green/status/1423079067805495296"&gt;he added&lt;/a&gt;. “These systems rely on a database of ‘problematic media hashes’ that you, as a consumer, can’t review.”&lt;/p&gt;
&lt;p id="6eIhPA"&gt;Apple already checks iCloud files against known child abuse imagery, like every other major cloud provider. But the system described here would go further, allowing central access to local storage. It would also be trivial to extend the system to crimes other than child abuse — a particular concern given Apple’s extensive business in China.&lt;/p&gt;
&lt;p id="c8MhAK"&gt;The company informed some US academics about it this week, and Apple may share more about the system “as soon as this week,” according to two security researchers who were briefed on Apple’s earlier meeting, the &lt;em&gt;Financial Times&lt;/em&gt; reports.&lt;/p&gt;
&lt;p id="vurNuE"&gt;Apple has previously &lt;a href="https://www.theverge.com/2021/5/20/22446220/apple-privacy-ad-video-ad-tracking-transparency"&gt;touted&lt;/a&gt; the privacy protections built into its devices, and famously &lt;a href="https://www.theverge.com/2016/2/17/11036306/apple-fbi-iphone-encryption-backdoor-tim-cook"&gt;stood up to the FBI&lt;/a&gt; when the agency wanted Apple to build a backdoor into iOS to access an iPhone used by one of the shooters in the 2015 attack in San Bernardino. The company did not respond to a request for comment on the &lt;em&gt;Financial Times&lt;/em&gt; report.&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/5/22611305/apple-scan-photos-iphones-icloud-child-abuse-imagery-neuralmatch"/>
    <id>https://www.theverge.com/2021/8/5/22611305/apple-scan-photos-iphones-icloud-child-abuse-imagery-neuralmatch</id>
    <author>
      <name>Jay Peters</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-05T12:28:04-04:00</published>
    <updated>2021-08-05T12:28:04-04:00</updated>
    <title>Here’s a closer look at Apple’s canceled AirPower wireless charger</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/QQOmG8rcOgnCV7MM-h483vOKNfg=/0x117:3696x2581/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69683450/IMG_9512.0.jpeg" /&gt;
        &lt;figcaption&gt;A working Apple AirPower prototype unit. | Image: &lt;a class="ql-link" href="https://twitter.com/1nsane_dev" target="_blank"&gt;&lt;strong&gt;Giulio Zompetti&lt;/strong&gt;&lt;/a&gt;&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="tAI3fQ"&gt;Apple’s AirPower wireless charger was supposed to arrive with the unique ability to charge an iPhone, Apple Watch, and AirPods all at the same time. Unfortunately, &lt;a href="https://www.theverge.com/circuitbreaker/2019/3/29/18287383/apple-airpower-wireless-charger-cancelled"&gt;Apple canceled AirPower in March 2019&lt;/a&gt;, citing difficulties in bringing the product to life. Since then, we’ve seen a &lt;a href="https://9to5mac.com/2020/08/21/airpower-prototype-teardown-likely-shows-why-apple-never-shipped-the-wireless-charger/"&gt;teardown of AirPower&lt;/a&gt;, some &lt;a href="https://www.theverge.com/circuitbreaker/2020/1/3/21047896/zens-liberty-airpower-clone-16-coils-wireless-charging-pad-mat"&gt;AirPower clones&lt;/a&gt;, and Apple’s &lt;a href="https://www.theverge.com/2021/7/13/22576245/iphone-12-reverse-wireless-charging-magsafe-battery-pack"&gt;MagSafe battery packs&lt;/a&gt;. Now, an Apple prototype collector has obtained a working AirPower unit for the first time.&lt;/p&gt;
&lt;p id="tsrd3I"&gt;Speaking to &lt;em&gt;The Verge&lt;/em&gt;, Giulio Zompetti, a 28-year-old from Italy, says he has been able to purchase a prototype AirPower unit from Chinese e-waste sources. “The unit lacks all of its exterior housing, and shows this beautiful and heavy stainless steel chassis,” says Zompetti.&lt;/p&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt=" " data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/SReGJYMIH7HhoqSVyid8OhAZSYs=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22763582/airpowerprototype.jpg"&gt;
      &lt;cite&gt;Image: &lt;a class="ql-link" href="https://twitter.com/1nsane_dev" target="_blank"&gt;&lt;strong&gt;Giulio Zompetti&lt;/strong&gt;&lt;/a&gt;&lt;/cite&gt;
      &lt;figcaption&gt;&lt;em&gt;The controller circuits on an AirPower prototype.&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;p id="5xgt0x"&gt;In photos supplied to &lt;em&gt;The Verge&lt;/em&gt;, you can see the AirPower mat powering a prototype iPhone, with its 22 coils on the front-facing side and 22 controller circuits on the rear. In order for this AirPower prototype to work, it has to be paired with special prototype iPhone hardware to activate the coils.&lt;/p&gt;
&lt;p id="rmfnSg"&gt;“It doesn’t work with production devices, because the coils are woken up by the device,” explains Zompetti, who says he’s been able to charge two prototype devices simultaneously so far. Zompetti says he received the unit in December and was able to interact with it initially through a serial lightning cable.&lt;/p&gt;
&lt;p id="smo4LO"&gt;“It’s an engineering prototype, it’s not meant for plug and play,” says Zompetti. “When I connected my serial lightning cable to it, I could see some chars on the log, so once I fixed the BAUD rate, I was able to read a comprehensible log.” There’s even an interactive shell to interact with the AirPower, as part of the engineering of the device.&lt;/p&gt;
&lt;div id="tFjSoS"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;AirPower &lt;a href="https://t.co/bv8gi0NiiL"&gt;pic.twitter.com/bv8gi0NiiL&lt;/a&gt;&lt;/p&gt;— Giulio Zompetti (@1nsane_dev) &lt;a href="https://twitter.com/1nsane_dev/status/1423277245381054472?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="YaNDpV"&gt;Apple’s canceled AirPower pad was supposed to let you drop devices anywhere on it to charge thanks to multiple coils, without having to find that specific sweet spot. But various reports suggested &lt;a href="https://www.theverge.com/2018/9/17/17869072/apple-airpower-overheating-issues"&gt;Apple was struggling with overheating issues&lt;/a&gt; during development. “I wasn’t able to reproduce the issue but still can’t say it isn’t there,” says Zompetti.&lt;/p&gt;
&lt;p id="Vl6GFv"&gt;While we haven’t been able to independently verify the AirPower device as it’s extremely rare, Zompetti has a history of collecting Apple prototype hardware. He’s been collecting devices since March 2018, including a &lt;a href="https://www.vice.com/en/article/3a89w8/this-is-a-rare-prototype-of-the-first-apple-watch"&gt;rare prototype of the first Apple Watch&lt;/a&gt;. “It became my main passion since then to find the most good looking prototypes,” says Zompetti. He’s collected around 35 units so far, with a variety of rare iPhone and iPod prototypes in his collection.&lt;/p&gt;
&lt;p id="hwOLl0"&gt;This passion has seen Zompetti travel to engineers for help repairing old devices. “It’s almost always about finding broken or incomplete units and fixing them to bring them back to life” says Zompetti. An unreleased AirPower device is “definitely among the best” prototype hardware he’s found so far, he says.&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/5/22611234/apple-airpower-wireless-charger-working-prototype"/>
    <id>https://www.theverge.com/2021/8/5/22611234/apple-airpower-wireless-charger-working-prototype</id>
    <author>
      <name>Tom Warren</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-04T19:17:42-04:00</published>
    <updated>2021-08-04T19:17:42-04:00</updated>
    <title>iOS 15 may give the iPhone’s camera an upgrade: fewer green flares</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/D1EEmaRhJrnLZ3NJ4cvReKzmsJg=/0x199:2388x1791/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69680500/IMG_2220.0.jpg" /&gt;
    &lt;/figure&gt;

  &lt;p id="dtVSH9"&gt;The latest version of Apple’s iOS 15 beta seems to be making subtle improvements to photos by processing out the green lens flares that can show up in outdoor pictures (&lt;a href="https://9to5mac.com/2021/08/04/ios-15-can-auto-remove-lens-flares-in-photos/#disqus_thread"&gt;via &lt;em&gt;9to5Mac&lt;/em&gt;&lt;/a&gt;). News of the feature was &lt;a href="https://www.reddit.com/r/iOSBeta/comments/oxc3a6/ios_15_beta_4_the_camera_app_now_autoremoves_lens/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3"&gt;posted to the iOSBeta subreddit&lt;/a&gt; by Reddit user Doubleluckstur, and &lt;em&gt;The Verge&lt;/em&gt; was able to see it in action by testing with an iPhone 12 Mini running the public beta.&lt;/p&gt;
&lt;p id="4xNJPR"&gt;Many iPhone users will be familiar with the green blobs, and while taking a picture it seems like nothing’s changed — the flare still shows up in the viewfinder. But when you go to view the final picture, the flare is nowhere to be seen (in some cases; we’ll get to that in a bit). It does seem to be the result of all the post-processing that’s done to the picture, as the flare shows up in the alternate (and less-processed) frames that are available if you’re using Apple’s Live Photo feature.&lt;/p&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt=" " data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/jxjdgr8cE301KrCX9jJufRFYiWo=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22762173/RPReplay_Final1628109977_Animated_Image__Large_.gif"&gt;
      &lt;figcaption&gt;&lt;em&gt;The green dot shows up in the viewfinder and Live Photo, but not the processed still.&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;div id="AsRhIt"&gt;&lt;div data-anthem-component="imageslider:10686247"&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p id="bYq911"&gt;So far it’s a bit unclear which iPhone models the processing happens on. In the Reddit thread, &lt;a href="https://www.reddit.com/r/iOSBeta/comments/oxc3a6/ios_15_beta_4_the_camera_app_now_autoremoves_lens/h7mecjl?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3"&gt;one user reports&lt;/a&gt; also seeing the green dot removal on their iPhone XS, while &lt;a href="https://www.reddit.com/r/iOSBeta/comments/oxc3a6/ios_15_beta_4_the_camera_app_now_autoremoves_lens/h7ohj3r?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3"&gt;another says&lt;/a&gt; it doesn’t work on their iPhone 8 Plus. &lt;a href="https://9to5mac.com/2021/08/04/ios-15-can-auto-remove-lens-flares-in-photos/#disqus_thread"&gt;&lt;em&gt;9to5Mac&lt;/em&gt; speculates&lt;/a&gt; that the feature could be limited to phones with an A12 Bionic processor or newer (so the XS and XR onward). The feature only being available on newer phones wouldn’t necessarily be surprising: some of iOS 15’s features, like Live Text or Portrait mode for FaceTime, &lt;a href="https://www.theverge.com/2021/6/8/22523351/ios-15-iphone-6s-plus-se-compatibility"&gt;already have the A12 Bionic listed as a requirement&lt;/a&gt;. &lt;/p&gt;
&lt;p id="MCaB9M"&gt;Of course, with this discovery came people trying to chase it down and find its limitations. Reddit user -DementedAvenger- &lt;a href="https://www.reddit.com/r/iOSBeta/comments/oxc3a6/ios_15_beta_4_the_camera_app_now_autoremoves_lens/h7lopz8?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3"&gt;posted examples of the flare still showing up&lt;/a&gt; on top of trees or mesh bug-proof window screens, as well as flares that came from a bathroom light instead of the sun. I was also able to replicate his tree example, as well as get some indoor flares of my own (though it’s worth noting that they’re not the same green bubble flares that so often occur from the sun).&lt;/p&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt=" " data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/0hZxs_ku6WSu6_mljI9EFsGlbqs=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22762112/IMG_2212.jpeg"&gt;
      &lt;figcaption&gt;&lt;em&gt;You can still get flares if you’re really trying, especially indoors.&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt=" " data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/FgXtxl0S2tqx2T5xF7vvSu3o7qY=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22762119/IMG_2215.jpg"&gt;
      &lt;figcaption&gt;&lt;em&gt;You can see the flare on the right side of the tree.&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;p id="xOvsrd"&gt;Another limitation is video: I couldn’t find any scenarios where flares showed up any differently in the final video than they did in the viewfinder. Of course, removing a lens flare from 30 or 60 frames per second 4K footage would be quite a bit more computationally intensive, and have a greater chance of looking a bit weird, so it’s not necessarily surprising that the feature seems to be photo-only for now.&lt;/p&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt=" " data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/GK_C-ZGCEC5do2EfQTAGN9UifT4=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22762271/RPReplay_Final1628115178_Animated_Image__Large_.gif"&gt;
      &lt;figcaption&gt;&lt;em&gt;The gif compression turns it white, but the flare is still clearly visible in this video.&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;p id="pNn8s7"&gt;As always with beta features, the functionality we’re seeing here could be different with the next release, or gone altogether. Still, it seems that Apple is at least experimenting with getting rid of the green blobs that can crop up in images from time to time, and it would be a welcome thing to see in the final version of iOS 15. &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/4/22610190/ios-15-beta-4-green-lens-flare-photos-processing-computation"/>
    <id>https://www.theverge.com/2021/8/4/22610190/ios-15-beta-4-green-lens-flare-photos-processing-computation</id>
    <author>
      <name>Mitchell Clark</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-04T17:18:33-04:00</published>
    <updated>2021-08-04T17:18:33-04:00</updated>
    <title>Apple places female engineering program manager on administrative leave after tweeting about sexism in the office</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="Apple" src="https://cdn.vox-cdn.com/thumbor/pfOdMl213orTGUFd0OKn-9z4C_Y=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69679863/acastro_170731_1777_0003_v6.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="ONzepy"&gt;Apple has placed senior engineering program manager Ashley Gjøvik on indefinite administrative leave after she tweeted about sexism in the office. The company is currently investigating claims Gjøvik made about a hostile work environment. &lt;/p&gt;
&lt;p id="DcaR7F"&gt;“For months, I have been raising concerns with Apple employee relations about years of experiences with sexism, a hostile work environment, sexual harassment, unsafe working conditions, and retaliation,” Gjøvik says in an interview with &lt;em&gt;The Verge&lt;/em&gt;. “I asked them to mitigate the hostile work environment while they investigate, and they initially offered me EAP therapy and medical leave. I told them that made no sense, and said they should talk to my leadership and set up oversight and boundaries. I added that if there was no other option they could give me paid administrative leave. They apparently made no effort to set boundaries and instead said they were placing me on administrative leave and implied they did not want me on Slack where I had been vocal about my concerns with certain policies at the company. They also implied they didn’t want me to meet one-on-one with other women at the company about their concerns with Apple policies, which I had been doing.”&lt;/p&gt;
&lt;p id="dYW22k"&gt;This afternoon, Gjøvik set an out of office message informing colleagues that the employee relations team had placed her on indefinite paid leave.&lt;/p&gt;
&lt;div id="dpRzyx"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;So, following raising concerns to &lt;a href="https://twitter.com/hashtag/Apple?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#Apple&lt;/a&gt; about &lt;a href="https://twitter.com/hashtag/sexism?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#sexism&lt;/a&gt;, &lt;a href="https://twitter.com/hashtag/hostileworkenvironment?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#hostileworkenvironment&lt;/a&gt;, &amp;amp; &lt;a href="https://twitter.com/hashtag/unsafeworkconditions?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#unsafeworkconditions&lt;/a&gt;, I'm now on indefinite paid administrative leave per &lt;a href="https://twitter.com/hashtag/Apple?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#Apple&lt;/a&gt; employee relations, while they investigate my concerns. This seems to include me not using Apple's internal Slack.&lt;/p&gt;— Ashley M. Gjøvik (@ashleygjovik) &lt;a href="https://twitter.com/ashleygjovik/status/1423014977661591552?ref_src=twsrc%5Etfw"&gt;August 4, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="QDTXTo"&gt;This is the second time Apple has investigated Gjøvik’s claims about sex discrimination at the company. The employee relations team closed an earlier investigation, allegedly finding that nothing was wrong, prompting Gjøvik to tweet screenshots with what she says is just a small portion of what she experienced:&lt;/p&gt;
&lt;div id="A4YgO7"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;Wanted to share: &lt;a href="https://twitter.com/hashtag/Apple?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#Apple&lt;/a&gt; employee relations confirmed this &lt;a href="https://twitter.com/hashtag/tonepolicing?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#tonepolicing&lt;/a&gt; is totally ok feedback for me to get from my &lt;a href="https://twitter.com/hashtag/bigtech?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#bigtech&lt;/a&gt; &lt;a href="https://twitter.com/hashtag/male?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#male&lt;/a&gt; leaders &amp;amp; not &lt;a href="https://twitter.com/hashtag/sexist?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#sexist&lt;/a&gt;. &lt;br&gt;&lt;br&gt;As this investigation rolls on, I've decided to start Tweeting the stuff they say is "ok." I mean, they did say it was ok? &lt;a href="https://t.co/EImLTjRTBl"&gt;pic.twitter.com/EImLTjRTBl&lt;/a&gt;&lt;/p&gt;— Ashley M. Gjøvik (@ashleygjovik) &lt;a href="https://twitter.com/ashleygjovik/status/1422380335703101443?ref_src=twsrc%5Etfw"&gt;August 3, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id="Z3eNab"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;In today's &lt;a href="https://twitter.com/hashtag/Apple?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#Apple&lt;/a&gt; employee relations said its fine update, here's the heartfelt email I sent my &lt;a href="https://twitter.com/hashtag/bigtech?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#bigtech&lt;/a&gt; male leadership in 2018 during the Kavanaugh hearings. I asked for support of women &amp;amp; to condemn &lt;a href="https://twitter.com/hashtag/sexism?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#sexism&lt;/a&gt; &amp;amp; &lt;a href="https://twitter.com/hashtag/sexualassault?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#sexualassault&lt;/a&gt;. The reply: a text saying "FWIW, RBG thinks he's ok." &lt;a href="https://t.co/0GTthZNEgH"&gt;pic.twitter.com/0GTthZNEgH&lt;/a&gt;&lt;/p&gt;— Ashley M. Gjøvik (@ashleygjovik) &lt;a href="https://twitter.com/ashleygjovik/status/1422953562724737024?ref_src=twsrc%5Etfw"&gt;August 4, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id="f11v2A"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;This happened to me at &lt;a href="https://twitter.com/hashtag/Apple?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#Apple&lt;/a&gt; too: they offered EAP and suggested medical leave after I spoke up about &lt;a href="https://twitter.com/hashtag/sexism?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#sexism&lt;/a&gt;, &lt;a href="https://twitter.com/hashtag/discrimination?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#discrimination&lt;/a&gt;, and a hostile work environment. They also suggested requesting &lt;a href="https://twitter.com/hashtag/ADA?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#ADA&lt;/a&gt; &lt;a href="https://twitter.com/hashtag/disability?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#disability&lt;/a&gt; accommodations after I raised concerns about unsafe &lt;a href="https://twitter.com/hashtag/workconditions?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#workconditions&lt;/a&gt;. &lt;a href="https://t.co/LW0Ueq1Leb"&gt;https://t.co/LW0Ueq1Leb&lt;/a&gt;&lt;/p&gt;— Ashley M. Gjøvik (@ashleygjovik) &lt;a href="https://twitter.com/ashleygjovik/status/1421204989687472130?ref_src=twsrc%5Etfw"&gt;July 30, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="yVcnq6"&gt;Apple is currently contending with &lt;a href="https://www.theverge.com/2021/5/25/22453302/apple-culture-secrecy-leak-antonio-garcia-martinez-letter"&gt;a wave of employee activism&lt;/a&gt;, including multiple women tweeting about their dissatisfaction with the company culture. In May, employees wrote a letter demanding an &lt;a href="https://www.theverge.com/2021/5/12/22432909/apple-petition-hiring-antonio-garcia-martinez-chaos-monkeys-facebook"&gt;investigation into the hiring of Antonio García Martínez&lt;/a&gt;, who’d written a book about Silicon Valley with descriptions of women many people found offensive.  Hours later, &lt;a href="https://www.theverge.com/2021/5/12/22433437/apple-hire-antonio-garcia-martinez-out-petition-investigation"&gt;García Martínez was fired&lt;/a&gt;. &lt;/p&gt;
&lt;p id="fvqKiC"&gt;Apple did not immediately respond to a request for comment from&lt;em&gt; The Verge&lt;/em&gt;. &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/4/22610112/apple-female-engineering-manager-leave-sexism-work-environment"/>
    <id>https://www.theverge.com/2021/8/4/22610112/apple-female-engineering-manager-leave-sexism-work-environment</id>
    <author>
      <name>Zoe Schiffer</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-04T13:59:04-04:00</published>
    <updated>2021-08-04T13:59:04-04:00</updated>
    <title>Colleges across the US and Canada are adopting virtual student IDs</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="US-ECONOMY-AUTO-MERCEDES" src="https://cdn.vox-cdn.com/thumbor/b43bWA5DvZJ0m9gyOtxGeql0tIk=/0x76:4463x3051/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69678528/695753658.0.jpg" /&gt;
        &lt;figcaption&gt;&lt;em&gt;The University of Alabama will be the first school to exclusively issue mobile student IDs this fall.&lt;/em&gt; | ANDREW CABALLERO-REYNOLDS/AFP via Getty Images&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="vC0XZi"&gt;Apple Wallet has supported contactless student IDs &lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.apple.com%2Fnewsroom%2F2018%2F10%2Fapple-adds-support-for-contactless-student-id-cards-in-wallet%2F&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F2021%2F8%2F4%2F22609571%2Fapple-wallet-student-ids-university-expansion" rel="sponsored nofollow noopener" target="_blank"&gt;since 2018&lt;/a&gt;, with three US universities supporting the feature at launch. The program has been &lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.apple.com%2Fnewsroom%2F2019%2F08%2Fapple-brings-contactless-student-ids-on-iphone-and-apple-watch-to-more-universities%2F&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F2021%2F8%2F4%2F22609571%2Fapple-wallet-student-ids-university-expansion" rel="sponsored nofollow noopener" target="_blank"&gt;gradually expanding&lt;/a&gt; ever since. Yesterday, &lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.apple.com%2Fnewsroom%2F2021%2F08%2Fstudent-ids-on-iphone-and-apple-watch-expand-to-canada-and-more-us-universities%2F&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F2021%2F8%2F4%2F22609571%2Fapple-wallet-student-ids-university-expansion" rel="sponsored nofollow noopener" target="_blank"&gt;the company announced&lt;/a&gt; that its virtual IDs will finally arrive in Canada this fall. An unspecified number of additional US universities will adopt it for the first time as well.&lt;/p&gt;
&lt;p id="lO6K5Z"&gt;The University of New Brunswick and Sheridan College will be the first two Canadian schools to use Apple Wallet IDs. The new US roster includes Auburn, Northern Arizona University, University of Maine, and New Mexico State University, in addition to “many more colleges across the country.” &lt;a href="https://news.ua.edu/2021/04/old-swipe-action-cards-deactivating-this-summer/"&gt;The University of Alabama&lt;/a&gt;, one of the program’s early adopters, will also be the first school to issue exclusively mobile student IDs (to students with eligible devices) this fall. (Those with Android phones can use the digital cards through Google Pay.)&lt;/p&gt;
&lt;p id="fl2DdY"&gt;Apple claims that “tens of thousands of college students” will have access to the feature during this upcoming school year.&lt;/p&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt="Duke University Campus" data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/IeQ6haafj4m7MeAWRQ3lXXzaa-Y=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22761220/523523556.jpg"&gt;
      &lt;cite&gt;Photo by Lance King / Getty Images&lt;/cite&gt;
      &lt;figcaption&gt;&lt;em&gt;Duke was one of the first universities to support virtual IDs in 2018.&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;p id="3KiTja"&gt;In theory, the virtual student ID should offer all the functionality of a regular student ID — holders can access restricted areas of campus or pay for amenities like food and laundry by placing their iPhone or Apple Watch near a physical reader. Transaction history isn’t shared with Apple or stored on Apple’s servers. &lt;/p&gt;
&lt;p id="nXmkxl"&gt;The new student ID format is part of Apple’s larger effort to expand Apple Wallet’s functionality. The app can also &lt;a href="https://www.theverge.com/2021/6/7/22522864/apple-wallet-iphone-airport-ids-hotel-key-card-ios-15-wwdc"&gt;store hotel room keys&lt;/a&gt; with the release of iOS 15 and will support driver’s licenses and state IDs. &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/4/22609571/apple-wallet-student-ids-university-expansion"/>
    <id>https://www.theverge.com/2021/8/4/22609571/apple-wallet-student-ids-university-expansion</id>
    <author>
      <name>Monica Chin</name>
    </author>
  </entry>
</feed>
