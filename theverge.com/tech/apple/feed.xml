<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <title>The Verge -  Apples</title>
  <icon>https://cdn.vox-cdn.com/community_logos/52801/VER_Logomark_32x32..png</icon>
  <updated>2021-08-13T11:23:03-04:00</updated>
  <id>https://www.theverge.com/rss/apple/index.xml</id>
  <link type="text/html" href="https://www.theverge.com/apple" rel="alternate"/>
  <entry>
    <published>2021-08-13T11:23:03-04:00</published>
    <updated>2021-08-13T11:23:03-04:00</updated>
    <title>Craig Federighi says Apple’s child safety scanning will have ‘multiple levels of auditability’</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="Epic-Apple Trial Hangs Over Some 50,000 Games On App Store" src="https://cdn.vox-cdn.com/thumbor/MzJYUURQ9UFgjUd0TWsSS-N-4HU=/0x0:3999x2666/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69721417/1232992663.0.jpg" /&gt;
    &lt;/figure&gt;

  &lt;p id="tPKT38"&gt;Apple executive Craig Federighi says iCloud Photos’ &lt;a href="https://www.theverge.com/2021/8/10/22613225/apple-csam-scanning-messages-child-safety-features-privacy-controversy-explained"&gt;plans to scan for child sexual abuse material&lt;/a&gt; (or CSAM) will include “multiple levels of auditability.” In &lt;a href="https://www.wsj.com/articles/apple-executive-defends-tools-to-fight-child-porn-acknowledges-privacy-backlash-11628859600"&gt;an interview with &lt;em&gt;The Wall Street Journal&lt;/em&gt;&lt;/a&gt;, Federighi — Apple’s senior vice president of software engineering — offered new details about its controversial child safety measures. That includes a claim that the iPad and iPhone’s device-level scanning will help security experts verify that Apple is using the system responsibly.&lt;/p&gt;
&lt;p id="iZeals"&gt;Like many companies with cloud storage services, Apple will check iCloud Photos images against a list from the National Center for Missing and Exploited Children (NCMEC), looking for exact matches with known CSAM pictures. But unlike many services, it will run searches on the device, not fully remotely. “Imagine someone was scanning images in the cloud. Well, who knows what’s being scanned for?” Federighi said, referring to remote scans. “In our case, the database is shipped on device. People can see, and it’s a single image across all countries.”&lt;/p&gt;
&lt;p id="1DjUrf"&gt;Federighi elaborated slightly on how this might give people confidence Apple isn’t greatly expanding the database to include material besides illegal CSAM, particularly in countries with restrictive censorship policies.&lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="vMPNRl"&gt;&lt;q&gt;“We’re making sure that you don’t have to trust any one entity, or even any one country”&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="B5anlI"&gt;“We ship the same software in China with the same database we ship in America, as we ship in Europe. If someone were to come to Apple [with a request to scan for data beyond CSAM], Apple would say no. But let’s say you aren’t confident. You don’t want to just rely on Apple saying no. You want to be sure that Apple couldn’t get away with it if we said yes,” he told the &lt;em&gt;Journal&lt;/em&gt;. “There are multiple levels of auditability, and so we’re making sure that you don’t have to trust any one entity, or even any one country, as far as what images are part of this process.”&lt;/p&gt;
&lt;p id="Y7s92c"&gt;Apple has previously said that it’s only rolling out the system in the United States and that it will &lt;a href="https://9to5mac.com/2021/08/06/apple-says-any-expansion-of-csam-detection-outside-of-the-us-will-occur-on-a-per-country-basis/"&gt;consider launching in other countries&lt;/a&gt; on a case-by-case basis. The company confirmed to &lt;em&gt;The Verge&lt;/em&gt; that Apple will ship the hash database of known CSAM on the operating system in all countries, but it will only be used for scanning in the US. The &lt;em&gt;Journal&lt;/em&gt; further clarifies that there will be an independent auditor who can verify the images involved.&lt;/p&gt;
&lt;p id="k7QNze"&gt;Federighi also offered more detail on when the scanning system will notify an Apple moderator of potential illegal content. Apple has said before that a single match won’t trigger a red flag — a measure intended to prevent false positives. Instead, the system generates “safety vouchers” for each match and alerts Apple if the number hits a certain threshold. Apple has declined to publicize the exact threshold, saying this could let abusers evade detection. But Federighi says it’s “on the order of 30 known child pornographic images.”&lt;/p&gt;
&lt;p id="dFkTE8"&gt;Some security experts have offered cautious praise of Apple’s system and acknowledged the importance of finding CSAM online. But many have &lt;a href="https://www.theverge.com/22617554/apple-csam-child-safety-features-jen-king-riana-pfefferkorn-interview-decoder"&gt;criticized Apple’s abrupt rollout&lt;/a&gt; and a lack of clarity on how the system worked. In his interview with the &lt;em&gt;Journal&lt;/em&gt;, Federighi acknowledged the confusion. “It’s really clear a lot of messages got jumbled pretty badly in terms of how things were understood,” he said.&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/13/22623336/craig-federighi-apple-icloud-photos-iphone-ipad-csam-scanning-auditability"/>
    <id>https://www.theverge.com/2021/8/13/22623336/craig-federighi-apple-icloud-photos-iphone-ipad-csam-scanning-auditability</id>
    <author>
      <name>Adi Robertson</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-13T08:40:54-04:00</published>
    <updated>2021-08-13T08:40:54-04:00</updated>
    <title>Verge readers can snag three months of Xbox Game Pass Ultimate for $30</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="xcloud" src="https://cdn.vox-cdn.com/thumbor/RZhHb07NlhEI2sul46R8YzM5IoE=/0x85:2040x1445/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69720439/vpavic_xcloud_20201009_0011_Edit.0.jpg" /&gt;
        &lt;figcaption&gt;Microsoft’s flagship subscription combines Xbox Game Pass and Xbox Live Gold in one attractive package. | Photo by Nick Statt / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="xJPIOV"&gt;If you’re a gamer, &lt;a href="https://www.theverge.com/2021/6/13/22530941/xbox-game-pass-e3-2021-bethesda-yakuza"&gt;Xbox Game Pass&lt;/a&gt; is one of the best deals in town. Microsoft’s popular subscription service — which touted &lt;a href="https://www.theverge.com/2021/1/26/22250795/xbox-game-pass-subscribers-growth-microsoft"&gt;more than 18 million subscribers&lt;/a&gt; earlier this year — has been dubbed the “Netflix of video games,” namely because it provides access to more than a &lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.xbox.com%2Fen-US%2Fxbox-game-pass%2Fgames%3FranMID%3D24542%26ranEAID%3DTnL5HPStwNw%26ranSiteID%3DTnL5HPStwNw-NG1EGejqTZh7KDYouebdEQ%26epi%3DTnL5HPStwNw-NG1EGejqTZh7KDYouebdEQ%26irgwc%3D1%26OCID%3DAID2200057_aff_7593_1243925%26tduid%3D%2528ir__0thgbaanw9kfqhhygvquhus6yn2xr3dfzggxj29e00%2529%25287593%2529%25281243925%2529%2528TnL5HPStwNw-NG1EGejqTZh7KDYouebdEQ%2529%2528%2529%26irclickid%3D_0thgbaanw9kfqhhygvquhus6yn2xr3dfzggxj29e00&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2Fgood-deals%2F2021%2F8%2F13%2F22622197%2Fxbox-game-pass-ultimate-subscription-samsung-galaxy-chromebook-2-apple-watch-series-6-deal" rel="sponsored nofollow noopener" target="_blank"&gt;hundred Xbox titles&lt;/a&gt; for a flat, monthly fee. Xbox Game Pass Ultimate takes things a step further, combining Xbox Game Pass with Xbox Live Gold, giving subscribers access to exclusive deals, online multiplayer, EA Play titles, and Microsoft’s cloud gaming service, xCloud, which is now &lt;a href="https://www.theverge.com/2021/6/28/22554267/microsoft-xcloud-game-streaming-xbox-pass-ios-iphone-ipad-pc"&gt;widely available on iOS and PC&lt;/a&gt;.&lt;/p&gt;
&lt;p id="PQE5WR"&gt;Typically, a three-month subscription to Xbox Game Pass Ultimate runs $45. And while &lt;a href="https://click.linksynergy.com/deeplink?id=nOD/rLJHOac&amp;amp;mid=24542&amp;amp;murl=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fp%2Fxbox-game-pass-ultimate%2Fcfq7ttc0khs0%3Factivetab%3Dpivot%253aoverviewtab" rel="sponsored nofollow noopener" target="_blank"&gt;Microsoft’s ongoing promotion&lt;/a&gt; will knock the price down to $1 for new subscribers, it’s not available for returning players. Thankfully, &lt;em&gt;Verge&lt;/em&gt; readers can purchase a &lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.eneba.com%2Fus%2Fxbox-xbox-game-pass-ultimate-3-month-membership-xbox-one-windows-10-xbox-live-key-global%2Fbest-pick&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2Fgood-deals%2F2021%2F8%2F13%2F22622197%2Fxbox-game-pass-ultimate-subscription-samsung-galaxy-chromebook-2-apple-watch-series-6-deal" rel="sponsored nofollow noopener" target="_blank"&gt;three-month subscription at Eneba for $30&lt;/a&gt;, while supplies last. The sale price will fluctuate around $30.85 (with service fees), but if you use promo code &lt;strong&gt;XGPU3VERGE&lt;/strong&gt;, the price should come in just shy of $30 at checkout.&lt;/p&gt;
&lt;div id="e1485R"&gt;&lt;div data-anthem-component="productcard:9532770"&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p id="MdR7AP"&gt;The Samsung Galaxy Chromebook 2 isn’t a direct sequel to the &lt;a href="https://www.theverge.com/2020/4/6/21206151/samsung-galaxy-chromebook-review-android-laptop"&gt;Galaxy Chromebook&lt;/a&gt; — and it’s better off for it. The midrange Chromebook hits all the right marks, while retaining an affordable price tag that becomes even more appealing when you factor in its &lt;a href="https://bestbuy.7tiv.net/c/482924/614286/10014?u=https%3A%2F%2Fwww.bestbuy.com%2Fsite%2Fsamsung-galaxy-chromebook-2-13-3-qled-touch-screen-intel-core-i3-8gb-memory-128gb-emmc-fiesta-red%2F6448525.p%3FskuId%3D6448525&amp;amp;sharedid=theverge.com" rel="sponsored nofollow noopener" target="_blank"&gt;current sale price at Best Buy: $600&lt;/a&gt;. For the money, you get a functional laptop with a gorgeous QLED display, all-day battery life, and a bright, eye-catching finish that’s sure to turn heads no matter where you go (it’s also available in a “mercury gray”). It’s one of the &lt;a href="https://www.theverge.com/21296102/best-chromebooks"&gt;best Chromebooks&lt;/a&gt; you can buy, and it comes with 8GB of RAM, 128GB of storage, and a Core i3 processor, which should be enough for everyday use. &lt;a href="https://www.theverge.com/22301481/samsung-galaxy-chromebook-2-review"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id="gAcR0s"&gt;&lt;div data-anthem-component="productcard:10698797"&gt;&lt;/div&gt;&lt;/div&gt;
&lt;aside id="PSu4DU"&gt;&lt;div data-anthem-component="readmore" data-anthem-component-data='{"stories":[{"title":"New Chromebooks will now have Google Meet installed by default","url":"https://www.theverge.com/2021/8/3/22607620/google-meet-app-chromebooks-chrome-os-now-preinstalled"}]}'&gt;&lt;/div&gt;&lt;/aside&gt;&lt;p id="0ehdqk"&gt;Like its predecessors, the Apple Watch Series 6 is easily the best smartwatch available for the iPhone. Not only does the Series 6 boast a wealth of health features and an always-on display, but it comes with built-in sleep tracking and a strong ecosystem of third-party complications, a hallmark no other smartwatch manufacturer has yet to replicate. The watch’s deep integration with the iPhone only bolsters the wearable’s appeal alongside watchOS 7, a mobile operating system built to handle all the basic features we’ve come to expect in a smartwatch.&lt;/p&gt;
&lt;p id="lZaCmI"&gt;Normally $430, you can purchase the 44mm, GPS-enabled &lt;a href="http://goto.target.com/b3Do0m"&gt;Apple Watch Series 6 at Target right now for $360&lt;/a&gt;, one of the better prices we’ve seen on this particular model in recent months. &lt;a href="https://www.theverge.com/21496141/apple-watch-series-6-review-blood-oxygen-monitor-watchos-7"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id="714qv9"&gt;&lt;div data-anthem-component="productcard:10598305"&gt;&lt;/div&gt;&lt;/div&gt;
&lt;aside id="7k7k6b"&gt;&lt;div data-anthem-component="readmore" data-anthem-component-data='{"stories":[{"title":"Apple announces watchOS 8 with new health features","url":"https://www.theverge.com/2021/6/7/22463618/apple-watchos-8-features-watch-wwdc-2021"}]}'&gt;&lt;/div&gt;&lt;/aside&gt;&lt;h2 id="70rnAa"&gt;Other great deals happening now&lt;/h2&gt;
&lt;ul&gt;
&lt;li id="pAgehN"&gt;Both editions of &lt;a href="https://shop-links.co/1748907191883258731#donotlink" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;em&gt;Mario Kart Live: Home Circuit&lt;/em&gt;&lt;/a&gt; are available at Best Buy for $75, matching the best price we’ve encountered on the inventive Switch title. &lt;a href="https://www.theverge.com/21514758/mario-kart-live-home-circuit-review-nintendo-switch" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li id="Sx4IwC"&gt;
&lt;a href="https://www.amazon.com/dp/B00N1YPXW2?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Blue’s Yeti Microphone&lt;/a&gt; is on sale at Amazon for $100 in a variety of colors. It’s not the lowest price we’ve seen on the versatile USB mic, but it’s still a notable discount.&lt;/li&gt;
&lt;li id="6uJjUD"&gt;
&lt;a href="https://www.amazon.com/Apple-Mini-Chip-256GB-Storage/dp/B08N5PHB83/?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Apple’s M1-powered Mac mini&lt;/a&gt; is $100 off at Amazon, matching the desktop machine’s best price. &lt;a href="https://www.theverge.com/2020/11/17/21570046/apple-mac-mini-2020-m1-review" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li id="jKXmIT"&gt;All colorways of the &lt;a href="https://www.amazon.com/dp/B096SV8SJG/?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Beats Studio Buds&lt;/a&gt; are on sale at Amazon for $130, the first significant discount to date on Apple’s latest true wireless earbuds. &lt;a href="https://www.theverge.com/22532970/beats-studio-buds-review" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li id="wkPJa9"&gt;
&lt;a href="https://shop-links.co/1748914964623059007#donotlink" rel="sponsored nofollow noopener" target="_blank"&gt;Nanoleaf’s Triangle Smarter Pack&lt;/a&gt; is $20 off at Best Buy, bringing the price of the customizable lighting panels down to $180.&lt;/li&gt;
&lt;li id="2VPteh"&gt;If you own the latest, 11-inch iPad Pro, you can pick up &lt;a href="https://www.anrdoezrs.net/click-8836598-11365093?url=https%3A%2F%2Fwww.verizon.com%2Fproducts%2Fapple-magic-keyboard-case-for-11-inch-ipad-pro-2021-11-inch-ipad-pro-2020%2F" rel="sponsored nofollow noopener" target="_blank"&gt;Apple’s Magic Keyboard Case&lt;/a&gt; and a &lt;a href="https://www.kqzyfj.com/click-8836598-11365093?url=https%3A%2F%2Fwww.verizon.com%2Fproducts%2Fapple-pencil-2nd-generation-ipad-pro%2F" rel="sponsored nofollow noopener" target="_blank"&gt;second-gen Apple Pencil&lt;/a&gt; for $300 at Verizon. Simply add both items to your cart to receive the sizable $115 discount.&lt;/li&gt;
&lt;li id="YkVHp7"&gt;
&lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.ebay.com%2Fitm%2FLG-C1PU-48-HDR-4K-Ultra-HD-Smart-OLED-TV-2021-Model-%2F184898835257%3F_trksid%3D%26mkcid%3D1%26mkrid%3D711-53200-19255-0%26siteid%3D0%26campid%3D5338794975%26customid%3DVergeDeals081221%26toolid%3D10001%26mkevt%3D1&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2Fgood-deals%2F2021%2F8%2F13%2F22622197%2Fxbox-game-pass-ultimate-subscription-samsung-galaxy-chromebook-2-apple-watch-series-6-deal" rel="sponsored nofollow noopener" target="_blank"&gt;LG’s 48-inch C1 OLED&lt;/a&gt; is just $1,197 at eBay with coupon code &lt;strong&gt;SAVE20FORBTS&lt;/strong&gt;, saving you more than 13 percent on the brilliant OLED TV.&lt;/li&gt;
&lt;li id="cWmsT5"&gt;A &lt;a href="https://www.tkqlhce.com/click-8836598-13527013?url=https%3A%2F%2Fsellout.woot.com%2Foffers%2Famazon-usb-c-to-lightning-cable-cord%3F" rel="sponsored nofollow noopener" target="_blank"&gt;foot-long AmazonBasics USB-C to Lightning Cable&lt;/a&gt; is $11 at Woot, the second-best price we’ve seen on the basic accessory.&lt;/li&gt;
&lt;/ul&gt;
&lt;aside id="FN5TjR"&gt;&lt;div data-anthem-component="newsletter" data-anthem-component-data='{"slug":"deals"}'&gt;&lt;/div&gt;&lt;/aside&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/good-deals/2021/8/13/22622197/xbox-game-pass-ultimate-subscription-samsung-galaxy-chromebook-2-apple-watch-series-6-deal"/>
    <id>https://www.theverge.com/good-deals/2021/8/13/22622197/xbox-game-pass-ultimate-subscription-samsung-galaxy-chromebook-2-apple-watch-series-6-deal</id>
    <author>
      <name>Brandon Widder</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-12T16:09:24-04:00</published>
    <updated>2021-08-12T16:09:24-04:00</updated>
    <title>Apple updates Eddy Cue’s title to better reflect its turn to services</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="eddy cue" src="https://cdn.vox-cdn.com/thumbor/jh0tWKaCOCJsN2Sg4SIygIt4zQ0=/6x0:1020x676/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69717596/2013-06-10eddycue-1.0.jpg" /&gt;
    &lt;/figure&gt;

  &lt;p id="jgwTry"&gt;Apple rolled out &lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.apple.com%2Fleadership%2Feddy-cue%2F&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F2021%2F8%2F12%2F22622178%2Fapple-eddy-cue-job-title-update-senior-vp-services" rel="sponsored nofollow noopener" target="_blank"&gt;a small but meaningful update&lt;/a&gt; to senior executive Eddy Cue’s job title on Thursday that features an area of interest the company has long been focused on: services (&lt;a href="https://9to5mac.com/2021/08/12/eddy-cue-title-change-services-apple/"&gt;via &lt;em&gt;9to5Mac&lt;/em&gt;&lt;/a&gt;). Eddy Cue is a longstanding veteran at Apple who &lt;a href="https://www.theverge.com/2013/4/26/4265172/itunes-store-at-10-how-apple-built-a-digital-media-juggernaut"&gt;helped build iTunes&lt;/a&gt; and the App Store, but his new title of “Senior Vice President, Services” reflects the company’s increasingly important side hustle, if not outright transformation into &lt;a href="https://www.theverge.com/2019/3/20/18273179/apple-icloud-itunes-app-store-music-services-businesses"&gt;a media business and subscription peddler&lt;/a&gt;.&lt;/p&gt;
&lt;p id="w3iqBM"&gt;Prior to Thursday, Eddy Cue was senior vice president of internet software and services, &lt;a href="https://web.archive.org/web/20210303073700/https://www.apple.com/leadership/eddy-cue/"&gt;with responsibilities&lt;/a&gt; that included overseeing the iTunes Store, Apple Music, Apple Pay, Maps, Search Ads, iCloud, and iWork. His new job description emphasizes Apple’s subscription darlings:&lt;/p&gt;
&lt;blockquote&gt;&lt;p id="6r296t"&gt;Eddy oversees the full range of Apple’s services, including Apple Music, Apple News, Apple Podcasts, the Apple TV app, and Apple TV Plus, as well as Apple Pay, Apple Card, Maps, Search Ads, Apple’s iCloud services, and Apple’s productivity and creativity apps. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p id="ApPa26"&gt;Apple still makes a ton of money selling hardware and software — &lt;a href="https://www.theverge.com/2021/7/27/22596120/apple-q3-2021-earnings-iphone-ipad-mac"&gt;earning a total of $81.43 billion during the third quarter of 2021&lt;/a&gt; — but its services business has specifically been growing as of late, earning an all-time revenue high of $17.5 billion during the same quarter. Apple’s found major success &lt;a href="https://www.theverge.com/2021/4/20/22394062/apple-tv-ted-lasso-season-2-trailer-premiere-date"&gt;in streaming hits like &lt;em&gt;Ted Lasso&lt;/em&gt;&lt;/a&gt; that may have helped, and seems primed to take even bigger, more &lt;em&gt;Game of Thrones&lt;/em&gt;-sized swings &lt;a href="https://www.theverge.com/2021/6/23/22547252/foundation-release-date-apple-tv-plus-september"&gt;with shows like &lt;em&gt;Foundation&lt;/em&gt;&lt;/a&gt; later this fall. &lt;/p&gt;
&lt;p id="mETswq"&gt;Cue’s had a hand in many pies over his time at Apple, including &lt;a href="https://www.theverge.com/2017/9/1/16240584/apple-eddy-cue-siri-craig-federighi"&gt;managing Siri for a period&lt;/a&gt; before Apple began to actively compete with Google Assistant. He’s also now infamously known as one of the few executives &lt;a href="https://www.theverge.com/2021/4/27/22406303/imessage-android-eddy-cue-emails-apple-epic-deposition"&gt;who pushed for Apple to bring iMessage to Android&lt;/a&gt;, thanks to an email exchange between Cue and senior vice president of software engineering Craig Federighi that was dug up as part of &lt;a href="https://www.theverge.com/2020/8/13/21367923/fortnite-apple-app-store-epic-games-need-to-know"&gt;the &lt;em&gt;Epic v. Apple&lt;/em&gt; antitrust lawsuit&lt;/a&gt;.&lt;/p&gt;
&lt;p id="hlhLGX"&gt;A title change might not mean that much in terms of what Cue does day to day, but it is yet more evidence that Apple’s services business is here to stay.&lt;/p&gt;
&lt;p id="RotckP"&gt;&lt;/p&gt;
&lt;p id="Sl1ehU"&gt;&lt;/p&gt;
&lt;p id="3lvlgv"&gt;&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/12/22622178/apple-eddy-cue-job-title-update-senior-vp-services"/>
    <id>https://www.theverge.com/2021/8/12/22622178/apple-eddy-cue-job-title-update-senior-vp-services</id>
    <author>
      <name>Ian Carlos Campbell</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-11T14:42:56-04:00</published>
    <updated>2021-08-11T14:42:56-04:00</updated>
    <title>1Password 8 on the Mac brings a big redesign</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/8NtDvhQr91Risk3Yk6Mq3T4x1bU=/24x0:2124x1400/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69711539/HeroUnlocked.0.png" /&gt;
    &lt;/figure&gt;

  &lt;p id="URwxbR"&gt;A few weeks after 1Password started rolling out the &lt;a href="https://blog.1password.com/1password-8-for-windows-is-now-in-early-access/"&gt;Windows version of the redesigned 1Password 8&lt;/a&gt;, the company is now &lt;a href="https://blog.1password.com/1password-8-for-mac-is-now-in-early-access/"&gt;showing off the Mac version&lt;/a&gt; of the update, which is also available today to try in early access.&lt;/p&gt;
&lt;p id="3X65Io"&gt;Like the Windows version, 1Password 8 on the Mac features an overhauled design, which aims to make it clearer when items are being shared, who they’re shared with, and better labeling of groups in the sidebar.  &lt;/p&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt=" " data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/u-MUEbWlGs5qVyTPSyopWZhNDsA=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22776517/WatchtowerDashboard.png"&gt;
  &lt;/figure&gt;
&lt;p id="PQjfm6"&gt;There’s also a new search bar, which shows suggestions as you search (similar to Apple’s Spotlight or Alfred), and an updated version of Watchtower, which shows a comprehensive overview of your overall password security. &lt;/p&gt;
&lt;p id="S5jp1U"&gt;Lastly, the new app overhauls the editing window, which the company says includes a “new password generator, smart suggestions, and simpler file attachments.” &lt;/p&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt=" " data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/agKgppnnD6WRmE7ghTm4WTwjpfo=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22776518/opm8ea_unlocked.png"&gt;
  &lt;/figure&gt;
&lt;p id="Z0Uehl"&gt;1Password 8 looks like a fairly sizable update, and users will have to opt in to the early access build to try it out today. &lt;a href="https://1password.community/discussion/122136/"&gt;Instructions are here&lt;/a&gt;, but doing so requires deleting the old 1Password 7 app and then installing the new version. Additionally, while the flashy new features and design look fun, the company cautions that 1Password 8 is “for testing and validation purposes only and is not suitable for business critical environments.” So you might not necessarily want to use it for anything super important just yet. &lt;/p&gt;
&lt;p id="oIDt42"&gt;&lt;/p&gt;
&lt;p id="rrwfK9"&gt;&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/11/22619846/1password-8-macos-early-access-password-manager-app"/>
    <id>https://www.theverge.com/2021/8/11/22619846/1password-8-macos-early-access-password-manager-app</id>
    <author>
      <name>Chaim Gartenberg</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-11T14:08:22-04:00</published>
    <updated>2021-08-11T14:08:22-04:00</updated>
    <title>Senators target Apple’s App Store exclusivity in new bill</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/InVLqrBh-kXo9CAONa4Uq094tG4=/0x0:3000x2000/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69711309/Google_Apple_App_Dominance2.0.jpg" /&gt;
    &lt;/figure&gt;

  &lt;p id="zPgcBF"&gt;There’s a new bill introduced in the Senate Wednesday targeting the power dominant tech firms like Apple and Google have over the app store market. &lt;/p&gt;
&lt;p id="aXF6EJ"&gt;The bipartisan “&lt;a href="https://www.blumenthal.senate.gov/imo/media/doc/8.11.21%20-%20Open%20App%20Markets%20Act%20-%20Bill%20Text.pdf"&gt;Open App Markets Act&lt;/a&gt;,” introduced by Sens. Richard Blumenthal (D-CT), Marsha Blackburn (R-TN), and Amy Klobuchar (D-MN) would ban app stores from forcing developers to use the store’s payment systems. It would also bar companies from punishing developers that offer lower prices on a separate app store or through their own payment systems, along the lines of Apple’s public dispute with Epic Games. Notably, the bill would also make it unlawful for companies like Apple to use non-public data from their stores to build competing products against companies using their service.&lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="mXlLqb"&gt;&lt;q&gt;“Apple and Google have squashed competitors and kept consumers in the dark”&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="NNBQst"&gt;“For years, Apple and Google have squashed competitors and kept consumers in the dark—pocketing hefty windfalls while acting as supposedly benevolent gatekeepers of this multi-billion dollar market,” Blumenthal said in a statement Wednesday. “This bipartisan bill will help break these tech giants’ ironclad grip, open the app economy to new competitors, and give mobile users more control over their own devices.” &lt;/p&gt;
&lt;p id="FOnZMb"&gt;An Apple spokesperson responded to the bill in a statement to &lt;em&gt;The Verge &lt;/em&gt;Wednesday, writing, “Since our founding, we’ve always put our users at the center of everything we do, and the App Store is the cornerstone of our work to connect developers and customers in a way that is safe and trustworthy.” The spokesperson continued, “At Apple, our focus is on maintaining an App Store where people can have confidence that every app must meet our rigorous guidelines and their privacy and security is protected.”&lt;/p&gt;
&lt;p id="g0PBEX"&gt;Earlier this year, the Senate Judiciary Committee &lt;a href="https://www.theverge.com/2021/4/21/22396544/apple-app-store-google-play-monopoly-antitrust-bill-hearings"&gt;hauled in representatives&lt;/a&gt; from companies like Spotify, Tile, and Match Group, a dating app company, to explain how Apple and Google’s app store policies and fees harm their businesses. &lt;/p&gt;
&lt;p id="O4O8gs"&gt;Specifically, Tile’s General Counsel Kirsten Daru said that once Apple decided to make its own competing item-tracking device, the company made it more difficult for Tile products to work on the devices. Match’s Chief Legal Officer Jared Sine also said that app store fees are the company’s single largest expense.&lt;/p&gt;
&lt;p id="jbX1Ud"&gt;“We have worked toward creating a fairer and more competitive app marketplace for both developers and consumers,” said The Coalition for App Fairness, which counts Epic Games as a member, in a statement Wednesday. “The bipartisan Open App Markets Act is a step towards holding big tech companies accountable for practices that stifle competition for developers in the U.S. and around the world.&lt;/p&gt;
&lt;p id="CXe3CQ"&gt;Still, tech-backed think tanks like Chamber for Progress argue that the bill could pose a safety risk for consumers. “This bill is a finger in the eye of anyone who bought an iPhone or Android because the phones and their app stores are safe, reliable, and easy to use,” Chamber of Progress CEO Adam Kovacevich said Wednesday. “I don’t see any consumers marching in Washington demanding that Congress make their smartphones dumber.”&lt;/p&gt;
&lt;p id="uDz23s"&gt;Last year, &lt;a href="https://www.theverge.com/2021/4/29/22410877/epic-games-apple-app-store-antitrust-trial-lawsuit-news"&gt;&lt;em&gt;Fortnite &lt;/em&gt;creator Epic Games&lt;/a&gt; challenged the app store model with lawsuits Apple and Google, asking for a court-ordered injunction that would have similar effects to the proposed bill. A federal judge is currently reviewing the Apple case to determine whether the company violated antitrust law by implementing these policies. Nearly &lt;a href="https://www.theverge.com/2021/7/7/22567532/google-play-store-antitrust-lawsuit-state-ag-app-fees"&gt;40 state attorneys general&lt;/a&gt; have also sued Google over its app store model.&lt;/p&gt;
&lt;p id="zjbIYg"&gt;&lt;em&gt;&lt;strong&gt;Updated 8/11/21 at 3:38PM ET: &lt;/strong&gt;&lt;/em&gt;&lt;em&gt;Added a statement from Apple.&lt;/em&gt;&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/11/22620454/apple-google-app-store-senate-play-bill-epic-games-fortnite"/>
    <id>https://www.theverge.com/2021/8/11/22620454/apple-google-app-store-senate-play-bill-epic-games-fortnite</id>
    <author>
      <name>Makena Kelly</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-11T08:37:53-04:00</published>
    <updated>2021-08-11T08:37:53-04:00</updated>
    <title>Apple’s AirPods are on sale again for their lowest price to date</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/EZtjQ8nUeUXb8jxWZ-2HCKGaQVQ=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69709202/akrales_190327_3315_0019.0.jpg" /&gt;
        &lt;figcaption&gt;Photo by Amelia Holowaty Krales / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="WAd3ld"&gt;Apple’s second-gen AirPods are more of a refinement than a revolution, but if you’ve been waiting for the price to come down before jumping on the AirPods bandwagon, now might be the best time to do so. Although they’re often discounted to just shy of $160, Apple’s iconic earbuds and their wireless charging case are &lt;a href="https://www.amazon.com/Apple-AirPods-Wireless-Charging-Latest/dp/B07PYLT6DN?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;now available at Amazon for $130&lt;/a&gt;, the steepest price cut we’ve seen on the in-ears to date.&lt;/p&gt;
&lt;p id="klnFI4"&gt;The latest AirPods lack the noise cancellation and flexible design found on the &lt;a href="https://www.theverge.com/2019/11/1/20942472/apple-airpods-pro-review-design-price-specs-features-noise-cancellation"&gt;AirPods Pro&lt;/a&gt;, however, they still manage to deliver satisfying sound quality and dependable battery life. Plus, they’re incredibly easy to use with both Apple and Android devices, even if you do lose the double-tap gestures and a bit of convenience with the latter operating system. &lt;a href="https://www.theverge.com/2019/3/29/18286012/apple-airpods-2-new-2nd-gen-review-price-specs-features"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id="8ZIlX8"&gt;&lt;div data-anthem-component="productcard:9507432"&gt;&lt;/div&gt;&lt;/div&gt;
&lt;aside id="klTSye"&gt;&lt;div data-anthem-component="readmore" data-anthem-component-data='{"stories":[{"title":"Apple AirPods update to arrive later this year with iPhone SE refresh coming 2022: report","url":"https://www.theverge.com/2021/7/21/22586507/apple-airpods-2021-refresh-rumor-iphone-se-2022-5g-15-details"}]}'&gt;&lt;/div&gt;&lt;/aside&gt;&lt;p id="XAR7O5"&gt;If you’re a PlayStation gamer, Amazon is currently discounting &lt;a href="https://www.theverge.com/2021/4/29/22408468/returnal-ps5-dualsense-3d-audio"&gt;&lt;em&gt;Returnal&lt;/em&gt;&lt;/a&gt; and a range of PS5 exclusives, along with at least one of Sony’s first-party accessories: the PlayStation HD Camera. The simple black-and-white device is built with streamers in mind, and as such, it features dual 1080p lenses, a built-in stand, and a set of software tools that let you crop your background or remove it entirely if you’re utilizing a green screen. It’s not compatible with the PSVR — Sony &lt;a href="https://blog.playstation.com/2020/10/09/ps4-games-on-ps5-your-top-questions-answered/"&gt;has confirmed as much&lt;/a&gt; — but it’s still a great way to broadcast yourself alongside your gameplay. Right now, it’s &lt;a href="https://www.amazon.com/dp/B08FC5V8L7/?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;available at Amazon for $40&lt;/a&gt;, the best price we’ve seen on the Sony peripheral since it launched in November.&lt;/p&gt;
&lt;div id="69ZPv7"&gt;&lt;div data-anthem-component="productcard:10694744"&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p id="iG8e1L"&gt;While many of us can understand the appeal of traditional books, there’s no denying the appeal of a device like the Kindle Paperwhite. Amazon’s 10th-gen device is a great way to lug your books around town — whether you own one or 1,000 titles — and comes with a crisp 300ppi, six-inch E Ink panel and support for Audible audiobooks. It’s also waterproof and, unlike most modern devices, lasts for weeks on a single charge, meaning you rarely need to worry about grabbing a power brick before heading out the door. Normally $130,  the 8GB, ad-supported version of the &lt;a href="https://goto.target.com/c/482924/81938/2092?u=https%3A%2F%2Fwww.target.com%2Fp%2Famazon-kindle-paperwhite---waterproof--ad-supported--10th-generation-%2F-%2FA-75574430"&gt;Kindle Paperwhite is available at Target today for $85&lt;/a&gt;, one of the best deals we’ve encountered on the popular e-reader outside of Amazon Prime Day. &lt;a href="https://www.theverge.com/2018/11/7/18065960/amazon-kindle-paperwhite-2018-review"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id="XAJNAJ"&gt;&lt;div data-anthem-component="productcard:10695294"&gt;&lt;/div&gt;&lt;/div&gt;
&lt;aside id="RQc2MS"&gt;&lt;div data-anthem-component="readmore" data-anthem-component-data='{"stories":[{"title":"Here are the best Kindle deals right now","url":"https://www.theverge.com/21539047/best-amazon-kindle-deals"}]}'&gt;&lt;/div&gt;&lt;/aside&gt;&lt;h2 id="KeHhcj"&gt;Other deals of note&lt;/h2&gt;
&lt;ul&gt;
&lt;li id="6cb9Zm"&gt;
&lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.lenovo.com%2Fus%2Fen%2Faccessories-and-monitors%2Fkeyboards-and-mice%2Fmice%2FMX-MASTER-2S-WL-MOUSE-WRLS%2Fp%2F78016250&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2Fgood-deals%2F2021%2F8%2F11%2F22617634%2Fapple-airpods-wireless-charging-case-playstation-5-hd-camera-amazon-kindle-paperwhite-deal-sale" rel="sponsored nofollow noopener" target="_blank"&gt;Logitech’s MX Master 2S&lt;/a&gt; is $50 at Lenovo with promo code &lt;strong&gt;MXMASTER50&lt;/strong&gt;, matching the best price we’ve seen on the last-gen wireless mouse.&lt;/li&gt;
&lt;li id="i02NBX"&gt;The 2020 iPad Air with 64GB of storage and Wi-Fi is $100 off at &lt;a href="https://www.amazon.com/gp/product/B08J61FCVN?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Amazon&lt;/a&gt; and &lt;a href="https://shop-links.co/1748634717956796230#donotlink" rel="sponsored nofollow noopener" target="_blank"&gt;Best Buy&lt;/a&gt;, a discount that puts it in line with its best price to date. &lt;a href="https://www.theverge.com/21525780/apple-ipad-air-2020-review" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li id="NIYILg"&gt;
&lt;a href="https://www.amazon.com/Apple-Mini-Chip-256GB-Storage/dp/B08N5PHB83/?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Apple’s M1-powered Mac Mini&lt;/a&gt; with 8GB of RAM and 256GB of storage is $100 off at Amazon (discount applies at checkout), bringing the desktop machine to an all-time low of $599. &lt;a href="https://www.theverge.com/2020/11/17/21570046/apple-mac-mini-2020-m1-review" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li id="H82cIf"&gt;A one-year, &lt;a href="https://start.1password.com/sign-up?c=SCHOOL2021" rel="sponsored nofollow noopener" target="_blank"&gt;individual subscription to 1Password&lt;/a&gt; is $18, a cool $7 off the typical list price. For a limited time, you can also save $20 on an &lt;a href="https://start.1password.com/sign-up/family?c=SCHOOL2021" rel="sponsored nofollow noopener" target="_blank"&gt;annual family plan&lt;/a&gt;, which allows for up to five family members, shared vaults, and unlimited devices.&lt;/li&gt;
&lt;li id="kiBjbR"&gt;Both editions of &lt;a href="https://shop-links.co/1748649502070179627#donotlink" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;em&gt;Mario Kart Live: Home Circuit&lt;/em&gt;&lt;/a&gt; are available at Best Buy for $75, matching the best price we’ve seen on the clever, remote-controlled racing title. &lt;a href="https://www.theverge.com/21514758/mario-kart-live-home-circuit-review-nintendo-switch" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li id="wnkutA"&gt;A three-foot, &lt;a href="https://www.anrdoezrs.net/click-8836598-13527013?url=https%3A%2F%2Fsellout.woot.com%2Foffers%2Famazonbasics-mfi-certified-usb-a-to-lightning-cable-1pk-1%3Futm_medium%3Daffiliate%26utm_campaign%3DCJ%26cjevent%3D8d6214e0f96e11eb80afd6d90a1c0e10%26utm_source%3DSlickdeals%2BLLC" rel="sponsored nofollow noopener" target="_blank"&gt;AmazonBasics USB-A to Lightning cable&lt;/a&gt; is $4 at Woot for Prime Members, a significant discount on the basic Apple accessory.&lt;/li&gt;
&lt;li id="cWdD94"&gt;The Beats Studio Buds are $130 at &lt;a href="https://www.amazon.com/dp/B096SV8SJG/?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Amazon&lt;/a&gt; and &lt;a href="http://goto.walmart.com/c/1141873/565706/9383?subId1=Verge&amp;amp;veh=aff&amp;amp;sourceid=imp_000011112222333344&amp;amp;u=https%3A%2F%2Fwww.walmart.com%2Fip%2FBeats-Studio-Buds-True-Wireless-Noise-Cancelling-Bluetooth-Earbuds-Black%2F643659699&amp;amp;partnerpropertyid=1065598" rel="sponsored nofollow noopener" target="_blank"&gt;Walmart&lt;/a&gt;, the first discount Apple’s fitness-focused earbuds have received since launching in June. &lt;a href="https://www.theverge.com/22532970/beats-studio-buds-review" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li id="4PXbhi"&gt;Best Buy has &lt;a href="https://shop-links.co/1748787582667771452#donotlink" rel="sponsored nofollow noopener" target="_blank"&gt;Geek Squad-certified refurbished versions of the Samsung Galaxy Buds Pro&lt;/a&gt; in silver for $85, a discount of $115 off their list price. &lt;a href="https://www.theverge.com/2021/1/15/22231848/samsung-galaxy-buds-pro-review" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review.&lt;/strong&gt;&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;aside id="JAgAgN"&gt;&lt;div data-anthem-component="newsletter" data-anthem-component-data='{"slug":"deals"}'&gt;&lt;/div&gt;&lt;/aside&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/good-deals/2021/8/11/22617634/apple-airpods-wireless-charging-case-playstation-5-hd-camera-amazon-kindle-paperwhite-deal-sale"/>
    <id>https://www.theverge.com/good-deals/2021/8/11/22617634/apple-airpods-wireless-charging-case-playstation-5-hd-camera-amazon-kindle-paperwhite-deal-sale</id>
    <author>
      <name>Brandon Widder</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-10T17:43:03-04:00</published>
    <updated>2021-08-10T17:43:03-04:00</updated>
    <title>Apple’s controversial new child protection features, explained</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/rxZvrW0rpUQ9VAnQVwCTqnsA-zM=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69706816/acastro_180604_1777_apple_wwdc_0003.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="Qvb3Xg"&gt;Apple stakes its reputation on privacy. The company has promoted encrypted messaging across its ecosystem, encouraged limits on how mobile apps can gather data, and fought law enforcement agencies looking for user records. For the past week, though, Apple has been fighting accusations that its upcoming iOS and iPadOS release will weaken user privacy.&lt;/p&gt;
&lt;p id="zVWpBi"&gt;The debate stems from an &lt;a href="https://www.theverge.com/2021/8/5/22611305/apple-scan-photos-iphones-icloud-child-abuse-imagery-neuralmatch"&gt;announcement Apple made&lt;/a&gt; on Thursday. In theory, the idea is pretty simple: Apple wants to fight child sexual abuse, and it’s taking more steps to find and stop it. But critics say &lt;a href="https://www.theverge.com/22617554/apple-csam-child-safety-features-jen-king-riana-pfefferkorn-interview-decoder"&gt;Apple’s strategy could weaken&lt;/a&gt; users’ control over their own phones, leaving them reliant on Apple’s promise that it won’t abuse its power. And Apple’s response has highlighted just how complicated — and sometimes downright confounding — the conversation really is.&lt;/p&gt;
&lt;h2 id="oxykkz"&gt;&lt;strong&gt;What did Apple announce last week?&lt;/strong&gt;&lt;/h2&gt;
&lt;p id="dc6dr1"&gt;Apple has &lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.apple.com%2Fchild-safety%2F&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F2021%2F8%2F10%2F22613225%2Fapple-csam-scanning-messages-child-safety-features-privacy-controversy-explained" rel="sponsored nofollow noopener" target="_blank"&gt;announced three changes&lt;/a&gt; that will roll out later this year — all related to curbing child sexual abuse but targeting different apps with different feature sets.&lt;/p&gt;
&lt;p id="ztjL4D"&gt;The first change affects Apple’s Search app and Siri. If a user searches for topics related to child sexual abuse, Apple will direct them to resources for reporting it or getting help with an attraction to it. That’s rolling out later this year on iOS 15, watchOS 8, iPadOS 15, and macOS Monterey, and it’s largely uncontroversial.&lt;/p&gt;
&lt;p id="DhX8SA"&gt;The other updates, however, have generated far more backlash. One of them adds a parental control option to Messages, obscuring sexually explicit pictures for users under 18 and sending parents an alert if a child 12 or under views or sends these pictures.&lt;/p&gt;
&lt;p id="9ZwidK"&gt;The final new feature scans iCloud Photos images to find child sexual abuse material, or CSAM, and reports it to Apple moderators — who can pass it on to the National Center for Missing and Exploited Children, or NCMEC. Apple says it’s designed this feature specifically to protect user privacy while finding illegal content. Critics say that same designs amounts to a security backdoor.&lt;/p&gt;
&lt;h2 id="XeULNq"&gt;&lt;strong&gt;What is Apple doing with Messages?&lt;/strong&gt;&lt;/h2&gt;
&lt;p id="YemRv3"&gt;Apple is introducing a Messages feature that’s meant to protect children from inappropriate images. If parents opt in, devices with users under 18 will scan incoming and outgoing pictures with an image classifier trained on pornography, looking for “sexually explicit” content. (Apple says it’s not technically limited to nudity but that a nudity filter is a fair description.) If the classifier detects this content, it obscures the picture in question and asks the user whether they really want to view or send it.&lt;/p&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt="A screenshot of Apple’s Messages filter for sexually explicit content." data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/DcBS2sGWzUDR2RWMe6AIhKN4IWY=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22774655/CCEA6371_9191_46CC_BDE4_B2DAB4CC4409.jpeg"&gt;
      &lt;cite&gt;Image: Apple&lt;/cite&gt;
      &lt;figcaption&gt;&lt;em&gt;A screenshot of Apple’s Messages filter for sexually explicit content.&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;p id="n4evJQ"&gt;The update — coming to accounts set up as families in iCloud on iOS 15, iPadOS 15, and macOS Monterey — also includes an additional option. If a user taps through that warning and they’re under 13, Messages will be able to notify a parent that they’ve done it. Children will see a caption warning that their parents will receive the notification, and the parents won’t see the actual message. The system doesn’t report anything to Apple moderators or other parties.&lt;/p&gt;
&lt;p id="A9Rr8f"&gt;The images are detected on-device, which Apple says protects privacy. And parents are notified if children actually confirm they want to see or send adult content, not if they simply receive it. At the same time, critics like Harvard Cyberlaw Clinic instructor Kendra Albert have &lt;a href="https://twitter.com/KendraSerra/status/1423365222841135114?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1423367106972852228%7Ctwgr%5E%7Ctwcon%5Es2_&amp;amp;ref_url=https%3A%2F%2Fwww.theverge.com%2F2021%2F8%2F6%2F22613365%2Fapple-icloud-csam-scanning-whatsapp-surveillance-reactions"&gt;raised concerns&lt;/a&gt; about the notifications — saying they could end up outing queer or transgender kids, for instance, by encouraging their parents to snoop on them.&lt;/p&gt;
&lt;h2 id="04Xy16"&gt;&lt;strong&gt;What does Apple’s new iCloud Photos scanning system do?&lt;/strong&gt;&lt;/h2&gt;
&lt;p id="OfIeOI"&gt;The iCloud Photos scanning system is focused on finding child sexual abuse images, which are illegal to possess. If you’re a US-based iOS or iPadOS user and you sync pictures with iCloud Photos, your device will locally check these pictures against a list of known CSAM. If it detects enough matches, it will alert Apple’s moderators and reveal the details of the matches. If a moderator confirms the presence of CSAM, they’ll disable the account and report the images to legal authorities.&lt;/p&gt;
&lt;h2 id="mmwusD"&gt;&lt;strong&gt;Is CSAM scanning a new idea?&lt;/strong&gt;&lt;/h2&gt;
&lt;p id="Qo0T8L"&gt;Not at all. Facebook, Twitter, Reddit, and many other companies scan users’ files against hash libraries, often using a Microsoft-built tool called PhotoDNA. They’re also legally required to report CSAM to the National Center for Missing and Exploited Children (NCMEC), a nonprofit that works alongside law enforcement.&lt;/p&gt;
&lt;p id="0ZjID1"&gt;Apple has limited its efforts until now, though. The company has said previously that it uses image matching technology to find child exploitation. But in a call with reporters, it said it’s never scanned iCloud Photos data. (It confirmed that it already scanned iCloud Mail but didn’t offer any more detail about scanning other Apple services.)&lt;/p&gt;
&lt;h2 id="AaZIXm"&gt;&lt;strong&gt;Is Apple’s new system different from other companies’ scans?&lt;/strong&gt;&lt;/h2&gt;
&lt;p id="OOjY2L"&gt;A typical CSAM scan runs remotely and looks at files that are stored on a server. Apple’s system, by contrast, checks for matches locally on your iPhone or iPad.&lt;/p&gt;
&lt;p id="EuJuhx"&gt;The system works as follows. When iCloud Photos is enabled on a device, the device uses a tool called NeuralHash to break these pictures into hashes — basically strings of numbers that identify the unique characteristics of an image but can’t be reconstructed to reveal the image itself. Then, it compares these hashes against a stored list of hashes from NCMEC, which compiles millions of hashes corresponding to known CSAM content. (Again, as mentioned above, there are no actual pictures or videos.)&lt;/p&gt;
&lt;p id="h8ucZY"&gt;If Apple’s system finds a match, your phone generates a “safety voucher” that’s uploaded to iCloud Photos. Each safety voucher indicates that a match exists, but it doesn’t alert any moderators and it encrypts the details, so an Apple employee can’t look at it and see which photo matched. However, if your account generates a certain number of vouchers, the vouchers all get decrypted and flagged to Apple’s human moderators — who can then review the photos and see if they contain CSAM.&lt;/p&gt;
&lt;p id="b52TDh"&gt;Apple emphasizes that it’s exclusively looking at photos you sync with iCloud, not ones that are only stored on your device. It tells reporters that disabling iCloud Photos will completely deactivate all parts of the scanning system, including the local hash generation. “If users are not using iCloud Photos, NeuralHash will not run and will not generate any vouchers,” Apple privacy head Erik Neuenschwander &lt;a href="https://techcrunch.com/2021/08/10/interview-apples-head-of-privacy-details-child-abuse-detection-and-messages-safety-features/?tpcc=ECTW2020"&gt;told &lt;em&gt;TechCrunch&lt;/em&gt; in an interview&lt;/a&gt;.&lt;/p&gt;
&lt;p id="pJqada"&gt;Apple has used on-device processing to bolster its privacy credentials in the past. iOS can &lt;a href="https://www.theverge.com/2016/6/13/11924080/apple-ai-on-device-privacy-wwdc-2016"&gt;perform a lot of AI analysis&lt;/a&gt; without sending any of your data to cloud servers, for example, which means fewer chances for a third party to get their hands on it.&lt;/p&gt;
&lt;p id="4wSx4y"&gt;But the local / remote distinction here is hugely contentious, and following a backlash, Apple has spent the past several days drawing extremely subtle lines between the two.&lt;/p&gt;
&lt;h2 id="rKzkRU"&gt;&lt;strong&gt;Why are some people upset about these changes?&lt;/strong&gt;&lt;/h2&gt;
&lt;p id="cAxm1C"&gt;Before we get into the criticism, it’s worth saying: Apple has gotten praise for these updates from some privacy and security experts, including the prominent cryptographers and computer scientists Mihir Bellare, David Forsyth, and Dan Boneh. “This system will likely significantly increase the likelihood that people who own or traffic in [CSAM] are found,” said Forsyth in an endorsement provided by Apple. “Harmless users should experience minimal to no loss of privacy.”&lt;/p&gt;
&lt;p id="M6nWSV"&gt;But other experts and advocacy groups have come out against the changes. They say the iCloud and Messages updates have the same problem: they’re creating surveillance systems that work directly from your phone or tablet. That could provide a blueprint for breaking secure end-to-end encryption, and even if its use is limited right now, it could open the door to more troubling invasions of privacy.&lt;/p&gt;
&lt;p id="kF34kp"&gt;&lt;a href="https://appleprivacyletter.com/"&gt;An August 6th open letter&lt;/a&gt; outlines the complaints in more detail. Here’s its description of what’s going on:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p id="b50GTi"&gt;While child exploitation is a serious problem, and while efforts to combat it are almost unquestionably well-intentioned, Apple’s proposal introduces a backdoor that threatens to undermine fundamental privacy protections for all users of Apple products.&lt;/p&gt;
&lt;p id="GC2dGn"&gt;Apple’s proposed technology works by continuously monitoring photos saved or shared on the user’s iPhone, iPad, or Mac. One system detects if a certain number of objectionable photos is detected in iCloud storage and alerts the authorities. Another notifies a child’s parents if iMessage is used to send or receive photos that a machine learning algorithm considers to contain nudity.&lt;/p&gt;
&lt;p id="drY3RR"&gt;Because both checks are performed on the user’s device, they have the potential to bypass any end-to-end encryption that would otherwise safeguard the user’s privacy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p id="wR3KIb"&gt;Apple has disputed the characterizations above, particularly the term “backdoor” and the description of monitoring photos saved on a user’s device. But as we’ll explain below, it’s asking users to put a lot of trust in Apple, while the company is facing government pressure around the world.&lt;/p&gt;
&lt;h2 id="7F22ax"&gt;&lt;strong&gt;What’s end-to-end encryption, again?&lt;/strong&gt;&lt;/h2&gt;
&lt;p id="Su1Rpy"&gt;To massively simplify, end-to-end encryption (or E2EE) makes data unreadable to anyone besides the sender and receiver; in other words, not even the company running the app can see it. Less secure systems can still be encrypted, but companies may hold keys to the data so they can scan files or grant access to law enforcement. Apple’s iMessages uses E2EE; iCloud Photos, like many cloud storage services, doesn’t.&lt;/p&gt;
&lt;p id="esnJuH"&gt;While E2EE can be incredibly effective, it doesn’t necessarily stop people from seeing data on the phone itself. That leaves the door open for specific kinds of surveillance, including a system that Apple is now accused of adding: client-side scanning.&lt;/p&gt;
&lt;h2 id="YEyzOe"&gt;&lt;strong&gt;What is client-side scanning?&lt;/strong&gt;&lt;/h2&gt;
&lt;p id="8jPj5E"&gt;The Electronic Frontier Foundation &lt;a href="https://www.eff.org/deeplinks/2019/11/why-adding-client-side-scanning-breaks-end-end-encryption"&gt;has a detailed outline&lt;/a&gt; of client-side scanning. Basically, it involves analyzing files or messages in an app before they’re sent in encrypted form, often checking for objectionable content — and in the process, bypassing the protections of E2EE by targeting the device itself. In a phone call with &lt;em&gt;The Verge&lt;/em&gt;, EFF senior staff technologist Erica Portnoy compared these systems to somebody looking over your shoulder while you’re sending a secure message on your phone.&lt;/p&gt;
&lt;h2 id="PQK32h"&gt;&lt;strong&gt;Is Apple doing client-side scanning?&lt;/strong&gt;&lt;/h2&gt;
&lt;p id="5x75cC"&gt;Apple vehemently denies it. In &lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.apple.com%2Fchild-safety%2Fpdf%2FExpanded_Protections_for_Children_Frequently_Asked_Questions.pdf&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F2021%2F8%2F10%2F22613225%2Fapple-csam-scanning-messages-child-safety-features-privacy-controversy-explained" rel="sponsored nofollow noopener" target="_blank"&gt;a frequently asked questions document&lt;/a&gt;, it says Messages is still end-to-end encrypted and absolutely no details about specific message content are being released to anybody, including parents. “Apple never gains access to communications as a result of this feature in Messages,” it promises.&lt;/p&gt;
&lt;p id="Cks3Ug"&gt;It also rejects the framing that it’s scanning photos &lt;em&gt;on your device &lt;/em&gt;for CSAM. “By design, this feature only applies to photos that the user chooses to upload to iCloud,” its FAQ says. “The system does not work for users who have iCloud Photos disabled. This feature does not work on your private iPhone photo library on the device.” The company later clarified to reporters that Apple could scan iCloud Photos images synced via third-party services as well as its own apps.&lt;/p&gt;
&lt;p id="8QKiFs"&gt;As Apple acknowledges, iCloud Photos doesn’t even have any E2EE to break, so it could easily run these scans on its servers — just like lots of other companies. Apple argues its system is actually more secure. Most users are unlikely to to have CSAM on their phone, and Apple claims only around 1 in 1 trillion accounts could be incorrectly flagged. With this local scanning system, Apple says it won’t expose any information about anybody else’s photos, which wouldn’t be true if it scanned its servers.&lt;/p&gt;
&lt;h2 id="L7G048"&gt;&lt;strong&gt;Are Apple’s arguments convincing?&lt;/strong&gt;&lt;/h2&gt;
&lt;p id="0BGcyZ"&gt;Not to a lot of its critics. As Ben Thompson &lt;a href="https://stratechery.com/2021/apples-mistake/"&gt;writes at &lt;em&gt;Stratechery&lt;/em&gt;&lt;/a&gt;, the issue isn’t whether Apple is only sending notifications to parents or restricting its searches to specific categories of content. It’s that the company is searching through data before it leaves your phone.&lt;/p&gt;
&lt;blockquote&gt;&lt;p id="rdr527"&gt;Instead of adding CSAM scanning to iCloud Photos in the cloud that they own and operate, Apple is compromising the phone that you and I own and operate, without any of us having a say in the matter. Yes, you can turn off iCloud Photos to disable Apple’s scanning, but that is a policy decision; the capability to reach into a user’s phone now exists, and there is nothing an iPhone user can do to get rid of it.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p id="7FEaCM"&gt;CSAM is illegal and abhorrent. But as the open letter to Apple notes, many countries have pushed to compromise encryption in the name of fighting terrorism, misinformation, and other objectionable content. Now that Apple has set this precedent, it will almost certainly face calls to expand it. And if Apple later rolls out end-to-end encryption for iCloud — something it’s reportedly &lt;a href="https://www.reuters.com/article/us-apple-fbi-icloud-exclusive/exclusive-apple-dropped-plan-for-encrypting-backups-after-fbi-complained-sources-idUSKBN1ZK1CT"&gt;considered doing, albeit never implemented&lt;/a&gt; — it’s laid out a possible roadmap for getting around E2EE’s protections.&lt;/p&gt;
&lt;p id="rH0qDp"&gt;Apple says it will refuse any calls to abuse its systems. And it boasts a lot of safeguards: the fact that parents can’t enable alerts for older teens in Messages, that iCloud’s safety vouchers are encrypted, that it sets a threshold for alerting moderators, and that its searches are US-only and strictly limited to NCMEC’s database.&lt;/p&gt;
&lt;blockquote&gt;&lt;p id="j65XiD"&gt;Apple’s CSAM detection capability is built solely to detect known CSAM images stored in iCloud Photos that have been identified by experts at NCMEC and other child safety groups. We have faced demands to build and deploy government-mandated changes that degrade the privacy of users before, and have steadfastly refused those demands. We will continue to refuse them in the future. Let us be clear, this technology is limited to detecting CSAM stored in iCloud and we will not accede to any government’s request to expand it.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p id="aOwkc0"&gt;The issue is, Apple has the power to modify these safeguards. “Half the problem is that the system is so easy to change,” says Portnoy. Apple has stuck to its guns in some clashes with governments; it &lt;a href="https://www.theverge.com/2016/2/17/11036306/apple-fbi-iphone-encryption-backdoor-tim-cook"&gt;famously defied&lt;/a&gt; a Federal Bureau of Investigation demand for data from a mass shooter’s iPhone. But it’s &lt;a href="https://www.theverge.com/2018/7/18/17587304/apple-icloud-china-user-data-state-run-telecom-privacy-security"&gt;acceded to other requests&lt;/a&gt; like storing Chinese iCloud data locally, even if it insists it hasn’t compromised user security by doing so.&lt;/p&gt;
&lt;p id="6AmFSw"&gt;Stanford Internet Observatory professor Alex Stamos &lt;a href="https://twitter.com/alexstamos/status/1424054555394727939"&gt;also questioned&lt;/a&gt; how well Apple had worked with the larger encryption expert community, saying that the company had declined to participate in a series of discussions about safety, privacy, and encryption. “With this announcement they just busted into the balancing debate and pushed everybody into the furthest corners with no public consultation or debate,” he tweeted.&lt;/p&gt;
&lt;h2 id="AqTnwc"&gt;&lt;strong&gt;How do the benefits of Apple’s new features stack up against the risks?&lt;/strong&gt;&lt;/h2&gt;
&lt;p id="EAtRi1"&gt;As usual, it’s complicated — and it depends partly on whether you see this change as a limited exception or an opening door.&lt;/p&gt;
&lt;p id="2jEzpt"&gt;Apple has legitimate reasons to step up its child protection efforts. In late 2019, &lt;a href="https://www.nytimes.com/interactive/2019/09/28/us/child-sex-abuse.html"&gt;&lt;em&gt;The New York Times&lt;/em&gt; published reports&lt;/a&gt; of an “epidemic” in online child sexual abuse. It blasted American tech companies for failing to address the spread of CSAM, and in a later article, &lt;a href="https://www.nytimes.com/2020/02/07/us/online-child-sexual-abuse.html"&gt;NCMEC singled out Apple&lt;/a&gt; for its low reporting rates compared to peers like Facebook, something the &lt;em&gt;Times&lt;/em&gt; attributed partly to the company not scanning iCloud files.&lt;/p&gt;
&lt;p id="Fo9lbl"&gt;Meanwhile, internal Apple documents have said that iMessage has a sexual predator problem. In documents revealed by the recent &lt;em&gt;Epic v. Apple&lt;/em&gt; trial, an Apple department head listed “child predator grooming” as an under-resourced “active threat” for the platform. Grooming often includes sending children (or asking children to send) sexually explicit images, which is exactly what Apple’s new Messages feature is trying to disrupt.&lt;/p&gt;
&lt;p id="9KQCtc"&gt;At the same time, Apple itself has &lt;a href="https://www.theverge.com/2018/3/28/17172718/apple-ceo-tim-cook-privacy-facebook-cambridge-analytica"&gt;called privacy&lt;/a&gt; a “human right.” Phones are intimate devices full of sensitive information. With its Messages and iCloud changes, Apple has demonstrated two ways to search or analyze content directly on the hardware rather than after you’ve sent data to a third party, even if it’s analyzing data that you &lt;em&gt;have&lt;/em&gt; consented to send, like iCloud photos.&lt;/p&gt;
&lt;p id="dWs0I6"&gt;Apple has acknowledged the objections to its updates. But so far, it hasn’t indicated plans to modify or abandon them. On Friday, &lt;a href="https://9to5mac.com/2021/08/06/apple-internal-memo-icloud-photo-scanning-concerns/"&gt;an internal memo&lt;/a&gt; acknowledged “misunderstandings” but praised the changes. “What we announced today is the product of this incredible collaboration, one that delivers tools to protect children, but also maintain Apple’s deep commitment to user privacy,” it reads. “We know some people have misunderstandings, and more than a few are worried about the implications, but we will continue to explain and detail the features so people understand what we’ve built.”&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/10/22613225/apple-csam-scanning-messages-child-safety-features-privacy-controversy-explained"/>
    <id>https://www.theverge.com/2021/8/10/22613225/apple-csam-scanning-messages-child-safety-features-privacy-controversy-explained</id>
    <author>
      <name>Adi Robertson</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-10T13:44:04-04:00</published>
    <updated>2021-08-10T13:44:04-04:00</updated>
    <title>Here’s why Apple’s new child safety features are so controversial</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/L8aonSnsyj7CRHujfw7YFDDk_38=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69705443/acstro_190902_apple_event_0004.0.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;


  &lt;p&gt;Encryption and consumer privacy experts break down Apple’s plan for child safety&lt;/p&gt; &lt;p class="p--has-dropcap p-large-text" id="IsDfmF"&gt;Last week, Apple, without very much warning at all, announced &lt;a href="https://www.theverge.com/2021/8/5/22611721/apple-csam-child-abuse-scanning-hash-system-ncmec"&gt;a new set of tools built into the iPhone designed to protect children from abuse&lt;/a&gt;. Siri will now offer resources to people who ask for child abuse material or who ask how to report it. iMessage will now flag nudes sent or received by kids under 13 and alert their parents. Images backed up to iCloud Photos will now be matched against a database of known child sexual abuse material (CSAM) and reported to the National Center for Missing and Exploited Children (NCMEC) if more than a certain number of images match. And that matching process doesn’t just happen in the cloud — part of it happens locally on your phone. That’s a big change from how things normally work.&lt;/p&gt;
&lt;p id="kGCO04"&gt;Apple claims it designed what it says is a much more private process that involves scanning images on your phone. And that is a very big line to cross — basically, the iPhone’s operating system now has the capability to look at your photos and match them up against a database of illegal content, and you cannot remove that capability. And while we might all agree that adding this capability is justifiable in the face of child abuse, there are huge questions about what happens when governments around the world, from the UK to China, ask Apple to match up other kinds of images — terrorist content, images of protests, pictures of dictators looking silly. These kinds of demands are routinely made around the world. And until now, no part of that happened on your phone in your pocket. &lt;/p&gt;
&lt;div&gt;  &lt;figure class="e-image"&gt;
        &lt;img alt="Riana Pfefferkorn and Jen King, from Stanford, in the the Decoder art style" data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/sci2ZRqVPfK84REZCRLuSAbN_FM=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22773381/VRG_ILLO_Decoder_King_Apple_alt_s.jpg"&gt;
      &lt;cite&gt;Photo Illustration by Grayson Blackmon / The Verge&lt;/cite&gt;
      &lt;figcaption&gt;Riana Pfefferkorn and Jen King&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;p id="cvYmzL"&gt;To unpack all of this, I asked Riana Pfefferkorn and Jennifer King to join me on the show. They’re both researchers at Stanford: Riana specializes in encryption policies, while Jen specializes in privacy and data policy. She’s also worked on child abuse issues at big tech companies in the past. &lt;/p&gt;
&lt;p id="6bjvBx"&gt;I think for a company with as much power and influence as Apple, rolling out a system that changes an important part of our relationship with our personal devices deserves thorough and frequent explanation. I hope the company does more to explain what it’s doing, and soon.&lt;/p&gt;
&lt;div id="UP7DUJ"&gt;
&lt;iframe frameborder="0" height="200" scrolling="no" src="https://playlist.megaphone.fm?e=VMP7739805133" width="100%"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p id="5wAaCG"&gt;&lt;em&gt;The following transcript has been lightly edited for clarity.&lt;/em&gt;&lt;/p&gt;
&lt;p id="KxKLBU"&gt;&lt;strong&gt;Jen King and Riana Pfefferkorn, you are both researchers at Stanford. Welcome to &lt;/strong&gt;&lt;em&gt;&lt;strong&gt;Decoder&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="9sFZPq"&gt;&lt;strong&gt;Jen King:&lt;/strong&gt; Thanks for having us.&lt;/p&gt;
&lt;p id="08rIGv"&gt;&lt;strong&gt;Riana Pfefferkorn:&lt;/strong&gt; Thank you.&lt;/p&gt;
&lt;p id="t6omtz"&gt;&lt;strong&gt;Let’s start with some introductions. Riana, what’s your title and what do you work on at Stanford?&lt;/strong&gt;&lt;/p&gt;
&lt;p id="sdjgPF"&gt;&lt;strong&gt;RP:&lt;/strong&gt; My name is Riana Pfefferkorn. I’m a research scholar at the Stanford Internet Observatory. I’ve been at Stanford in various capacities since late 2015, and I primarily focus on encryption policies. So this is really a moment in the sun for me, for better or for worse.&lt;/p&gt;
&lt;p id="wmcb35"&gt;&lt;strong&gt;Welcome to the light. Jen, what about you? What’s your title, what do you work on?&lt;/strong&gt;&lt;/p&gt;
&lt;p id="vqfdMT"&gt;&lt;strong&gt;JK: &lt;/strong&gt;I am a fellow on privacy and data policy at the Stanford Institute for Human-Centered Artificial Intelligence. I’ve been at Stanford since 2018, and I focus primarily on consumer privacy issues. And so, that runs the gamut across social networks, AI, you name it. If it involves data and people and privacy, it’s kind of in my wheelhouse.&lt;/p&gt;
&lt;p id="zKYsvx"&gt;&lt;strong&gt;I asked both of you to come on the show because of a very complicated new set of tools from Apple, designed to protect children from harm. &lt;/strong&gt;&lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.apple.com%2Fchild-safety%2F&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F22617554%2Fapple-csam-child-safety-features-jen-king-riana-pfefferkorn-interview-decoder" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;The announcement of those tools&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;, the tools themselves, how they’ve been announced, how they’ve been communicated about, have generated a tremendous amount of confusion and controversy, so I’m hoping you can help me understand the tools, and then understand the controversy.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="xINx0r"&gt;&lt;strong&gt;There’s three of them. Let’s go through them from simplest to most complicated. The simplest one actually seems totally fine to me. Correct me if I’m wrong. If you ask Siri on the iPhone for information on how to report child abuse, or much more oddly, if you ask it for child abuse material, it will give you resources to help you report it, or tell you to get support for yourself. This does not seem very controversial at all. It also frankly seems very strange that Apple realized that it was getting this many inquiries to Siri. But, there it is.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="pgwMzW"&gt;&lt;strong&gt;That seems fine to me.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="1Gc5yr"&gt;&lt;strong&gt;JK:&lt;/strong&gt; It doesn’t really raise any red flags for me, I don’t know about you, Riana.&lt;/p&gt;
&lt;p id="tGhHk3"&gt;&lt;strong&gt;RP: &lt;/strong&gt;This seems like something that I’m not sure if this was part of their initial announcement, or if they’d hurriedly added this after the fact, once people started critiquing them or saying, oh my God, this is going to have such a terrible impact on trans and queer and closeted youth. &lt;/p&gt;
&lt;p id="K2rMtS"&gt;As it stands, I don’t think it’s controversial, I just am not convinced that it’s going to be all that helpful. Because what they are saying is, if you ask Siri, “Siri, I’m being abused at home, what can I do?” Siri will basically tell you, according to their documentation, go report it somewhere else. Apple still doesn’t want to know about this. &lt;/p&gt;
&lt;p id="pAqKdm"&gt;Note that they are not making any changes to the abuse reporting functionality of iMessage, which, as I understand it, is limited basically to like, spam. They could’ve added that directly in iMessage, given that iMessage is the tool where all of this is happening. Instead, they’re saying, if you just happen to go and talk to Siri about this, we will point you to some other resources that are not Apple.&lt;/p&gt;
&lt;p id="AX6rXI"&gt;&lt;strong&gt;I think that question about overall effectiveness pervades this entire conversation. But in terms of, here’s the thing, the controversy is pretty small. This one to me feels simple and seemingly the least important to focus on.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="1hqgvR"&gt;&lt;strong&gt;The next one does have some meaningful controversy associated with it, which is, if you are a child who is [12 years old] or younger, and you’re on your family’s iCloud plan, and you send or receive nudes in iMessage, the Messages app on your phone will detect it, and then tell your parents if you view it. And if you’re sending it, it will detect it, say, “do you really want send it?” and then tell your parents if you choose to send it. This has a wide variety of privacy implications for children; a wide variety of implications particularly for queer youth, and transgender youth.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="ID21At"&gt;&lt;strong&gt;At the same time, it feels to me like the controversy around this one is just: how is this deployed? Who will get to use it? Will they always be operating with their children’s best interests at heart? But there’s no technical controversy here. This is a policy controversy, as near as I understand. Is that right, Jen?&lt;/strong&gt;&lt;/p&gt;
&lt;p id="5y0o4Q"&gt;&lt;strong&gt;JK: &lt;/strong&gt;I think so. I say that with a small hesitation, because I am not sure, and Riana may know the answer to this. where they’re doing that real-time scanning to determine whether the image itself, how much, I guess — the proportion of skin it probably contains. I assume that’s happening on the client side, on the phone itself. And I don’t know if Riana has any particular concerns about how that’s being done.&lt;/p&gt;
&lt;p id="ZqIfTS"&gt;Most of the criticisms I’ve heard raised about this are some really good normative questions around what type of family and what type of parenting structure does this really seek to help? I’m a parent, I have my kid’s best interests at heart. But not every family operates in that way. And so I think there’s just been a lot of concerns that just assuming that reporting to parents is the right thing to do won’t always yield the best consequences for a wide variety of reasons.&lt;/p&gt;
&lt;p id="sGXeBS"&gt;&lt;strong&gt;Riana, do you have any concerns on the technical side that are not policy concerns? That’s how I keep thinking about it. There’s a bunch of technical stuff: we’re creating capabilities. And there’s a bunch of policy stuff: how we’re using those capabilities. And obviously the third one, which is the scanning iCloud photos, contains both of those controversies. This one, it really feels like, as Jen called it, a normative controversy.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="q6b2J7"&gt;&lt;strong&gt;RP: &lt;/strong&gt;So, yeah — their documentation is clear that they are analyzing images on the device, and I know that there has been some concern that because it’s not transparent from their documentation exactly how this is happening, how accurate is this image analysis going to be. What else is going to get ensnared in this, that might not actually be as accurate as Apple is saying it’s going to be? That’s definitely a concern that I’ve seen from some of the people who work on the issue of trying to help people who have been abused, in their family life or by intimate partners.&lt;/p&gt;
&lt;p id="GQh91j"&gt;And it’s something that honestly, I don’t understand the technology well enough, and I also don’t think that Apple has provided enough documentation to enable reasoned analysis, and thoughtful analysis. That seems to be one of the [things] they’ve tripped over, is not providing sufficient documentation to enable people to really inspect and test out their claims.&lt;/p&gt;
&lt;p id="cKKre3"&gt;&lt;strong&gt;That is absolutely a theme that runs right into the third announcement, which is this very complicated cryptographic system to check images that are uploaded to iCloud photos for known child sexual abuse material. I’m not even going try to explain this one. Riana, I’m just going defer to you. Explain how Apple says this system works.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="diLvbW"&gt;&lt;strong&gt;RP: &lt;/strong&gt;This will be done on the client baked into the operating system and deployed for every iPhone running iOS 15, once that comes out around the world. But this will only be turned on within the United States at least, so far. There is going to be an on-device attempt to try and make a hash of the photos you have uploaded to iCloud Photos, and check the hash against the hash database that is maintained by the National Center for Missing and Exploited Children, or NCMEC, that contains known child sex abuse material, or CSAM for short.&lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;div id="GIl3Ux"&gt;&lt;div data-anthem-component="aside:9545330"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p id="C7PTLz"&gt;There is not going to be a hash of actual CSAM on your phone. There’s not going to be a search of everything so far on your camera roll, only if [the photos] are going into iCloud photos. If you have one image that is in the NCMEC database, that will not trigger review by Apple, where they will have a human in the loop to take a look. It will be some unspecified threshold number of images that have to be triggered by their system, which is more complex than I want to try and explain.&lt;/p&gt;
&lt;p id="4IHH8K"&gt;So, if there is a collection of CSAM material sufficient to cross the threshold, then there will be the ability for a human reviewer at Apple to review and confirm that these are images that are part of the NCMEC database. They’re not going be looking at unfiltered, horrific imagery. There is going to be some degraded version of the image, so that they aren’t going to be exposed to this. Really, it’s very traumatic for people who have to review this stuff.&lt;/p&gt;
&lt;p id="aliaOc"&gt;And then if they confirm that it is in fact, known as CSAM, then that report goes to NCMEC, pursuant to Apple’s duties under federal law, and then NCMEC will involve law enforcement.&lt;/p&gt;
&lt;p id="RxOtoO"&gt;&lt;strong&gt;One of the things that’s very challenging to understand here is that Apple has built it this way so they’re not scanning iCloud data in the cloud, from what I understand. What they don’t want to do is have people upload their photo libraries to iCloud, and then scan a bunch of information in the cloud. &lt;/strong&gt;&lt;/p&gt;
&lt;p id="iOx6jS"&gt;&lt;strong&gt;That other way of doing it, which is in the cloud, is what the other major tech companies do, and that is kind of our expectation of what they do.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="WGHoDT"&gt;&lt;strong&gt;JK:&lt;/strong&gt; Right, although I think the use case is potentially quite different. It’s one of the interesting questions why Apple is doing this in such an aggressive and public way, given that they were not a major source of child sexual violence imagery reporting to begin with. But when you think about these different products, in the online ecosystem, a lot of what you’re seeing are pedophiles who are sharing these things on these very public platforms, even if they carve out little small spaces of them.&lt;/p&gt;
&lt;p id="b10waX"&gt;And so they’re usually doing it on a platform, right? Whether it’s something like Facebook, WhatsApp, Dropbox, whatever it might be. And so, yes, in that case, you’re usually uploading imagery to the platform provider, it’s up to them whether they want to scan it in real time to see what you are uploading. Does it match one of these known images, or known videos that NCMEC maintains a database of?&lt;/p&gt;
&lt;div class="c-float-left"&gt;&lt;aside id="of2hyG"&gt;&lt;q&gt;“The idea that I was going to have the entire NCMEC hash database sitting on my phone...the idea that we’re pushing that to everybody’s individual devices was kind of shocking to me.”&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="lcmnTo"&gt;That they’re doing it this way is just a really interesting, different use case than what we often see. And I’m not sure if Riana has any kind of theory behind why they’ve decided to take this particular tactic. I mean, when I first heard about it, the idea that I was going to have the entire NCMEC hash database sitting on my phone — I mean, obviously, hashes are extremely small text files, so we’re talking about just strings of characters that to the human eye, it just looks like garbage, and they don’t take up a lot of memory, but at the same time, the idea that we’re pushing that to everybody’s individual devices was kind of shocking to me. I’m still kind of in shock about it. Because it’s just such a different use case than what we’ve seen before.&lt;/p&gt;
&lt;p id="T7YGkq"&gt;&lt;strong&gt;RP:&lt;/strong&gt; One of the concerns that has been raised with having this kind of client-side technology being deployed is that once you’re pushing it to people’s devices, it is possible — this is a concern of researchers in this space — for people to try and reverse-engineer that, basically, and figure out what is in the database. There’s a lot of research that’s done there. There are fears on one side about, well what if something that is not CSAM gets slipped into this database?&lt;/p&gt;
&lt;p id="yIlT1X"&gt;The fear on the other side is, what if people who have really strong motivations to continue trading CSAM try to defeat the database by figuring out what’s in it, figuring out how they can perturb an image, so that it slips past the hash matching feature.&lt;/p&gt;
&lt;p id="yoxbKP"&gt;And that’s something that I think is a worry, that once this is put onto people’s devices — rather than happening server-side as currently happens with other technologies such as PhotoDNA — that you are opening up an avenue for malicious reverse engineering to try and figure out how to continue operating, unimpeded and uncaught.&lt;/p&gt;
&lt;p id="uBvCn8"&gt;&lt;a href="https://www.theverge.com/2021/8/6/22613365/apple-icloud-csam-scanning-whatsapp-surveillance-reactions"&gt;&lt;strong&gt;I read some strident statements&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt; from the EFF (Electronic Frontier Foundation) and Edward Snowden, and others, calling this a backdoor into the iPhone. Do you think that is a fair characterization, Riana?&lt;/strong&gt; &lt;/p&gt;
&lt;p id="1ODviq"&gt;&lt;strong&gt;RP: &lt;/strong&gt;I don’t like using the word backdoor because it’s a very loaded term and it means different things to different people. And I don’t know that I agree with that because this is all still happening on the client. Right? Apple is very careful to not mention that there are end-to-end encryption for iMessage. And I agree gives an insight into what people are doing on their phone that was not there before. But I don’t know whether that means that you could characterize it as a backdoor.&lt;/p&gt;
&lt;p id="7MeDcb"&gt;I’ve heard a lot of people talking about, like, “Does this mean it’s not end-to-end encryption anymore? Does this mean it’s a backdoor?” I don’t care. I don’t care what we’re calling it. That’s a way of distracting from the main things that we’re actually trying to talk about here, which I think are: what are the policy and privacy and free expression data security impacts that will result from Apple’s decision here? And how will that go out beyond the particular CSAM context? And will what they’re doing work to actually protect children better than what they’ve been doing to date? So quibbling over labels is just not very interesting to me, frankly.&lt;/p&gt;
&lt;p id="SkDq43"&gt;&lt;strong&gt;This comes back to that efficacy question that we’re talking about with Siri. Right now, in order to detect CSAM material, you have to A, be somebody who has it, B, be putting it into your camera roll, and then C, uploading that to iCloud photos. I feel like if criminals are dumb, maybe they’re going to get caught. But it seems very easy for anybody with even a moderate amount of interest to avoid this system, thus reducing the need for this controversy at all.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="1HsMAp"&gt;&lt;strong&gt;JK:&lt;/strong&gt; There’s a couple things here. One is that you could take the position that Apple’s being extremely defensive here and saying, essentially, “Hey, pedophile community, we don’t want you here, so we’re going to, in a very public way, work to defeat your use of our products for that purpose.” Right? And that might be quite effective. &lt;/p&gt;
&lt;p id="MIZBXc"&gt;I want to actually add a little context here for why I’m in this conversation. Before I worked in academia, I used to work in [the tech] industry. I worked for about two years building a tool to review CSAM material and detect it. And when I worked on this project, it was very clear from the beginning that the goal was to get it off the servers of the company I was working for. Like — there was no higher goal. We were not going to somehow solve the child pornography problem.&lt;/p&gt;
&lt;p id="j7w5Dp"&gt;That’s where I have a particular insight. One of the reasons Apple could be taking this stand could be a moral issue — it could be that they’ve decided that they just simply do not want their products associated with this type of material, and in a very public way they’re going to take a stand against it. I think you’re right. I think that there are people for whom, if you’re going to get caught using an Apple product, it’s probably because you weren’t necessarily well-versed in all the ways to try to defeat this type of thing.&lt;/p&gt;
&lt;p id="DGlRxU"&gt;[But] I think it’s really important to remember [that] when you talk about these issues and you think about this group of people, that they are a &lt;em&gt;community&lt;/em&gt;. And there are a lot of different ways that you can detect this content. I would feel a lot better about this decision if I felt like what we were hearing is that all other methods have been exhausted, and this is where we are at.&lt;/p&gt;
&lt;p id="VIizA0"&gt;And I am in no way of the belief that all other methods have been exhausted, by Apple or by kind of the larger tech community et al, who I think has really failed on this issue, given I worked on it from 2002 to 2004 and it’s gotten tremendously worse since that time. A lot more people have joined the internet since then, so it is kind of a question of scale. But I would say industry across the board has really been bad at really trying to defeat this as an issue.&lt;/p&gt;
&lt;p id="DUhJjk"&gt;&lt;strong&gt;What are the other methods?&lt;/strong&gt;&lt;/p&gt;
&lt;p id="U7MBzm"&gt;&lt;strong&gt;JK:&lt;/strong&gt;  It’s important to understand that this is a community of users, and different communities use different products in different ways. When you’re in product design, you’re designing a product with particular users in mind. You kind of have your optimal user groups that you want to privilege the product for, who you want to attract, how you want to design the features for.&lt;/p&gt;
&lt;p id="rkgkbl"&gt;The kind of work I did to try to understand this community, it became very clear that this group of users know what they’re doing is illegal. They don’t want to get caught, and they use things very materially different than other users. And so if you’re willing to put in the time to understand how they operate and put in the resources to detect them, and to really see how they differ from other users — because they don’t use these products the same way that you and I probably do. Right? They’re not loading up photos to share with friends and family. They’re operating under subterfuge. They know what they’re doing is highly illegal. &lt;/p&gt;
&lt;p id="qPoAGZ"&gt;There’s often a great deal of pressure in terms of timing, for example. One of the things I witnessed in the work I did was that people often would create accounts and basically have an upload party. They would use the service at an extremely high rate for an extremely short amount of time and then ditch it, ditch whatever product they were working in. Because they knew that they only had a limited amount of time before they would get caught.&lt;/p&gt;
&lt;p id="nSAQg8"&gt;To just assume that you can’t potentially put in more work to understand how these people use your product, and that they may be detectable in ways that don’t require the types of work that we’re seeing Apple do — if I had more reassurance they’d actually kind of done that level of research and really exhausted their options I would probably feel more confident about what they’re doing. &lt;/p&gt;
&lt;p id="KPs5fx"&gt;I don’t want to just point the finger at Apple. I think this is an industry-wide problem, with a real lack of devotion to resources behind it. &lt;/p&gt;
&lt;p id="e0qcIW"&gt;&lt;strong&gt;RP: &lt;/strong&gt;The trouble with this particular context is how extremely unique CSAM is compared to any other kind of abusive content that a provider might encounter. It is uniquely opaque in terms of how much outside auditability or oversight or information anybody can have.&lt;/p&gt;
&lt;p id="vyPGTF"&gt;I mentioned earlier that there’s a risk that people might be able to try and reverse-engineer what’s in the database of hashed values to try and figure out how they could  subvert and sneak CSAM around the database.&lt;/p&gt;
&lt;p id="FKNFVN"&gt;The other thing is that it’s hard for us to know exactly what it is that providers are doing. As Jen was saying, there’s a bunch of different techniques that they could take and different approaches that they can employ. But when it comes to what they are doing on the backend about CSAM, they are not very forthcoming because everything that they tell people to explain what it is they’re doing is basically a roadmap to the people who want to abuse that process, who want to evade it.&lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="GJk6oD"&gt;&lt;q&gt;CSAM databases are a black box&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="PR5PMG"&gt;So it is uniquely difficult to get information about this on the outside, as a researcher, as a user, as a policymaker, as a concerned parent, because of this veil of secrecy that hangs over everything to do with this whole process, from what is in the database, to what are different providers doing. Some of that sometimes comes out a little bit in prosecutions of people who get caught, by providers, for uploading and sharing CSAM on their services. There will be depositions and testimony and so forth. But it’s still kind of a black box. And that makes it hard to critique the suggested improvements, to have any kind of oversight. &lt;/p&gt;
&lt;p id="ipSGIP"&gt;And that’s part of the frustration here, I think, is that it’s very difficult to, say, “You just have to trust us and trust everything all the way down from every point, from NCMEC on down,” and simultaneously, “Just know that what we’re doing is not something that has other collateral harms,” because for anything outside of CSAM, you have more ambiguity and legitimate use cases and context where it matters. &lt;/p&gt;
&lt;p id="f4STsa"&gt;When it comes to CSAM, context does not matter. Something that I’ve been saying in recent days is: there’s no fair use for CSAM the way that there is for using copyrighted work. There’s this lack of information that makes it really difficult for folks like Jen or me or other people in civil society, other researchers, to be able to comment. And Jen, I’m so glad that you have this background, that you at least have both the privacy and the understanding from working on this from the provider’s side.&lt;/p&gt;
&lt;p id="bKk2N0"&gt;&lt;strong&gt;If you take that and you view it from Apple’s side, most charitably: well, at least Apple announced &lt;/strong&gt;&lt;em&gt;&lt;strong&gt;something&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt;. Right? They are being transparent, to a degree. We went and asked Google, “Hey, do you do this scanning in Google Photos?” And there’s no way to know. We just don’t know the answer to that question.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="bznAW4"&gt;&lt;strong&gt;I think if you went to Dropbox and asked them they would just not tell you. We assume that they are. But at least here, Apple is saying, “We’re doing it. Here’s the method by which we’re doing it.” That method, that addition of capability to the iPhone, is problematic in various ways. But they’re copping to it and they’re explaining how it works. Do they get points for that?&lt;/strong&gt;&lt;/p&gt;
&lt;p id="TG24gM"&gt;&lt;strong&gt;RP: &lt;/strong&gt;They certainly learned that they won’t get any plaudits for that. You’ve identified that. This might be a point where they say other organizations scan using PhotoDNA in the cloud, and they do so over email. And I don’t know how well understood that is by the general public, that, for most of the services that you use, if you are uploading photos, they are getting scanned to look for CSAM for the most part. If you’re using webmail, if you’re using a cloud storage provider — Dropbox absolutely does. &lt;/p&gt;
&lt;p id="T4PYwb"&gt;But you’re right that they are not necessarily that forthcoming about it in their documentation. And that’s something that might kind of redound to the benefit of those who are trying to track and catch these offenders, is that there may be some misunderstanding or just lack of clarity about what is happening. That trips up people who trade in this stuff and share and store this stuff because they don’t realize that.&lt;/p&gt;
&lt;p id="4twvGr"&gt;I guess there’s almost some question about whether Apple is kind of ensuring that there will be less CSAM on iCloud Photos three months from now than there is today, because they’re being more transparent about this and about what they are doing.&lt;/p&gt;
&lt;p id="fuoH5l"&gt;&lt;strong&gt;JK:&lt;/strong&gt; There is a really complicated relationship here between the companies and law enforcement that I think bears mentioning, which is that, the companies, broadly, are the source of all this material. You know? Hands down. I don’t even know if you see offline CSAM these days. It’s all online, and it’s all being traded on the backs of these large organizations.&lt;/p&gt;
&lt;p id="O4q4iS"&gt;Holding CSAM is illegal. Every copy the platforms hold is a felony, essentially, a criminal felony. At the same time that they are the source of this material and law enforcement wants to crack down, law enforcement needs the platforms to report it. So there’s this tension at play that I think is not necessarily well understood from the outside. &lt;/p&gt;
&lt;p id="LA7MoL"&gt;There’s a bit of a symbiotic relationship here where, if the companies crack down too much and force it all off their services, it all ends up on the dark web, completely out of the reach of law enforcement without really heavy investigative powers. In some ways, that disadvantages law enforcement. One could argue that they need the companies to not crack down so much that it completely disappears off their services because it makes their job much harder. So there is a very weird tension here that I think needs to be acknowledged.&lt;/p&gt;
&lt;p id="qSQvww"&gt;&lt;strong&gt;It feels like one enormous aspect of this entire controversy is the fact that the scanning is being done on the device. That’s the Rubicon that’s been crossed: up until now, your local computer has not scanned your local storage in any way. But once you hit the cloud, all kinds of scanning happens. That’s problematic, but it happens.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="Ro4Fdn"&gt;&lt;strong&gt;But we have not yet entered the point where law enforcement is pushing a company to do local scanning on your phone, or your computer. Is that the big bright line here that’s causing all the trouble?&lt;/strong&gt;&lt;/p&gt;
&lt;p id="Msc4V9"&gt;&lt;strong&gt;RP: &lt;/strong&gt;I view this as a paradigm shift, to take where the scanning is happening from in the cloud, where you are making the &lt;em&gt;choice&lt;/em&gt; to say, “I’m going to upload these photos into iCloud.” It’s being held in third parties’ hands. You know, there’s that saying that “it’s not the cloud; it’s just somebody else’s computer,” right?&lt;/p&gt;
&lt;p id="hah3C8"&gt;You’re kind of assuming some level of risk in doing that: that it might be scanned, that it might be hacked, whatever. Whereas moving it down onto the device — even if, right now, it’s only for photos that are in the cloud — I think is very different and is intruding into what we consider a more private space that, until now, we could take for granted that it would stay that way. So I do view that as a really big conceptual shift.&lt;/p&gt;
&lt;div class="c-float-left"&gt;&lt;aside id="1TAk9e"&gt;&lt;q&gt;“The illusion that you’ve been able to control the data on your phone has been nothing more than an illusion for most people for quite a while now. “&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="Bbp4Ml"&gt;Not only is it a conceptual shift in how people might think about this, but also from a legal standpoint. There is a big difference between data that you hand over to a third party and assume the risk that they’re going to turn around and report to the cops, versus what you have in the privacy of your own home or in your briefcase or whatever.&lt;/p&gt;
&lt;p id="jfbQLE"&gt;I do view that as a big change.&lt;/p&gt;
&lt;p id="qwY2AD"&gt;&lt;strong&gt;JK:&lt;/strong&gt; I would add that some of the dissonance here is the fact that we just had Apple come out with the &lt;a href="https://www.theverge.com/2021/4/27/22405474/apple-app-tracking-transparency-ios-14-5-privacy-update-facebook-data"&gt;“asks apps to not track” feature&lt;/a&gt;, which was already in existence before, but they actually made that dialog box prominent to ask you when you were using an app if you want the app to track you. It seems a bit dissonant that they just rolled out that feature, and then suddenly, we have this thing that seems almost more invasive on the phone.&lt;/p&gt;
&lt;p id="INPE1K"&gt;But I would say, as someone who’s been studying privacy in the mobile space for almost a decade, there is already an extent to which these phones aren’t ours, especially when you have third-party apps downloading your data, which has been a feature of this ecosystem for some time. This is a paradigm shift. But maybe it’s a paradigm shift in the sense that we had areas of the phone that we maybe thought were more off-limits, and now they are less so than they were before.&lt;/p&gt;
&lt;p id="dnpaI0"&gt;The illusion that you’ve been able to control the data on your phone has been nothing more than an illusion for most people for quite a while now.&lt;/p&gt;
&lt;p id="TCiVLq"&gt;&lt;strong&gt;The idea that you have a local phone that has a networking stack, that then goes to talk to the server and comes back — that is almost a 1990s conception of connected devices, right? In 2021, everything in your house is always talking to the internet, and the line between the client and the server is extremely blurry to the point where we market the networks. We market 5G networks, not just for speed but for capability, whether or not that’s true.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="Tri5Jn"&gt;&lt;strong&gt;But that fuzziness between client and server and network means that the consumer might expect privacy on local storage versus cloud storage, but I’m wondering if this is &lt;/strong&gt;&lt;em&gt;&lt;strong&gt;actually&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt; a line that we crossed  — or if just because Apple announced this feature, we’re now perceiving that there &lt;/strong&gt;&lt;em&gt;&lt;strong&gt;should&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt; be a line.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="N6Pcvc"&gt;&lt;strong&gt;RP:&lt;/strong&gt; It’s a great point because there are a number of people who are kind of doing the equivalent of “If the election goes the wrong way, I’m going to move to Canada” by saying “I’m just going to abandon Apple devices and move to Android instead.” But Android devices are basically just a local version of your Google Cloud. I don’t know if that’s better.&lt;/p&gt;
&lt;p id="pX2a8m"&gt;And at least you can fork Android, [although] I wouldn’t want to run a forked version of Android that I sideloaded from some sketchy place. But we’re talking about a possibility that people just don’t necessarily understand the different ways that the different architectures of their phones work.&lt;/p&gt;
&lt;div class="c-float-right c-float-hang"&gt;&lt;aside id="JtbfcW"&gt;&lt;q&gt;“People’s rights, people’s privacy, people’s free expression — that shouldn’t depend upon a consumer choice.”&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="PoLQ9s"&gt;A point that I’ve made before is that people’s rights, people’s privacy, people’s free expression, that shouldn’t depend upon a consumer choice that they made at some point in the past. That shouldn’t be path-dependent for the rest of time on whether or not their data that they have on their phone is really theirs or whether it actually is on the cloud.&lt;/p&gt;
&lt;p id="QNiqNT"&gt;But you’re right that, as the border becomes blurrier, it becomes both harder to reason about these things from arm’s length, and it also becomes harder for just average people to understand and make choices accordingly.&lt;/p&gt;
&lt;p id="x57xbG"&gt;&lt;strong&gt;JK: &lt;/strong&gt;Privacy shouldn’t be a market choice. I think it’s a market failure, for the most part, across industry. A lot of the assumptions we had going into the internet in the early 2000s was that privacy could be a competitive value. And we do see a few companies competing on it. DuckDuckGo comes to mind, for example, on search. But bottom line, privacy shouldn’t be left up to... or at least many aspects of privacy shouldn’t be left up to the market.&lt;/p&gt;
&lt;p id="RP3xQ6"&gt;&lt;strong&gt;There’s another tension that I want to explore with both of you, which is the sort of generalized surveillance tension around encryption and Apple specifically. Apple famously will not unlock iPhones for law enforcement, or at least they say they won’t do it here. They say they don’t do it in other countries like China. They have wanted to encrypt the whole of iCloud, &lt;/strong&gt;&lt;a href="https://www.theverge.com/2020/1/21/21075033/apple-icloud-end-to-end-encryption-scrapped-fbi-reuters-report"&gt;&lt;strong&gt;and famously the FBI talked them out of it&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;. And in China, they’ve &lt;/strong&gt;&lt;a href="https://www.theverge.com/2018/7/18/17587304/apple-icloud-china-user-data-state-run-telecom-privacy-security"&gt;&lt;strong&gt;handed over the iCloud data centers&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt; to the Chinese government. The Chinese government holds those keys.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="fECxjW"&gt;&lt;strong&gt;I believe what they want to do is encrypt everything and just wash their hands of it, and walk away, and say, “It’s our customers’ data. It’s private. It’s up to them.” They cannot, for various reasons. Do you think that tension has played into this system as it is currently architected, where they &lt;/strong&gt;&lt;em&gt;&lt;strong&gt;could&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt; just say, “We’re scanning all the data in the cloud directly and handing it over to the FBI or NCMEC or whoever,” but instead they want to encrypt that data, so they’ve now built this other ancillary system that does a little bit of local hashing comparison against the table in the cloud, it generates these complicated security vouchers, and then it reports to NCMEC if you pass a threshold. &lt;/strong&gt;&lt;/p&gt;
&lt;p id="dWf7DD"&gt;&lt;strong&gt;All of that seems like at some point they’re going to want to encrypt the cloud, and this is the first step towards a deal with law enforcement, at least in this country.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="JF5yTZ"&gt;&lt;strong&gt;RP:&lt;/strong&gt; I have heard that idea from someone else I talked to about this and mentioned it to my colleague at SIO, Alex Stamos. Alex is convinced that this is a prelude to announcing end-to-end encryption for iCloud later on. It seems to be the case that, however it is that they are encrypting iCloud data for photos, that they have said it is “too difficult to decrypt everything that’s in the cloud, scan it for CSAM, and do that at scale.”  So it’s actually more efficient and, in Apple’s opinion, more privacy-protective, to do this on the client side of the architecture instead.&lt;/p&gt;
&lt;div class="c-float-left"&gt;&lt;aside id="mWSocq"&gt;&lt;q&gt;Child safety features could be a prelude to a totally encrypted iCloud&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="nTfG2y"&gt;I don’t know enough about the different ways that Dropbox encrypts their cloud, that Apple encrypts their cloud, that Microsoft encrypts its cloud, versus how iCloud does it, to know whether Apple is in fact doing something different that makes it uniquely hard for them to scan in the cloud the way that other entities do. But certainly, I think that looming over all of this is that there has been several years’ worth of encryption files, not just here in the US, but around the world, primarily focused in the last couple of years on child sex abuse material. Prior to that, it was terrorism. And there’s always concerns about other types of material as well.&lt;/p&gt;
&lt;p id="DUO4mX"&gt;One thing that’s a specter looming over this move by Apple is that they may see this as something where they can provide some kind of a compromise and hopefully preserve the legality of device encryption and of end-to-end encryption, writ large, and maybe try and rebuff efforts that we have seen, including in the US, even just last year, to effectively ban strong encryption. This might be, “If we give an inch, maybe they won’t take a mile.”&lt;/p&gt;
&lt;p id="m1Bwao"&gt;&lt;strong&gt;I’ve seen a lot of pushback against that idea. Just to be honest, personally, if the outcome is the same — there’s scanning done of stuff you put on the cloud — I think that is the consumer expectation. Once you upload something to somebody else’s server, they can look at it. They can, I don’t know, copyright strike it. They can scan it for CSAM. That stuff is going to happen once you give your data away to a cloud provider. That does feel like a consumer expectation in 2021, whether that is good or bad. I just think it’s the expectation.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="NKEFwp"&gt;&lt;strong&gt;It seems like this is a very complicated mechanism to accomplish the same goal of just scanning in the cloud. But because it is this very complicated mechanism, that is “give an inch so they won’t take a mile,” the controversy seems to be they’re not just going take the inch. &lt;/strong&gt;&lt;/p&gt;
&lt;p id="wi3FSZ"&gt;&lt;strong&gt;Governments around the world will now ask you to expand this capability in various ways that maybe the United States government won’t do, but certainly the Chinese government or the Indian government or other more oppressive governments would certainly take advantage of. Is there a backstop here for Apple to not expand the capability beyond CSAM?&lt;/strong&gt;&lt;/p&gt;
&lt;p id="tChyNf"&gt;&lt;strong&gt;RP:&lt;/strong&gt; This is my primary concern. The direction I think this is going is that we don’t have, ready to go, hashed databases or hashes of images of other types of abusive content besides CSAM, with the exception of terrorist and violent extremist content. There is a database called GIFCT that is an industry collaboration, to collaboratively contribute imagery to a database of terror and violent extremist content, largely arising out of the Christchurch shooting a few years back, which really woke up a new wave of concern around the world about providers hosting terrorists and violent extremist material on their services.&lt;/p&gt;
&lt;p id="M7bg8d"&gt;So my prediction is that the next thing that Apple will be pressured to do will be to deploy the same thing for GIFCT as they are currently doing for the NECMC database of hashes of CSAM. And from there on, I mean, you can put anything you’d like into a hashed image database. &lt;/p&gt;
&lt;p id="lBd94c"&gt;Apple just said, “If we’re asked to do this for anything but CSAM, we simply will not.” And, that’s fine, but why should I believe you? Previously, their slogan was, “What happens on your iPhone stays on your iPhone.” And now that’s not true, right?&lt;/p&gt;
&lt;div class="c-float-right c-float-hang"&gt;&lt;aside id="QsAmmW"&gt;&lt;q&gt;“For a large enough market, like China, I think that they will fold.”&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="EkBK9f"&gt;They might abide by that, where they think that the reputational trade off is not worth the upside. But if there’s a distinction with choices between either you implement this hashed database of images that this particular government doesn’t like, or you lose access to our market, and you will never get to sell a Mac or an iPhone in this country again? For a large enough market, like China, I think that they will fold.&lt;/p&gt;
&lt;p id="xGCrbO"&gt;India is one place that a lot of people have pointed to. India has a billion people. They actually are not that big of a market for iPhones, at least commensurate with the size of the market that currently exists in China. But the EU is. The European Union is a massive market for Apple. And the EU just barely got talked off the ledge from having &lt;a href="https://www.theverge.com/2019/3/26/18280726/europe-copyright-directive"&gt;an upload filter mandate for copyright-infringing material&lt;/a&gt; pretty recently. And there are rumblings that they are going to introduce a similar plan for CSAM at the end of this year.&lt;/p&gt;
&lt;p id="w9DQmm"&gt;For a large enough market, basically, it’s hard to see how Apple, thinking of their shareholders, not just of their users’ privacy or of the good of the world, continues taking that stand and says, “No, we’re not going to do this,” for whatever it is they’re confronted with. Maybe if it’s lese majeste laws in Thailand that say, “You are banned from letting people share pictures of the king in a crop top” — which is a real thing — maybe they’ll say, “Eh, this market isn’t worth the hit that we would take on the world stage.” But if it’s the EU, I don’t know. &lt;/p&gt;
&lt;p id="cMbomq"&gt;&lt;strong&gt;Let’s say the EU was going implement this upload filter. If they say, “We need an upload filter for CSAM,” and Apple’s already built it, and it preserves encryption, isn’t that the correct trade-off?&lt;/strong&gt;&lt;/p&gt;
&lt;p id="t4sHj8"&gt;&lt;strong&gt;RP:&lt;/strong&gt; I think that there are absolutely a lot of folks that you could talk to who would quietly admit that they might think — if this really did get limited only ever to CSAM for real — that that might be a compromise that they could live with. Even though we’re talking about moving surveillance down into your device. And, really, there’s no limitation on them for only doing this for iCloud photos. It could be on your camera roll next. If we really believe that this would not move beyond CSAM, there are a lot of folks who might be happy with that trade-off.&lt;/p&gt;
&lt;p id="a1Or7B"&gt;Going back to your question about what a backstop might be, though, to keep it from going up beyond CSAM, this goes back to what I mentioned earlier about how CSAM is really unique among types of abuse. And once you’re talking about literally any other type of content, you’re necessarily going to have an impact on free expression, values on news, commentary, documentation of human rights abuses, all of these things. &lt;/p&gt;
&lt;p id="64VzWS"&gt;And that’s why there’s already a lot of criticism of the GIFCT database that I mentioned, and why it would be supremely difficult to build out a database of images that are hate speech, whatever that means. Much less something that is copyright infringing. There is nothing that is only ever illegal and there’s no legitimate context, except for CSAM.&lt;/p&gt;
&lt;p id="ydIgHW"&gt;So I think that this is a backstop that Apple could potentially try to point to. But just because it would trample free expression and human rights to deal with this for anything else — I don’t necessarily know that that’s something that’s going to stop governments from demanding it.&lt;/p&gt;
&lt;p id="NM5epQ"&gt;&lt;strong&gt;For CSAM, there is a database of images that exist that are just illegal. You can’t have them, you can’t look at them. And there’s no value towards even pointing them out and saying, “look at this” for things like scholarship or research.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="R8GbG0"&gt;&lt;strong&gt;But a database of images of terrorism, &lt;/strong&gt;&lt;a href="https://www.theverge.com/2019/3/15/18266859/new-zealand-shooting-video-social-media-manipulation"&gt;&lt;strong&gt;the video of the Christchurch shooting&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;, there are fuzzier boundaries there. Right? There are legitimate reasons for some people to have that video or to have other terrorism-related content: to report on it, to talk about it, to analyze it. And because that is a fuzzier set, it’s inherently more dangerous to implement these kinds of filters.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="0OTPrW"&gt;&lt;strong&gt;JK:&lt;/strong&gt; I would argue that your example points to one of the easiest examples of that whole genre, and that it’s much harder from those extreme examples to work backwards to “what is terrorism” versus “what are groups engaging in rightful protests on terrorism-related issues,” for example?  The line-drawing becomes much, much harder.&lt;/p&gt;
&lt;p id="xHVQOH"&gt;To kind add some context to what Riana was saying, we are very much talking about the US and the fact that this content is illegal in the US. In Europe, those boundaries, I think, are much broader because they’re not operating under the First Amendment. I’m not a lawyer, so I’m definitely speaking a little bit outside my lane, but there isn’t the same free speech absolutism in the EU because they don’t have the First Amendment we have here in the US. The EU has been much more willing to try to draw lines around particular content that we don’t do here.&lt;/p&gt;
&lt;p id="cFaHHB"&gt;&lt;strong&gt;RP:&lt;/strong&gt; I think that there are different regimes in different countries for the protection of fundamental rights that look a little different from our Constitution. But they exist. And so, when there have been laws or surveillance regimes that would infringe upon those, there are other mechanisms, where people have brought challenges and where some things have been struck down as being incompatible with people’s fundamental rights as recognized, in other countries. &lt;/p&gt;
&lt;p id="YSOUoU"&gt;And it’s very difficult to engage in that line-drawing. I have a side hustle talking about deepfakes. There is absolutely a lot of interest in trying to figure out, okay, how do we keep mis- and disinformation from undermining democracy, from hurting vaccine rollout efforts, and also from having deepfakes influence an election. And it would be real easy — this is what law professors Danielle Citron and Bobby Chesney call &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3213954"&gt;“the liar’s dividend”&lt;/a&gt; — for a government that does not like evidence of something that actually happened, something that is true and authentic but inconvenient for them, to say, “That’s fake news. That is a deepfake. This is going in our database of hashes of deepfakes that we’re gonna make you implement in our country.”&lt;/p&gt;
&lt;p id="HDVdmC"&gt;So there’s all of these different issues that get brought up on on the free expression side once you’re talking about anything other than child sex abuse material. Even there, it takes a special safe harbor under the federal law that applies to make it okay for providers to have this on their services. As Jen was saying, otherwise that is just a felony, and you have to report it. If you don’t report it, you don’t get the safe harbor, and that provider is also a felon.&lt;/p&gt;
&lt;p id="7pMqyS"&gt;The National Center for Missing and Exploited Children is the only entity in America that is allowed to have this stuff. There are some debates going on in different places right now about whether there are legitimate applications for using CSAM to train AI and ML models. Is that a permissible use? Is that re-victimizing the people who are depicted? Or would it have an upside in helping better detect other images? Because the more difficult side of this is detecting &lt;em&gt;new&lt;/em&gt; imagery, rather than detecting known imagery that’s in a hashed database.&lt;/p&gt;
&lt;p id="HW3kw7"&gt;So even there, that’s a really hot button issue. But it gets back to Jen’s point: if you start from the fuzzy cases and work backwards, Apple could say “We’re not going to do this for anything other than CSAM because there’s never going to be agreement on anything else other than this particular database.”&lt;/p&gt;
&lt;p id="7Kg5Gq"&gt;Apple has also said they are not compiling the hashed databases, the image databases themselves. They’re taking what is handed to them, with the hashes, that NCMEC provides or that other child safety groups in other countries provide. If they don’t have visibility into what is in those databases, then again, it’s just as much of a black box to them as it is to anybody else. Which has been a problem with GIFCT: we don’t know what’s in it. We don’t know if it contains human rights documentation or news or commentary or whatever. Rather than just something that everybody can agree nobody should ever get to look at ever, not even consenting adults.&lt;/p&gt;
&lt;p id="BJB5eb"&gt;&lt;strong&gt;So you’re saying the danger there is, there’s a child safety organization in some corrupt country. And, the dictator of that country says, “There’s eight photos of me sneezing, and I just want them to not exist anymore. Add them to the database.” Apple will never know that it’s being used in that way, but the photos will be detected and potentially reported to the authorities.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="sElEcg"&gt;&lt;strong&gt;RP: &lt;/strong&gt;Well, Apple is saying one of the protections against non-CSAM uses of this is that they have a human in the loop who reviews matches, if there is a hit for a sufficiently large collection of CSAM. They will take a look and be like, “Yep, that matches the NCMEC databases.” If what they’re looking at is the Thai king in a crop top, then they can say, “What the heck? No, this isn’t CSAM.” And supposedly, that’s going to be another further layer of protection.&lt;/p&gt;
&lt;p id="5JZULq"&gt;I think that I have already started seeing some concerns, though, about, “Well, what if there’s a secret court order that tells NCMEC to stick something in there? And then NCMEC employees have to just go along with it somehow?”  That seems like something that could be happening now, given that PhotoDNA is based off of hashes that NCMEC provides even now for scanning Dropbox and whatever.&lt;/p&gt;
&lt;p id="O5EqCY"&gt;This is really highlighting how it’s just trust all the way down. You have to trust the device. You have to trust the people who are providing the software to you. You have to trust NCMEC. And it’s really kind of revealing the feet of clay that I think is kind of underpinning the whole thing. We thought our devices were ours, and Apple had taken pains during &lt;em&gt;Apple v. FBI&lt;/em&gt; to say, “Your device is yours. It doesn’t belong to us.” Now it looks like, well, maybe the device really is still Apple’s after all, or at least the software on it.&lt;/p&gt;
&lt;p id="exRIWQ"&gt;&lt;strong&gt;This brings me to just the way they’ve communicated about this, which we were talking about briefly before we started recording. You both mentioned big meaty debates happening in civil society organizations, with policymakers, with academics, with researchers, about how to handle these things, about the state of encryption, about the various tradeoffs.&lt;/strong&gt;&lt;/p&gt;
&lt;p id="sBREE2"&gt;&lt;strong&gt;It does not appear that Apple engaged those debates in any substantive way before rolling this out. Do you think if they had, or if they had been more transparent with members of that community, that the reaction wouldn’t have been quite so heated?&lt;/strong&gt;&lt;/p&gt;
&lt;p id="BP2C3t"&gt;&lt;strong&gt;RP: &lt;/strong&gt;The fact that Apple rolled this out with maybe a one day’s heads up to some people in civil society orgs and maybe some media, isn’t helpful. Nobody was brought into this process while they were designing this, to tell them, “Here are the concerns that we have for queer 12-year-olds. Here are the concerns for privacy. Here are the civil liberties and the human rights concerns,” all of that. It looks like this was just rolled out as a fait accompli with no notice. &lt;/p&gt;
&lt;p id="aiJ8md"&gt;With, I have to say, really confusing messaging, given that there are these three different components and it was easy to conflate two of them and get mixed up about what was happening. That has further caused a lot of hammering and wailing and gnashing of teeth. &lt;/p&gt;
&lt;p id="abgrvS"&gt;But if they had involved elements of civil society other than, presumably, NCMEC itself and probably law enforcement agencies, maybe some of the worst could have been averted. Or maybe they would have ignored everything that we would have said and just gone forth with the thing that they’re doing it as-is.&lt;/p&gt;
&lt;p id="dto65l"&gt;But, as Jen and I can tell you — Jen and I have both been consulted before by tech companies who have something that impacts privacy. And they’ll preview that for us in a meeting and take our feedback. And that’s standard practice for tech companies, at least at some points. If you don’t really care what people’s feedback is, then you roll out where you get feedback from people later and later in the process,&lt;/p&gt;
&lt;p id="YlAzuP"&gt;But if they had really wanted to minimize the free expression and privacy concerns, then they should have consulted with outsiders, even if there are voices they thought that would be “too screechy,” as the executive director of NCMEC called everybody who expressed any kind of reservation about this. Even if they didn’t want to talk to what Apple might think is somehow the lunatic fringe or whatever, they could have talked to more moderate voices. They could have talked to academics. They could have talked to me, although I’m probably too screechy for them, and at least taken those concerns back and thought about them. But they didn’t.&lt;/p&gt;
&lt;p id="chUWwR"&gt;&lt;strong&gt;We’ve heard about the controversy, we’ve heard about the criticism. Do you think Apple responds to that in any meaningful way? Do you think they back off this plan, or is this just shipping in iOS 15, as they’ve said?&lt;/strong&gt;&lt;/p&gt;
&lt;p id="unQYZb"&gt;&lt;strong&gt;JK:&lt;/strong&gt; I think image hashing match ships. I don’t know about the “nanny cam,” again, for lack of a better word.&lt;/p&gt;
&lt;p id="ZAKiiC"&gt;I predict that they will double down on the CSAM image scanning for all of the different reasons we’ve talked about today. I think Riana really hit the nail on the head — I think there’s some kind of political strategizing going on behind the scenes here. If they are trying to take a bigger stand on encryption overall, that this was the piece that they had to give up to law enforcement in order to do so.&lt;/p&gt;
&lt;p id="rVGzAQ"&gt;&lt;strong&gt;RP:&lt;/strong&gt; I think certainly for the stuff about Siri that is uncontroversial, they’ll keep rolling that out. I’m not certain, but it seems like the iMessage stuff either wasn’t messaged clearly at the beginning, or maybe they really did change over the course of the last few days in terms of what they said they were going to do. If that’s true, and I’m not sure whether it is, that then indicates that maybe there is some room to at least make some tweaks. &lt;/p&gt;
&lt;p id="7zdEmH"&gt;However, the fact that they rolled out this whole plan as a fait accompli, that’s going to be put into iOS 15 at the very end, without any consultations, suggests to me that they are definitely going to go forward with these plans. With that said, there may be some silver lining in the fact that civil society was not consulted at any point in this process, that now, maybe there’s an opportunity to use this concerted blowback as a way to try and get pushback in that might not have been possible, had civil society been looped in all along the way, and incorporated and neutralized, almost.&lt;/p&gt;
&lt;p id="VAT51A"&gt;So, I’m not sanguine about the odds of them just not deploying this CSAM thing at all. Don’t get me wrong, I would love to be wrong with the slippery slope arguments, that the next thing will be demanding this for GIFCT and then it’ll be not as much to say in deepfakes and copyright infringement. I would love to be proved wrong about that, even as silly as it would make me look. But I’m not sure that that’s going to be the case.&lt;/p&gt;
&lt;aside id="jA4WOx"&gt;&lt;div data-anthem-component="actionbox" data-anthem-component-data='{"title":"Decoder with Nilay Patel","description":"A podcast from &amp;lt;em&amp;gt;The Verge&amp;lt;/em&amp;gt; about big ideas and other problems.","label":"Subscribe now!","url":"https://podcasts.apple.com/us/podcast/decoder-with-nilay-patel/id1011668648"}'&gt;&lt;/div&gt;&lt;/aside&gt;&lt;p id="OnXzp8"&gt;&lt;em&gt;&lt;strong&gt;Update August 10th, 5:53PM ET: &lt;/strong&gt;&lt;/em&gt;&lt;em&gt;Added full transcript.&lt;/em&gt;&lt;/p&gt;
&lt;p id="K5cfwt"&gt;&lt;/p&gt;
&lt;p id="Q2om1A"&gt;&lt;/p&gt;
&lt;p id="flYo2u"&gt;&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/22617554/apple-csam-child-safety-features-jen-king-riana-pfefferkorn-interview-decoder"/>
    <id>https://www.theverge.com/22617554/apple-csam-child-safety-features-jen-king-riana-pfefferkorn-interview-decoder</id>
    <author>
      <name>Nilay Patel</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-10T09:15:00-04:00</published>
    <updated>2021-08-10T09:15:00-04:00</updated>
    <title>The new Beats Studio Buds are already $20 off at Amazon and Walmart</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/vcoTzDBjvW18DhQigmIWvGClqe4=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69703765/DSCF4152_Edited.0.jpg" /&gt;
        &lt;figcaption&gt;Typically $150, Amazon and Walmart are both taking $20 off the recently-released earbuds. | Photo by Chris Welch / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="qh5ECz"&gt;The Beats name carries quite a bit of clout, which is perhaps the reason Apple is able to sell headphones and earbuds that fall under the Beats umbrella for a premium, regardless of their performance. The &lt;a href="https://www.theverge.com/2021/6/14/22533158/beats-studio-buds-features-price"&gt;Beat Studio Buds&lt;/a&gt; are a great case in point. The fitness-focused earbuds lack wireless charging and suffer from lackluster noise cancellation, however, they typically command a higher price than some of the like-minded competition.&lt;/p&gt;
&lt;p id="YJri1v"&gt;Thankfully, they’re currently on sale at &lt;a href="https://www.amazon.com/dp/B096SV8SJG/?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Amazon&lt;/a&gt; and &lt;a href="http://goto.walmart.com/c/1141873/565706/9383?subId1=Verge&amp;amp;veh=aff&amp;amp;sourceid=imp_000011112222333344&amp;amp;u=https%3A%2F%2Fwww.walmart.com%2Fip%2FBeats-Studio-Buds-True-Wireless-Noise-Cancelling-Bluetooth-Earbuds-Black%2F643659699&amp;amp;partnerpropertyid=1065598" rel="sponsored nofollow noopener" target="_blank"&gt;Walmart&lt;/a&gt; for $20 off, the first discount the colorful earbuds have received since making their debut in June. Noted flaws aside, the Beats Studio Buds still tout a comfortable, stem-less design and satisfying sound for the price, along with USB-C charging and support for a handful of Android-specific features — a hallmark we hope Apple brings to more devices in the future. &lt;a href="https://www.theverge.com/22532970/beats-studio-buds-review"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id="RN8hwK"&gt;&lt;div data-anthem-component="productcard:10693512"&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p id="LmGDy1"&gt;The latest iPad Air is, arguably, the best tablet for most people right now. The well-built, midrange device adopts some design elements from the &lt;a href="https://www.theverge.com/2018/11/5/18062612/apple-ipad-pro-review-2018-screen-usb-c-pencil-price-features"&gt;2018 iPad Pro&lt;/a&gt; and is compatible with many of the same devices, yet it’s not nearly as big or expensive as its larger sibling. Nonetheless, it comes with a terrific display, USB-C connectivity, and Apple’s A14 Bionic processor, a chip that promises to provide ample speed for years to come. Normally $600, &lt;a href="https://www.amazon.com/gp/product/B08J61FCVN?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Amazon&lt;/a&gt; and &lt;a href="https://shop-links.co/1748634717956796230#donotlink" rel="sponsored nofollow noopener" target="_blank"&gt;Best Buy&lt;/a&gt; are selling the 10.9-inch iPad Air with Wi-Fi and 64GB of storage for $500, matching the best price we’ve seen on the 2020 iPad Air this year. &lt;a href="https://www.theverge.com/21525780/apple-ipad-air-2020-review" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id="ACt7lS"&gt;&lt;div data-anthem-component="productcard:9546269"&gt;&lt;/div&gt;&lt;/div&gt;
&lt;aside id="CbVvYe"&gt;&lt;div data-anthem-component="readmore" data-anthem-component-data='{"stories":[{"title":"iOS 15 and iPadOS 15 preview: a first look at Apple’s latest software","url":"https://www.theverge.com/2021/6/30/22556236/ios-15-ipados-iphone-ipad-software-update-public-beta-preview-apple"}]}'&gt;&lt;/div&gt;&lt;/aside&gt;&lt;p id="MJQRQT"&gt;If you prefer a laptop over a tablet, Google’s Pixelbook Go is a standout that also happens to be discounted at Amazon for a limited time. While still occasionally pricier than similarly specced Chromebooks, Google’s sensible 13.3-inch laptop remains one of the &lt;a href="https://www.theverge.com/21296102/best-chromebooks" rel="sponsored nofollow noopener" target="_blank"&gt;best Chromebooks&lt;/a&gt; you can buy, with good battery life, an excellent keyboard, and an attractive, understated design that makes the most of its sturdy magnesium chassis. This particular model — which is currently &lt;a href="https://www.amazon.com/dp/B07YMM4YC1/?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;on sale at Amazon&lt;/a&gt; and &lt;a href="https://shop-links.co/1748639044897168537#donotlink" rel="sponsored nofollow noopener" target="_blank"&gt;Best Buy for $749&lt;/a&gt; — also packs in a Core i5 processor and 8GB of RAM, while remaining plenty light at 2.3 pounds. &lt;a href="https://www.theverge.com/2019/10/25/20931476/google-pixelbook-go-review-the-price-of-simplicity" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id="x7lVfd"&gt;&lt;div data-anthem-component="productcard:9508145"&gt;&lt;/div&gt;&lt;/div&gt;
&lt;aside id="8ORaE4"&gt;&lt;div data-anthem-component="readmore" data-anthem-component-data='{"stories":[{"title":"New Chromebooks will now have Google Meet installed by default","url":"https://www.theverge.com/2021/8/3/22607620/google-meet-app-chromebooks-chrome-os-now-preinstalled"}]}'&gt;&lt;/div&gt;&lt;/aside&gt;&lt;h2 id="JWkcqL"&gt;Other deals of note&lt;/h2&gt;
&lt;ul&gt;
&lt;li id="QOYZLp"&gt;The digital, Nintendo Switch edition of &lt;a href="https://www.amazon.com/dp/B076TK4M96/?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;em&gt;Stardew Valley &lt;/em&gt;is available for $10&lt;/a&gt;, a healthy 33 percent off its typical retail price.&lt;/li&gt;
&lt;li id="G2eP0a"&gt;Sony’s WH-1000XM3 are down to $200 at &lt;a href="https://api.narrativ.com/api/v0/client_redirect/?url=https%3A%2F%2Fbestbuy.7tiv.net%2Fc%2F376373%2F633495%2F10014%3Fprodsku%3D6280544%26u%3Dhttp%253A%252F%252Fwww.bestbuy.com%252Fsite%252F-%252F6280544.p%253Fcmp%253DRMX%26nrtv_cid%3D.nrtv_plchldr.%26subId2%3Dnymag%26subId3%3D1748627482240752605%26subId1%3Dgeneral&amp;amp;a=1743780474724360893&amp;amp;uuid=d3c8488d-ecbb-4a74-be6e-3f754f83bd98&amp;amp;uid_bam=1742974147761218429&amp;amp;ar=1748627482240752605" rel="sponsored nofollow noopener" target="_blank"&gt;Best Buy&lt;/a&gt; and &lt;a href="https://www.amazon.com/Sony-Noise-Cancelling-Headphones-WH1000XM3/dp/B07G4MNFS1?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Amazon&lt;/a&gt;, the second-best price we’ve seen on Sony’s last-gen, noise-canceling headphones. &lt;a href="https://www.theverge.com/2018/9/11/17844914/sony-1000x-m3-review-noise-canceling-headphones" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li id="VoPV7G"&gt;Amazon’s second-gen Echo Show 8 is $100 at &lt;a href="https://www.amazon.com/All-new-Echo-Show-8-2nd-Gen-2021-release/dp/B084DC4LW6?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Amazon&lt;/a&gt; and &lt;a href="https://api.narrativ.com/api/v0/client_redirect/?url=https%3A%2F%2Fbestbuy.7tiv.net%2Fc%2F376373%2F633495%2F10014%3Fprodsku%3D6461328%26u%3Dhttp%253A%252F%252Fwww.bestbuy.com%252Fsite%252F-%252F6461328.p%253Fcmp%253DRMX%26nrtv_cid%3D.nrtv_plchldr.%26subId2%3Dverge%26subId3%3D1748627482219940052%26subId1%3Dgeneral&amp;amp;a=1742759409782754841&amp;amp;uuid=d3c8488d-ecbb-4a74-be6e-3f754f83bd98&amp;amp;uid_bam=1742974147761218429&amp;amp;ar=1748627482219940052" rel="sponsored nofollow noopener" target="_blank"&gt;Best Buy&lt;/a&gt;, the best price to date on Amazon’s midsize smart display. &lt;a href="https://www.theverge.com/22521948/amazon-echo-show-8-2nd-gen-2021-review" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li id="QYGFO1"&gt;
&lt;a href="https://www.amazon.com/gp/product/B07ZPC9QD4/?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Apple’s AirPods Pro&lt;/a&gt; are currently $190 at Amazon, one of the better prices we’ve seen on the iconic, noise-canceling earbuds in recent months. &lt;a href="https://www.theverge.com/2019/11/1/20942472/apple-airpods-pro-review-design-price-specs-features-noise-cancellation" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li id="HDbvZE"&gt;
&lt;em&gt;The Last of Us Part II&lt;/em&gt;, Naughty Dog’s harrowing sequel to the PlayStation 2 hit, is on sale at &lt;a href="https://shop-links.co/1748629708216196460#donotlink" rel="sponsored nofollow noopener" target="_blank"&gt;Best Buy&lt;/a&gt; and &lt;a href="https://www.amazon.com/Last-Us-Part-II-PlayStation-4/dp/B07DJRFSDF?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Amazon&lt;/a&gt; for $20, matching its best-ever price. &lt;a href="https://www.theverge.com/21286964/the-last-of-us-part-2-review-ps4" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;strong&gt;Read our review&lt;/strong&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li id="CXo9ei"&gt;
&lt;a href="https://www.amazon.com/dp/B00N1YPXW2/?tag=theverge02-20" rel="sponsored nofollow noopener" target="_blank"&gt;Blue’s Yeti Microphone&lt;/a&gt; is $100 at Amazon, one of the steeper discounts we’ve seen this year on the popular USB mic.&lt;/li&gt;
&lt;/ul&gt;
&lt;aside id="WwpjXI"&gt;&lt;div data-anthem-component="newsletter" data-anthem-component-data='{"slug":"deals"}'&gt;&lt;/div&gt;&lt;/aside&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/good-deals/2021/8/10/22617041/apple-beats-studio-buds-2020-ipad-air-google-pixelbook-go-deal-sale"/>
    <id>https://www.theverge.com/good-deals/2021/8/10/22617041/apple-beats-studio-buds-2020-ipad-air-google-pixelbook-go-deal-sale</id>
    <author>
      <name>Brandon Widder</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-10T08:02:29-04:00</published>
    <updated>2021-08-10T08:02:29-04:00</updated>
    <title>Apple’s 2021 iPhones will reportedly have a video portrait mode</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="The iPhone 12, in blue." src="https://cdn.vox-cdn.com/thumbor/RTk5pBi9ZINbC-QvxznUJ4R-7BE=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69703347/vpavic_4243_20201018_0121.0.0.jpg" /&gt;
        &lt;figcaption&gt;&lt;em&gt;Last year’s iPhone 12. &lt;/em&gt; | Photo by Vjeran Pavic / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="tdeYaK"&gt;Apple’s upcoming flagship iPhones, likely to be called the iPhone 13 line, will be able to automatically blur the backgrounds of footage as part of a new video portrait mode, according to a &lt;a href="https://www.bloomberg.com/news/articles/2021-08-10/apple-readies-new-iphones-with-pro-focused-camera-video-updates?sref=ExbtjcSG"&gt;new report from &lt;em&gt;Bloomberg&lt;/em&gt;&lt;/a&gt;. This “Cinematic Video” feature is said to be one of three major new camera features coming to this year’s iPhones. The other two are support for ProRes video recording, and new editing options for photographs. &lt;/p&gt;
&lt;p id="ZJAMmG"&gt;The improvements join another camera upgrade that’s believed to be on the way for this year’s phones. Last November, reliable Apple analyst Min-Chi Kuo said that the phones’ &lt;a href="https://www.theverge.com/2020/11/6/21553255/apple-iphone-13-camera-2021-ming-chi-kuo-analyst-prediction"&gt;ultrawide cameras would be improved&lt;/a&gt;, with a larger aperture for better low-light photography. &lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="hhgM34"&gt;&lt;q&gt;A new filters-style photo editing feature is also rumored&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="sxY4Zx"&gt;ProRes support will be especially helpful for video editors, giving them more control over footage once it’s already been shot. Its rumored arrival follows the addition of ProRAW support to Apple’s iPhone lineup last year, which allows more flexibility while editing photos. When it comes to photos, &lt;em&gt;Bloomberg&lt;/em&gt; reports that this year’s iPhones will have a new filters-style editing feature, which will let users choose a style to apply to their photos. Unlike a filter, the new feature will apply changes to specific elements within photos, rather than uniformly across the whole shot. &lt;/p&gt;
&lt;p id="smqPZZ"&gt;&lt;em&gt;Bloomberg &lt;/em&gt;re-iterates some previous reporting about this year’s devices. It says the phones could have faster refresh rates, echoing a previous rumor that this year’s Pro models could have &lt;a href="https://www.theverge.com/2021/3/1/22307312/iphone-13-smaller-notch-high-refresh-rate-screen-hole-punch-foldable-se-5g"&gt;120Hz LTPO displays&lt;/a&gt;. All iPhone 13 models could have smaller display notches, as well as the traditional boost to processing power with a new A15 chip. However, &lt;em&gt;Bloomberg&lt;/em&gt; says this year’s updates will be “modest,” and there will be the same variety of models and screen sizes as what we saw last year. &lt;/p&gt;
&lt;p id="FaqAMf"&gt;The report doesn’t indicate when the new iPhones might be announced, but Apple tends to announce its flagship phones in September each year (the exception was last year, when they were announced in October due to the pandemic). Other new Apple products thought to be on the way include new Apple Silicon-powered MacBook Pros, Apple Watches, AirPods, and iPads.&lt;/p&gt;
&lt;p id="YM6tug"&gt;&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/10/22618070/apple-2021-iphone-13-camera-features-video-portrait-prores-ai-filters"/>
    <id>https://www.theverge.com/2021/8/10/22618070/apple-2021-iphone-13-camera-features-video-portrait-prores-ai-filters</id>
    <author>
      <name>Jon Porter</name>
    </author>
  </entry>
</feed>
