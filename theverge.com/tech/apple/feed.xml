<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <title>The Verge -  Apples</title>
  <icon>https://cdn.vox-cdn.com/community_logos/52801/VER_Logomark_32x32..png</icon>
  <updated>2021-08-10T00:01:00-04:00</updated>
  <id>https://www.theverge.com/rss/apple/index.xml</id>
  <link type="text/html" href="https://www.theverge.com/apple" rel="alternate"/>
  <entry>
    <published>2021-08-10T00:01:00-04:00</published>
    <updated>2021-08-10T00:01:00-04:00</updated>
    <title>The new Parallels 17 officially lets you run Windows 11 on your Mac</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/SnQXhOAzBK-ZuMh8YD-8Oh_0D7o=/206x0:3562x2237/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69702570/1_Windows_on_Macbook_Pro_Parallels_Desktop_17_for_Mac.0.png" /&gt;
    &lt;/figure&gt;

  &lt;p id="t6r4zg"&gt;Windows 11 is coming to Macs, even those without Boot Camp. &lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.parallels.com%2Fproducts%2Fdesktop%2Fwhats-new&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F2021%2F8%2F10%2F22617544%2Fparallels-17-mac-windows-11-preview-emulation-performance-upgrades" rel="sponsored nofollow noopener" target="_blank"&gt;Parallels Desktop 17&lt;/a&gt; will allow Mac users to experience &lt;a href="https://www.theverge.com/2021/6/24/22546791/microsoft-windows-11-announcement-features-updates"&gt;Microsoft’s next version of Windows&lt;/a&gt; in a window on their Mac desktop. Parallels supports both Intel and M1 Macs (though there’s a catch for those running Arm-based machines), and can even be used to run &lt;a href="https://www.theverge.com/2021/7/29/22600261/windows-11-beta-release-insider-microsoft-download-test"&gt;the Windows 11 preview&lt;/a&gt; for those who can’t wait.&lt;/p&gt;
&lt;p id="vJA6go"&gt;The catch for M1 users is &lt;a href="https://www.theverge.com/22383598/parallels-desktop-mac-windows-10-install-m1-macbook"&gt;the same as when Parallels first added support&lt;/a&gt; for Apple’s latest machines — you’ll only be able to emulate Arm-based operating systems, which means you’ll be limited to Windows on Arm. While &lt;a href="https://www.youtube.com/watch?v=7BE-Ca7OX5o"&gt;it does seem possible&lt;/a&gt; to install a Windows 11 preview for Arm machines, you’ll probably want to proceed with caution. Windows on Arm’s x86 emulation has been a bit of a rocky road, and the x64 app emulation &lt;a href="https://www.theverge.com/2020/12/10/22168542/x64-emulation-windows-on-arm-surface-pro-x"&gt;is still a work in progress.&lt;/a&gt; Basically, if you’re looking to run a virtualized version of Windows on your M1, you’ll still have to deal with the same caveats that would come with running Windows on any other Arm machines.&lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="3UHJhK"&gt;&lt;q&gt;Windows on M1 will likely have the same caveats as Windows on any other Arm machines&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="Im90r8"&gt;While M1 users have to deal with Windows on Arm, they also get some performance improvements if they’re coming from Parallels 16: Parallels says that the new version will let M1 Macs get up to 28 percent better DirectX 11 performance, and up to 33 percent faster start times for Windows 10 on Arm Insider Preview VMs. This comes alongside the up to 25 percent faster 2D graphics and up to 6 times faster OpenGL performance that Parallels says will be coming to Windows VMs on all supported Macs, Intel and M1 alike. M1 users will also be able to use BitLocker and Secure Boot thanks to a virtualized TPM.&lt;/p&gt;
&lt;p id="FkEY3O"&gt;There are other under-the-hood improvements with Parallels 17 (for example, it’s now a universal app, which should make IT departments’ lives easier), and it’s also getting support for &lt;a href="https://www.theverge.com/2021/6/7/22458628/apple-macos-12-monterey-features-updates-wwdc-2021"&gt;macOS Monterey&lt;/a&gt; — the virtualization software will be able to run on macOS 12 computers, as well as create virtual ones. &lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="1OSvCU"&gt;&lt;q&gt;If you’re someone who keeps a foot in both the Windows and Mac worlds, Parallels is worth a look&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt="A chart describing pricing and availability. Parallels Desktop 17 - $79.99 per year. Parallels Desktop 17 Perpetual license - $99.99. Parallels Desktop Pro or Business Edition: $99.99 per year. Upgrade from any previous version of Parallels Desktop to Desktop 17: $49.99. Upgrade from any previous version to Parallels Desktop Pro Edition: $49.99 per year." data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/F_NgUH730q0kbKcmh3nBILHUVeo=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22772698/Pricing_and_Availability_Parallels_Desktop_17.png"&gt;
      &lt;cite&gt;Image: Parallels&lt;/cite&gt;
      &lt;figcaption&gt;&lt;em&gt;Parallels has kept the pricing the same this year.&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;p id="NGmNGV"&gt;If you want the regular version of Parallels Desktop 17, you have the choice of getting a subscription for $79.99 a year, or a perpetual license for $99.99. If you had a perpetual license for a previous version of Parallels, you can upgrade to 17 for $49.99. There’s also Pro and Business editions that cost $99.99 a year. Parallels sells the software on its website, but before you plunk down any cash, it may be worth waiting until Windows 11 launches (&lt;a href="https://www.theverge.com/2021/6/28/22553666/microsoft-windows-11-october-20th-release-date-hint-rumor"&gt;potentially in October&lt;/a&gt;) to see how well it fares on Parallels — or if Windows 11 is even worth jumping to in the first place.&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/10/22617544/parallels-17-mac-windows-11-preview-emulation-performance-upgrades"/>
    <id>https://www.theverge.com/2021/8/10/22617544/parallels-17-mac-windows-11-preview-emulation-performance-upgrades</id>
    <author>
      <name>Mitchell Clark</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-09T17:09:00-04:00</published>
    <updated>2021-08-09T17:09:00-04:00</updated>
    <title>Apple keeps shutting down employee-run surveys on pay equity — and labor lawyers say it’s illegal</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/ePHQrieoO2mNGruhek063Lp3-RU=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69701173/acastro_210809_4703_0001.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;


  &lt;p&gt;The company bans surveys that include diversity data&lt;/p&gt; &lt;p class="p--has-dropcap p-large-text" id="auIHVh"&gt;Apple &lt;a href="https://www.apple.com/diversity/"&gt;insists&lt;/a&gt; it does not have a problem with pay inequality. Skeptical Apple employees have been trying to verify that claim by sending out informal surveys on how much people make, particularly as it relates to women and underrepresented minorities. But the company has shut down three of those surveys, citing stringent rules on how employees can collect data. Now, multiple labor lawyers tell &lt;em&gt;The Verge&lt;/em&gt; the company may be violating worker protections: the surveys can be considered a form of labor organizing — &lt;a href="https://www.nlrb.gov/about-nlrb/rights-we-protect/the-law/employees/concerted-activity"&gt;under US law&lt;/a&gt;, employees have the right to discuss pay. &lt;/p&gt;
&lt;p id="W7CVA1"&gt;“Apple cannot bar its employees from discussing pay equity as it relates to protected classes,” says Vincent P. White, a labor lawyer with White, Hilferty &amp;amp; Albanese. “If they were, they could tell people not to talk about pronouns. The logical outgrowth of that doesn’t even track. I view their effort to shut this down as an act of retaliation.”&lt;/p&gt;
&lt;p id="rsN1Lf"&gt;The first known survey began in the spring and asked people to volunteer salary information in addition to how they identify in terms of race, ethnicity, gender, and disability. After about 100 responses, Apple’s people team — the company’s name for what is commonly called human resources — asked employees to take the survey down, saying the demographic questions constituted personally identifying information, or PII.&lt;/p&gt;
&lt;p id="cQiVKd"&gt;Last week, employees tried to start another pay equity survey but were again told to take it down because it included a question on gender. When they created a new survey without the gender question, the Apple people team allegedly said it had to be shut down because it was hosted on the company’s corporate Box account.&lt;/p&gt;
&lt;p id="At1WUd"&gt;“This is like a 2021 version of a foreman on the docks telling people they can’t compare their wages way back in the 1800s,” says White. “This isn’t new. It’s just the newest version of ‘you can’t talk about your pay.’” &lt;/p&gt;
&lt;p id="bIIAhw"&gt;The people team also sent employees the following information on “prohibited surveys”:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p id="OXjvmq"&gt;&lt;strong&gt;Prohibited Surveys&lt;/strong&gt;&lt;br&gt;The following employee surveys are prohibited in all cases and may not be conducted.&lt;/p&gt;
&lt;p id="Oa604m"&gt;&lt;strong&gt;Surveys as Data Collection&lt;/strong&gt;&lt;/p&gt;
&lt;p id="JtT1LC"&gt;Surveys are not permitted to be used as a means of collecting identifiable employee data without following the usual process to obtain this data from the People team. This includes any questions about an employee’s address, demographics, and so on, except for collecting country or region, which is permitted.&lt;/p&gt;
&lt;p id="RQfYC6"&gt;Using surveys as a tool to collect health information — including but not limited to health reports, testing results, and vaccination status — is also prohibited.&lt;/p&gt;
&lt;p id="wQWnQK"&gt;All requests for identifiable employee data must be submitted to the People team via the People Report Request Form. If approved, the People team will provide the employee data directly from their systems.&lt;/p&gt;
&lt;p id="GcK28s"&gt;&lt;strong&gt;Surveys Requesting Diversity Data&lt;/strong&gt;&lt;br&gt;Diversity data is highly sensitive personal data. If you have a need for such information, you must work with your I&amp;amp;D Business Partner and the I&amp;amp;D Insights and Solutions team before collecting any data. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p id="jwlBUn"&gt;“Those rules may themselves violate the protected right to concerted activity — while [Apple] might point to these handbook type rules that you’ve agreed to not do this as a condition of employment, that doesn’t mean they can legally prevent employees from doing what they’re doing,” says Veena Dubal, a law professor at UC Hastings.&lt;/p&gt;
&lt;p id="mhGsbO"&gt;Now, Apple engineer Cher Scarlett has started a new survey on Typeform, which she is paying for out of pocket. “I was looking at levels.fyi (a website that lets people compare salary data across companies) and noticed a few very low salaries in a certain geographic area that were 10 to 15 percent lower compared to other people on the team,” Scarlett says. “Every time I looked at gender, they were women. I’m not going to say that’s a definitive issue, but it’s a prompt for anyone to ask if this is a widespread problem. We should be able to easily find out whether or not that’s the case so we can know whether people are truly being paid fairly.”&lt;/p&gt;
&lt;div id="Y2ANx0"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;Two pay transparency surveys have been shut down in the past 6 months at Apple. I won't be intimidated. We have the right to collect this data amongst ourselves.&lt;br&gt;&lt;br&gt;There's a new survey, voluntary and totally anonymous. &lt;br&gt;&lt;br&gt;The password is my status in Slack.&lt;a href="https://t.co/fUr1DZ5Df1"&gt;https://t.co/fUr1DZ5Df1&lt;/a&gt;&lt;/p&gt;— Cher Scarlett (@cherthedev) &lt;a href="https://twitter.com/cherthedev/status/1423918155185811460?ref_src=twsrc%5Etfw"&gt;August 7, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="9N3Xhw"&gt;The new survey, which has nearly 500 entries, asks employees to volunteer information on their salary, level, team, latest RSU grant, tenure at Apple, geographic location, signing bonus, relevant work experience, as well as whether they’re permanently remote, and a member of an underrepresented race or gender. &lt;/p&gt;
&lt;p id="o4b7VL"&gt;“We want our colleagues and industry peers to have the knowledge of Apple’s pay bands and to give minoritized employees and prospective employees the confidence to negotiate fair wages and bonuses,” the survey reads.&lt;/p&gt;
&lt;p id="GbIp9s"&gt;Grace Reckers, an organizer with the Office and Professional Employees International Union, says the fact that this information is all voluntary should protect employees. “This is protected activity — because you’re opting into the survey, I don’t even know how the PII excuse would work or matter.”&lt;/p&gt;
&lt;p id="YMUxCt"&gt;Scarlett says Apple’s response to the surveys has only made employees more suspicious: “I don’t think anyone is going into this saying there for sure is a wage gap, whether that’s gender or race or disability. But it is concerning to everyone that every single time someone tries to create more transparency, Apple shuts it down. It makes it feel like maybe there is a problem, and they’re already aware of it.”&lt;/p&gt;
&lt;p id="Nlg7KS"&gt;In 2018, Apple’s mean and median gender pay gap for employees in the UK was &lt;a href="https://www.apple.com/legal/more-resources/docs/uk-gender-pay-gap-report-2019.pdf"&gt;12 percent in favor of men&lt;/a&gt;. That’s 5 percentage points below the overall gender pay gap in the UK. The company has to publish this data under UK law, but it does not have the same requirements in the US. &lt;/p&gt;
&lt;p id="y32n17"&gt;Two years earlier, &lt;a href="https://www.nytimes.com/2016/02/27/technology/apple-shareholders-show-their-support-for-tim-cook.html"&gt;Apple CEO Tim Cook told investors&lt;/a&gt; that women at Apple made 99.6 cents for every dollar men made, while underrepresented minorities made 99.7 cents for every dollar white employees made. That same year, the company released a diversity report &lt;a href="https://www.theverge.com/2016/8/3/12371204/apple-diversity-report-pay-gap-hiring-equal-pay"&gt;saying it had fixed the problem&lt;/a&gt;. &lt;/p&gt;
&lt;p class="c-end-para" id="tUEk5i"&gt;Apple did not respond to a request for comment from &lt;em&gt;The Verge&lt;/em&gt;. &lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/9/22609687/apple-pay-equity-employee-surveys-protected-activity"/>
    <id>https://www.theverge.com/2021/8/9/22609687/apple-pay-equity-employee-surveys-protected-activity</id>
    <author>
      <name>Zoe Schiffer</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-09T06:49:08-04:00</published>
    <updated>2021-08-09T06:49:08-04:00</updated>
    <title>Apple pushes back against child abuse scanning concerns in new FAQ </title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/3UQv-Ep-FwzGk_VnzIk8s6KW_1M=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69698169/acastro_180604_1777_apple_wwdc_0002.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="ZGzBGm"&gt;In a &lt;a href="https://www.apple.com/child-safety/pdf/Expanded_Protections_for_Children_Frequently_Asked_Questions.pdf"&gt;new FAQ&lt;/a&gt;, Apple has attempted to assuage concerns that its new &lt;a href="https://www.theverge.com/2021/8/5/22611721/apple-csam-child-abuse-scanning-hash-system-ncmec"&gt;anti-child abuse measures&lt;/a&gt; could be turned into surveillance tools by authoritarian governments. “Let us be clear, this technology is limited to detecting CSAM [child sexual abuse material] stored in iCloud and we will not accede to any government’s request to expand it,” the company writes. &lt;/p&gt;
&lt;p id="XeChzT"&gt;Apple’s new tools, &lt;a href="https://www.theverge.com/2021/8/5/22611721/apple-csam-child-abuse-scanning-hash-system-ncmec"&gt;announced last Thursday&lt;/a&gt;, include two features designed to protect children. One, called “communication safety,” uses on-device machine learning to identify and blur sexually explicit images received by children in the Messages app, and can notify a parent if a child age 12 and younger decides to view or send such an image. The second is designed to detect known CSAM by scanning users’ images if they choose to upload them to iCloud. Apple is notified if CSAM is detected, and it will alert the authorities when it verifies such material exists.&lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="G0Hzjw"&gt;&lt;q&gt;“Apple’s CSAM detection capability is built solely to detect known CSAM images”&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="QqqbpC"&gt;The plans met with a swift backlash from digital &lt;a href="https://www.theverge.com/2021/8/6/22613365/apple-icloud-csam-scanning-whatsapp-surveillance-reactions"&gt;privacy groups and campaigners&lt;/a&gt;, who argued that these introduce a backdoor into Apple’s software. These groups note that once such a backdoor exists there is always the potential for it to be expanded to scan for types of content that go beyond child sexual abuse material. Authoritarian governments could use it to scan for politically dissent material, or anti-LGBT regimes could use it to crack down on sexual expression.&lt;/p&gt;
&lt;p id="1A2zHQ"&gt;“Even a thoroughly documented, carefully thought-out, and narrowly-scoped backdoor is still a backdoor,” the &lt;a href="https://www.eff.org/deeplinks/2021/08/apples-plan-think-different-about-encryption-opens-backdoor-your-private-life"&gt;Electronic Frontier Foundation wrote&lt;/a&gt;. “We’ve already seen this mission creep in action. One of the technologies originally built to scan and hash child sexual abuse imagery has been repurposed to create a database of ‘terrorist’ content that companies can contribute to and access for the purpose of banning such content.”&lt;/p&gt;
&lt;p id="ArY2kw"&gt;However, Apple argues that it has safeguards in place to stop its systems from being used to detect anything other than sexual abuse imagery. It says that its list of banned images is provided by the National Center for Missing and Exploited Children (NCMEC) and other child safety organizations, and that the system “only works with CSAM image hashes provided by NCMEC and other child safety organizations.” Apple says it won’t add to this list of image hashes, and that the list is the same across all iPhones and iPads to prevent individual targeting of users.&lt;/p&gt;
&lt;p id="e5ce9I"&gt;The company also says that it will refuse demands from governments to add non-CSAM images to the list. “We have faced demands to build and deploy government-mandated changes that degrade the privacy of users before, and have steadfastly refused those demands. We will continue to refuse them in the future,” it says. &lt;/p&gt;
&lt;p id="KkMQzE"&gt;It’s worth noting that despite Apple’s assurances, the company has made concessions to governments in the past in order to continue operating in their countries. It sells &lt;a href="https://support.apple.com/en-us/HT204170#:~:text=FaceTime%20isn%27t%20available%20or,iPod%20touch%20in%20Saudi%20Arabia.&amp;amp;text=Search%20for%20the%20FaceTime%20app%20in%20Spotlight%20or%20using%20Siri."&gt;iPhones without FaceTime&lt;/a&gt; in countries that don’t allow encrypted phone calls, and in China it’s removed &lt;a href="https://www.theverge.com/2020/8/18/21374246/apple-china-chinese-operations-restrictions"&gt;thousands of apps from its App Store&lt;/a&gt;, as well as moved to &lt;a href="https://www.theverge.com/2018/7/18/17587304/apple-icloud-china-user-data-state-run-telecom-privacy-security"&gt;store user data on the servers of a state-run telecom&lt;/a&gt;. &lt;/p&gt;
&lt;p id="c1f0jU"&gt;The FAQ also fails to address some concerns about the feature that scans Messages for sexually explicit material. The feature does not share any information with Apple or law enforcement, the company says, but it doesn’t say how it’s ensuring that the tool’s focus remains solely on sexually explicit images.&lt;/p&gt;
&lt;p id="RXy2yk"&gt;“All it would take to widen the narrow backdoor that Apple is building is an expansion of the machine learning parameters to look for additional types of content, or a tweak of the configuration flags to scan, not just children’s, but anyone’s accounts,” wrote the EFF. The EFF also notes that machine-learning technologies frequently classify this content incorrectly, and cites &lt;a href="https://www.eff.org/tossedout/tumblr-ban-adult-content"&gt;Tumblr’s attempts to crack down on sexual content&lt;/a&gt; as a prominent example of where the technology has gone wrong.&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/9/22616381/apple-child-sexual-abuse-material-scanning-icloud-faq-pushback-privacy"/>
    <id>https://www.theverge.com/2021/8/9/22616381/apple-child-sexual-abuse-material-scanning-icloud-faq-pushback-privacy</id>
    <author>
      <name>Jon Porter</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-07T15:55:22-04:00</published>
    <updated>2021-08-07T15:55:22-04:00</updated>
    <title>WhatsApp lead and other tech experts fire back at Apple’s Child Safety plan</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/TGtA_nWVkDJWCy43HTsdInDqf6Q=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69691082/acastro_170731_1777_0006_v4.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="ai81Iq"&gt;The chorus of voices expressing concern and dismay over &lt;a href="https://www.apple.com/child-safety/"&gt;Apple’s new Child Safety measures&lt;/a&gt; grew louder over the weekend, as an open letter with more than 4,000 signatures made the rounds online. &lt;a href="https://appleprivacyletter.com/"&gt;The Apple Privacy Letter&lt;/a&gt; asked the iPhone maker to “reconsider its technology rollout,” lest it undo “decades of work by technologists, academics and policy advocates” on privacy-preserving measures.&lt;/p&gt;
&lt;p id="UPWw1g"&gt;Apple’s plan, &lt;a href="https://www.theverge.com/2021/8/5/22611721/apple-csam-child-abuse-scanning-hash-system-ncmec"&gt;which it announced on Thursday&lt;/a&gt;, involves taking hashes of images uploaded to iCloud and comparing them to a database that contains hashes of known CSAM images. According to Apple, this allows it to keep user data encrypted and &lt;a href="https://twitter.com/reneritchie/status/1423726172849033216?s=20"&gt;run the analysis on-device&lt;/a&gt; while still allowing it to report users to the authorities if they’re found to be sharing child abuse imagery. Another prong of Apple’s Child Safety strategy involves optionally warning parents if their child &lt;a href="https://twitter.com/rsgnl/status/1423389211542032384"&gt;under 13 years old&lt;/a&gt; sends or views photos containing sexually explicit content. &lt;a href="https://www.theverge.com/2021/8/6/22612934/apple-vp-memo-concerns-privacy-new-scanning-photos-images-ios"&gt;An internal memo at Apple&lt;/a&gt; acknowledged that people would be “worried about the implications” of the systems.&lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="1dseaO"&gt;&lt;q&gt;Cathcart calls Apple’s approach “very concerning,” and he’s not alone&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="yIGcHp"&gt;&lt;a href="https://twitter.com/wcathcart/status/1423701473624395784?s=20"&gt;WhatsApp’s head Will Cathcart&lt;/a&gt; said in a Twitter thread that his company wouldn’t be adopting the safety measures, &lt;a href="https://twitter.com/wcathcart/status/1423701476841385988?s=20"&gt;calling Apple’s approach&lt;/a&gt; “very concerning.” Cathcart said WhatsApp’s system to fight child exploitation, which partly utilizes user reports, preserves encryption like Apple’s and has led to the company &lt;a href="https://twitter.com/wcathcart/status/1423701475595755524?s=20"&gt;reporting over 400,000 cases&lt;/a&gt; to the National Center for Missing and Exploited Children in 2020. (Apple is also working with the Center for its CSAM detection efforts.)&lt;/p&gt;
&lt;p id="iuhKXJ"&gt;WhatsApp’s owner, Facebook, has reasons to pounce on Apple for privacy concerns. Apple’s &lt;a href="https://www.theverge.com/2021/4/27/22405474/apple-app-tracking-transparency-ios-14-5-privacy-update-facebook-data"&gt;changes to how ad tracking works in iOS 14.5&lt;/a&gt; started a fight between the two companies, with Facebook &lt;a href="https://www.theverge.com/2020/12/16/22178068/facebook-apple-newspaper-ads-ios-privacy-changes"&gt;buying newspaper ads&lt;/a&gt; criticizing Apple’s privacy changes as harmful to small businesses. &lt;a href="https://www.theverge.com/2020/12/16/22179721/apple-defends-upcoming-privacy-changes-standing-up-for-users-facebook-data"&gt;Apple fired back&lt;/a&gt;, saying that the change “simply requires” that users be given a choice on whether to be tracked.&lt;/p&gt;
&lt;p id="7HaVEp"&gt;The list of people and organizations raising concerns about Apple’s policy includes Edward Snowden, the Electronic Frontier Foundation, professors, and more. We’ve collected some of those reactions here to act as an overview of some of the criticisms levied against Apple’s new policy.&lt;/p&gt;
&lt;hr class="p-entry-hr" id="TJSuYM"&gt;
&lt;p id="ZZcaWR"&gt;Matthew Green, an associate professor at Johns Hopkins University, pushed back on the feature before it was publicly announced. He tweeted about Apple’s plans and about how the hashing system could be abused by governments and malicious actors.&lt;/p&gt;
&lt;div id="My9zJN"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;These tools will allow Apple to scan your iPhone photos for photos that match a specific perceptual hash, and report them to Apple servers if too many appear.&lt;/p&gt;— Matthew Green (@matthew_d_green) &lt;a href="https://twitter.com/matthew_d_green/status/1423072476888805376?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="AKpR2F"&gt;The EFF &lt;a href="https://www.eff.org/deeplinks/2021/08/apples-plan-think-different-about-encryption-opens-backdoor-your-private-life"&gt;released a statement&lt;/a&gt; that blasted Apple’s plan, more or less calling it a “thoroughly documented, carefully thought-out, and narrowly-scoped backdoor.” The EFF’s press release goes into detail on how it believes Apple’s Child Safety measures could be abused by governments and how they decrease user privacy.&lt;/p&gt;
&lt;div id="jacoNW"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;Apple's filtering of iMessage and iCloud is not a slippery slope to backdoors that suppress speech and make our communications less secure. We’re already there: this is a fully-built system just waiting for external pressure to make the slightest change. &lt;a href="https://t.co/f2nv062t2n"&gt;https://t.co/f2nv062t2n&lt;/a&gt;&lt;/p&gt;— EFF (@EFF) &lt;a href="https://twitter.com/EFF/status/1423375818693038084?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="Yuo1qD"&gt;Kendra Albert, an instructor at Harvard’s Cyberlaw Clinic, has a thread on the potential dangers to queer children and Apple’s initial lack of clarity around age ranges for the parental notifications feature.&lt;/p&gt;
&lt;div id="6bBV1n"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;The idea that parents are safe people for teens to have conversations about sex or sexting with is admirable, but in many cases, not true. (And as far as I can tell, this stuff doesn't just apply to kids under the age for 13.)&lt;/p&gt;— Kendra Albert (@KendraSerra) &lt;a href="https://twitter.com/KendraSerra/status/1423367106972852228?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id="p5xtGT"&gt;
&lt;blockquote class="twitter-tweet" data-conversation="none"&gt;
&lt;p lang="en" dir="ltr"&gt;EFF reports that the iMessage nudity notifications will not go to parents if the kid is between 13-17 but that is not anywhere in the Apple documentation that I can find. &lt;a href="https://t.co/Ma1BdyqZfW"&gt;https://t.co/Ma1BdyqZfW&lt;/a&gt;&lt;/p&gt;— Kendra Albert (@KendraSerra) &lt;a href="https://twitter.com/KendraSerra/status/1423436593696854018?ref_src=twsrc%5Etfw"&gt;August 6, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="CEqw4k"&gt;Edward Snowden retweeted the &lt;em&gt;Financial Time&lt;/em&gt;s article about the system, giving his own characterization of what Apple is doing.&lt;/p&gt;
&lt;div id="CCaMt8"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;Apple plans to modify iPhones to constantly scan for contraband: &lt;br&gt;&lt;br&gt;“It is an absolutely appalling idea, because it is going to lead to distributed bulk surveillance of our phones and laptops,” said Ross Anderson, professor of security engineering. &lt;a href="https://t.co/rS92HR3pUZ"&gt;https://t.co/rS92HR3pUZ&lt;/a&gt;&lt;/p&gt;— Edward Snowden (@Snowden) &lt;a href="https://twitter.com/Snowden/status/1423387232963022848?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="sceSPL"&gt;Politician Brianna Wu called the system “the worst idea in Apple History.”&lt;/p&gt;
&lt;div id="wB779u"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;This is the worst idea in Apple history, and I don't say that lightly.&lt;br&gt;&lt;br&gt;It destroys their credibility on privacy. It will be abused by governments. It will get gay children killed and disowned. This is the worst idea ever. &lt;a href="https://t.co/M2EIn2jUK2"&gt;https://t.co/M2EIn2jUK2&lt;/a&gt;&lt;/p&gt;— Brianna Wu (@BriannaWu) &lt;a href="https://twitter.com/BriannaWu/status/1423384759858774026?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id="H0QULK"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;Just to state: Apple's scanning does not detect photos of child abuse. It detects a list of known banned images added to a database, which are initially child abuse imagery found circulating elsewhere. What images are added over time is arbitrary. It doesn't know what a child is.&lt;/p&gt;— SoS (@SwiftOnSecurity) &lt;a href="https://twitter.com/SwiftOnSecurity/status/1423383256003747840?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="r1g6Co"&gt;Writer Matt Blaze also tweeted about the concerns that the technology could be abused by overreaching governments, trying to prevent content other than CSAM.&lt;/p&gt;
&lt;div id="PouZDU"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;In other words, not only does the policy have to be exceptionally robust, so does the implementation.&lt;/p&gt;— matt blaze (@mattblaze) &lt;a href="https://twitter.com/mattblaze/status/1423476875817635840?ref_src=twsrc%5Etfw"&gt;August 6, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="rvN3WU"&gt;Epic CEO Tim Sweeney also criticized Apple, saying that the company “vacuums up everybody’s data into iCloud by default.” He also promised to share more thoughts specifically about Apple’s Child Safety system.&lt;/p&gt;
&lt;div id="wfglq3"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;It’s atrocious how Apple vacuums up everybody’s data into iCloud by default, hides the 15+ separate options to turn parts of it off in Settings underneath your name, and forces you to have an unwanted email account. Apple would NEVER allow a third party to ship an app like this.&lt;/p&gt;— Tim Sweeney (@TimSweeneyEpic) &lt;a href="https://twitter.com/TimSweeneyEpic/status/1423728945225211908?ref_src=twsrc%5Etfw"&gt;August 6, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id="kuuOuE"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;I will share some very detailed thoughts on this related topic later.&lt;/p&gt;— Tim Sweeney (@TimSweeneyEpic) &lt;a href="https://twitter.com/TimSweeneyEpic/status/1423730378234376206?ref_src=twsrc%5Etfw"&gt;August 6, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="7YCGmI"&gt;Not every reaction has been critical, however. Ashton Kutcher (who has done &lt;a href="https://thecnnfreedomproject.blogs.cnn.com/2011/04/14/moore-kutcher-join-our-crusade-to-end-child-sex-trafficking/"&gt;advocacy work to end child sex trafficking since 2011&lt;/a&gt;) calls Apple’s work “a major step forward” for efforts to eliminate CSAM.&lt;/p&gt;
&lt;div id="SFDxLg"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;I believe in privacy - including for kids whose sexual abuse is documented and spread online without consent. These efforts announced by &lt;a href="https://twitter.com/Apple?ref_src=twsrc%5Etfw"&gt;@Apple&lt;/a&gt; are a major step forward in the fight to eliminate CSAM from the internet. &lt;a href="https://t.co/TQIxHlu4EX"&gt;https://t.co/TQIxHlu4EX&lt;/a&gt;&lt;/p&gt;— ashton kutcher (@aplusk) &lt;a href="https://twitter.com/aplusk/status/1423387418451922950?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/6/22613365/apple-icloud-csam-scanning-whatsapp-surveillance-reactions"/>
    <id>https://www.theverge.com/2021/8/6/22613365/apple-icloud-csam-scanning-whatsapp-surveillance-reactions</id>
    <author>
      <name>Mitchell Clark</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-06T18:47:42-04:00</published>
    <updated>2021-08-06T18:47:42-04:00</updated>
    <title>Spotify says it plans to add AirPlay 2 to its iOS app — eventually</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/DDD20yR_WaPMtNUO2rsOrGSinnc=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69690480/acastro_180213_1777_0004.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="qolgag"&gt;Spotify still hasn’t added AirPlay 2 support to its iOS app — but despite the delay, it’s still “working to make [it] a reality,” the company tells &lt;em&gt;The Verge&lt;/em&gt;. Some doubt was cast on AirPlay 2 inclusion when &lt;a href="https://www.macrumors.com/2021/08/06/spotify-pauses-airplay-2-support-for-ios-app/"&gt;&lt;em&gt;MacRumors&lt;/em&gt; spotted a forum post&lt;/a&gt; where a Spotify forum moderator claimed that &lt;a href="https://community.spotify.com/t5/Closed-Ideas/iOS-Airplay-2-Support-for-iOS/idc-p/5244350/highlight/true#M235171"&gt;“audio driver compatibility issues”&lt;/a&gt; might mean the feature wouldn’t be added for the foreseeable future. Spotify now claims that’s wrong.&lt;/p&gt;
&lt;p id="lIlb4R"&gt;&lt;em&gt;The Verge&lt;/em&gt; received the following statement from Spotify regarding AirPlay 2:&lt;/p&gt;
&lt;blockquote&gt;&lt;p id="l6Ose4"&gt;A post on one of Spotify’s Community pages contained incomplete information regarding our plans for AirPlay2. Spotify will support AirPlay2 and we’re working to make that a reality.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p id="5hM8lP"&gt;AirPlay 2, &lt;a href="https://www.theverge.com/2018/5/29/17403684/airplay-2-ios-114-stereo-homepod-available-now"&gt;added as part of iOS 11 update&lt;/a&gt;, introduced multiroom audio, Siri voice control, and fairly broad support across a wide swath of speakers, &lt;a href="https://www.theverge.com/2019/1/8/18173637/tv-airplay-2-apple-lg-samsung-sony-vizio-ces-2019"&gt;televisions&lt;/a&gt;, and streaming services. It was a real first for Apple’s “casting” feature, which had previously been somewhat poorly supported outside of Apple’s own devices. &lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="BIY2Ct"&gt;&lt;q&gt;I’m not going to call it petty, but...&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="w59IH1"&gt;Spotify has its own way to get audio from its service to other devices in the form of &lt;a href="https://www.spotify.com/us/connect/"&gt;Spotify Connect&lt;/a&gt;, but considering Spotify already supports Google Cast, skipping Apple’s newest streaming protocol would seem like an odd omission. As &lt;em&gt;MacRumors&lt;/em&gt; notes, Apple provides a seemingly simple &lt;a href="https://developer.apple.com/documentation/avfoundation/media_playback_and_selection/getting_airplay_2_into_your_app"&gt;four step developer document&lt;/a&gt; explaining how to enable the feature. However, &lt;a href="https://twitter.com/marcoarment/status/1423744958541058052?s=20"&gt;developer Marco Arment points&lt;/a&gt; out that the fourth step (adopting a new API that supports enhanced buffering) is a bigger hurdle than it appears. &lt;/p&gt;
&lt;div id="BhtYf6"&gt;
&lt;blockquote class="twitter-tweet" data-conversation="none"&gt;
&lt;p lang="en" dir="ltr"&gt;…and that new API:&lt;br&gt;&lt;br&gt;- is barely documented&lt;br&gt;&lt;br&gt;- has no public sample code&lt;br&gt;&lt;br&gt;- is full of major gotchas&lt;br&gt;&lt;br&gt;- can’t change speeds seamlessly&lt;br&gt;&lt;br&gt;- doesn’t provide precise timing&lt;br&gt;&lt;br&gt;- requires much more complex logic&lt;br&gt;&lt;br&gt;- is less efficient, which can cause background CPU-overage terminations&lt;/p&gt;— Marco Arment (@marcoarment) &lt;a href="https://twitter.com/marcoarment/status/1423744958541058052?ref_src=twsrc%5Etfw"&gt;August 6, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="d6ALoR"&gt;But add in that Spotify has a less-than-friendly relationship with Apple, even going as far as &lt;a href="https://www.theverge.com/2019/3/13/18263453/spotify-apple-app-store-antitrust-complaint-ec-30-percent-cut-unfair"&gt;filing an antitrust complaint&lt;/a&gt; and &lt;a href="https://www.theverge.com/22457400/spotify-horacio-gutierrez-apple-app-store-interview-decoder"&gt;publicly calling it a bully&lt;/a&gt;, and a choice to not prioritize incorporating AirPlay 2 makes even more sense. It’s good that it’s still happening, but for any Spotify subscriber on iOS, it’s hard to not feel like you’re caught in the crossfire between two tech giants on the outs. &lt;/p&gt;
&lt;p id="XlsirN"&gt;&lt;em&gt;&lt;strong&gt;Update August 6th, 6:47PM ET:&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt; &lt;/strong&gt;&lt;em&gt;Changed headline and added statement from Spotify confirming it is working on AirPlay2 support.&lt;/em&gt;&lt;/p&gt;
&lt;p id="2tmCRK"&gt;&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/6/22613420/spotify-airplay2-support-audio-issues-drivers"/>
    <id>https://www.theverge.com/2021/8/6/22613420/spotify-airplay2-support-audio-issues-drivers</id>
    <author>
      <name>Ian Carlos Campbell</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-06T12:01:35-04:00</published>
    <updated>2021-08-06T12:01:35-04:00</updated>
    <title>Apple VP acknowledges concerns about new scanning feature in internal memo</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/VSGhQl7q43Qpftf2KZ6WSgH_o0I=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69688995/acstro_190902_apple_event_0004.0.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="OrjUON"&gt;Apple’s &lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.apple.com%2Fchild-safety%2F&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F2021%2F8%2F6%2F22612934%2Fapple-vp-memo-concerns-privacy-new-scanning-photos-images-ios" rel="sponsored nofollow noopener" target="_blank"&gt;forthcoming feature&lt;/a&gt; that will scan iOS devices for images of child abuse is an “important mission,” a software vice president at the company wrote in an internal memo. First reported by&lt;a href="https://9to5mac.com/2021/08/06/apple-internal-memo-icloud-photo-scanning-concerns/"&gt; &lt;em&gt;9to5 Mac&lt;/em&gt;&lt;/a&gt;, the memo by Sebastian Marineau-Mes acknowledges that the new protections have some people “worried about the implications” but that the company will “maintain Apple’s deep commitment to user privacy.”&lt;/p&gt;
&lt;p id="8Ig9yv"&gt;As part of its Expanded Protections for Children, &lt;a href="https://www.theverge.com/2021/8/5/22611721/apple-csam-child-abuse-scanning-hash-system-ncmec"&gt;Apple plans to scan images&lt;/a&gt; on iPhones and other devices before they are uploaded to iCloud. If it finds an image that matches one in the database of the National Center for Missing and Exploited Children (NCMEC), a human at Apple will review the image to confirm whether it contains child pornography. If it’s confirmed, NCMEC will be notified and the user’s account will be disabled. &lt;/p&gt;
&lt;p id="3HB3oD"&gt;The announcement raised concerns among privacy advocates who questioned how Apple could prevent the system from being exploited by bad actors. The Electronic Frontier Foundation &lt;a href="https://www.eff.org/deeplinks/2021/08/apples-plan-think-different-about-encryption-opens-backdoor-your-private-life"&gt;said in a statement&lt;/a&gt; that “it’s impossible to build a client-side scanning system that can only be used for sexually explicit images sent or received by children” and that the system, however well-intended, “will break key promises of the messenger’s encryption itself and open the door to broader abuses.”&lt;/p&gt;
&lt;p id="7BFvDx"&gt;According to &lt;em&gt;9to5Mac&lt;/em&gt;, Marineau-Mes wrote in the memo that the project involved “deep cross-functional commitment” across the company that “delivers tools to protect children, but also maintain Apple’s deep commitment to user privacy.”&lt;/p&gt;
&lt;p id="uGfQad"&gt;Apple did not immediately reply to a request for comment Friday.&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/6/22612934/apple-vp-memo-concerns-privacy-new-scanning-photos-images-ios"/>
    <id>https://www.theverge.com/2021/8/6/22612934/apple-vp-memo-concerns-privacy-new-scanning-photos-images-ios</id>
    <author>
      <name>Kim Lyons</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-05T17:59:34-04:00</published>
    <updated>2021-08-05T17:59:34-04:00</updated>
    <title>IMDb TV app finally arrives on iOS and Android</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/YWBqDDedP4ZmG3dxwZYKciScfbY=/0x157:947x788/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69685791/iOS_Image.0.jpg" /&gt;
        &lt;figcaption&gt;Image: IMDb TV&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="jKRoK9"&gt;Amazon’s free streaming service IMDb TV now has its own dedicated app for the iPhone, iPad, and Android after launching on other major platforms earlier this year. &lt;/p&gt;
&lt;p id="43jTsV"&gt;IMDb TV is a dedicated hub for free, ad-supported movies and series as well as its own dedicated originals produced by Amazon Studios. Previously, you could find IMDb TV’s content slate in the primary IMDb app, but a standalone streaming app for the service was not available for iOS and Android. A spokesperson told &lt;em&gt;The Verge&lt;/em&gt; the content is still available to stream through IMDb, but the new IMDb TV app was “designed for the streaming experience.”&lt;/p&gt;
&lt;p id="4C2Opp"&gt;IMDb TV’s content slate is quite good, even if its originals have struggled to make as much of a splash as titles from larger premium services. But if you don’t mind ads, there’s a ton of great stuff to stream for free on the service, including documentaries, sci-fi titles, dramas, and plenty of TV to binge. &lt;em&gt;Mad Men&lt;/em&gt;, &lt;em&gt;How to Train Your Dragon&lt;/em&gt;, &lt;em&gt;Schitt’s Creek&lt;/em&gt;, and &lt;em&gt;Lost&lt;/em&gt; are all currently streamable on the service. &lt;/p&gt;
&lt;p id="RxmqnT"&gt;Plus, through a recently announced deal with Universal, IMDb TV will also &lt;a href="https://www.theverge.com/2021/7/9/22570590/universal-films-prime-video-streaming-peacock"&gt;exclusively stream&lt;/a&gt; some live-action and animated titles from the studio following their release in theaters and a brief pay-one premiere on Peacock.&lt;/p&gt;
&lt;p id="gEuOWw"&gt;The app was previously made available on the majority of major streaming devices and some smart TVs, including Fire TV, Roku, Xbox, Android TV, Android TV OS devices, newer LG Smart TVs, PlayStation 4, Chromecast with Google TV, and Nvidia Shield. It’s also available as a free channel within the Prime Video experience.&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/5/22611993/imdb-tv-mobile-app-ios-ipad-android"/>
    <id>https://www.theverge.com/2021/8/5/22611993/imdb-tv-mobile-app-ios-ipad-android</id>
    <author>
      <name>Catie Keck</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-05T16:02:58-04:00</published>
    <updated>2021-08-05T16:02:58-04:00</updated>
    <title>Apple reveals new efforts to fight child abuse imagery</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/gok31hxdir1iv9lGvMHre9icNaQ=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69685176/acastro_180130_1777_0005_v2.0.jpg" /&gt;
        &lt;figcaption&gt;Illustration by Alex Castro / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="ijVtvE"&gt;In a briefing on Thursday afternoon, Apple confirmed &lt;a href="https://www.theverge.com/2021/8/5/22611305/apple-scan-photos-iphones-icloud-child-abuse-imagery-neuralmatch"&gt;previously reported plans&lt;/a&gt; to deploy new technology within iOS, macOS, watchOS, and iMessage that will detect potential child abuse imagery, but clarified crucial details from the ongoing project. For devices in the US, new versions of iOS and iPadOS rolling out this fall have “new applications of cryptography to help limit the spread of CSAM [child sexual abuse material] online, while designing for user privacy.” &lt;/p&gt;
&lt;p id="wVAAte"&gt;The project is also detailed in &lt;a href="https://www.apple.com/child-safety/"&gt;a new “Child Safety” page on Apple’s website&lt;/a&gt;. The most invasive and potentially controversial implementation is the system that performs on-device scanning before an image is backed up in iCloud. From the description, scanning does not occur until a file is getting backed up to iCloud, and Apple only receives data about a match if the cryptographic vouchers (uploaded to iCloud along with the image) for a particular account meet a threshold of matching known CSAM.&lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="s7c9Mt"&gt;&lt;q&gt;Apple described several restrictions that are included to protect privacy&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="MWQ3zI"&gt;For years, Apple has used hash systems to scan for child abuse imagery sent over email, in line with similar systems at Gmail and other cloud email providers. The program announced today will apply the same scans to user images stored in iCloud Photos, even if the images are never sent to another user or otherwise shared.&lt;/p&gt;
&lt;p id="TVFdM5"&gt;In a &lt;a href="https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf"&gt;PDF&lt;/a&gt; provided along with the briefing, Apple justified its moves for image scanning by describing several restrictions that are included to protect privacy:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p id="SWQhU3"&gt;Apple does not learn anything about images that do not match the known CSAM&lt;/p&gt;
&lt;p id="mnepX8"&gt;database.&lt;/p&gt;
&lt;p id="eyjJWd"&gt;Apple can’t access metadata or visual derivatives for matched CSAM images until a&lt;/p&gt;
&lt;p id="eFPm9k"&gt;threshold of matches is exceeded for an iCloud Photos account.&lt;/p&gt;
&lt;p id="8hlnFE"&gt;The risk of the system incorrectly flagging an account is extremely low. In addition,&lt;/p&gt;
&lt;p id="YWYbmK"&gt;Apple manually reviews all reports made to NCMEC to ensure reporting accuracy.&lt;/p&gt;
&lt;p id="o7XIpC"&gt;Users can’t access or view the database of known CSAM images.&lt;/p&gt;
&lt;p id="kNtzsj"&gt;Users can’t identify which images were flagged as CSAM by the system&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p id="xsxTtI"&gt;The new details build on concerns leaked earlier this week, but also add a number of safeguards that should guard against the privacy risks of such a system. In particular, the threshold system ensures that lone errors will not generate alerts, allowing apple to target an error rate of one false alert per trillion users per year. The hashing system is also limited to material flagged by the National Center for Missing and Exploited Children (NCMEC), and images uploaded to iCloud Photos. Once an alert is generated, it is reviewed by Apple and NCMEC before alerting law enforcement, providing an additional safeguard against the system being used to detect non-CSAM content.&lt;/p&gt;
&lt;p id="E5RQd2"&gt;Apple commissioned technical assessments of the system from three independent cryptographers (&lt;a href="https://www.apple.com/child-safety/pdf/Technical_Assessment_of_CSAM_Detection_Benny_Pinkas.pdf"&gt;PDFs 1&lt;/a&gt;, &lt;a href="https://www.apple.com/child-safety/pdf/Technical_Assessment_of_CSAM_Detection_David_Forsyth.pdf"&gt;2&lt;/a&gt;, and &lt;a href="https://www.apple.com/child-safety/pdf/Technical_Assessment_of_CSAM_Detection_Mihir_Bellare.pdf"&gt;3&lt;/a&gt;), who found it to be mathematically robust. “In my judgement this system will likely significantly increase the likelihood that people who own or traffic in such pictures (harmful users) are found; this should help protect children,” said professor David Forsyth, chair of computer science at University of Illinois, in &lt;a href="https://www.apple.com/child-safety/pdf/Technical_Assessment_of_CSAM_Detection_David_Forsyth.pdf"&gt;one of the assessments&lt;/a&gt;. “The accuracy of the matching system, combined with the threshold, makes it very unlikely that pictures that are not known CSAM pictures will be revealed.”&lt;/p&gt;
&lt;p id="DNvsmU"&gt;However, Apple said other child safety groups were likely to be added as hash sources as the program expands, and the company did not commit to making the list of partners publicly available going forward. That is likely to heighten anxieties about how the system might be exploited by the Chinese government, which has long sought greater access to iPhone user data within the country.&lt;/p&gt;
&lt;p id="iVILkJ"&gt;&lt;/p&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt="Sample Messages warning for children and parents when sexually explicit photos are detected" data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/YMgiqX4ORjTh6vSUvHOAFrLTHr8=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22764418/child_safety__evd7tla79kqe_large.jpg"&gt;
      &lt;cite&gt;Photo: Apple&lt;/cite&gt;
      &lt;figcaption&gt;&lt;em&gt;Sample Messages warning for children and parents when sexually explicit photos are detected.&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;p id="erd5tl"&gt;Alongside the new measures in iCloud Photos, Apple added two additional systems to protect young iPhone owners at risk of child abuse. The Messages app already did on-device scanning of image attachments for children’s accounts to detect content that’s potentially sexually explicit. Once detected, the content is blurred and a warning appears. A new setting that parents can enable on their family iCloud accounts will trigger a message telling the child that if they view (incoming) or send (outgoing) the detected image, their parents will get a message about it.&lt;/p&gt;
&lt;p id="obkAvI"&gt;Apple is also updating how Siri and the Search app respond to queries about child abuse imagery. Under the new system, the apps “will explain to users that interest in this topic is harmful and problematic, and provide resources from partners to get help with this issue.”&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/5/22611721/apple-csam-child-abuse-scanning-hash-system-ncmec"/>
    <id>https://www.theverge.com/2021/8/5/22611721/apple-csam-child-abuse-scanning-hash-system-ncmec</id>
    <author>
      <name>Russell Brandom</name>
      <name>Richard Lawler</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-05T12:55:26-04:00</published>
    <updated>2021-08-05T12:55:26-04:00</updated>
    <title>Apple will scan photos stored on iPhones and iCloud for child abuse imagery</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="The iPhone 12, in blue." src="https://cdn.vox-cdn.com/thumbor/KsFKmmiIIY2DKiRyCwL_H-zqdNk=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69683696/vpavic_4243_20201018_0121.0.0.jpg" /&gt;
        &lt;figcaption&gt;Photo by Vjeran Pavic / The Verge&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="Eo4wHZ"&gt;&lt;em&gt;&lt;strong&gt;Update August 5th, 3:21PM ET:&lt;/strong&gt;&lt;/em&gt;&lt;em&gt; Apple has announced more about what the &lt;/em&gt;Financial Times&lt;em&gt; reported and revealed new tools coming to iMessage that warn children about sexually explicit photos. The new features will be coming later this year as updates to iOS 15, iPadOS 15, watchOS 8, and macOS Monterey. You can read &lt;/em&gt;&lt;a href="https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.apple.com%2Fchild-safety%2F&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F2021%2F8%2F5%2F22611305%2Fapple-scan-photos-iphones-icloud-child-abuse-imagery-neuralmatch" rel="sponsored nofollow noopener" target="_blank"&gt;&lt;em&gt;more about them on Apple’s website&lt;/em&gt;&lt;/a&gt;&lt;em&gt;. Our original article follows.&lt;/em&gt;&lt;/p&gt;
&lt;hr class="p-entry-hr" id="1GNi4O"&gt;
&lt;p id="yUDRuC"&gt;Apple plans to scan photos stored on iPhones and iCloud for child abuse imagery, &lt;a href="https://www.ft.com/content/14440f81-d405-452f-97e2-a81458f5411f?accessToken=zwAAAXsXFw3Akc8URA-B1AVFL9OX4qgUWPVBHw.MEQCIAlL-dncQ3QfMOhh2uX_WQcMbz9dxjkEyYqIbvpX7pNnAiBPOFPraAkWgtfFk9Z_X3XiV5f1-mI4Mvos0mL8SCQqUg&amp;amp;sharetype=gift?token=076dc4a2-d758-4db8-8114-bc29b71cf72f"&gt;according the &lt;em&gt;Financial Times&lt;/em&gt;&lt;/a&gt;. The new system could help law enforcement in criminal investigations but may open the door to increased legal and government demands for user data.&lt;/p&gt;
&lt;p id="qCd5ME"&gt;The system, called neuralMatch, will “proactively alert a team of human reviewers if it believes illegal imagery is detected, who would then contact law enforcement if the material can be verified,” the &lt;em&gt;Financial Times&lt;/em&gt; said. neuralMatch, which was trained using 200,000 images from the National Center for Missing &amp;amp; Exploited Children, will roll out first in the US. Photos will be hashed and compared with a database of known images of child sexual abuse. &lt;/p&gt;
&lt;div class="c-float-right"&gt;&lt;aside id="pv6k39"&gt;&lt;q&gt;The system will be used first in the US&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id="VByGry"&gt;“According to people briefed on the plans, every photo uploaded to iCloud in the US will be given a ‘safety voucher,’ saying whether it is suspect or not,” the &lt;em&gt;Financial Times&lt;/em&gt; said. “Once a certain number of photos are marked as suspect, Apple will enable all the suspect photos to be decrypted and, if apparently illegal, passed on to the relevant authorities.”&lt;/p&gt;
&lt;p id="id__uo580rn63xk"&gt;John Hopkins University professor and cryptographer Matthew Green raised concerns about the system on Twitter Wednesday night. “This sort of tool can be a boon for finding child pornography in people’s phones,” &lt;a href="https://twitter.com/matthew_d_green/status/1423075906894106625"&gt;Green said&lt;/a&gt;. “But imagine what it could do in the hands of an authoritarian government?”&lt;/p&gt;
&lt;p id="XIfczG"&gt;“Even if you believe Apple won’t allow these tools to be misused [crossed fingers emoji] there’s still a lot to be concerned about,” &lt;a href="https://twitter.com/matthew_d_green/status/1423079067805495296"&gt;he added&lt;/a&gt;. “These systems rely on a database of ‘problematic media hashes’ that you, as a consumer, can’t review.”&lt;/p&gt;
&lt;p id="6eIhPA"&gt;Apple already checks iCloud files against known child abuse imagery, like every other major cloud provider. But the system described here would go further, allowing central access to local storage. It would also be trivial to extend the system to crimes other than child abuse — a particular concern given Apple’s extensive business in China.&lt;/p&gt;
&lt;p id="c8MhAK"&gt;The company informed some US academics about it this week, and Apple may share more about the system “as soon as this week,” according to two security researchers who were briefed on Apple’s earlier meeting, the &lt;em&gt;Financial Times&lt;/em&gt; reports.&lt;/p&gt;
&lt;p id="vurNuE"&gt;Apple has previously &lt;a href="https://www.theverge.com/2021/5/20/22446220/apple-privacy-ad-video-ad-tracking-transparency"&gt;touted&lt;/a&gt; the privacy protections built into its devices, and famously &lt;a href="https://www.theverge.com/2016/2/17/11036306/apple-fbi-iphone-encryption-backdoor-tim-cook"&gt;stood up to the FBI&lt;/a&gt; when the agency wanted Apple to build a backdoor into iOS to access an iPhone used by one of the shooters in the 2015 attack in San Bernardino. The company did not respond to a request for comment on the &lt;em&gt;Financial Times&lt;/em&gt; report.&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/5/22611305/apple-scan-photos-iphones-icloud-child-abuse-imagery-neuralmatch"/>
    <id>https://www.theverge.com/2021/8/5/22611305/apple-scan-photos-iphones-icloud-child-abuse-imagery-neuralmatch</id>
    <author>
      <name>Jay Peters</name>
    </author>
  </entry>
  <entry>
    <published>2021-08-05T12:28:04-04:00</published>
    <updated>2021-08-05T12:28:04-04:00</updated>
    <title>Here’s a closer look at Apple’s canceled AirPower wireless charger</title>
    <content type="html">  

    &lt;figure&gt;
      &lt;img alt="" src="https://cdn.vox-cdn.com/thumbor/QQOmG8rcOgnCV7MM-h483vOKNfg=/0x117:3696x2581/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/69683450/IMG_9512.0.jpeg" /&gt;
        &lt;figcaption&gt;A working Apple AirPower prototype unit. | Image: &lt;a class="ql-link" href="https://twitter.com/1nsane_dev" target="_blank"&gt;&lt;strong&gt;Giulio Zompetti&lt;/strong&gt;&lt;/a&gt;&lt;/figcaption&gt;
    &lt;/figure&gt;

  &lt;p id="tAI3fQ"&gt;Apple’s AirPower wireless charger was supposed to arrive with the unique ability to charge an iPhone, Apple Watch, and AirPods all at the same time. Unfortunately, &lt;a href="https://www.theverge.com/circuitbreaker/2019/3/29/18287383/apple-airpower-wireless-charger-cancelled"&gt;Apple canceled AirPower in March 2019&lt;/a&gt;, citing difficulties in bringing the product to life. Since then, we’ve seen a &lt;a href="https://9to5mac.com/2020/08/21/airpower-prototype-teardown-likely-shows-why-apple-never-shipped-the-wireless-charger/"&gt;teardown of AirPower&lt;/a&gt;, some &lt;a href="https://www.theverge.com/circuitbreaker/2020/1/3/21047896/zens-liberty-airpower-clone-16-coils-wireless-charging-pad-mat"&gt;AirPower clones&lt;/a&gt;, and Apple’s &lt;a href="https://www.theverge.com/2021/7/13/22576245/iphone-12-reverse-wireless-charging-magsafe-battery-pack"&gt;MagSafe battery packs&lt;/a&gt;. Now, an Apple prototype collector has obtained a working AirPower unit for the first time.&lt;/p&gt;
&lt;p id="tsrd3I"&gt;Speaking to &lt;em&gt;The Verge&lt;/em&gt;, Giulio Zompetti, a 28-year-old from Italy, says he has been able to purchase a prototype AirPower unit from Chinese e-waste sources. “The unit lacks all of its exterior housing, and shows this beautiful and heavy stainless steel chassis,” says Zompetti.&lt;/p&gt;
  &lt;figure class="e-image"&gt;
        &lt;img alt=" " data-mask-text="false" src="https://cdn.vox-cdn.com/thumbor/SReGJYMIH7HhoqSVyid8OhAZSYs=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/22763582/airpowerprototype.jpg"&gt;
      &lt;cite&gt;Image: &lt;a class="ql-link" href="https://twitter.com/1nsane_dev" target="_blank"&gt;&lt;strong&gt;Giulio Zompetti&lt;/strong&gt;&lt;/a&gt;&lt;/cite&gt;
      &lt;figcaption&gt;&lt;em&gt;The controller circuits on an AirPower prototype.&lt;/em&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;p id="5xgt0x"&gt;In photos supplied to &lt;em&gt;The Verge&lt;/em&gt;, you can see the AirPower mat powering a prototype iPhone, with its 22 coils on the front-facing side and 22 controller circuits on the rear. In order for this AirPower prototype to work, it has to be paired with special prototype iPhone hardware to activate the coils.&lt;/p&gt;
&lt;p id="rmfnSg"&gt;“It doesn’t work with production devices, because the coils are woken up by the device,” explains Zompetti, who says he’s been able to charge two prototype devices simultaneously so far. Zompetti says he received the unit in December and was able to interact with it initially through a serial lightning cable.&lt;/p&gt;
&lt;p id="smo4LO"&gt;“It’s an engineering prototype, it’s not meant for plug and play,” says Zompetti. “When I connected my serial lightning cable to it, I could see some chars on the log, so once I fixed the BAUD rate, I was able to read a comprehensible log.” There’s even an interactive shell to interact with the AirPower, as part of the engineering of the device.&lt;/p&gt;
&lt;div id="tFjSoS"&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p lang="en" dir="ltr"&gt;AirPower &lt;a href="https://t.co/bv8gi0NiiL"&gt;pic.twitter.com/bv8gi0NiiL&lt;/a&gt;&lt;/p&gt;— Giulio Zompetti (@1nsane_dev) &lt;a href="https://twitter.com/1nsane_dev/status/1423277245381054472?ref_src=twsrc%5Etfw"&gt;August 5, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p id="YaNDpV"&gt;Apple’s canceled AirPower pad was supposed to let you drop devices anywhere on it to charge thanks to multiple coils, without having to find that specific sweet spot. But various reports suggested &lt;a href="https://www.theverge.com/2018/9/17/17869072/apple-airpower-overheating-issues"&gt;Apple was struggling with overheating issues&lt;/a&gt; during development. “I wasn’t able to reproduce the issue but still can’t say it isn’t there,” says Zompetti.&lt;/p&gt;
&lt;p id="Vl6GFv"&gt;While we haven’t been able to independently verify the AirPower device as it’s extremely rare, Zompetti has a history of collecting Apple prototype hardware. He’s been collecting devices since March 2018, including a &lt;a href="https://www.vice.com/en/article/3a89w8/this-is-a-rare-prototype-of-the-first-apple-watch"&gt;rare prototype of the first Apple Watch&lt;/a&gt;. “It became my main passion since then to find the most good looking prototypes,” says Zompetti. He’s collected around 35 units so far, with a variety of rare iPhone and iPod prototypes in his collection.&lt;/p&gt;
&lt;p id="hwOLl0"&gt;This passion has seen Zompetti travel to engineers for help repairing old devices. “It’s almost always about finding broken or incomplete units and fixing them to bring them back to life” says Zompetti. An unreleased AirPower device is “definitely among the best” prototype hardware he’s found so far, he says.&lt;/p&gt;

</content>
    <link rel="alternate" type="text/html" href="https://www.theverge.com/2021/8/5/22611234/apple-airpower-wireless-charger-working-prototype"/>
    <id>https://www.theverge.com/2021/8/5/22611234/apple-airpower-wireless-charger-working-prototype</id>
    <author>
      <name>Tom Warren</name>
    </author>
  </entry>
</feed>
